pkg_name,first_release,title,description
gcite,2017-05-14,gcite: Google Citation Parser,Scrapes Google Citation pages and creates data frames of 
    citations over time.
EdSurvey,2017-04-26,EdSurvey: Analysis of NCES Education Survey and Assessment Data,Read in and analysis functions for education survey and assessment data from the National Center for Education Statistics (NCES) <https://nces.ed.gov/>, including National Assessment of Educational Progress (NAEP) data <https://nces.ed.gov/nationsreportcard/> and data from the International Assessment Database: OECD <http://www.oecd.org/>, including PISA, TALIS, PIAAC, and IEA <http://www.iea.nl/>, including TIMSS, TIMSS Advanced, PIRLS, ICCS, ICILS, and CivEd.
fdq,2016-11-12,fdq: Forest Data Quality,Forest data quality is a package that contains methods of 
    analysis of forest databases, the purpose of the analyzes is to evaluate 
    the quality of the data present in the databases focusing on the dimensions
    of consistency, pountuality and completeness. Databases can range from forest
    inventory data to growth model data. The package has methods to work with large 
    volumes of data quickly, in addition in certain analyzes it is possible to generate
    the graphs for a better understanding of the analysis and reporting of the analyzed analysis.
RBesT,2017-07-12,RBesT: R Bayesian Evidence Synthesis Tools,Tool-set to support Bayesian evidence synthesis.
    This includes meta-analysis, (robust) prior derivation
    from historical data, operating characteristics
    and analysis (1 and 2 sample cases).
recipes,2017-07-27,recipes: Preprocessing Tools to Create Design Matrices,An extensible framework to create and preprocess 
    design matrices. Recipes consist of one or more data manipulation 
    and analysis "steps". Statistical parameters for the steps can 
    be estimated from an initial data set and then applied to 
    other data sets. The resulting design matrices can then be used 
    as inputs into statistical or machine learning models. 
tensorflow,2017-03-22,tensorflow: R Interface to 'TensorFlow',Interface to 'TensorFlow' <https://www.tensorflow.org/>, 
  an open source software library for numerical computation using data
  flow graphs. Nodes in the graph represent mathematical operations, 
  while the graph edges represent the multidimensional data arrays 
  (tensors) communicated between them. The flexible architecture allows
  you to deploy computation to one or more 'CPUs' or 'GPUs' in a desktop, 
  server, or mobile device with a single 'API'. 'TensorFlow' was originally
  developed by researchers and engineers working on the Google Brain Team 
  within Google's Machine Intelligence research organization for the 
  purposes of conducting machine learning and deep neural networks research,
  but the system is general enough to be applicable in a wide variety
  of other domains as well.
BART,2017-04-07,BART: Bayesian Additive Regression Trees,Bayesian Additive Regression Trees (BART) provide flexible nonparametric modeling of covariates for continuous, binary, categorical and time-to-event outcomes.  For more information on BART, see Chipman, George and McCulloch (2010) <doi:10.1214/09-AOAS285> and Sparapani, Logan, McCulloch and Laud (2016) <doi:10.1002/sim.6893>.
cleanNLP,2016-11-11,cleanNLP: A Tidy Data Model for Natural Language Processing,Provides a set of fast tools for converting a textual corpus into a set of normalized
  tables. Users may make use of the 'udpipe' back end with no external dependencies, a Python back
  end with 'spaCy' <https://spacy.io> or the Java back end 'CoreNLP'
  <http://stanfordnlp.github.io/CoreNLP/>. Exposed annotation tasks include
  tokenization, part of speech tagging, named entity recognition, entity linking, sentiment
  analysis, dependency parsing, coreference resolution, and word embeddings. Summary
  statistics regarding token unigram, part of speech tag, and dependency type frequencies
  are also included to assist with analyses.
lvnet,2016-10-01,lvnet: Latent Variable Network Modeling,Estimate, fit and compare Structural Equation Models (SEM) and network models (Gaussian Graphical Models; GGM) using OpenMx. Allows for two possible generalizations to include GGMs in SEM: GGMs can be used between latent variables (latent network modeling; LNM) or between residuals (residual network modeling; RNM). For details, see Epskamp, Rhemtulla and Borsboom (2017) <doi:10.1007/s11336-017-9557-x>.
pinbasic,2016-10-25,pinbasic: Fast and Stable Estimation of the Probability of Informed
Trading (PIN),Utilities for fast and stable estimation of the probability of 
 informed trading (PIN) in the model introduced by Easley et al. (2002) 
 <doi:10.1111/1540-6261.00493> are implemented. Since the basic model developed 
 by Easley et al. (1996) <doi:10.1111/j.1540-6261.1996.tb04074.x> is nested in the 
 former due to equating the intensity of uninformed buys and sells, functions 
 can also be applied to this simpler model structure, if needed. 
 State-of-the-art factorization of the model likelihood function as well as 
 most recent algorithms for generating initial values for optimization routines are implemented. 
 In total, two likelihood factorizations and three methodologies for 
 starting values are included. 
 Furthermore, functions for simulating datasets of daily aggregated buys and sells, 
 calculating confidence intervals for the probability of informed trading and posterior probabilities 
 of trading days' conditions are available. 
RcppMsgPack,2017-06-12,RcppMsgPack: 'MsgPack' C++ Header Files and Interface Functions for R,'MsgPack' header files are provided for use by R packages, along 
 with the ability to access, create and alter 'MsgPack' objects directly from R.
 'MsgPack' is an efficient binary serialization format. It lets you exchange
 data among multiple languages like 'JSON' but it is faster and smaller.
 Small integers are encoded into a single byte, and typical short strings
 require only one extra byte in addition to the strings themselves. This
 package provides headers from the 'msgpack-c' implementation for C and
 C++(11) for use by R, particularly 'Rcpp'. The included 'msgpack-c' headers
 are licensed under the Boost Software License (Version 1.0); the code added
 by this package as well the R integration are licensed under the GPL (>= 2).
 See the files 'COPYRIGHTS' and 'AUTHORS' for a full list of  copyright holders
 and contributors to 'msgpack-c'.  
SpaDES.core,2017-08-30,SpaDES.core: Core Utilities for Developing and Running Spatially Explicit
Discrete Event Simulation Models,Provide the core discrete event simulation (DES) framework for
    implementing spatially explicit simulation models. The core DES components 
    facilitate modularity, and easily enable the user to include additional
    functionality by running user-built simulation modules.
valr,2016-11-21,valr: Genome Interval Arithmetic in R,Read and manipulate genome intervals and signals. Provides
             functionality similar to command-line tool suites within R,
             enabling interactive analysis and visualization of genome-scale data. 
ggeffects,2017-04-26,ggeffects: Create Tidy Data Frames of Marginal Effects for 'ggplot' from
Model Outputs,Compute marginal effects from statistical models and returns the 
    result as tidy data frames. These data frames are ready to use with the 
    'ggplot2'-package. Marginal effects can be calculated for many different 
    models. Interaction terms, splines and polynomial terms are also supported. 
    The two main functions are ggpredict() and ggeffect(). There is a generic 
    plot()-method to plot the results using 'ggplot2'.
wTO,2017-05-29,wTO: Computing Weighted Topological Overlaps (wTO) & Consensus wTO
Network,Computes the Weighted Topological Overlap with positive and negative signs (wTO) networks given a data frame containing the mRNA count/ expression/ abundance per sample, and a vector containing the interested nodes of interaction (a subset of the elements of the full data frame). It also computes the cut-off threshold or p-value based on the individuals bootstrap or the values reshuffle per individual. It also allows the construction of a consensus network, based on multiple wTO networks. The package includes a visualization tool for the networks.  More about the methodology can be found at <arXiv:1711.04702>.
ems,2017-04-26,ems: Epimed Solutions Collection for Data Editing, Analysis, and
Benchmark of Health Units,Collection of functions for data analysis and
    editing of clinical and epidemiological data.
    Most of them are related to benchmark with prediction models.
GENEAclassify,2017-08-30,GENEAclassify: Segmentation and Classification of Accelerometer Data,Segmentation and classification procedures for data from the 'Activinsights GENEActiv' <https://www.activinsights.com/products/geneactiv/> accelerometer that provides the user with a model to guess behaviour from test data where behaviour is missing.
    Includes a step counting algorithm, a function to create segmented data with custom features and a function to use recursive partitioning provided in the function rpart() of the 'rpart' package to create classification models.
jmv,2017-02-13,jmv: The 'jamovi' Analyses,A suite of common statistical methods such as descriptives,
    t-tests, ANOVAs, regression, correlation matrices, proportion tests,
    contingency tables, and factor analysis. This package is also useable from
    the 'jamovi' statistical spreadsheet (see <https://www.jamovi.org> for more
    information).
reproducible,2017-08-05,reproducible: A Set of Tools that Enhance Reproducibility Beyond Package
Management,Collection of high-level, robust, machine- and OS-independent tools
    for making deeply reproducible and reusable content in R.
    This includes light weight package management (similar to 'packrat' and
    'checkpoint', but more flexible, lightweight and simpler than both), tools
    for caching, downloading and verifying or writing checksums, post-processing 
    of common spatial datasets, and accessing GitHub repositories. 
    Some features are still under active development.
canvasXpress,2017-03-08,canvasXpress: Visualization Package for CanvasXpress in R,Enables creation of visualizations using the CanvasXpress framework
    in R. CanvasXpress is a standalone JavaScript library for reproducible research
    with complete tracking of data and end-user modifications stored in a single
    PNG image that can be played back. See <http://canvasxpress.org> for more
    information.
divest,2016-12-11,divest: Get Images Out of DICOM Format Quickly,Provides tools to sort DICOM-format medical image files, and
    convert them to NIfTI-1 format.
FRegSigCom,2017-09-06,FRegSigCom: Functional Regression using Signal Compression Approach,Signal compression methods for functional regression. It includes various function-on-function (FOF) regression models such as the linear FOF model with functional response and both scalar and functional predictors for a small number of functional predictors, linear FOF models with a large number of functional predictors, linear FOF model for spiky data, stepwise selection for FOF models with two-way interactions, and nonlinear FOF models. It also includes scalar-on-function regression models with single (SOF) or multivariate (mSOF) scalar response variable, and SOF model for spiky data. 
hommel,2017-05-17,hommel: Methods for Closed Testing with Simes Inequality, in Particular
Hommel's Method,Provides methods for closed testing using Simes local tests. In particular, calculates adjusted p-values for Hommel's multiple testing method, and provides lower confidence bounds for true discovery proportions. A robust but more conservative variant of the closed testing procedure that does not require the assumption of Simes inequality is also implemented. The methods have been described in detail in Meijer et al (2016) <arXiv:1611.06739>.
pkggraph,2017-06-02,pkggraph: A Consistent and Intuitive Platform to Explore the Dependencies
of Packages on the Comprehensive R Archive Network Like
Repositories,Interactively explore various dependencies of a package(s) (on the Comprehensive R Archive Network Like repositories) and perform analysis using tidy philosophy. Most of the functions return a 'tibble' object (enhancement of 'dataframe') which can be used for further analysis. The package offers functions to produce 'network' and 'igraph' dependency graphs. The 'plot' method produces a static plot based on 'ggnetwork' and 'plotd3' function produces an interactive D3 plot based on 'networkD3'.
POUMM,2017-03-11,POUMM: The Phylogenetic Ornstein-Uhlenbeck Mixed Model,The Phylogenetic Ornstein-Uhlenbeck Mixed Model (POUMM) allows to 
    estimate the phylogenetic heritability of continuous traits, to test 
    hypotheses of neutral evolution versus stabilizing selection, to quantify 
    the strength of stabilizing selection, to estimate measurement error and to
    make predictions about the evolution of a phenotype and phenotypic variation 
    in a population. The package implements combined maximum likelihood and 
    Bayesian inference of the univariate Phylogenetic Ornstein-Uhlenbeck Mixed 
    Model, fast parallel likelihood calculation, maximum likelihood 
    inference of the genotypic values at the tips, functions for summarizing and
    plotting traces and posterior samples, functions for simulation of a univariate 
    continuous trait evolution along a phylogenetic tree. For examples on using
    the package, see the package vignettes.
Rdimtools,2017-09-21,Rdimtools: Dimension Reduction and Estimation Methods,We provide linear and nonlinear dimension reduction techniques.
	Intrinsic dimension estimation methods for exploratory analysis are also provided.
    For more details on dimensionality techniques, see the paper by
    Ma and Zhu (2013) <doi:10.1111/j.1751-5823.2012.00182.x> if you are interested in
    statistical approach, or Engel, Huttenberger, and Hamann (2012)
    <doi:10.4230/OASIcs.VLUDS.2011.135> for a broader multi-disciplinary overview.
wrapr,2017-02-11,wrapr: Wrap R Tools for Debugging and Parametric Programming,Tools for writing and debugging R code. Provides: 
    'let()' 
    (converts non-standard evaluation interfaces to parametric standard
    evaluation interfaces, inspired by 'gtools:strmacro()' and 'base::bquote()'), 
    '%.>%' dot-pipe (an 'S3' configurable pipe),
    'build_frame()'/'draw_frame()' ('data.frame' example tools),
    'qc()' (quoting concatenate), 
    ':=' (named map builder),
    and more.
DescToolsAddIns,2017-04-19,DescToolsAddIns: Some Functions to be Used as Shortcuts in 'RStudio','RStudio' as of recently offers the option to define addins and assign shortcuts to them. This package contains addins for a few most frequently used functions in a data scientist's (at least mine) daily work (like str(), example(), plot(), head(), view(), Desc()). Most of these functions will use the current selection in the editor window and send the specific command to the console while instantly executing it. Assigning shortcuts to these addins will save you quite a few keystrokes.
giphyr,2017-03-22,giphyr: R Interface to the Giphy API,An interface to the 'API' of 'Giphy', a popular index-based search 
    engine for 'GIFs' and animated stickers (see <http://giphy.com/faq> and 
    <https://github.com/Giphy/GiphyAPI> for more information about 'Giphy' and 
    its 'API') . This package also provides a 'RStudio Addin', which can help 
    users easily search and download 'GIFs' and insert them to a 'rmarkdown' 
    presentation. 
GJRM,2017-07-14,GJRM: Generalised Joint Regression Modelling,Routines for fitting various joint (and univariate) regression models, with several types of covariate effects, in the presence of equations' errors association, endogeneity, non-random sample selection or partial observability.
LNIRT,2016-10-06,LNIRT: LogNormal Response Time Item Response Theory Models,Allows the simultaneous analysis of responses and response times in an Item Response Theory (IRT) modelling framework. Supports covariates for item and person (random) parameters. Parameter estimation is done with a MCMC algorithm. LNIRT replaces the package CIRT, which was written by Rinke Klein Entink. For reference, see the paper by Fox, Klein Entink and Van der Linden (2007), "Modeling of Responses and Response Times with the Package cirt", Journal of Statistical Software, <doi:10.18637/jss.v020.i07>.
mnreadR,2017-07-27,mnreadR: MNREAD Parameters Estimation and Curve Plotting,Allows to analyze the reading data obtained with the MNREAD Acuity 
    Chart, a continuous-text reading acuity chart for normal and low vision. 
    Provides the necessary functions to plot the MNREAD curve and estimate 
    automatically the four MNREAD parameters: Maximum Reading Speed, 
    Critical Print Size, Reading Acuity and Reading Accessibility Index.
    Parameters can be estimated either with the standard method 
    or with a nonlinear mixed-effects (NLME) modeling. 
    See Calabrese et al. 2018 for more details <doi.org/10.1167/18.1.8>.
palm,2017-01-30,palm: Fitting Point Process Models via the Palm Likelihood,Functions to fit point process models using the Palm likelihood. First proposed by Tanaka, Ogata, and Stoyan (2008) <doi:10.1002/bimj.200610339>, maximisation of the Palm likelihood can provide computationally efficient parameter estimation for point process models in situations where the full likelihood is intractable. This package is chiefly focused on Neyman-Scott point processes, but can also fit void processes. The development of this package was motivated by the analysis of capture-recapture surveys on which individuals cannot be identified—the data from which can conceptually be seen as a clustered point process. As such, some of the functions in this package are specifically for the estimation of cetacean density from two-camera aerial surveys.
personalized,2017-06-12,personalized: Estimation and Validation Methods for Subgroup Identification
and Personalized Medicine,Provides functions for fitting and validation of models for subgroup
    identification and personalized medicine / precision medicine under the general subgroup
    identification framework of Chen et al. (2017) <doi:10.1111/biom.12676>.
    This package is intended for use for both randomized controlled trials and
    observational studies.
configr,2017-01-15,configr: An Implementation of Parsing and Writing Configuration File
(JSON/INI/YAML/TOML),
    Implements the JSON, INI, YAML and TOML parser for R setting and writing of configuration file. The functionality of this package is similar to that of package 'config'. 
dimRed,2017-01-19,dimRed: A Framework for Dimensionality Reduction,A collection of dimensionality reduction
    techniques from R packages and a common
    interface for calling the methods.
helixvis,2017-06-26,helixvis: Visualize Alpha-Helical Peptide Sequences,Create publication-quality, 2-dimensional visualizations of alpha-helical peptide
  sequences. Specifically, allows the user to programmatically generate
  helical wheels and wenxiang diagrams to provide a bird's eye, top-down view of
  alpha-helical oligopeptides. See Wadhwa RR, et al. (2018)
  <doi:10.21105/joss.01008> for more information.
skpr,2017-08-18,skpr: Design of Experiments Suite: Generate and Evaluate Optimal
Designs,Generates and evaluates D, I, A, Alias, E, T, and G optimal designs. Supports generation and evaluation of split/split-split/.../N-split plot designs. Includes parametric and Monte Carlo power evaluation functions, and supports calculating power for censored responses. Provides a framework to evaluate power using functions provided in other packages or written by the user. Includes a Shiny graphical user interface that displays the underlying code used to create and evaluate the design to improve ease-of-use and make analyses more reproducible.
sys,2017-01-17,sys: Powerful and Reliable Tools for Running System Commands in R,Drop-in replacements for the base system2() function with fine control
    and consistent behavior across platforms. Supports clean interruption, timeout, 
    background tasks, and streaming STDIN / STDOUT / STDERR over binary or text 
    connections. Arguments on Windows automatically get encoded and quoted to work on different 
    locales. On Unix platforms the package also provides functions for evaluating 
    expressions inside a temporary fork. Such evaluations have no side effects on the
    main R process, and support reliable interrupts and timeouts. This provides the
    basis for a sandboxing mechanism.
fastLink,2017-07-09,fastLink: Fast Probabilistic Record Linkage with Missing Data,Implements a Fellegi-Sunter probabilistic record linkage model that allows for missing data
    and the inclusion of auxiliary information. This includes functionalities to conduct a merge of two datasets under the Fellegi-Sunter model
    using the Expectation-Maximization algorithm. In addition, tools for preparing, adjusting, and summarizing
    data merges are included. The package implements methods described in Enamorado, Fifield,
    and Imai (2017) ”Using a Probabilistic Model to Assist Merging of Large-scale Administrative
    Records”, available at <http://imai.princeton.edu/research/linkage.html>.
fingertipsR,2017-06-18,fingertipsR: Fingertips Data for Public Health,Fingertips (<http://fingertips.phe.org.uk/>) contains data for many indicators of public health in England. The underlying data is now more easily accessible by making use of the API.
FSelectorRcpp,2017-03-06,FSelectorRcpp: 'Rcpp' Implementation of 'FSelector' Entropy-Based Feature
Selection Algorithms with a Sparse Matrix Support,'Rcpp' (free of 'Java'/'Weka') implementation of 'FSelector' entropy-based feature selection 
 algorithms based on an MDL discretization (Fayyad U. M., Irani K. B.: Multi-Interval Discretization of Continuous-Valued Attributes for Classification Learning.
 In 13'th International Joint Conference on Uncertainly in Artificial Intelligence (IJCAI93), pages 1022-1029, Chambery, France, 1993.) <https://www.ijcai.org/Proceedings/93-2/Papers/022.pdf>
 with a sparse matrix support. It is also equipped with a parallel backend.
reqres,2017-08-12,reqres: Powerful Classes for HTTP Requests and Responses,In order to facilitate parsing of http requests and creating 
    appropriate responses this package provides two classes to handle a lot of
    the housekeeping involved in working with http exchanges. The infrastructure
    builds upon the 'rook' specification and is thus well suited to be combined
    with 'httpuv' based web servers.
STARTS,2017-05-12,STARTS: Functions for the STARTS Model,
    Contains functions for estimating the STARTS model of
    Kenny and Zautra (1995, 2001) <doi:10.1037/0022-006X.63.1.52>,
    <doi:10.1037/10409-008>. Penalized maximum likelihood
    estimation and Markov Chain Monte Carlo estimation are
    also provided, see Luedtke, Robitzsch and Wagner (2018) 
    <doi:10.1037/met0000155>.
AMCTestmakeR,2017-03-29,AMCTestmakeR: Generate LaTeX Code for Auto-Multiple-Choice (AMC),Generate code for use with the Optical Mark Recognition free software Auto Multiple Choice (AMC). More specifically, this package provides functions that use as input the question and answer texts, and output the LaTeX code for AMC.
nandb,2017-05-29,nandb: Number and Brightness Image Analysis,Calculation of molecular number and brightness from 
    fluorescence microscopy image series. The software was published in a 2016
    paper <doi:10.1093/bioinformatics/btx434>. The seminal paper for the 
    technique is Digman et al. 2008 <doi:10.1529/biophysj.107.114645>. A review
    of the technique was published in 2017 <doi:10.1016/j.ymeth.2017.12.001>.
Rcrawler,2017-06-15,Rcrawler: Web Crawler and Scraper,Performs parallel web crawling and web scraping. It is designed to crawl, parse and store web pages to produce data that can be directly used for analysis application. For details see Khalil and Fakir (2017) <doi:10.1016/j.softx.2017.04.004>.
reportReg,2017-05-19,reportReg: An Easy Way to Report Regression Analysis,Provides an easy way to report the results of regression analysis, including:
    1. Proportional hazards regression from function 'coxph' of package 'survival';
    2. Conditional logistic regression from function 'clogit' of package 'survival';
    3. Ordered logistic regression from function 'polr' of package 'MASS';
    4. Binary logistic regression from function 'glm' of package 'stats';
    5. Linear regression from function 'lm' of package 'stats';
    6. Risk regression model for survival analysis with competing risks from function 'FGR' of package 'riskRegression';
    7. Multilevel model from function 'lme' of package 'nlme'.
aphid,2017-06-24,aphid: Analysis with Profile Hidden Markov Models,Designed for the development and application of
    hidden Markov models and profile HMMs for biological sequence analysis. 
    Contains functions for multiple and pairwise sequence alignment, 
    model construction and parameter optimization, file import/export,
    implementation of the forward, backward and Viterbi algorithms for 
    conditional sequence probabilities, tree-based sequence weighting, 
    and sequence simulation. 
    Features a wide variety of potential applications including 
    database searching, gene-finding and annotation, phylogenetic 
    analysis and sequence classification.
    Based on the models and algorithms described in Durbin et 
    al (1998, ISBN: 9780521629713).
gastempt,2017-05-10,gastempt: Analyzing Gastric Emptying from MRI or Scintigraphy,Fits gastric emptying time series from MRI or scintigraphic measurements
   using nonlinear mixed-model population fits with 'nlme' and Bayesian methods with 
   Stan; computes derived parameters such as t50 and AUC.
antiword,2017-04-22,antiword: Extract Text from Microsoft Word Documents,Wraps the 'AntiWord' utility to extract text from Microsoft
    Word documents. The utility only supports the old 'doc' format, not the 
    new xml based 'docx' format. Use the 'xml2' package to read the latter.
arsenal,2016-12-30,arsenal: An Arsenal of 'R' Functions for Large-Scale Statistical
Summaries,An Arsenal of 'R' functions for large-scale statistical summaries,
  which are streamlined to work within the latest reporting tools in 'R' and
  'RStudio' and which use formulas and versatile summary statistics for summary
  tables and models. The primary functions include tableby(), a Table-1-like
  summary of multiple variable types 'by' the levels of a categorical
  variable; paired(), a Table-1-like summary of multiple variable types paired across
  two time points; modelsum(), which performs simple model fits on the same endpoint
  for many variables (univariate or adjusted for standard covariates);
  freqlist(), a powerful frequency table across many categorical variables;
  compare.data.frame(), the S3 method for comparing data.frames; and
  write2(), a function to output tables to a document.
dtangle,2017-05-30,dtangle: Cell Type Deconvolution from Gene Expressions,Deconvolving cell types from high-throughput gene profiling data. 
httptest,2016-12-31,httptest: A Test Environment for HTTP Requests,Testing and documenting code that communicates with remote servers
    can be painful. Dealing with authentication, server state,
    and other complications can make testing seem too costly to
    bother with. But it doesn't need to be that hard. This package enables one
    to test all of the logic on the R sides of the API in your package without
    requiring access to the remote service. Importantly, it provides three
    contexts that mock the network connection in different ways, as well as
    testing functions to assert that HTTP requests were—or were
    not—made. It also allows one to safely record real API responses to use as
    test fixtures. The ability to save responses and load them offline also
    enables one to write vignettes and other dynamic documents that can be
    distributed without access to a live server.
idefix,2017-06-27,idefix: Efficient Designs for Discrete Choice Experiments,Generates efficient designs for discrete choice experiments based on the multinomial logit model, and individually adapted designs for the mixed multinomial logit model. The generated designs can be presented on screen and choice data can be gathered using a shiny application. Crabbe M, Akinc D and Vandebroek M (2014) <doi:10.1016/j.trb.2013.11.008>.
MALDIrppa,2017-07-29,MALDIrppa: MALDI Mass Spectrometry Data Robust Pre-Processing and Analysis,Provides methods for quality control and robust pre-processing and analysis of MALDI mass spectrometry data.
quickPlot,2017-08-04,quickPlot: A System of Plotting Optimized for Speed and Modularity,A high-level plotting system, built using 'grid' graphics, that is
    optimized for speed and modularity. This has great utility for quick
    visualizations when testing code, with the key benefit that visualizations
    are updated independently of one another.
survHE,2017-06-30,survHE: Survival Analysis in Health Economic Evaluation,Contains a suite of functions for survival analysis in health economics. These can be used to run survival models under a frequentist (based on maximum likelihood) or a Bayesian approach (both based on Integrated Nested Laplace Approximation or Hamiltonian Monte Carlo). The user can specify a set of parametric models using a common notation and select the preferred mode of inference. The results can also be post-processed to produce probabilistic sensitivity analysis and can be used to export the output to an Excel file (e.g. for a Markov model, as often done by modellers and practitioners).
unrtf,2017-06-10,unrtf: Extract Text from Rich Text Format (RTF) Documents,Wraps the 'unrtf' utility to extract text from RTF files. Supports
    document conversion to HTML, LaTeX or plain text. Output in HTML is recommended
    because 'unrtf' has limited support for converting between character encodings.
walker,2017-06-15,walker: Bayesian Regression with Time-Varying Coefficients,Bayesian dynamic regression models where the regression 
    coefficients can vary over time as random walks. 
    Gaussian, Poisson, and binomial observations are supported. 
    The Markov chain Monte Carlo computations are done using 
    Hamiltonian Monte Carlo provided by Stan, using a state space representation 
    of the model in order to marginalise over the coefficients for efficient sampling. 
    For non-Gaussian models, walker uses the importance sampling type estimators based on 
    approximate marginal MCMC as in Vihola, Helske, Franks (2017, <arXiv:1609.02541>).
MADPop,2017-01-18,MADPop: MHC Allele-Based Differencing Between Populations,Tools for the analysis of population differences
    using the Major Histocompatibility Complex (MHC) genotypes of samples
    having a variable number of alleles (1-4) recorded for each
    individual.  A hierarchical Dirichlet-Multinomial model on the
    genotype counts is used to pool small samples from multiple
    populations for pairwise tests of equality.  Bayesian inference is
    implemented via the 'rstan' package.  Bootstrapped and posterior
    p-values are provided for chi-squared and likelihood ratio tests of
    equal genotype probabilities.
memapp,2017-06-06,memapp: The Moving Epidemic Method Web Application,The Moving Epidemic Method, created by T Vega and JE Lozano (2012, 2015) <doi:10.1111/j.1750-2659.2012.00422.x>, <doi:10.1111/irv.12330>, allows the weekly assessment of the epidemic and intensity status to help in routine respiratory infections surveillance in health systems. Allows the comparison of different epidemic indicators, timing and shape with past epidemics and across different regions or countries with different surveillance systems. Also, it gives a measure of the performance of the method in terms of sensitivity and specificity of the alert week. 'memapp' is a web application created in the Shiny framework for the 'mem' R package.
breathteststan,2017-05-13,breathteststan: Stan-Based Fit to Gastric Emptying Curves,Stan-based curve-fitting function
  for use with package 'breathtestcore' by the same author.
  Stan functions are refactored here for easier testing.
elasticsearchr,2016-11-24,elasticsearchr: A Lightweight Interface for Interacting with Elasticsearch from
R,A lightweight R interface to 'Elasticsearch' - a NoSQL search-engine and 
    column store database (see <https://www.elastic.co/products/elasticsearch> for more 
    information). This package implements a simple Domain-Specific Language (DSL) for indexing, 
    deleting, querying, sorting and aggregating data using 'Elasticsearch'.
exampletestr,2017-03-18,exampletestr: Help for Writing Unit Tests Based on Function Examples,Take the examples written in your documentation of functions and 
    use them to create shells (skeletons which must be manually completed by
    the user) of test files to be tested with the 'testthat' package. 
gggenes,2017-08-24,gggenes: Draw Gene Arrow Maps in 'ggplot2',Provides a 'ggplot2' geom and helper functions for drawing gene
  arrow maps.
huxtable,2017-03-09,huxtable: Easily Create and Style Tables for LaTeX, HTML and Other Formats,Like 'xtable', creates styled tables. Export to HTML, LaTeX, 'Word', 
  'Excel', 'PowerPoint' and RTF. Simple, modern interface to manipulate 
  borders, size, position, captions, colours, text styles and number formatting.
  Table cells can span multiple rows and/or columns.
  Includes  a 'huxreg' function for creation of regression tables, and 'quick_*' 
  one-liners to print data to a new document.
worrms,2017-01-14,worrms: World Register of Marine Species (WoRMS) Client,Client for World Register of Marine Species
    (<http://www.marinespecies.org/>). Includes functions for each
    of the API methods, including searching for names by name, date and
    common names, searching using external identifiers, fetching
    synonyms, as well as fetching taxonomic children and
    taxonomic classification.
mdmb,2017-01-26,mdmb: Model Based Treatment of Missing Data,
    Contains model-based treatment of missing data for regression 
    models with missing values in covariates or the dependent 
    variable using maximum likelihood or Bayesian estimation 
    (Ibrahim et al., 2005; <doi:10.1198/016214504000001844>).
    The regression model can be nonlinear (e.g., interaction 
    effects, quadratic effects or B-spline functions). 
    Multilevel models with missing data in predictors are
    available for Bayesian estimation. Substantive-model compatible 
    multiple imputation can be also conducted.
webmockr,2017-05-20,webmockr: Stubbing and Setting Expectations on 'HTTP' Requests,Stubbing and setting expectations on 'HTTP' requests.
    Includes tools for stubbing 'HTTP' requests, including expected
    request conditions and response conditions. Match on
    'HTTP' method, query parameters, request body, headers and
    more. Can be used for unit tests or outside of a testing 
    context.
WVPlots,2017-01-17,WVPlots: Common Plots for Analysis,Select data analysis plots, under a standardized calling interface implemented on top of 'ggplot2' and 'plotly'.  
   Plots of interest include: 'ROC', gain curve, scatter plot with marginal distributions, 
   conditioned scatter plot with marginal densities,
   box and stem with matching theoretical distribution, and density with matching theoretical distribution.
augSIMEX,2017-09-21,augSIMEX: Analysis of Data with Mixed Measurement Error and
Misclassification in Covariates,Implementation of the augmented
            Simulation-Extrapolation (SIMEX) algorithm proposed by Yi et al. (2015) <doi:10.1080/01621459.2014.922777>
            for analyzing the data with mixed measurement error and misclassification. The main
            function provides a similar summary output as that of glm() function. Both parametric and
            empirical SIMEX are considered in the package.
autothresholdr,2017-02-24,autothresholdr: An R Port of the 'ImageJ' Plugin 'Auto Threshold',Algorithms for automatically finding appropriate thresholds for 
    numerical data, with special functions for thresholding images. Provides the
    'ImageJ' 'Auto Threshold' plugin functionality to R users. See 
    <http://imagej.net/Auto_Threshold> and Landini et al. (2017) 
    <doi:10.1111/jmi.12474>.
eulerr,2016-10-16,eulerr: Area-Proportional Euler and Venn Diagrams with Ellipses,Generate area-proportional Euler diagrams
    using numerical optimization. An Euler diagram is a generalization of a Venn
    diagram, relaxing the criterion that all interactions need to be
    represented. Diagrams may be fit with ellipses and circles via
    a wide range of inputs and can be visualized in numerous ways.
jmvcore,2017-01-05,jmvcore: Dependencies for the 'jamovi' Framework,A framework for creating rich interactive analyses for the jamovi
    platform (see <https://www.jamovi.org> for more information).
semtree,2016-12-16,semtree: Recursive Partitioning for Structural Equation Models,SEM Trees and SEM Forests – an extension of model-based decision
    trees and forests to Structural Equation Models (SEM). SEM trees hierarchically
    split empirical data into homogeneous groups sharing similar data patterns
    with respect to a SEM by recursively selecting optimal predictors of these
    differences. SEM forests are an extension of SEM trees. They are ensembles of
    SEM trees each built on a random sample of the original data. By aggregating
    over a forest, we obtain measures of variable importance that are more robust
    than measures from single trees.
sessioninfo,2017-06-21,sessioninfo: R Session Information,Query and print information about the current R session.
    It is similar to 'utils::sessionInfo()', but includes more information
    about packages, and where they were installed from.
shinyWidgets,2017-03-23,shinyWidgets: Custom Inputs Widgets for Shiny,Some custom inputs widgets to use in Shiny applications, like a toggle switch to replace checkboxes. And other components to pimp your apps.
spant,2017-04-26,spant: MR Spectroscopy Analysis Tools,Tools for reading, visualising and processing Magnetic Resonance
    Spectroscopy data.
KarsTS,2017-05-27,KarsTS: An Interface for Microclimate Time Series Analysis,An R graphical user interface for microclimate time series, with an emphasis on underground environments. 'KarsTS' provides linear and nonlinear methods, including recurrence analysis (Marwan et al. (2007) <10.1016/j.physrep.2006.11.001>) and filling methods (Moffat et al. (2007) <doi:10.1016/j.agrformet.2007.08.011>), as well as tools to manipulate easily time series and gap sets.
sigr,2017-01-16,sigr: Succinct and Correct Statistical Summaries for Reports,Succinctly and correctly format statistical summaries of
    various models and tests (F-test, Chi-Sq-test, Fisher-test, T-test, and rank-significance).  The main purpose is unified reporting 
    of experimental results, working around issue such as the difficulty of
    extracting model summary facts (such as with 'lm'/'glm').  This package also
    includes empirical tests, such as bootstrap estimates.
egg,2017-09-12,egg: Extensions for 'ggplot2': Custom Geom, Plot Alignment,
Symmetrised Scale, and Fixed Panel Size,Miscellaneous functions to help customise 'ggplot2' objects. High-level functions are provided to post-process 'ggplot2' layouts and allow alignment between plot panels, as well as setting panel sizes to fixed values. Other functions include a custom 'geom', and helper functions to enforce symmetric scales or add tags to facetted plots.
numform,2017-07-29,numform: Tools to Format Numbers for Publication,Format numbers and plots for publication; includes the removal of leading zeros,
           standardization of number of digits, addition of affixes, and a p-value formatter. These
           tools combine the functionality of several 'base' functions such as 'paste()',
           'format()', and 'sprintf()' into specific use case functions that are named in a way
           that is consistent with usage, making their names easy to remember and easy to deploy.
owmr,2017-01-14,owmr: OpenWeatherMap API Wrapper,Accesses OpenWeatherMap's (owm) <https://openweathermap.org/> API.
   'owm' itself is a service providing weather data in the past, in the future and now.
   Furthermore, 'owm' serves weather map layers usable in frameworks like 'leaflet'.
   In order to access the API, you need to sign up for an API key. There are free and paid plans.
   Beside functions for fetching weather data from 'owm', 'owmr' supplies
   tools to tidy up fetched data (for fast and simple access) and to show it on leaflet maps.
tidyRSS,2017-02-24,tidyRSS: Tidy RSS for R,
    With the objective of including data from RSS feeds into your analysis, 'tidyRSS' parses RSS, Atom XML, JSON and geoRSS feeds and returns a tidy data frame.
dexter,2017-02-08,dexter: Data Management and Analysis of Tests,A system for the management, assessment, and psychometric analysis of data from educational and psychological tests. 
    Developed at Cito, The Netherlands, with subsidy from the Dutch Ministry of Education, Culture, and Science.
redlistr,2017-07-07,redlistr: Tools for the IUCN Red List of Ecosystems and Species,A toolbox created by members of the International Union for
    Conservation of Nature (IUCN) Red List of Ecosystems Committee for
    Scientific Standards. Primarily, it is a set of tools suitable
    for calculating the metrics required for making assessments of species and
    ecosystems against the IUCN Red List of Threatened Species and the IUCN Red
    List of Ecosystems categories and criteria. See the IUCN website for
    detailed guidelines, the criteria, publications and other information.
tesseract,2016-11-04,tesseract: Open Source OCR Engine,Bindings to 'Tesseract' <https://opensource.google.com/projects/tesseract>: 
     a powerful optical character recognition (OCR) engine that supports over 100 languages.
     The engine is highly configurable in order to tune the detection algorithms and
     obtain the best possible results.
VARtests,2017-08-07,VARtests: Tests for Error Autocorrelation, ARCH Errors, and Cointegration
in Vector Autoregressive Models,Implements the Wild bootstrap tests for autocorrelation in vector autoregressive models of Ahlgren, N. & Catani, P. 
	(2016, <doi:10.1007/s00362-016-0744-0>), the Combined LM test for ARCH in VAR models of Catani, P. & Ahlgren, N. 
	(2016, <doi:10.1016/j.ecosta.2016.10.006>), and Bootstrap determination of the co-integration rank (Cavaliere, G., Rahbek, A.,
	& Taylor, A. M. R., 2012, 2014).
hutils,2017-07-09,hutils: Miscellaneous R Functions and Aliases,Provides utility functions for, and drawing on, the 'data.table' package. The package also collates useful miscellaneous functions extending base R not available elsewhere. The name is a portmanteau of 'utils' and the author.
incidence,2016-11-03,incidence: Compute, Handle, Plot and Model Incidence of Dated Events,Provides functions and classes to compute, handle and visualise incidence from dated events for a defined time interval. Dates can be provided in various standard formats. The class 'incidence' is used to store computed incidence and can be easily manipulated, subsetted, and plotted. In addition, log-linear models can be fitted to 'incidence' objects using 'fit'. This package is part of the RECON (<http://www.repidemicsconsortium.org/>) toolkit for outbreak analysis.
automultinomial,2016-10-05,automultinomial: Models for Spatially Correlated Data,Fits the autologistic model described in Besag's famous 1974 paper on auto- models <http://www.jstor.org/stable/2984812>. Fits a multicategory generalization of the autologistic model when there are more than 2 response categories. Provides support for both asymptotic and bootstrap confidence intervals. For full model descriptions and a guide to the use of this package, please see the vignette.
flextable,2017-03-28,flextable: Functions for Tabular Reporting,Create pretty tables for 'HTML', 'Microsoft Word' and 'Microsoft PowerPoint' documents. 
  Functions are provided to let users create tables, modify and format their content. 
  It extends package 'officer' that does not contain any feature for customized tabular reporting 
  and can be used within R markdown documents when rendering to HTML and to 'Microsoft Word' documents.
gibble,2017-09-08,gibble: Geometry Decomposition,Build a map of path-based geometry, this is a simple description of the number
 of parts in an object and their basic structure. Translation and restructuring operations for 
 planar shapes and other hierarchical types require a data model with a record of the underlying
 relationships between elements. The gibble() function creates a geometry map, a simple record of 
 the underlying structure in path-based hierarchical types. There are methods for the planar shape 
 types in the 'sf' and 'sp' packages and for types in the the 'trip' and in-development 'silicate' packages. 
mvord,2017-09-07,mvord: Multivariate Ordinal Regression Models,A flexible framework for fitting multivariate
    ordinal regression models with composite likelihood methods.
RATest,2017-08-14,RATest: Randomization Tests,A collection of randomization tests, data sets and examples. The current version focuses on two testing problems and their implementation in empirical work. First, it facilitates the empirical researcher to test for particular hypotheses, such as comparisons of means, medians, and variances from k populations using robust permutation tests, which asymptotic validity holds under very weak assumptions, while retaining the exact rejection probability in finite samples when the underlying distributions are identical. Second, the description and implementation of a permutation test for testing the continuity assumption of the baseline covariates in the sharp regression discontinuity design (RDD) as in Canay and Kamat (2017) <https://goo.gl/UZFqt7>. More specifically, it allows the user to select a set of covariates and test the aforementioned hypothesis using a permutation test based on the Cramer-von Miss test statistic. Graphical inspection of the empirical CDF and histograms for the variables of interest is also supported in the package.
restriktor,2017-02-22,restriktor: Restricted Statistical Estimation and Inference for Linear
Models,Allow for easy-to-use testing or evaluating of linear equality and inequality 
 restrictions about parameters and effects in (generalized) linear statistical models.
shallot,2017-05-12,shallot: Random Partition Distribution Indexed by Pairwise Information,Implementations are provided for the models described in the paper D. B. Dahl, R. Day, J. Tsai (2017) <doi:10.1080/01621459.2016.1165103>. The Ewens, Ewens-Pitman, Ewens attraction, Ewens-Pitman attraction, and ddCRP distributions are available for prior and posterior simulation. Posterior simulation is based on a user-supplied likelihood. Supporting functions for partition estimation and plotting are also provided.
spatstat.utils,2017-02-16,spatstat.utils: Utility Functions for 'spatstat',Contains utility functions for the 'spatstat' package
             which may also be useful for other purposes.
AMModels,2016-12-03,AMModels: Adaptive Management Model Manager,Helps enable adaptive management by codifying knowledge in the
    form of models generated from numerous analyses and data sets. Facilitates
    this process by storing all models and data sets in a single object that can
    be updated and saved, thus tracking changes in knowledge through time. A shiny
    application called AM Model Manager (modelMgr()) enables the use of these
    functions via a GUI.
cpt,2017-03-02,cpt: Classification Permutation Test,Non-parametric test for equality of multivariate distributions.  Trains a classifier to classify (multivariate) observations as coming from one of several distributions.  If the classifier is able to classify the observations better than would be expected by chance (using permutation inference), then the null hypothesis that the distributions are equal is rejected.  
filesstrings,2017-02-23,filesstrings: Handy File and String Manipulation,This started out as a package for file and string manipulation. 
    Since then, the 'fs' and 'strex' packages emerged, offering functionality
    previously given by this package (but it's done better in these new ones). 
    Those packages have hence almost pushed 'filesstrings' into extinction. 
    However, it still has a small number of unique, handy file manipulation 
    functions which can be seen in the vignette. 
    One example is a function to remove spaces from all file names in a 
    directory.
GDINA,2016-12-12,GDINA: The Generalized DINA Model Framework,A set of psychometric tools for cognitive diagnosis modeling for both dichotomous and polytomous responses. Various cognitive diagnosis models can be estimated, include the generalized deterministic inputs, noisy and gate (G-DINA) model by de la Torre (2011) <doi:10.1007/s11336-011-9207-7>, the sequential G-DINA model by Ma and de la Torre (2016) <doi:10.1111/bmsp.12070>, and many other models they subsume. Joint attribute distribution can be independent, saturated, higher-order, loglinear smoothed or structured. Q-matrix validation, item and model fit statistics, model comparison at test and item level and differential item functioning can also be conducted. A graphical user interface is also provided.
greta,2017-06-26,greta: Simple and Scalable Statistical Modelling in R,Write statistical models in R and fit them by MCMC on CPUs and GPUs, using Google TensorFlow (see <https://greta-dev.github.io/greta> for more information).
lemon,2017-05-22,lemon: Freshing Up your 'ggplot2' Plots,Functions for working with legends and axis lines of 'ggplot2',
    facets that repeat axis lines on all panels, and some 'knitr' extensions.
vennLasso,2017-07-15,vennLasso: Variable Selection for Heterogeneous Populations,Provides variable selection and estimation routines for models
    with main effects stratified on multiple binary factors. The 'vennLasso' package
    is an implementation of the method introduced in Huling, et al. (2017) <doi:10.1111/biom.12769>.
rsparkling,2017-01-24,rsparkling: R Interface for H2O Sparkling Water,An extension package for 'sparklyr' that provides an R interface to
    H2O Sparkling Water machine learning library (see <https://github.com/h2oai/sparkling-water> for more information).
strip,2017-01-13,strip: Lighten your R Model Outputs,The strip function deletes components of R model outputs that are useless for specific purposes, such as predict[ing], print[ing], summary[izing], etc.
atus,2017-07-19,atus: American Time Use Survey Data,Abridged data from the American Time Use Survey (ATUS) for years 2003-2016. The ATUS is an annual survey conducted on a sample of individuals across the United States studying how individuals spent their time over the course of a day. Individual respondents were interviewed about what activities they did, during what times (rounded to 15 minute increments), at what locations, and in the presence of which individuals. The activities are subsequently encoded based on 3 separate tier codes for classification. This package includes data from the multi-year ATUS Activities, ATUS-CPS, and ATUS Respondents files were included. Columns were selected based on completeness of data as well as presence on the Frequently Used Variables list provided by the ATUS website. All activity codes (other than code '50' for 'Unable to Code') were included. Permission was obtained from the Bureau of Labor Statistics for inclusion in this package. The full data can be obtained from <http://www.bls.gov/tus/>.
ebimetagenomics,2016-10-16,ebimetagenomics: EBI Metagenomics Portal,Functions for querying the EBI Metagenomics Portal <https://www.ebi.ac.uk/metagenomics/>. The current main focus is on taxa abundance data, but the intention is that this package should evolve into a general purpose package for working with EBI Metagenomics data using R. 
spectrolab,2017-09-14,spectrolab: Class and Methods for Hyperspectral Data,Input/Output, processing and visualization of spectra taken with different spectrometers, including SVC (Spectra Vista), ASD and PSR (Spectral Evolution). Implements an S3 class 'spectra' that other packages can build on. Provides methods to access, plot, manipulate, splice sensor overlap, vector normalize and smooth spectra.
sugrrants,2017-07-28,sugrrants: Supporting Graphs for Analysing Time Series,Provides 'ggplot2' graphics for analysing time
    series data. It aims to fit into the 'tidyverse' and grammar of
    graphics framework for handling temporal data.
uavRmp,2017-08-30,uavRmp: UAV Mission Planner,The Unmanned Aerial Vehicle Mission Planner provides an easy to use work flow for planning autonomous obstacle avoiding surveys of (almost) ready to fly unmanned aerial vehicles to retrieve aerial or spot related data. It creates either intermediate flight control files for the DJI phantom series or ready to upload control files for the pixhawk based flight controller as used in the 3DR Solo. Additionally it contains some useful tools for digitizing and data manipulation.
vistime,2017-01-29,vistime: Pretty Timeline Creation,Create timelines or Gantt charts, offline and interactive, that are usable in the 'RStudio' viewer pane, in 'R Markdown' documents and in 'Shiny' apps using 'plotly.js', a high-level, declarative charting library (see <https://plot.ly/javascript>). Hover the mouse pointer over a point or task to show details or drag a rectangle to zoom in. Timelines (and the data behind them) can be manipulated using 'plotly_build()' or, once uploaded to a 'plotly' account, viewed and modified in a web browser.
ggspatial,2017-04-02,ggspatial: Spatial Data Framework for ggplot2,Spatial data plus the power of the ggplot2 framework means easier mapping when input 
  data are already in the form of spatial objects.
BayesS5,2017-01-17,BayesS5: Bayesian Variable Selection Using Simplified Shotgun Stochastic
Search with Screening (S5),In p >> n settings, full posterior sampling using existing Markov chain Monte
    Carlo (MCMC) algorithms is highly inefficient and often not feasible from a practical
    perspective. To overcome this problem, we propose a scalable stochastic search algorithm that is called the Simplified Shotgun Stochastic Search (S5) and aimed at rapidly explore interesting regions of model space and finding the maximum a posteriori(MAP) model. Also, the S5 provides an approximation of posterior probability of each model (including the marginal inclusion probabilities).
commonsMath,2017-05-24,commonsMath: JAR Files of the Apache Commons Mathematics Library,Java JAR files for the Apache Commons Mathematics Library for use by users and other packages.
drake,2017-02-27,drake: A Pipeline Toolkit for Reproducible Computation at Scale,A general-purpose computational engine for data analysis,
  drake rebuilds intermediate data objects when their dependencies change,
  and it skips work when the results are already up to date.
  Not every execution starts from scratch,
  and completed projects have tangible evidence
  that they are reproducible.
  Extensive documentation, from beginner-friendly tutorials
  to practical examples and more, is available at the reference website
  <https://ropensci.github.io/drake/> and the online manual
  <https://ropenscilabs.github.io/drake-manual/>.
latexpdf,2017-09-27,latexpdf: Convert Tables to PDF or PNG,Converts table-like objects to stand-alone PDF or PNG.
 Can be used to embed tables and arbitrary content in PDF or Word
 documents. Provides a low-level R interface for creating 'LaTeX'
 code, e.g. command() and a high-level interface for creating PDF
 documents, e.g. as.pdf.data.frame(). Extensive customization is
 available via mid-level functions, e.g. as.tabular(). See also 
 'package?latexpdf'. Support for PNG is experimental; see
 'as.png.data.frame'. Adapted from 'metrumrg' 
 <http://r-forge.r-project.org/R/?group_id=1215>.
 Requires a compatible installation of 'pdflatex',
 e.g. <https://miktex.org/>.
link2GI,2017-01-22,link2GI: Linking Geographic Information Systems, Remote Sensing and Other
Command Line Tools,Functions to simplify the linking of open source GIS and remote sensing related command line interfaces.
electoral,2017-09-28,electoral: Allocating Seats Methods and Party System Scores,Highest averages & largest remainders allocating seats methods and
    several party system scores.
    Implemented highest averages allocating seats methods are D'Hondt, Webster,
    Danish, Imperiali, Hill-Huntington, Dean, Modified Sainte-Lague,
    equal proportions and Adams.
    Implemented largest remainders allocating seats methods are Hare, Droop,
    Hangenbach-Bischoff, Imperial, modified Imperial and quotas & remainders.
    The main advantage of this package is that ties are always reported
    and not incorrectly allocated.
    Party system scores provided are competitiveness, concentration,
    effective number of parties, party nationalization score,
    party system nationalization score and volatility.
    References.
    Gallagher (1991) <doi:10.1016/0261-3794(91)90004-C>.
    Norris (2004, ISBN:0-521-82977-1).
    Consejo Nacional Electoral del Ecuador (2014)<http://cne.gob.ec/documents/Estadisticas/Atlas/ATLAS/CAPITULO%206%20web.pdf>.
    Laakso & Taagepera (1979) <http://journals.sagepub.com/doi/pdf/10.1177/001041407901200101>.
    Jones & Mainwaring (2003) <https://kellogg.nd.edu/sites/default/files/old_files/documents/304_0.pdf>.
    Pedersen (1979) <http://janda.org/c24/Readings/Pedersen/Pedersen.htm>.
JuliaCall,2017-09-01,JuliaCall: Seamless Integration Between R and 'Julia',Provides an R interface to 'Julia',
    which is a high-level, high-performance dynamic programming language
    for numerical computing, see <https://julialang.org/> for more information.
    It provides a high-level interface as well as a low-level interface.
    Using the high level interface, you could call any 'Julia' function just like
    any R function with automatic type conversion. Using the low level interface,
    you could deal with C-level SEXP directly while enjoying the convenience of
    using a high-level programming language like 'Julia'.
microdemic,2017-09-25,microdemic: 'Microsoft Academic' API Client,The 'Microsoft Academic Knowledge' API provides programmatic access
	to scholarly articles in the 'Microsoft Academic Graph'
	(<https://academic.microsoft.com/>). Includes methods matching all 'Microsoft
	Academic' API routes, including search, graph search, text similarity, and
	interpret natural language query string.
MODIS,2017-01-10,MODIS: Acquisition and Processing of MODIS Products,Download and processing functionalities for the Moderate Resolution
    Imaging Spectroradiometer (MODIS). The package provides automated access to the
    global online data archives LP DAAC (<https://lpdaac.usgs.gov/>), LAADS 
    (<https://ladsweb.modaps.eosdis.nasa.gov/>) and NSIDC (<https://nsidc.org/>) 
    as well as processing capabilities such as file conversion, mosaicking, 
    subsetting and time series filtering.
PhenotypeSimulator,2017-05-21,PhenotypeSimulator: Flexible Phenotype Simulation from Different Genetic and Noise
Models,Simulation is a critical part of method development and assessment
    in quantitative genetics. 'PhenotypeSimulator' allows for the flexible 
    simulation of phenotypes under different models, including genetic variant 
    and  infinitesimal genetic effects (reflecting population structure) as well 
    as non-genetic covariate effects, observational noise and additional 
    correlation effects. The different phenotype components are combined into a 
    final phenotype while controlling for the proportion of variance explained 
    by each of the components. For each effect component, the number of 
    variables, their distribution and the design of their effect across traits 
    can be customised. For the simulation of the genetic effects, external 
    genotype data from a number of standard software ('plink', 'hapgen2'/
    'impute2', 'genome', 'bimbam', simple text files) can be imported. The final 
    simulated phenotypes and its components can be automatically saved into .rds 
    or .csv files. In addition, they can be saved in formats compatible with 
    commonly used genetic association software ('gemma', 'bimbam', 'plink', 
    'snptest', 'LiMMBo'). 
reactR,2016-11-05,reactR: React Helpers,Make it easy to use 'React' in R with helper
              dependency functions, embedded 'Babel' 'transpiler',
              and examples.
rlang,2017-05-06,rlang: Functions for Base Types and Core R and 'Tidyverse' Features,A toolbox for working with base types, core R features
  like the condition system, and core 'Tidyverse' features like tidy
  evaluation.
rlas,2016-12-23,rlas: Read and Write 'las' and 'laz' Binary File Formats Used for
Remote Sensing Data,Read and write 'las' and 'laz' binary file formats. The LAS file format is a public file format for the interchange of 3-dimensional point cloud data between data users. The LAS specifications are approved by the American Society for Photogrammetry and Remote Sensing <https://www.asprs.org/committee-general/laser-las-file-format-exchange-activities.html>. The LAZ file format is an open and lossless compression scheme for binary LAS format versions 1.0 to 1.3 <https://www.laszip.org/>.
sitree,2017-01-10,sitree: Single Tree Simulator,Forecasts plots at tree level.
solvebio,2016-10-25,solvebio: The Official SolveBio API Client,R language bindings for SolveBio's API.
    SolveBio is a biomedical knowledge hub that enables life science
    organizations to collect and harmonize the complex, disparate
    "multi-omic" data essential for today's R&D and BI needs.
    For more information, visit <https://www.solvebio.com>.
texPreview,2017-04-03,texPreview: Compile and Preview Snippets of 'LaTeX' in 'RStudio',Compile and preview snippets of 'LaTeX'. Can be used directly from the R console, from 'RStudio', 
    in Shiny apps and R Markdown documents. Must have 'pdflatex' or 'xelatex' or 'lualatex' in 'PATH'.
CrossVA,2016-11-10,CrossVA: Verbal Autopsy Data Transform for Use with Various Coding
Algorithms,Enables transformation of Verbal Autopsy data collected with the WHO 2016 questionnaire (versions 1.4.1 & 1.5.1)
  for automated coding of Cause of Death using different computer algorithms. Currently supports user-supplied mappings, and
  provides unvalidated, experimental-stage mapping definitions to transform to InterVA4, InterVA5, Tariff 2, and InSilicoVA.
  This package is made available by WHO, in collaboration with the Swiss Tropical and Public Health Institute and the
  Bloomberg Data for Health Initiative.
d3r,2016-10-14,d3r: 'd3.js' Utilities for R,Provides a suite of functions to help ease the use of 'd3.js' in R.
              These helpers include 'htmltools::htmlDependency' functions, hierarchy
              builders, and conversion tools for 'partykit', 'igraph,' 'table',
              and 'data.frame' R objects into the 'JSON' that 'd3.js' expects.
dodgr,2017-09-28,dodgr: Distances on Directed Graphs,Distances on dual-weighted directed graphs using priority-queue
    shortest paths. Weighted directed graphs have weights from A to B which may
    differ from those from B to A. Dual-weighted directed graphs have two sets
    of such weights. A canonical example is a street network to be used for
    routing in which routes are calculated by weighting distances according to
    the type of way and mode of transport, yet lengths of routes must be
    calculated from direct distances.
mmpf,2016-11-12,mmpf: Monte-Carlo Methods for Prediction Functions,Marginalizes prediction functions using Monte-Carlo integration and computes permutation importance.
mvLSW,2016-12-23,mvLSW: Multivariate, Locally Stationary Wavelet Process Estimation,Tools for analysing multivariate time series with wavelets. This includes: simulation of a multivariate locally stationary wavelet (mvLSW) process from a multivariate evolutionary wavelet spectrum (mvEWS); estimation of the mvEWS, local coherence and local partial coherence. See Park, Eckley and Ombao (2014) <doi:10.1109/TSP.2014.2343937> for details.
NetworkInference,2017-03-26,NetworkInference: Inferring Latent Diffusion Networks,This is an R implementation of the netinf algorithm (Gomez Rodriguez, Leskovec, and Krause, 2010)<doi:10.1145/1835804.1835933>. Given a set of events that spread between a set of nodes the algorithm infers the most likely stable diffusion network that is underlying the diffusion process.
rsMove,2017-07-15,rsMove: Guidelines for the use of Remote Sensing in Movement Ecology,Tools for the guided selection of satellite data and environmental predictors, the combination of remote sensing and animal movement data and the mapping of resource suitabilitz. Based on the paper by Remelgado et al. (2015) <doi:10.1002/rse2.70>.
rWind,2016-12-03,rWind: Download, Edit and Include Wind Data in Ecological and
Evolutionary Analysis,Tools for download and manage surface wind data from the Global Forecasting System <https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs> and to compute wind connectivity between locations.
sf,2016-10-26,sf: Simple Features for R,Support for simple features, a standardized way to
    encode spatial vector data. Binds to 'GDAL' for reading and writing
    data, to 'GEOS' for geometrical operations, and to 'PROJ' for
    projection conversions and datum transformations.
taskscheduleR,2017-03-03,taskscheduleR: Schedule R Scripts and Processes with the Windows Task Scheduler,Schedule R scripts/processes with the Windows task scheduler. This
    allows R users to automate R processes on specific time points from R itself.
trackdem,2017-04-24,trackdem: Particle Tracking and Demography,Obtain population density and body size structure, using video material or image sequences as input. Functions assist in the creation of image sequences from videos, background detection and subtraction, particle identification and tracking. An artificial neural network can be trained for noise filtering. The goal is to supply accurate estimates of population size, structure and/or individual behavior, for use in  evolutionary and ecological studies. 
blogdown,2017-08-22,blogdown: Create Blogs and Websites with R Markdown,Write blog posts and web pages in R Markdown. This package supports
    the static site generator 'Hugo' (<https://gohugo.io>) best, and it also
    supports 'Jekyll' (<http://jekyllrb.com>) and 'Hexo' (<https://hexo.io>).
DEploid,2016-11-25,DEploid: Deconvolute Mixed Genomes with Unknown Proportions,Traditional phasing programs are limited to diploid organisms.
 Our method modifies Li and Stephens algorithm with Markov chain Monte Carlo
 (MCMC) approaches, and builds a generic framework that allows haplotype searches
 in a multiple infection setting. This package is primarily developed as part of
 the Pf3k project, which is a global collaboration using the latest
 sequencing technologies to provide a high-resolution view of natural variation
 in the malaria parasite Plasmodium falciparum. Parasite DNA are extracted from
 patient blood sample, which often contains more than one parasite strain, with
 unknown proportions. This package is used for deconvoluting mixed haplotypes,
 and reporting the mixture proportions from each sample.
isdparser,2016-11-03,isdparser: Parse 'NOAA' Integrated Surface Data Files,Tools for parsing 'NOAA' Integrated Surface Data ('ISD') files,
    described at <https://www.ncdc.noaa.gov/isd>. Data includes for example,
    wind speed and direction, temperature, cloud data, sea level pressure,
    and more. Includes data from approximately 35,000 stations worldwide,
    though best coverage is in North America/Europe/Australia. Data is stored
    as variable length ASCII character strings, with most fields optional.
    Included are tools for parsing entire files, or individual lines of data.
websearchr,2017-09-15,websearchr: Access Domains and Search Popular Websites,Functions that allow for accessing domains and a number of search engines.
xaringan,2016-12-13,xaringan: Presentation Ninja,Create HTML5 slides with R Markdown and the JavaScript library
    'remark.js' (<https://remarkjs.com>).
bikedata,2017-05-31,bikedata: Download and Aggregate Data from Public Hire Bicycle Systems,Download and aggregate data from all public hire bicycle systems
    which provide open data, currently including 'Santander' Cycles in London,
    U.K., and from the U.S.A., 'citibike' in New York City NY, 'Divvy' in
    Chicago IL, 'Capital Bikeshare' in Washington DC, 'Hubway' in Boston MA, 
    'Metro' in Los Angeles LA, and 'Indego' in Philadelphia PA.
dLagM,2017-08-08,dLagM: Time Series Regression Models with Distributed Lag Models,Provides time series regression models with one predictor using finite distributed lag models, polynomial (Almon) distributed lag models, geometric distributed lag models with Koyck transformation, and autoregressive distributed lag models. It also consists of functions for computation of h-step ahead forecasts from these models. See Baltagi (2011) <doi:10.1007/978-3-642-20059-5> for more information.
dynamichazard,2016-12-28,dynamichazard: Dynamic Hazard Models using State Space Models,Contains functions that lets you fit dynamic hazard models using 
  state space models. The first implemented model is described in Fahrmeir 
  (1992) <doi:10.1080/01621459.1992.10475232> and Fahrmeir (1994) 
  <doi:10.1093/biomet/81.2.317>. Extensions hereof are available where the  
  Extended Kalman filter is replaced by an unscented Kalman filter and other 
  options including particle filters. The implemented particle filters support
  more general state space models. 
FishResp,2017-05-09,FishResp: Analytical Tool for Aquatic Respirometry,Calculates metabolic rate of fish and other aquatic organisms measured using
             an intermittent-flow respirometry approach. The tool is used to run a set of graphical
             QC tests of raw respirometry data, correct it for background respiration and chamber
             effect, filter and extract target values of absolute and mass-specific metabolic rate.
             Experimental design should include background respiration tests and measuring of one
             or more metabolic rate traits. The package allows a user to import raw respirometry
             data obtained from 'AquaResp' (free software), 'AutoResp' ('LoligoSystems'), 'OxyView'
             ('PreSens'), 'Pyro Oxygen Logger' ('PyroScience') and 'Q-box Aqua' ('QubitSystems').
meteoland,2016-10-03,meteoland: Landscape Meteorology Tools,Functions to estimate weather variables at any position of a landscape [De Caceres et al. (2018) <doi:10.1016/j.envsoft.2018.08.003>].
osmdata,2017-05-18,osmdata: Import 'OpenStreetMap' Data as Simple Features or Spatial
Objects,Download and import of 'OpenStreetMap' ('OSM') data as 'sf' or 'sp'
    objects.  'OSM' data are extracted from the 'Overpass' web server and
    processed with very fast 'C++' routines for return to 'R'.
bridgesampling,2017-03-24,bridgesampling: Bridge Sampling for Marginal Likelihoods and Bayes Factors,Provides functions for estimating marginal likelihoods, Bayes
    factors, posterior model probabilities, and normalizing constants in general,
    via different versions of bridge sampling (Meng & Wong, 1996, 
    <http://www3.stat.sinica.edu.tw/statistica/j6n4/j6n43/j6n43.htm>).
cdata,2017-03-29,cdata: Fluid Data Transformations,Supplies higher-order fluid data transform operators that include pivot and anti-pivot as special cases. 
    The methodology is describe in 'Zumel', 2018, "Fluid data reshaping with 'cdata'", <http://winvector.github.io/FluidData/FluidDataReshapingWithCdata.html> , doi:10.5281/zenodo.1173299 . 
    Based on the 'DBI' database interface.
RApiDatetime,2017-03-23,RApiDatetime: R API Datetime,Access to the C-level R date and datetime code is provided for
 C-level API use by other packages via registration of native functions.
 Client packages simply include a single header 'RApiDatetime.h' provided
 by this package, and also 'import' it.  The R Core group is the original
 author of the code made available with slight modifications by this package. 
lexicon,2017-01-08,lexicon: Lexicons for Text Analysis,A collection of lexical hash tables, dictionaries, and word lists.
ciTools,2017-08-07,ciTools: Confidence or Prediction Intervals, Quantiles, and Probabilities
for Statistical Models,Functions to append confidence intervals, prediction intervals,
    and other quantities of interest to data frames. All appended quantities
    are for the response variable, after conditioning on the model and covariates.
    This package has a data frame first syntax that allows for easy piping.
    Currently supported models include (log-) linear, (log-) linear mixed,
    generalized linear models, generalized linear mixed models, and
    accelerated failure time models.
poliscidata,2016-10-25,poliscidata: Datasets and Functions Featured in Pollock and Edwards, An R
Companion to Essentials of Political Analysis, Second Edition,Bundles the datasets and functions used in the textbook by Philip
    Pollock and Barry Edwards, An R Companion to Essentials of Political Analysis,
    Second Edition.
webTRISr,2017-08-25,webTRISr: A Wrapper Around 'WebTRIS' Traffic Flow API from Highways
England,Provides functions to query data from the 'WebTRIS' Traffic Flow API (from Highways England) into tidy data frames.
    The API documentation is available here: <http://webtris.highwaysengland.co.uk/api/swagger/ui/index>.
wikitaxa,2017-04-03,wikitaxa: Taxonomic Information from 'Wikipedia','Taxonomic' information from 'Wikipedia', 'Wikicommons',
    'Wikispecies', and 'Wikidata'. Functions included for getting
    taxonomic information from each of the sources just listed, as
    well performing taxonomic search.
xtensor,2017-09-11,xtensor: Headers for the 'xtensor' Library,The 'xtensor' C++ library for numerical analysis with
 multi-dimensional array expressions is provided as a header-only
 C++14 library. It offers an extensible expression system enabling
 lazy broadcasting; an API following the idioms of the C++ standard
 library; and tools to manipulate array expressions and build upon 'xtensor'.
antaresRead,2017-04-03,antaresRead: Import, Manipulate and Explore the Results of an 'Antares'
Simulation,Import, manipulate and explore results generated by 'Antares', a 
    powerful open source software developed by RTE (Réseau de Transport d’Électricité) to simulate and study electric power systems
    (more information about 'Antares' here : <https://github.com/AntaresSimulatorTeam/Antares_Simulator>). You can see the results of several ANTARES studies here : <http://bpnumerique.rte-france.com/>. 
bsplinePsd,2017-07-18,bsplinePsd: Bayesian Nonparametric Spectral Density Estimation Using
B-Spline Priors,Implementation of a Metropolis-within-Gibbs MCMC algorithm to flexibly estimate the spectral density of a stationary time series.  The algorithm updates a nonparametric B-spline prior using the Whittle likelihood to produce pseudo-posterior samples and is based on the work presented in Edwards, M.C., Meyer, R. and Christensen, N., Statistics and Computing (2018). <doi.org/10.1007/s11222-017-9796-9>.
charlatan,2017-06-16,charlatan: Make Fake Data,Make fake data, supporting addresses, person names, dates,
    times, colors, coordinates, currencies, digital object identifiers
    ('DOIs'), jobs, phone numbers, 'DNA' sequences, doubles and integers
    from distributions and within a range.
evaluator,2017-02-26,evaluator: Quantified Risk Assessment Toolkit,An open source risk analysis toolkit based on the OpenFAIR taxonomy 
  <https://www2.opengroup.org/ogsys/catalog/C13K> and risk assessment standard 
  <https://www2.opengroup.org/ogsys/catalog/C13G>. Empowers an organization to 
  perform a quantifiable, repeatable, and data-driven risk review.
hNMF,2017-03-15,hNMF: Hierarchical Non-Negative Matrix Factorization,Hierarchical and single-level non-negative matrix factorization. Several NMF algorithms are available.
PowerUpR,2016-11-01,PowerUpR: Power Analysis Tools for Multilevel Randomized Experiments,
 Includes tools to calculate statistical power, minimum detectable effect size, and minimum required sample size for various multilevel randomized experiments with continuous outcomes. Some of the functions can assist with planning two- and three-level cluster-randomized trials (CRTs) sensitive to moderation effects, and with planning two-level CRTs sensitive to 2-2-1 and 2-1-1 mediation effects. See 'PowerUp!' series at <https://www.causalevaluation.org/>. 
PWEALL,2016-12-23,PWEALL: Design and Monitoring of Survival Trials Accounting for Complex
Situations,Calculates various functions needed for design and monitoring survival trials
    accounting for complex situations such as delayed treatment effect, treatment crossover, non-uniform accrual,
    and different censoring distributions between groups. The event time distribution is assumed to be
    piecewise exponential (PWE) distribution and the entry time is assumed to be piecewise uniform distribution.
    As compared with Version 1.2.1, two more types of hybrid crossover are added. 
    A bug is corrected in the function "pwecx" that calculates the crossover-adjusted survival, distribution, 
    density, hazard and cumulative hazard functions. 
    Also, to generate the crossover-adjusted event time random variable,  a more efficient 
    algorithm is used and the output includes crossover indicators. 
sdpt3r,2017-09-04,sdpt3r: Semi-Definite Quadratic Linear Programming Solver,Solves the general Semi-Definite Linear Programming formulation using an R implementation of SDPT3 (K.C. Toh, M.J. Todd, and R.H. Tutuncu (1999) <doi:10.1080/10556789908805762>). This includes problems such as the nearest correlation matrix problem (Higham (2002) <doi:10.1093/imanum/22.3.329>), D-optimal experimental design (Smith (1918) <doi:10.2307/2331929>), Distance Weighted Discrimination (Marron and Todd (2012) <doi:10.1198/016214507000001120>), as well as graph theory problems including the maximum cut problem. Technical details surrounding SDPT3 can be found in R.H Tutuncu, K.C. Toh, and M.J. Todd (2003) <doi:10.1007/s10107-002-0347-5>. 
BimodalIndex,2017-07-14,BimodalIndex: The Bimodality Index,Defines the functions used to compute the
  bimodal index as defined by Wang et al. (2009)
  <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2730180/>,
  <doi:10.4137/CIN.S2846>.
breathtestcore,2017-05-11,breathtestcore: Core Functions to Read and Fit 13c Time Series from Breath Tests,Reads several formats of 13C data (IRIS/Wagner, BreathID) and CSV.
        Creates artificial sample data for testing. 
        Fits Maes/Ghoos, Bluck-Coward self-correcting formula using 'nls', 'nlme'.
        Methods to fit breath test curves with Bayesian Stan methods are refactored to 
        package 'breathteststan'. For a Shiny GUI, see package 
        'dmenne/breathtestshiny' on github.
clickR,2016-11-21,clickR: Fix Data and Create Report Tables from Different Objects,Tools for assessing data quality, performing exploratory analysis, 
    fixing data errors in numerical, factor and date variables and creating report 
    tables from models and summaries.
dataPreparation,2017-07-07,dataPreparation: Automated Data Preparation,Do most of the painful data preparation for a data science project with a minimum amount of code; Take advantages of data.table efficiency and use some algorithmic trick in order to perform data preparation in a time and RAM efficient way.
fergm,2017-08-14,fergm: Estimation and Fit Assessment of Frailty Exponential Random
Graph Models,Frailty Exponential Random Graph Models estimated through pseudo likelihood with frailty terms estimated using 'Stan' as per Box-Steffensmeier et. al (2017) <doi:10.7910/DVN/K3D1M2>.
    Goodness of fit for Frailty Exponential Random Graph Models is also available, with easy visualizations for comparison to fit Exponential Random Graph Models.  
GenAlgo,2017-07-13,GenAlgo: Classes and Methods to Use Genetic Algorithms for Feature
Selection,Defines classes and methods that can be used
  to implement genetic algorithms for feature selection.  The idea is
  that we want to select a fixed number of features to combine into a
  linear classifier that can predict a binary outcome, and can use a
  genetic algorithm heuristically to select an optimal set of features.
pinyin,2017-06-19,pinyin: Convert Chinese Characters into Pinyin, Sijiao, Wubi or Other
Codes,Convert Chinese characters into Pinyin (the official romanization system for Standard Chinese in mainland China, Malaysia, Singapore, and Taiwan. See <https://en.wikipedia.org/wiki/Pinyin> for details), Sijiao (four or five numerical digits per character. See <https://en.wikipedia.org/wiki/Four-Corner_Method>.), Wubi (an input method with five strokes. See <https://en.wikipedia.org/wiki/Wubi_method>) or user-defined codes.
pivottabler,2017-03-27,pivottabler: Create Pivot Tables in R,Create regular pivot tables with just a few lines of R.  
    More complex pivot tables can also be created, e.g. pivot tables
    with irregular layouts, multiple calculations and/or derived 
    calculations based on multiple data frames.  Pivot tables are
    constructed using R only and can be written to a range of
    output formats (plain text, 'HTML', 'Latex' and 'Excel'), 
    including with styling/formatting.
bcROCsurface,2016-11-17,bcROCsurface: Bias-Corrected Methods for Estimating the ROC Surface of
Continuous Diagnostic Tests,The bias-corrected estimation methods for the receiver operating characteristics
  ROC surface and the volume under ROC surfaces (VUS) under missing at random (MAR)
  assumption.
bookdownplus,2017-06-22,bookdownplus: Generate Assorted Books and Documents with R 'bookdown' Package,A collection and selector of R 'bookdown' templates. 'bookdownplus' helps you write academic journal articles, guitar books, chemical equations, mails, calendars, and diaries. R 'bookdownplus' extends the features of 'bookdown', and simplifies the procedure. Users only have to choose a template, clarify the book title and author name, and then focus on writing the text. No need to struggle in 'YAML' and 'LaTeX'.
grattan,2017-01-18,grattan: Australian Tax Policy Analysis,Utilities for costing and evaluating Australian tax policy, including high-performance tax and transfer calculators, a fast method of projecting tax collections, and an interface to common indices from the Australian Bureau of Statistics.  Written to support Grattan Institute's Australian Perspectives program. For access to the 'taxstats' package, please run
 install.packages("taxstats", repos = "https://hughparsonage.github.io/tax-drat/", type = "source"). 
 N.B. The 'taxstats' package is approximately 50 MB.
queuecomputer,2016-11-15,queuecomputer: Computationally Efficient Queue Simulation,Implementation of a computationally efficient method for
    simulating queues with arbitrary arrival and service times.
cosinor2,2017-08-21,cosinor2: Extended Tools for Cosinor Analysis of Rhythms,Statistical procedures for calculating population–mean cosinor, non–stationary cosinor, estimation of best–fitting period, tests of population rhythm differences and more. See Cornélissen, G. (2014). <doi:10.1186/1742-4682-11-16>.
crminer,2017-04-27,crminer: Fetch 'Scholary' Full Text from 'Crossref',Text mining client for 'Crossref' (<https://crossref.org>). Includes
    functions for getting getting links to full text of articles, fetching full
    text articles from those links or Digital Object Identifiers ('DOIs'),
    and text extraction from 'PDFs'.
define,2017-09-30,define: Create FDA-Style Data and Program Definitions,Creates a directory of archived files with a descriptive 'PDF'
 document at the root level (i.e. 'define.pdf') containing tables
 of definitions of data items and relative-path hyperlinks to 
 the documented files. Converts file extensions to 'txt' per FDA
 expectations and converts 'CSV' files to 'SAS' Transport format.
 Relies on data item descriptors stored as per R package 'spec'.
 See 'package?define'. See also '?define'. 
 Requires a compatible installation of 'pdflatex',
 e.g. <https://miktex.org/>.
dendroTools,2017-09-28,dendroTools: Linear and Nonlinear Methods for Analyzing Dendroclimatological
Data,Provides novel dendroclimatological methods, primarily used by the
    Tree-ring research community. There are two core functions. The first one is 
    daily_response(), which finds the optimal sequence of days that are related 
    to one or more tree-ring proxy records. The second one is compare_methods(), 
    which effectively compares several linear and nonlinear regression algorithms.  
dslabs,2017-01-19,dslabs: Data Science Labs,Datasets and functions that can be used for data analysis practice, homework and projects in data science courses and workshops. 
readJDX,2016-12-22,readJDX: Import Data in the JCAMP-DX Format,Import data written in the JCAMP-DX format. This is an instrument-independent format used in the field of spectroscopy. Examples include IR, NMR, and Raman spectroscopy. See the vignette for background and supported formats.  The official JCAMP-DX site is <http://www.jcamp-dx.org/>.
stormwindmodel,2017-01-09,stormwindmodel: Model Tropical Cyclone Wind Speeds,Allows users to input tracking data for a hurricane
    or other tropical storm, along with a data frame of grid points at which
    to model wind speeds. Functions in this package will then calculate wind
    speeds at each point based on wind model equations. This modeling framework
    is currently set up to model winds for North American locations with 
    Atlantic basin storms. This work was supported 
    in part by grants from the National Institute of Environmental Health 
    Sciences (R00ES022631), the National Science Foundation (1331399), and the 
    Department of Energy (DE-FG02-08ER64644).
analytics,2017-01-26,analytics: Regression Outlier Detection, Stationary Bootstrap, Testing Weak
Stationarity, NA Imputation, and Other Tools for Data Analysis,Current version includes outlier detection in a fitted linear model, stationary bootstrap using a truncated geometric distribution, a comprehensive test for weak stationarity, missing value imputation, column/rows sums/means by group, weighted biplots, and a heuristic to obtain a better initial configuration in non-metric MDS.
touch,2016-12-17,touch: Tools of Utilization and Cost in Healthcare,R implementation of the software tools developed in the H-CUP
    (Healthcare Cost and Utilization Project) <https://www.hcup-us.ahrq.gov>
    and AHRQ (Agency for Healthcare Research and Quality)
    <https://www.ahrq.gov>.  It currently contains functions for mapping ICD-9
    codes to the AHRQ comorbidity measures and translating ICD-9
    (resp. ICD-10) codes to ICD-10 (resp. ICD-9) codes based on GEM (General
    Equivalence Mappings) from CMS (Centers for Medicare and Medicaid
    Services).
GSED,2016-10-21,GSED: Group Sequential Enrichment Design,Provides function to apply "Group sequential enrichment design incorporating subgroup selection" (GSED) method proposed by Magnusson and Turnbull (2013) <doi:10.1002/sim.5738>.
hoardr,2017-04-21,hoardr: Manage Cached Files,Suite of tools for managing cached files, targeting
    use in other R packages. Uses 'rappdirs' for cross-platform paths.
    Provides utilities to manage cache directories, including targeting
    files by path or by key; cached directories can be compressed and
    uncompressed easily to save disk space.
psychmeta,2017-08-21,psychmeta: Psychometric Meta-Analysis Toolkit,Tools for computing bare-bones and psychometric meta-analyses and for generating psychometric data for use in meta-analysis simulations. Supports bare-bones, individual-correction, and artifact-distribution methods for meta-analyzing correlations and d values. Includes tools for converting effect sizes, computing sporadic artifact corrections, reshaping meta-analytic databases, computing multivariate corrections for range variation, and more. Bugs can be reported to <https://github.com/psychmeta/psychmeta/issues> or <issues@psychmeta.com>.
Rnightlights,2017-08-05,Rnightlights: Satellite Nightlight Data Extraction,Extracts raster and zonal statistics
    from satellite nightlight rasters downloaded from the United States 
    National Oceanic and Atmospheric Administration (<http://www.noaa.gov>) 
    free data repositories. Both the DMSP-OLS annual and SNPP-VIIRS monthly 
    nightlight raster data are supported. Satellite nightlight raster tiles are 
    downloaded and cropped to the country boundaries using shapefiles from the GADM
    database of Global Administrative Areas (<http://gadm.org>). Zonal statistics
    are then calculated at the lowest administrative boundary for the selected
    country and cached locally for future retrieval. Finally, a simple data
    explorer/browser is included that allows one to visualize the cached data e.g.
    graphing, mapping and clustering regional data.
treemapify,2017-08-28,treemapify: Draw Treemaps in 'ggplot2',Provides 'ggplot2' geoms for drawing treemaps.
bamlss,2017-02-22,bamlss: Bayesian Additive Models for Location Scale and Shape (and
Beyond),Infrastructure for estimating probabilistic distributional regression models in a Bayesian framework.
  The distribution parameters may capture location, scale, shape, etc. and every parameter may depend
  on complex additive terms (fixed, random, smooth, spatial, etc.) similar to a generalized additive model.
  The conceptual and computational framework is introduced in Umlauf, Klein, Zeileis (2017)
  <doi:10.1080/10618600.2017.1407325>.
mMPA,2017-03-22,mMPA: Implementation of Marker-Assisted Mini-Pooling with Algorithm,To determine the number of quantitative assays needed for a sample 
    of data using pooled testing methods, which include mini-pooling (MP), MP 
    with algorithm (MPA), and marker-assisted MPA (mMPA). To estimate the number 
    of assays needed, the package also provides a tool to conduct Monte Carlo (MC) 
    to simulate different orders in which the sample would be collected to form pools. 
    Using MC avoids the dependence of the estimated number of assays on any specific 
    ordering of the samples to form pools.
mrfDepth,2017-01-13,mrfDepth: Depth Measures in Multivariate, Regression and Functional
Settings,Tools to compute depth measures and implementations of related 
             tasks such as outlier detection, data exploration and 
            classification of multivariate, regression and functional data.
antaresViz,2017-04-20,antaresViz: Antares Visualizations,Visualize results generated by Antares, a powerful open source software
    developed by RTE to simulate and study electric power systems
    (more information about Antares here: <https://github.com/AntaresSimulatorTeam/Antares_Simulator>).
    This package provides functions that create interactive charts to help
    Antares users visually explore the results of their simulations. 
    You can see the results of several ANTARES studies here : <http://bpnumerique.rte-france.com/>.
BatchGetSymbols,2016-11-06,BatchGetSymbols: Downloads and Organizes Financial Data for Multiple Tickers,Makes it easy to download a large number of trade data from Yahoo Finance.
FLightR,2016-12-15,FLightR: A Package for Reconstructing Animal Paths from Solar Geolocation
Loggers,Spatio-temporal locations of an animal are computed 
    from annotated data with a hidden Markov  model via particle
    filter algorithm. The package is relatively robust to varying
    degrees of shading.
    The hidden Markov model is described in Movement Ecology (Rakhimberdiev et al., 2015)<doi:10.1186/s40462-015-0062-5>,
    general package description is in the Methods in Ecology and Evolution (Rakhimberdiev et al., 2017)<doi:10.1111/2041-210X.12765>
    and package accuracy assessed in the Journal of Avian Biology (Rakhimberdiev et al. 2016)<doi:10.1111/jav.00891>.
GetLattesData,2017-09-05,GetLattesData: Reading Bibliometric Data from Lattes Platform,A simple API for downloading and reading xml data directly from Lattes <http://lattes.cnpq.br/>.
GROAN,2017-07-12,GROAN: Genomic Regression Workbench,Workbench for testing genomic regression accuracy on (optionally noisy) phenotypes.
itunesr,2017-08-05,itunesr: Access iTunes App Store Ratings and Reviews using R,To enable 'iOS' App Developers to access iTunes App Store Ratings and Reviews using R to extract Basic App Information and Reviews submitted by their App users, Since Apple Store does not provide this straightforward. 
partialCI,2017-04-26,partialCI: Partial Cointegration,A collection of time series is partially cointegrated if a linear combination of these time series can be found so that the residual spread is partially autoregressive - meaning that it can be represented as a sum of an autoregressive series and a random walk. This concept is useful in modeling certain sets of financial time series and beyond, as it allows for the spread to contain transient and permanent components alike. Partial cointegration has been introduced by Clegg and Krauss (2017) <doi:10.1080/14697688.2017.1370122>, along with a large-scale empirical application to financial market data. The partialCI package comprises estimation, testing, and simulation routines for partial cointegration models in state space. Clegg et al. (2017) <https://hdl.handle.net/10419/150014> provide an in in-depth discussion of the package functionality as well as illustrating examples in the fields of finance and macroeconomics.
Rodam,2016-10-05,Rodam: Wrapper Functions for 'ODAM' (Open Data for Access and Mining)
Web Services,'ODAM' (Open Data for Access and Mining) is a framework that implements a simple way to make research data broadly accessible and fully available for reuse, including by a script language such as R. The main purpose is to make a data set accessible online with a minimal effort from the data provider, and to allow any scientists or bioinformaticians to be able to explore the data set and then extract a subpart or the totality of the data according to their needs. The Rodam package has only one class, 'odamws', that provides methods to allow you to retrieve online data using 'ODAM' Web Services. This obviously requires that data are implemented according the 'ODAM' approach , namely that the data subsets were deposited in the suitable data repository in the form of TSV files associated with  their metadata also described  in TSV files. See <http://www.slideshare.net/danieljacob771282/odam-open-data-access-and-mining>.
stacomiR,2017-06-26,stacomiR: Fish Migration Monitoring,Graphical outputs and treatment for a database of fish pass
    monitoring. It is a part of the 'STACOMI' open source project developed in
    France by the French Agency for Biodiversity (AFB) institute to centralize
    data obtained by fish pass monitoring. This version is available in French and
    English. See <http://stacomir.r-forge.r-project.org/> for more information on
    'STACOMI'.     
tidyselect,2017-07-24,tidyselect: Select from a Set of Strings,A backend for the selecting functions of the 'tidyverse'.
    It makes it easy to implement select-like functions in your own
    packages in a way that is consistent with other 'tidyverse'
    interfaces for selection.
airGR,2017-01-24,airGR: Suite of GR Hydrological Models for Precipitation-Runoff
Modelling,Hydrological modelling tools developed at Irstea-Antony (HYCAR Research Unit, France). The package includes several conceptual rainfall-runoff models (GR4H, GR4J, GR5J, GR6J, GR2M, GR1A), a snow accumulation and melt model (CemaNeige) and the associated functions for their calibration and evaluation. Use help(airGR) for package description and references.
emdi,2016-11-08,emdi: Estimating and Mapping Disaggregated Indicators,Functions that support estimating, assessing and mapping regional
    disaggregated indicators. So far, estimation methods comprise direct estimation
    and the model-based approach Empirical Best Prediction (see "Small area
    estimation of poverty indicators" by Molina and Rao (2010) <doi:10.1002/cjs.10051>), 
    as well as their precision estimates. The assessment of the used model
    is supported by a summary and diagnostic plots. For a suitable presentation of
    estimates, map plots can be easily created. Furthermore, results can easily be
    exported to excel.
NetworkChange,2017-03-30,NetworkChange: Bayesian Package for Network Changepoint Analysis,Network changepoint analysis for undirected network data. The package implements a hidden Markov multilinear tensor regression model (Park and Sohn, 2017, <http://jhp.snu.ac.kr/NetworkChange.pdf>). Functions for break number detection using the approximate marginal likelihood and WAIC are also provided.
wooldridge,2017-07-11,wooldridge: 111 Data Sets from "Introductory Econometrics: A Modern
Approach, 6e" by Jeffrey M. Wooldridge,Students learning both econometrics and R may find the introduction 
    to both challenging. However, if the text is "Introductory Econometrics: 
    A Modern Approach" by Jeffrey M. Wooldridge, they are in luck! 
    The wooldridge data package aims to lighten the task by efficiently loading 
    any data set found in the text with a single command. Data sets have all been 
    compressed to a fraction of their original size and are well documented. 
    Documentation files contain the page numbers of the text where each set is used, 
    the original source, time of publication, and notes suggesting ideas for further 
    exploratory data analysis and research. If one need's to brush-up on model syntax, a 
    vignette contains R solutions to examples from each chapter of the text. 
    Data sets are from the 6th edition (Wooldridge 2016, ISBN-13: 978-1-305-27010-7), 
    and are backwards compatible with all versions of the text.
EFAutilities,2016-12-03,EFAutilities: Utility Functions for Exploratory Factor Analysis,A number of utility function for exploratory factor analysis
    are included in this package. In particular, it computes standard errors for
    parameter estimates and factor correlations under a variety of conditions.
mindr,2017-06-19,mindr: Convert Files Between Markdown or Rmarkdown Files and Mindmaps,Convert Markdown ('.md') or Rmarkdown ('.Rmd') files into FreeMind mindmap ('.mm') files, and vice versa. FreeMind mindmap ('.mm') files can be opened by or imported to common mindmap software such as 'FreeMind' (<http://freemind.sourceforge.net/wiki/index.php/Main_Page>) and 'XMind' (<http://www.xmind.net>).
nucim,2016-10-15,nucim: Nucleome Imaging Toolbox,Tools for 4D nucleome imaging. Quantitative analysis of the 3D nuclear landscape recorded with super-resolved fluorescence microscopy.
billboarder,2017-08-29,billboarder: Create Interactive Chart with the JavaScript 'Billboard' Library,Provides an 'htmlwidgets' interface to 'billboard.js', 
    a re-usable easy interface JavaScript chart library, based on D3 v4+.
    Chart types include line charts, scatterplots, bar/lollipop charts, histogram/density plots, pie/donut charts and gauge charts.
    All charts are interactive, and a proxy method is implemented to smoothly update a chart without rendering it again in 'shiny' apps. 
c212,2017-01-07,c212: Methods for Detecting Safety Signals in Clinical Trials Using
Body-Systems (System Organ Classes),Methods for detecting safety signals in clinical trials using groupings of adverse events by body-system or system organ class.The package title c212 is in reference to the original Engineering and Physical Sciences Research Council (UK) funded project which was named CASE 2/12.
easyreg,2016-10-13,easyreg: Easy Regression,Performs analysis of regression in simple designs with quantitative treatments, 
             including mixed models and non linear models. 
psda,2017-09-05,psda: Polygonal Symbolic Data Analysis,An implementation of symbolic polygonal data analysis. The package presents the estimation of main descriptive statistical measures, e.g, mean, covariance, variance, correlation and coefficient of variation. 
            In addition, transformation of the data in polygons. Empirical probability distribution function based on 
            polygonal histogram and regression models are presented.
sptemExp,2017-08-29,sptemExp: Constrained Spatiotemporal Mixed Models for Exposure Estimation,The approach of constrained spatiotemporal mixed models is to make reliable estimation of air pollutant concentrations at high spatiotemporal
    resolution (Li, L., Zhang, J., Meng, X., Fang, Y., Ge, Y., Wang, J., Wang, C., Wu, J., Kan, H. (2018) <doi.org/10.1016/j.rse.2018.09.001>; 
    Li, L., Lurmann, F., Habre, R., Urman, R., Rappaport, E., Ritz, B., Chen, J., Gilliland, F., Wu, J., (2017) <doi:10.1021/acs.est.7b01864>).
    This package is an extensive tool for this modeling approach with support of block Kriging (Goovaerts, P. (1997) <http://www.gbv.de/dms/goettingen/229148123.pdf>)
    and uses the PM2.5 modeling as examples. It provides the following functionality:
    (1) Extraction of covariates from the satellite images such as GeoTiff and NC4 raster;
    (2) Generation of temporal basis functions to simulate the seasonal trends in the study regions;
    (3) Generation of the regional monthly or yearly means of air pollutant concentration;
    (4) Generation of Thiessen polygons and spatial effect modeling;
    (5) Ensemble modeling for spatiotemporal mixed models, supporting multi-core parallel computing;
    (6) Integrated predictions with or without weights of the model's performance, supporting multi-core parallel computing;
    (7) Constrained optimization to interpolate the missing values;
    (8) Generation of the grid surfaces of air pollutant concentration estimates at high resolution;
    (9) Block Kriging for regional mean estimation at multiple scales.
pollen,2016-10-02,pollen: Analysis of Aerobiological Data,Supports analysis of aerobiological data. 
    Available features include determination of pollen season limits, 
    replacement of outliers (Kasprzyk and Walanus (2014) <doi:10.1007/s10453-014-9332-8>),
    and calculation of growing degree days.
ratelimitr,2016-12-20,ratelimitr: Rate Limiting for R,Allows to limit the rate at which one or more functions can be called.
rmapzen,2017-08-12,rmapzen: Client for 'Mapzen' and Related Map APIs,Provides an interface to 'Mapzen'-based APIs (including 
    geocode.earth, Nextzen, and NYC GeoSearch) for geographic search 
    and geocoding, isochrone calculation, and vector data to draw map tiles. 
    See <https://mapzen.com/documentation/> for more information. The original 
    Mapzen has gone out of business, but 'rmapzen' can be set up to work with 
    any provider who implements the Mapzen API. 
wallace,2017-01-24,wallace: A Modular Platform for Reproducible Modeling of Species Niches
and Distributions,The 'shiny' application 'wallace' is a modular platform for reproducible modeling of species niches and distributions. 'wallace' guides users through a complete analysis, from the acquisition of species occurrence and environmental data to visualizing model predictions on an interactive map, thus bundling complex workflows into a single, streamlined interface.
bazar,2017-01-14,bazar: Miscellaneous Basic Functions,A collection of miscellaneous functions for 
    copying objects to the clipboard ('Copy');
    manipulating strings ('concat', 'mgsub', 'trim', 'verlan'); 
    loading or showing packages ('library_with_dep', 'require_with_dep', 
    'sessionPackages'); 
    creating or testing for named lists ('nlist', 'as.nlist', 'is.nlist'), 
    formulas ('is.formula'), empty objects ('as.empty', 'is.empty'), 
    whole numbers ('as.wholenumber', 'is.wholenumber'); 
    testing for equality ('almost.equal', 'almost.zero') and computing 
    uniqueness ('almost.unique'); 
    getting modified versions of usual functions ('rle2', 'sumNA'); 
    making a pause or a stop ('pause', 'stopif'); 
    converting into a function ('as.fun'); 
    providing a C like ternary operator ('condition %?% true %:% false'); 
    finding packages and functions ('get_all_pkgs', 'get_all_funs');
    and others ('erase', '%nin%', 'unwhich', 'top', 'bot', 'normalize'). 
googledrive,2017-08-28,googledrive: An Interface to Google Drive,Manage Google Drive files from R. 
pdSpecEst,2017-01-16,pdSpecEst: An Analysis Toolbox for Hermitian Positive Definite Matrices,An implementation of data analysis tools for samples of symmetric or 
  Hermitian positive definite matrices, such as collections of covariance matrices 
  or spectral density matrices. The tools in this package can be used to perform: (i) 
  intrinsic wavelet transforms for curves (1D) or surfaces (2D) of Hermitian positive 
  definite matrices with applications to dimension reduction, denoising and clustering in the 
  space of Hermitian positive definite matrices; and (ii) exploratory data analysis and inference 
  for samples of positive definite matrices by means of intrinsic data depth functions and 
  rank-based hypothesis tests in the space of Hermitian positive definite matrices.
spmoran,2017-03-12,spmoran: Moran's Eigenvector-Based Spatial Regression Models,Functions for estimating Moran's eigenvector-based
    spatial regression models.
    For details see Murakami (2018) <arXiv:1703.04467>.
CMatching,2017-09-19,CMatching: Matching Algorithms for Causal Inference with Clustered Data,Provides functions to perform matching algorithms for causal inference with clustered data, as described in B. Arpino and M. Cannas (2016) <doi:10.1002/sim.6880>. Pure within-cluster and preferential within-cluster matching are implemented. Both algorithms provide causal estimates with cluster-adjusted estimates of standard errors. 
comtradr,2017-04-05,comtradr: Interface with the United Nations Comtrade API,Interface with and extract data from the United Nations Comtrade 
  API <https://comtrade.un.org/data/>. Comtrade provides country level shipping 
  data for a variety of commodities, these functions allow for easy API query 
  and data returned as a tidy data frame.
PWFSLSmoke,2017-03-11,PWFSLSmoke: Utilities for Working with Air Quality Monitoring Data,Utilities for working with air quality monitoring data
    with a focus on small particulates (PM2.5) generated by wildfire
    smoke. Functions are provided for downloading available data from
    the United States 'EPA' <https://www.epa.gov/outdoor-air-quality-data> and
    it's 'AirNow' air quality site <https://www.airnow.gov>.
    Additional sources of PM2.5 data made accessible by the package include:
    'AIRSIS' (password protected) <https://www.oceaneering.com/data-management/>
    and 'WRCC' <https://wrcc.dri.edu/cgi-bin/smoke.pl>.
    Data compilations are provided by 'PWFSL'
    <https://www.fs.fed.us/pnw/pwfsl/>.
uiucthemes,2016-10-27,uiucthemes: 'R' 'Markdown' Themes for 'UIUC' Documents and Presentations,A set of custom 'R' 'Markdown' templates for documents and
   presentations with the University of Illinois at Urbana-Champaign (UIUC)
   color scheme and identity standards.
auk,2017-07-05,auk: eBird Data Extraction and Processing in R,Extract and process bird sightings records from eBird 
    (<http://ebird.org>), an online tool for recording bird observations. 
    Public access to the full eBird database is via the eBird Basic Dataset 
    (EBD; see <http://ebird.org/ebird/data/download> for access), a downloadable 
    text file. This package is an interface to AWK for extracting data from the 
    EBD based on taxonomic, spatial, or temporal filters, to produce a 
    manageable file size that can be imported into R.
Delta,2017-06-06,Delta: Measure of Agreement Between Two Raters,Measure of agreement delta was originally by Martín & Femia (2004) <doi:10.1348/000711004849268>. 
    Since then has been considered as agreement measure for different 
    fields, since their behavior is usually better than the usual kappa index
    by Cohen (1960) <doi:10.1177/001316446002000104>. The main issue with delta 
    is that can not be computed by hand contrary to kappa. The current algorithm
    is based on the Version 5 of the delta windows program that can be found on
    <https://www.ugr.es/~bioest/software/delta/cmd.php?seccion=downloads>.
partitionComparison,2017-08-25,partitionComparison: Implements Measures for the Comparison of Two Partitions,Provides several measures ((dis)similarity, distance/metric,
    correlation, entropy) for comparing two partitions of the same set of
    objects. The different measures can be assigned to three different
    classes: Pair comparison (containing the famous Jaccard and Rand
    indices), set based, and information theory based.
    Many of the implemented measures can be found in
    Albatineh AN, Niewiadomska-Bugaj M and Mihalko D (2006)
    <doi:10.1007/s00357-006-0017-z> and
    Meila M (2007) <doi:10.1016/j.jmva.2006.11.013>.
    Partitions are represented by vectors of class labels which allow a
    straightforward integration with existing clustering algorithms
    (e.g. kmeans()). The package is mostly based on the S4 object system.
rjmcmc,2017-03-20,rjmcmc: Reversible-Jump MCMC Using Post-Processing,Performs reversible-jump Markov chain Monte Carlo (Green, 1995)
    <doi:10.2307/2337340>, specifically the restriction introduced by 
    Barker & Link (2013) <doi:10.1080/00031305.2013.791644>. By utilising 
    a 'universal parameter' space, RJMCMC is treated as a Gibbs sampling 
    problem. Previously-calculated posterior distributions are used to 
    quickly estimate posterior model probabilities. Jacobian matrices are 
    found using automatic differentiation.
soundgen,2017-09-04,soundgen: Parametric Voice Synthesis,Tools for sound synthesis and acoustic analysis.
    Performs parametric synthesis of sounds with harmonic and noise components
    such as animal vocalizations or human voice. Also includes tools for
    spectral analysis, pitch tracking, audio segmentation, self-similarity
    matrices, morphing, etc.
spatstat.data,2017-09-14,spatstat.data: Datasets for 'spatstat',Contains all the datasets for the 'spatstat' package.
TileManager,2017-01-16,TileManager: Tile Manager,Tools for creating and detecting tiling schemes for raster data sets.
ClassDiscovery,2017-07-12,ClassDiscovery: Classes and Methods for "Class Discovery" with Microarrays or
Proteomics,Defines the classes used for "class discovery" problems
  in the OOMPA project (<http://oompa.r-forge.r-project.org/>). Class
  discovery primarily consists of unsupervised clustering methods with
  attempts to assess their statistical significance. 
dataMaid,2017-01-02,dataMaid: A Suite of Checks for Identification of Potential Errors in a
Data Frame as Part of the Data Screening Process,Data screening is an important first step of any statistical
    analysis. dataMaid auto generates a customizable data report with a thorough
    summary of the checks and the results that a human can use to identify possible
    errors. It provides an extendable suite of test for common potential
    errors in a dataset. 
mdsOpt,2017-01-20,mdsOpt: Searching for Optimal MDS Procedure for Metric and
Interval-Valued Symbolic Data,Selecting the optimal multidimensional scaling (MDS) procedure for metric data via metric MDS (ratio, interval, mspline) and nonmetric MDS (ordinal). Selecting the optimal multidimensional scaling (MDS) procedure for interval-valued data via metric MDS (ratio, interval, mspline).Selecting the optimal multidimensional scaling procedure for interval-valued data by varying all combinations of normalization and optimization methods.Selecting the optimal MDS procedure for statistical data referring to the evaluation of tourist attractiveness of Lower Silesian counties.
 (Borg, I., Groenen, P.J.F., Mair, P. (2013) <doi:10.1007/978-3-642-31848-1>, 
 Groenen, P.J.F., Winsberg, S., Rodriguez, O., Diday, E. (2006) <doi:10.1016/j.csda.2006.04.003>,
 Walesiak, M. (2016) <doi:10.15611/ekt.2016.2.01>, 
 Walesiak, M. (2017) <doi:10.15611/ekt.2017.3.01>).
odr,2017-09-17,odr: Optimal Design and Statistical Power of Multilevel Randomized
Trials,Calculate the optimal sample allocation that minimizes the variance of
    treatment effect in multilevel randomized trials under fixed budget and cost structure,
    perform power analyses with and without accommodating costs and budget. The references 
    for proposed methods are: 
    (1) Shen, Z. (in progress). Using optimal sample allocation to
    improve statistical precision and design efficiency for multilevel randomized trials.
    (unpublished doctoral dissertation). University of Cincinnati, Cincinnati, OH.
    (2) Shen, Z., & Kelcey, B. (revise & resubmit). 
    Optimal sample allocation accounts for the full variation of sampling costs 
    in cluster-randomized trials.
    Journal of Educational and Behavioral Statistics. 
    (3) Shen, Z., & Kelcey, B. (2018, April). Optimal design of cluster
    randomized trials under condition- and unit-specific cost structures. Roundtable
    discussion presented at American Educational Research Association (AERA)
    annual conference.
    (4) Champely., S. (2018). pwr: Basic functions for power analysis 
    (Version 1.2-2) [Software]. Available from 
    <https://CRAN.R-project.org/package=pwr>.
PeakSegJoint,2017-08-16,PeakSegJoint: Joint Peak Detection in Several ChIP-Seq Samples,Jointly segment several ChIP-seq samples to find the peaks 
 which are the same and different across samples. The fast approximate
 maximum Poisson likelihood algorithm is described in
 "PeakSegJoint: fast supervised peak detection via joint segmentation
 of multiple count data samples"
 <arXiv:1506.01286> by TD Hocking and G Bourque.
RcmdrPlugin.RiskDemo,2017-08-09,RcmdrPlugin.RiskDemo: R Commander Plug-in for Risk Demonstration,R Commander plug-in to demonstrate various actuarial and financial risks. It includes valuation of bonds and stocks, portfolio optimization, classical ruin theory and demography. 
vein,2017-05-14,vein: Vehicular Emissions Inventories,Elaboration of vehicular emissions inventories,
    consisting in four stages, pre-processing activity data, preparing 
    emissions factors, estimating the emissions and post-processing of emissions 
    in maps and databases. More details in Ibarra-Espinosa et al (2018) <doi:10.5194/gmd-11-2209-2018>.
tensorBF,2016-12-29,tensorBF: Bayesian Tensor Factorization,Bayesian Tensor Factorization for decomposition of tensor data sets using the trilinear CANDECOMP/PARAFAC (CP) factorization, with automatic component selection. The complete data analysis pipeline is provided, including functions and recommendations for data normalization and model definition, as well as missing value prediction and model visualization. The method performs factorization for three-way tensor datasets and the inference is implemented with Gibbs sampling.
WeightedROC,2017-06-20,WeightedROC: Fast, Weighted ROC Curves,Fast computation of
 Receiver Operating Characteristic (ROC) curves
 and Area Under the Curve (AUC)
 for weighted binary classification problems
 (weights are example-specific cost values).
carData,2017-08-28,carData: Companion to Applied Regression Data Sets,
  Datasets to Accompany J. Fox and S. Weisberg, 
  An R Companion to Applied Regression, Third Edition, Sage (forthcoming).
loon,2017-07-26,loon: Interactive Statistical Data Visualization,An extendable toolkit for interactive data visualization and exploration.
metaplot,2017-04-17,metaplot: Data-Driven Plot Design,Designs plots in terms of core structure.  See 'example(metaplot)'.
 Primary arguments are (unquoted) column names; order and type (numeric or not)
 dictate the resulting plot.  Specify any y variables, x variable, any groups variable,
 and any conditioning variables to metaplot() to generate density plots, boxplots, 
 mosaic plots, scatterplots, scatterplot matrices, or conditioned plots. Use multiplot() 
 to arrange plots in grids. Wherever present, scalar column attributes 'label' and 'guide' 
 are honored, producing fully annotated plots with minimal effort. Attribute 'guide' 
 is typically units, but may be encoded() to provide interpretations of categorical 
 values (see '?encode').  Utility unpack() transforms scalar column attributes to row 
 values and pack() does the reverse, supporting tool-neutral storage of metadata along 
 with primary data. The package supports customizable aesthetics such as such as reference 
 lines, unity lines, smooths, log transformation, and linear fits. The user may choose
 between trellis and ggplot output. Compact syntax and integrated metadata promote workflow 
 scalability.
nanotime,2016-12-16,nanotime: Nanosecond-Resolution Time for R,Full 64-bit resolution date and time support with resolution up
 to nanosecond granularity is provided, with easy transition to and from the
 standard 'POSIXct' type.
nonmemica,2017-04-21,nonmemica: Create and Evaluate NONMEM Models in a Project Context,Systematically creates and modifies NONMEM(R) control streams. Harvests
 NONMEM output, builds run logs, creates derivative data, generates diagnostics.
 NONMEM (ICON Development Solutions <http://www.iconplc.com/>) is software for 
 nonlinear mixed effects modeling. See 'package?nonmemica'. 
clustermq,2017-08-28,clustermq: Evaluate Function Calls on HPC Schedulers (LSF, SGE, SLURM,
PBS/Torque),Evaluate arbitrary function calls using workers on HPC schedulers
    in single line of code. All processing is done on the network without
    accessing the file system. Remote schedulers are supported via SSH.
fDMA,2017-07-10,fDMA: Dynamic Model Averaging and Dynamic Model Selection for
Continuous Outcomes,Allows to estimate dynamic model averaging, dynamic model selection and median probability model. The original methods are implemented, as well as, selected further modifications of these methods. In particular the user might choose between recursive moment estimation and exponentially moving average for variance updating. Inclusion probabilities might be modified in a way using 'Google Trends'. The code is written in a way which minimises the computational burden (which is quite an obstacle for dynamic model averaging if many variables are used). For example, this package allows for parallel computations and Occam's window approach. The package is designed in a way that is hoped to be especially useful in economics and finance. Main reference: Raftery, A.E., Karny, M., Ettler, P. (2010) <doi:10.1198/TECH.2009.08104>. 
LearnGeom,2017-08-05,LearnGeom: Learning Plane Geometry,Contains some functions to learn and teach basic plane Geometry at undergraduate level with the aim of being helpful to young students with little programming skills.
shadow,2016-12-07,shadow: Geometric Shadow Calculations,Functions for calculating: (1) shadow height, (2) logical shadow flag, (3) shadow footprint, (4) Sky View Factor and (5) radiation load. Basic required inputs include a polygonal layer of obstacle outlines along with their heights (i.e. "extruded polygons"), sun azimuth and sun elevation. The package also provides functions for related preliminary calculations: breaking polygons into line segments, determining azimuth of line segments, shifting segments by azimuth and distance, constructing the footprint of a line-of-sight between an observer and the sun, and creating a 3D grid covering the surface area of extruded polygons.
antaresProcessing,2017-04-06,antaresProcessing: 'Antares' Results Processing,
    Process results generated by 'Antares', a powerful open source software developed by
    RTE (Réseau de Transport d’Électricité) to simulate and study electric power systems (more information about
    'Antares' here: <https://github.com/AntaresSimulatorTeam/Antares_Simulator>). You can see the results of several ANTARES studies here : <http://bpnumerique.rte-france.com/>. 
    This package provides functions to create new columns like net load, load factors, upward and
    downward margins or to compute aggregated statistics like economic surpluses
    of consumers, producers and sectors.
BETS,2016-12-20,BETS: Brazilian Economic Time Series,It provides access to and information about the most important
    Brazilian economic time series - from the Getulio Vargas Foundation <http://portal.fgv.br/en>,
    the Central Bank of Brazil <http://www.bcb.gov.br> and the Brazilian Institute of Geography
    and Statistics <http://www.ibge.gov.br>. It also presents tools for managing, analysing (e.g.
    generating dynamic reports with a complete analysis of a series) and exporting
    these time series.
ecm,2016-10-21,ecm: Build Error Correction Models,Functions for easy building of error correction models (ECM) for time series regression. 
scalpel,2017-03-14,scalpel: Processes Calcium Imaging Data,Identifies the locations of neurons, and estimates their calcium concentrations over time using the SCALPEL method proposed in Petersen, A., Simon, N., and Witten, D. SCALPEL: Extracting Neurons from Calcium Imaging Data <https://ajpetecom.files.wordpress.com/2017/12/scalpel_dec17.pdf>, which is to appear in the Annals of Applied Statistics.
textreadr,2017-01-11,textreadr: Read Text Documents into R,A small collection of convenience tools for reading text documents into R.
ggridges,2017-09-14,ggridges: Ridgeline Plots in 'ggplot2',Ridgeline plots provide a convenient way of visualizing changes in distributions over time or space. This package enables the creation of such plots in 'ggplot2'.
boxcoxmix,2017-07-29,boxcoxmix: Box-Cox-Type Transformations for Linear and Logistic Models with
Random Effects,Box-Cox-type transformations for linear and logistic models
             with random effects using non-parametric profile maximum
             likelihood estimation. The main functions are optim.boxcox()
             and boxcoxtype().
seplyr,2017-07-15,seplyr: Improved Standard Evaluation Interfaces for Common Data
Manipulation Tasks,The 'seplyr' (standard evaluation plying) package supplies improved
    standard evaluation adapter methods for important common 'dplyr' data manipulation tasks.
    In addition the 'seplyr' package supplies several new "key operations
    bound together" methods.  These include 'group_summarize()' (which
    combines grouping, arranging and calculation in an atomic unit),
    'add_group_summaries()' (which joins grouped summaries into a 'data.frame'
    in a well documented manner), 'add_group_indices()' (which adds
    per-group identifiers to a 'data.frame' without depending on row-order),
    'partition_mutate_qt()' (which optimizes mutate sequences), and 'if_else_device()'
    (which simulates per-row if-else blocks in expression sequences).
frequencyConnectedness,2017-05-02,frequencyConnectedness: Spectral Decomposition of Connectedness Measures,Accompanies a paper (Barunik, Krehlik (2018) <doi:10.1093/jjfinec/nby001>) dedicated to spectral decomposition of connectedness measures and their interpretation. We implement all the developed estimators as well as the historical counterparts. For more information, see the help or GitHub page (<https://github.com/tomaskrehlik/frequencyConnectedness>) for relevant information.
grf,2017-07-04,grf: Generalized Random Forests (Beta),A pluggable package for forest-based statistical estimation and inference.
    GRF currently provides methods for non-parametric least-squares regression,
    quantile regression, and treatment effect estimation (optionally using instrumental
    variables). This package is currently in beta, and we expect to make continual
    improvements to its performance and usability.
parallelDist,2017-06-06,parallelDist: Parallel Distance Matrix Computation using Multiple Threads,A fast parallelized alternative to R's native 'dist' function to
    calculate distance matrices for continuous, binary, and multi-dimensional
    input matrices, which supports a broad variety of 39 predefined distance
    functions from the 'stats', 'proxy' and 'dtw' R packages, as well as user-
    defined functions written in C++. For ease of use, the 'parDist' function
    extends the signature of the 'dist' function and uses the same parameter
    naming conventions as distance methods of existing R packages. The package
    is mainly implemented in C++ and leverages the 'RcppParallel' package to
    parallelize the distance computations with the help of the 'TinyThread'
    library. Furthermore, the 'Armadillo' linear algebra library is used for
    optimized matrix operations during distance calculations. The curiously
    recurring template pattern (CRTP) technique is applied to avoid virtual
    functions, which improves the Dynamic Time Warping calculations while
    the implementation stays flexible enough to support different DTW step
    patterns and normalization methods.
revengc,2017-08-18,revengc: Reverse Engineering Summarized Data,Decoupled (e.g. separate averages) and censored (e.g. > 100 species) variables are continually reported by many well-established organizations (e.g. World Health Organization (WHO), Centers for Disease Control and Prevention (CDC), World Bank, and various national censuses).  The challenge therefore is to infer what the original data could have been given summarized information.  We present an R package that reverse engineers decoupled and/or censored count data with two main functions.  The cnbinom.pars() function estimates the average and dispersion parameter of a censored univariate frequency table.  The rec() function reverse engineers summarized data into an uncensored bivariate table of probabilities.
smapr,2016-10-05,smapr: Acquisition and Processing of NASA Soil Moisture Active-Passive
(SMAP) Data,
    Facilitates programmatic access to NASA Soil Moisture Active
    Passive (SMAP) data with R. It includes functions to search for, acquire,
    and extract SMAP data.
geex,2017-09-04,geex: An API for M-Estimation,Provides a general, flexible framework for estimating parameters
    and empirical sandwich variance estimator from a set of unbiased estimating
    equations (i.e., M-estimation in the vein of Stefanski & Boos (2002)
    <doi:10.1198/000313002753631330>). Also provides an API to compute finite-sample
    variance corrections. 
geojsonR,2017-03-28,geojsonR: A GeoJson Processing Toolkit,Includes functions for processing GeoJson objects <https://en.wikipedia.org/wiki/GeoJSON> relying on 'RFC 7946' <https://tools.ietf.org/pdf/rfc7946.pdf>. The geojson encoding is based on 'json11', a tiny JSON library for 'C++11' <https://github.com/dropbox/json11>. Furthermore, the source code is exported in R through the 'Rcpp' and 'RcppArmadillo' packages.
jtools,2017-02-27,jtools: Analysis and Presentation of Social Scientific Data,This is a collection of tools that the author (Jacob) has written
  for the purpose of more efficiently understanding and sharing the results of
  (primarily) regression analyses. There are a number of functions focused
  specifically on the interpretation and presentation of interactions.
  Just about everything supports models from the survey package.
sparsepp,2016-12-30,sparsepp: 'Rcpp' Interface to 'sparsepp',Provides interface to 'sparsepp' - fast, memory efficient hash map. 
    It is derived from Google's excellent 'sparsehash' implementation.
    We believe 'sparsepp' provides an unparalleled combination of performance and memory usage, 
    and will outperform your compiler's unordered_map on both counts. 
    Only Google's 'dense_hash_map' is consistently faster, at the cost of much greater 
    memory usage (especially when the final size of the map is not known in advance).
uGMAR,2017-08-28,uGMAR: Estimate Univariate Gaussian or Student's t Mixture
Autoregressive Model,Maximum likelihood estimation of univariate Gaussian Mixture Autoregressive (GMAR),
    Student's t Mixture Autoregressive (StMAR) and Gaussian and Student's t Mixture Autoregressive (G-StMAR) models, 
    quantile residual tests, graphical diagnostics, forecast and simulate from GMAR, StMAR and G-StMAR processes. 
    Also general linear constraints and restricting autoregressive parameters to be the same for all regimes are supported. 
    Leena Kalliovirta, Mika Meitz, Pentti Saikkonen (2015) <doi:10.1111/jtsa.12108>, 
    Mika Meitz, Daniel Preve, Pentti Saikkonen (2018) <arXiv:1805.04010>.
HEMDAG,2017-08-11,HEMDAG: Hierarchical Ensemble Methods for Directed Acyclic Graphs,An implementation of Hierarchical Ensemble Methods for Directed Acyclic Graphs (DAGs). The 'HEMDAG' package can be used to enhance the predictions of virtually any flat learning methods, by taking into account the hierarchical nature of the classes of a bio-ontology. 'HEMDAG' is specifically designed for exploiting the hierarchical relationships of DAG-structured taxonomies, such as the Human Phenotype Ontology (HPO) or the Gene Ontology (GO), but it can be also safely applied to tree-structured taxonomies (as FunCat), since trees are DAGs. 'HEMDAG' scale nicely both in terms of the complexity of the taxonomy and in the cardinality of the examples. (Marco Notaro, Max Schubach, Peter N. Robinson and Giorgio Valentini (2017) <doi:10.1186/s12859-017-1854-y>).
RInno,2017-03-02,RInno: An Installation Framework for Shiny Apps,Installs shiny apps packaged as stand-alone Electron apps using Inno Setup, an open source software that builds installers for Windows programs <http://www.jrsoftware.org/ishelp/>.
datasauRus,2017-05-09,datasauRus: Datasets from the Datasaurus Dozen,The Datasaurus Dozen is a set of datasets with the same summary statistics. They 
             retain the same summary statistics despite having radically different distributions.
             The datasets represent a larger and quirkier object lesson that is typically taught
             via Anscombe's Quartet (available in the 'datasets' package). Anscombe's Quartet
             contains four very different distributions with the same summary statistics and as 
             such highlights the value of visualisation in understanding data, over and above
             summary statistics. As well as being an engaging variant on the Quartet, the data
             is generated in a novel way. The simulated annealing process used to derive datasets 
             from the original Datasaurus is detailed in "Same Stats, Different Graphs: Generating 
             Datasets with Varied Appearance and Identical Statistics through Simulated Annealing" 
             <doi:10.1145/3025453.3025912>.
gravity,2017-01-31,gravity: Estimation Methods for Gravity Models,A wrapper of different standard estimation methods for gravity models. 
  This package provides estimation methods for log-log models and multiplicative models.
phuse,2017-09-26,phuse: Web Application Framework for 'PhUSE' Scripts,Make it easy to review, download and execute scripts stored in Github
  'phuse-scripts' repository <https://github.com/phuse-org/phuse-scripts>. Some examples
  included show the web application framework using the script metadata. The 'PhUSE'
  is Pharmaceutical Users Software Exchange <http://www.phuse.eu>.
rcoreoa,2017-06-20,rcoreoa: Client for the CORE API,Client for the CORE API (<https://core.ac.uk/docs/>).
    CORE (<https://core.ac.uk>) aggregates open access research
    outputs from repositories and journals worldwide and make them
    available to the public.
ROptSpace,2017-09-05,ROptSpace: Matrix Reconstruction from a Few Entries,Matrix reconstruction, also known as matrix completion, is
    the task of inferring missing entries of a partially observed matrix.
    This package provides a method called OptSpace,
    which was proposed by Keshavan, R.H., Oh, S., and Montanari, A. (2009)
    <doi:10.1109/ISIT.2009.5205567> for a case under low-rank assumption.
BayLum,2017-09-01,BayLum: Chronological Bayesian Models Integrating Optically Stimulated
Luminescence and Radiocarbon Age Dating,Bayesian analysis of luminescence data and C-14 age estimates. Bayesian models are based on the following publications: Combes, B. & Philippe, A. (2017) <doi:10.1016/j.quageo.2017.02.003> and Combes et al (2015) <doi:10.1016/j.quageo.2015.04.001>. This includes, amongst others, data import, export, application of age models and palaeodose model.
CIAAWconsensus,2016-12-31,CIAAWconsensus: Isotope Ratio Meta-Analysis,Calculation of consensus values for atomic weights, isotope amount ratios, and isotopic abundances with the associated uncertainties using multivariate meta-regression approach for consensus building.
dataCompareR,2017-07-17,dataCompareR: Compare Two Data Frames and Summarise the Difference,Easy comparison of two tabular data
    objects in R. Specifically designed to show differences between two sets of
    data in a useful way that should make it easier to understand the differences,
    and if necessary, help you work out how to remedy them. Aims
    to offer a more useful output than all.equal() when your two data sets do not
    match, but isn't intended to replace all.equal() as a way to test for equality.
replyr,2016-12-09,replyr: Patches to Use 'dplyr' on Remote Data Sources,Patches to use 'dplyr' on remote data sources ('SQL' databases,
   'Spark' 2.0.0 and above) in a reliable "generic" fashion (generic meaning
   user code works similarly on all such sources, without needing per-source
   adaption).  Due to the fluctuating nature of 'dplyr'/'dbplyr'/'rlang' 'APIs' this package
   is going into maintenance mode.  Most of the 'replyr' functions are already 
   done better by one of the non-monolithic replacement packages: 'wrapr', 'seplyr', 'rquery',
   or 'cdata'.
hetGP,2017-09-28,hetGP: Heteroskedastic Gaussian Process Modeling and Design under
Replication,Performs Gaussian process regression with heteroskedastic noise following Binois, M., Gramacy, R., Ludkovski, M. (2016) <arXiv:1611.05902>. The input dependent noise is modeled as another Gaussian process. Replicated observations are encouraged as they yield computational savings. Sequential design procedures based on the integrated mean square prediction error and lookahead heuristics are provided, and notably fast update functions when adding new observations.
later,2017-06-25,later: Utilities for Delaying Function Execution,Executes arbitrary R or C functions some time after the current
    time, after the R execution stack has emptied.
ReIns,2016-12-23,ReIns: Functions from "Reinsurance: Actuarial and Statistical Aspects",Functions from the book "Reinsurance: Actuarial and Statistical Aspects" (2017) by Hansjoerg Albrecher, Jan Beirlant and Jef Teugels <http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470772689.html>.
gdns,2016-10-01,gdns: Tools to Work with Google's 'DNS-over-HTTPS' ('DoH') 'API',To address the problem of insecurity of 'UDP'-based 'DNS' requests,
    'Google Public DNS' offers 'DNS' resolution over an encrypted 'HTTPS'
    connection. 'DNS-over-HTTPS' greatly enhances privacy and security
    between a client and a recursive resolver, and complements 'DNSSEC'
    to provide end-to-end authenticated 'DNS' lookups. Functions that enable
    querying individual requests that bulk requests that return detailed
    responses and bulk requests are both provided. Support for reverse
    lookups is also provided. See <https://developers.google.com/speed/public-dns/docs/dns-over-https> 
    for more information.
mbir,2017-08-14,mbir: Magnitude-Based Inferences,Allows practitioners and researchers a wholesale approach for deriving magnitude-based inferences from raw data. A major goal of 'mbir' is to programmatically detect appropriate statistical tests to run in lieu of relying on practitioners to determine correct stepwise procedures independently.
aiRthermo,2017-07-15,aiRthermo: Atmospheric Thermodynamics and Visualization,Deals with many computations related to the thermodynamics of atmospheric processes. It includes many functions designed to consider the density of air with varying degrees of water vapour in it, saturation pressures and mixing ratios, conversion of moisture indices, computation of atmospheric states of parcels subject to dry or pseudoadiabatic vertical evolutions and atmospheric instability indices that are routinely used for operational weather forecasts or meteorological diagnostics.
graphon,2017-09-04,graphon: A Collection of Graphon Estimation Methods,Provides a not-so-comprehensive list of methods for estimating graphon,
    a symmetric measurable function, from a single or multiple of observed networks. 
    For a detailed introduction on graphon and popular estimation techniques, 
    see the paper by Orbanz, P. and Roy, D.M.(2014) <doi:10.1109/TPAMI.2014.2334607>.
    It also contains several auxiliary functions for generating sample networks
    using various network models and graphons.
hIRT,2017-07-23,hIRT: Hierarchical Item Response Theory Models,Implementation of a class of hierarchical item response
  theory (IRT) models where both the mean and the variance of latent preferences
  (ability parameters) may depend on observed covariates. The current
  implementation includes both the two-parameter latent trait model for binary data and the
  graded response model for ordinal data. Both are fitted via the Expectation-Maximization (EM)
  algorithm. Asymptotic standard errors are derived from the observed information
  matrix. 
reprex,2017-01-10,reprex: Prepare Reproducible Example Code via the Clipboard,Convenience wrapper that uses the 'rmarkdown' package to render
  small snippets of code to target formats that include both code and output.
  The goal is to encourage the sharing of small, reproducible, and runnable
  examples on code-oriented websites, such as <https://stackoverflow.com> and
  <https://github.com>, or in email. The user's clipboard is the default source
  of input code and the default target for rendered output. 'reprex' also
  extracts clean, runnable R code from various common formats, such as
  copy/paste from an R session. 
usmap,2017-01-29,usmap: US Maps Including Alaska and Hawaii,Obtain United States map data frames of varying region types (e.g. county, 
    state). The map data frames include Alaska and Hawaii conveniently placed to the
    bottom left, as they appear in most maps of the US. Convenience functions for plotting
    choropleths and working with FIPS codes are also provided.
BLPestimatoR,2017-03-16,BLPestimatoR: Performs a BLP Demand Estimation,Provides the estimation algorithm to perform the demand estimation described in Berry, Levinsohn and Pakes (1995) <doi:10.2307/2171802> . The routine uses analytic gradients and offers a large number of implemented integration methods and optimization routines.
spData,2017-07-23,spData: Datasets for Spatial Analysis,Diverse spatial datasets for demonstrating, benchmarking and teaching spatial data analysis. 
    It includes R data of class sf (defined by the package 'sf'), Spatial ('sp'), and nb ('spdep').
    Unlike other spatial data packages such as 'rnaturalearth' and 'maps', 
    it also contains data stored in a range of file formats including GeoJSON, ESRI Shapefile and GeoPackage. 
    Some of the datasets are designed to illustrate specific analysis techniques.
    cycle_hire() and cycle_hire_osm(), for example, is designed to illustrate point pattern analysis techniques.
LabourMarketAreas,2016-10-03,LabourMarketAreas: Identification, Tuning, Visualisation and Analysis of Labour
Market Areas,Produces Labour Market Areas from commuting flows available at elementary territorial units. It provides tools for automatic tuning based on spatial contiguity. It also allows for statistical analyses and visualisation of the new functional geography.
mize,2017-07-14,mize: Unconstrained Numerical Optimization Algorithms,Optimization algorithms implemented in R, including
    conjugate gradient (CG), Broyden-Fletcher-Goldfarb-Shanno (BFGS) and the
    limited memory BFGS (L-BFGS) methods. Most internal parameters can be set 
    through the call interface. The solvers hold up quite well for 
    higher-dimensional problems.
moveVis,2017-05-18,moveVis: Movement Data Visualization,Tools to visualize movement data (e.g. from GPS tracking) and temporal changes of environmental data (e.g. from remote sensing) by creating video animations.
sgmcmc,2017-07-18,sgmcmc: Stochastic Gradient Markov Chain Monte Carlo,Provides functions that performs popular stochastic gradient Markov chain Monte Carlo (SGMCMC) methods on user specified models. The required gradients are automatically calculated using 'TensorFlow' <https://www.tensorflow.org/>, an efficient library for numerical computation. This means only the log likelihood and log prior functions need to be specified. The methods implemented include stochastic gradient Langevin dynamics (SGLD), stochastic gradient Hamiltonian Monte Carlo (SGHMC), stochastic gradient Nose-Hoover thermostat (SGNHT) and their respective control variate versions for increased efficiency. References: M. Welling, Y. W. Teh (2011) <http://www.icml-2011.org/papers/398_icmlpaper.pdf>; T. Chen, E. B. Fox, C. E. Guestrin (2014) <arXiv:1402.4102>; N. Ding, Y. Fang, R. Babbush, C. Chen, R. D. Skeel, H. Neven (2014) <https://papers.nips.cc/paper/5592-bayesian-sampling-using-stochastic-gradient-thermostats>; J. Baker, P. Fearnhead, E. B. Fox, C. Nemeth (2017) <arXiv:1706.05439>.
document,2017-05-08,document: Run 'roxygen2' on (Chunks of) Single Code Files,Have you ever been tempted to create 'roxygen2'-style documentation
    comments for one of your functions that was not part of one of your
    packages (yet)?
    This is exactly what this package is about: running 'roxygen2' on
    (chunks of) a single code file.
EnvCpt,2016-10-13,EnvCpt: Detection of Structural Changes in Climate and Environment Time
Series,Tools for automatic model selection and diagnostics for Climate and Environmental data.  In particular the envcpt() function does automatic model selection between a variety of trend, changepoint and autocorrelation models.  The envcpt() function should be your first port of call.
HDtest,2016-12-30,HDtest: High Dimensional Hypothesis Testing for Mean Vectors, Covariance
Matrices, and White Noise of Vector Time Series,High dimensional testing procedures on mean, covariance and white noises.
knor,2017-08-14,knor: Non-Uniform Memory Access ('NUMA') Optimized, Parallel K-Means,The k-means 'NUMA' Optimized Routine library or 'knor' is a highly optimized and fast library for computing k-means in parallel with accelerations for Non-Uniform Memory Access ('NUMA') architectures.
nse,2017-01-24,nse: Numerical Standard Errors Computation in R,Collection of functions designed to calculate numerical standard error (NSE) of univariate time series as described in Ardia et al. (2018) <doi:10.2139/ssrn.2741587> and Ardia and Bluteau (2017) <doi:10.21105/joss.00172>.
SimPhe,2017-01-04,SimPhe: Tools to Simulate Phenotype(s) with Epistatic Interaction,Provides functions to simulate single or multiple, independent or correlated phenotype(s) with additive, dominance effects and their interactions. Also includes functions to generate phenotype(s) with specific heritability. Flexible and user-friendly options for simulation.
bigstep,2016-10-27,bigstep: Stepwise Selection for Large Data Sets,Selecting linear and generalized linear models for large data sets
    using modified stepwise procedure and modern selection criteria (like
    modifications of Bayesian Information Criterion). Selection can be
    performed on data which exceed RAM capacity.
bomrang,2017-09-23,bomrang: Australian Government Bureau of Meteorology (BOM) Data from R,Provides functions to interface with Australian Government Bureau
    of Meteorology (BOM) data, fetching data and returning a tidy data frame of
    précis forecasts, historical and current weather data from stations,
    agriculture bulletin data, BOM 0900 or 1500 weather bulletins and
    downloading and importing radar and satellite imagery files. Data (c)
    Australian Government Bureau of Meteorology Creative Commons (CC)
    Attribution 3.0 licence or Public Access Licence (PAL) as appropriate. See
    <http://www.bom.gov.au/other/copyright.shtml> for further details.
geosapi,2017-02-22,geosapi: GeoServer REST API R Interface,Provides an R interface to the GeoServer REST API, allowing to upload 
 and publish data in a GeoServer web-application and expose data to OGC Web-Services. 
 The package currently supports all CRUD (Create,Read,Update,Delete) operations
 on GeoServer workspaces, namespaces, datastores (stores of vector data), featuretypes,
 layers, styles, as well as vector data upload operations. For more information about 
 the GeoServer REST API, see <http://docs.geoserver.org/stable/en/user/rest/>.
getCRUCLdata,2017-01-05,getCRUCLdata: Use and Explore CRU CL v. 2.0 Climatology Elements in R,Provides functions that automate downloading and importing
    University of East Anglia Climate Research Unit (CRU) CL v. 2.0 climatology
    data into R, facilitates the calculation of minimum temperature and maximum
    temperature and formats the data into a tidy data frame as a tibble or a 
    list of raster stack objects for use in an R session.  CRU CL v. 2.0 data 
    are a gridded climatology of 1961-1990 monthly means released in 2002 and
    cover all land areas (excluding Antarctica) at 10 arcminutes
    (0.1666667 degree) resolution.  For more information see the description of
    the data provided by the University of East Anglia Climate Research Unit,
    <https://crudata.uea.ac.uk/cru/data/hrg/tmc/readme.txt>.
ggmosaic,2016-12-30,ggmosaic: Mosaic Plots in the 'ggplot2' Framework,Mosaic plots in the 'ggplot2' framework. Mosaic
    plot functionality is provided in a single 'ggplot2' layer by calling
    the geom 'mosaic'.
grec,2017-07-09,grec: GRadient-Based RECognition of Spatial Patterns in Environmental
Data,Provides algorithms for detection of spatial patterns from oceanographic data using image processing methods based on Gradient Recognition.
merDeriv,2017-02-18,merDeriv: Case-Wise and Cluster-Wise Derivatives for Mixed Effects Models,Compute analytic case-wise and cluster-wise derivative for 
  mixed effects models with respect to fixed effects parameter, random effect (co)variances, 
  and residual variance.
odpc,2017-08-18,odpc: One-Sided Dynamic Principal Components,Functions to compute the one-sided dynamic
	principal components ('odpc') introduced in Smucler, Peña and Yohai (2018)
	<doi:10.1080/01621459.2018.1520117>. 'odpc' is a novel dimension
	reduction technique for multivariate time series, that is useful
	for forecasting. These dynamic principal components are defined as
	the linear combinations of the present and past values of the series
	that minimize the reconstruction mean squared error.
sjlabelled,2017-06-12,sjlabelled: Labelled Data Utility Functions,Collection of functions dealing with labelled data, like reading and 
    writing data between R and other statistical software packages like 'SPSS',
    'SAS' or 'Stata', and working with labelled data. This includes easy ways 
    to get, set or change value and variable label attributes, to convert 
    labelled vectors into factors or numeric (and vice versa), or to deal with 
    multiple declared missing values.
fastnet,2016-12-30,fastnet: Large-Scale Social Network Analysis,We present an implementation of the algorithms required to simulate large-scale social networks and retrieve their most relevant metrics.
IncDTW,2017-07-03,IncDTW: Incremental Calculation of Dynamic Time Warping,The Dynamic Time Warping (DTW) distance for time series allows non-linear alignments of time series to match  similar patterns in time series of different lengths and or different speeds. Beside the traditional implementation of the DTW algorithm, the specialities of this package are, (1) the incremental calculation, which is specifically useful for life data streams due to computationally efficiency, (2) the vector based implementation of the traditional DTW algorithm which is faster because no matrices are allocated and is especially useful for computing distance matrices of pairwise DTW distances for many time series  and (3) the combination of incremental and vector-based calculation. C++ in the heart. For details about DTW see the original paper "Dynamic programming algorithm optimization for spoken word recognition" by Sakoe and Chiba (1978) <doi:10.1109/TASSP.1978.1163055>.
mixKernel,2017-05-18,mixKernel: Omics Data Integration Using Kernel Methods,Kernel-based methods are powerful methods for integrating 
    heterogeneous types of data. mixKernel aims at providing methods to combine
    kernel for unsupervised exploratory analysis. Different solutions are 
    provided to compute a meta-kernel, in a consensus way or in a way that 
    best preserves the original topology of the data. mixKernel also integrates
    kernel PCA to visualize similarities between samples in a non linear space
    and from the multiple source point of view. Functions to assess and display
    important variables are also provided in the package. Jerome Mariette and 
    Nathalie Villa-Vialaneix (2017) <doi:10.1093/bioinformatics/btx682>.
PhylogeneticEM,2017-01-31,PhylogeneticEM: Automatic Shift Detection using a Phylogenetic EM,
    Implementation of the automatic shift detection method for
    Brownian Motion (BM) or Ornstein–Uhlenbeck (OU) models of trait evolution on
    phylogenies. Some tools to handle equivalent shifts configurations are also
    available. See Bastide et al. (2017) <doi:10.1111/rssb.12206> and
    Bastide et al. (2018) <doi:10.1093/sysbio/syy005>.
prettycode,2017-01-27,prettycode: Pretty Print R Code in the Terminal,Replace the standard print method for functions with one that
    performs syntax highlighting, using ANSI colors, if the terminal
    supports them.
scorecard,2017-09-16,scorecard: Credit Risk Scorecard,
  The 'scorecard' package makes the development of credit risk scorecard 
  easier and efficient by providing functions, such as information 
  value, variable filter, optimal woe binning, scorecard scaling and 
  performance evaluation etc. 
    The references including: 
  1. Refaat, M. (2011, ISBN: 9781447511199). Credit Risk Scorecard: 
  Development and Implementation Using SAS. 
  2. Siddiqi, N. (2006, ISBN: 9780471754510). Credit risk scorecards. 
  Developing and Implementing Intelligent Credit Scoring.
zoocat,2016-11-10,zoocat: 'zoo' Objects with Column Attributes,Tools for manipulating multivariate time series data by extending
    'zoo' class.
BIGL,2017-06-30,BIGL: Biochemically Intuitive Generalized Loewe Model,Response surface methods for drug synergy analysis. Available
    methods include generalized and classical Loewe formulations as well as Highest
    Single Agent methodology. Response surfaces can be plotted in an interactive
    3-D plot and formal statistical tests for presence of synergistic effects are
    available. Implemented methods and tests are described in the article 
    "BIGL: Biochemically Intuitive Generalized Loewe null model for prediction 
    of the expected combined effect compatible with partial agonism and antagonism"
    by Koen Van der Borght, Annelies Tourny, Rytis Bagdziunas, Olivier Thas, 
    Maxim Nazarov, Heather Turner, Bie Verbist & Hugo Ceulemans (2017) 
    <doi:10.1038/s41598-017-18068-5>.
datasets.load,2016-12-14,datasets.load: Interface for Loading Datasets,Visual interface for loading datasets in RStudio from all installed (unloaded) packages.
ghibli,2017-08-14,ghibli: Studio Ghibli Palette Generator,Colour palettes inspired by Studio Ghibli films, ported to R for your enjoyment.
naniar,2017-08-09,naniar: Data Structures, Summaries, and Visualisations for Missing Data,Missing values are ubiquitous in data and need to be explored and
    handled in the initial stages of analysis. 'naniar' provides data structures 
    and functions that facilitate the plotting of missing values and examination 
    of imputations. This allows missing data dependencies to be explored with 
    minimal deviation from the common work patterns of 'ggplot2' and tidy data. 
penaltyLearning,2017-06-08,penaltyLearning: Penalty Learning,Implementations of algorithms from 
 Learning Sparse Penalties for Change-point Detection
 using Max Margin Interval Regression, by
 Hocking, Rigaill, Vert, Bach
 <http://proceedings.mlr.press/v28/hocking13.html>
 published in proceedings of ICML2013.
rly,2016-11-27,rly: 'Lex' and 'Yacc',R implementation of the common parsing tools 'lex' and 'yacc'.
udpipe,2017-09-01,udpipe: Tokenization, Parts of Speech Tagging, Lemmatization and
Dependency Parsing with the 'UDPipe' 'NLP' Toolkit,This natural language processing toolkit provides language-agnostic
    'tokenization', 'parts of speech tagging', 'lemmatization' and 'dependency
    parsing' of raw text. Next to text parsing, the package also allows you to train
    annotation models based on data of 'treebanks' in 'CoNLL-U' format as provided
    at <http://universaldependencies.org/format.html>. The techniques are explained
    in detail in the paper: 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0
    with UDPipe', available at <doi:10.18653/v1/K17-3009>.
redR,2017-06-14,redR: REgularization by Denoising (RED),Regularization by Denoising uses a denoising engine to solve
  many image reconstruction ill-posed inverse problems. This is a R
  implementation of the algorithm developed by Romano et.al. (2016) <arXiv:1611.02862>. Currently,
  only the gradient descent optimization framework is implemented. Also,
  only the median filter is implemented as a denoiser engine. However,
  (almost) any denoiser engine can be plugged in. There are currently available
  3 reconstruction tasks: denoise, deblur and super-resolution. And again,
  any other task can be easily plugged into the main function 'RED'.
reportROC,2017-04-17,reportROC: An Easy Way to Report ROC Analysis,Provides an easy way to report the results of ROC analysis, including:
  1. an ROC curve. 2. the value of Cutoff, AUC (Area Under Curve), ACC (accuracy),
  SEN (sensitivity), SPE (specificity),
  PLR (positive likelihood ratio), NLR (negative likelihood ratio),
  PPV (positive predictive value), NPV (negative predictive value).
fitur,2017-02-19,fitur: Fit Univariate Distributions,Wrapper for computing parameters for univariate distributions using MLE. It creates an object that stores d, p, q, r functions as well as parameters and statistics for diagnostics. Currently supports automated fitting from base and actuar packages. A manually fitting distribution fitting function is included to support directly specifying parameters for any distribution from ancillary packages.
ggdmc,2016-10-28,ggdmc: Cognitive Models,Hierarchical Bayesian modelling. The 'ggdmc' package provides tools designed for fitting cognitive models, using population-based Markov Chain Monte Carlo (pMCMC) and fast C++ libraries. The paper by Heathcote, Lin, Reynolds, Strickland, Gretton, and Matzke (2018, <doi:10.3758/s13428-018-1067-y>) describes the early prototype of the package (by the version 0.4.2). The paper accompanied with the revamped latest version (> 0.2.4.5) is under preparation Lin, Strickland, Reynold, and Heathcote (2018) and a further paper regarding the new pMCMC sampling modified based on Hu and Tsai's (2010) work is also under preparation. See 'citation("ggdmc")' for details.
healthcareai,2017-02-14,healthcareai: Tools for Healthcare Machine Learning,A machine learning toolbox tailored to healthcare data.
fastR2,2017-08-30,fastR2: Foundations and Applications of Statistics Using R (2nd Edition),Data sets and utilities to accompany the second edition of
    "Foundations and Applications of Statistics: an Introduction
    using R" (R Pruim, published by AMS, 2017), a text covering
    topics from probability and mathematical statistics at an advanced
    undergraduate level.  R is integrated throughout, and access to all
    the R code in the book is provided via the snippet() function.
gamesGA,2017-06-13,gamesGA: Genetic Algorithm for Sequential Symmetric Games,Finds adaptive strategies for sequential symmetric 
    games using a genetic algorithm. Currently, any symmetric two by two matrix
    is allowed, and strategies can remember the history of an opponent's play
    from the previous three rounds of moves in iterated interactions between
    players. The genetic algorithm returns a list of adaptive strategies given
    payoffs, and the mean fitness of strategies in each generation.
iMediate,2017-03-18,iMediate: Likelihood Methods for Mediation Analysis,Implements likelihood based methods for mediation analysis. 
sinew,2017-05-03,sinew: Create 'roxygen2' Skeleton with Information from Function Script,Create 'roxygen2' skeleton populated with information scraped from the
         within the function script. Also creates field entries for imports in the
         'DESCRIPTION' and import in the 'NAMESPACE' files. Can be run from the R
         console or through the 'RStudio' 'addin' menu.
taxonomizr,2017-03-09,taxonomizr: Functions to Work with NCBI Accessions and Taxonomy,Functions for assigning taxonomy to NCBI accession numbers and taxon IDs based on NCBI's accession2taxid and taxdump files. This package allows the user to downloads NCBI data dumps and create a local database for fast and local taxonomic assignment.
bayesImageS,2016-11-03,bayesImageS: Bayesian Methods for Image Segmentation using a Potts Model,Various algorithms for segmentation of 2D and 3D images, such
    as computed tomography and satellite remote sensing. This package implements
    Bayesian image analysis using the hidden Potts model with external field
    prior of Moores et al. (2015) <doi:10.1016/j.csda.2014.12.001>.
    Latent labels are sampled using chequerboard updating or Swendsen-Wang.
    Algorithms for the smoothing parameter include pseudolikelihood, path sampling,
    the exchange algorithm, approximate Bayesian computation (ABC-MCMC and ABC-SMC),
    and Bayesian indirect likelihood (BIL). Refer to <doi:10.1007/s11222-014-9525-6>
    and <arXiv:1503.08066> for further details.
intccr,2017-08-30,intccr: Semiparametric Competing Risks Regression under Interval
Censoring,Semiparametric regression models on the cumulative incidence function with interval-censored competing risks data as described in Bakoyannis, Yu, & Yiannoutsos (2017) <doi:10.1002/sim.7350>. The main function fits the proportional subdistribution hazards model (Fine-Gray model), the proportional odds model, and other models that belong to the class of semiparametric generalized odds rate transformation models.
lero.lero,2017-03-23,lero.lero: Generate 'Lero Lero' Quotes,Generates quotes from 'Lero Lero', a database for meaningless sentences filled with corporate buzzwords, intended to be used as corporate lorem ipsum (see <http://www.lerolero.com/> for more information). Unfortunately, quotes are currently portuguese-only.
OOBCurve,2017-02-24,OOBCurve: Out of Bag Learning Curve,Provides functions to calculate the out-of-bag learning curve for random forests for any measure that is available in the 'mlr' package. Supported random forest packages are 'randomForest' and 'ranger' and trained models of these packages with the train function of 'mlr'. The main function is OOBCurve() that calculates the out-of-bag curve depending on the number of trees. With the OOBCurvePars() function out-of-bag curves can also be calculated for 'mtry', 'sample.fraction' and 'min.node.size' for the 'ranger' package.
PeerPerformance,2017-01-29,PeerPerformance: Luck-Corrected Peer Performance Analysis in R,Provides functions to perform the peer performance
    analysis of funds' returns as described in Ardia and Boudt (2018) <doi:10.1016/j.jbankfin.2017.10.014>.
RiskPortfolios,2017-02-05,RiskPortfolios: Computation of Risk-Based Portfolios,Collection of functions designed to compute risk-based portfolios as described 
    in Ardia et al. (2017) <doi:10.1007/s10479-017-2474-7> and Ardia et al. (2017) <doi:10.21105/joss.00171>.
covatest,2017-04-27,covatest: Tests on Properties of Space-Time Covariance Functions,Tests on properties of space-time covariance functions.
    Tests on symmetry, separability and for assessing 
    different forms of non-separability are available. Moreover tests on 
    some classes of covariance functions, such that the classes of 
    product-sum models, Gneiting models and integrated product models have 
    been provided.
fdANOVA,2017-09-08,fdANOVA: Analysis of Variance for Univariate and Multivariate Functional
Data,Performs analysis of variance testing procedures for univariate and multivariate functional data (Cuesta-Albertos and Febrero-Bande (2010) <doi:10.1007/s11749-010-0185-3>, Gorecki and Smaga (2015) <doi:10.1007/s00180-015-0555-0>, Gorecki and Smaga (2017) <doi:10.1080/02664763.2016.1247791>, Zhang et al. (2018) <doi:10.1016/j.csda.2018.05.004>).
cytometree,2017-06-26,cytometree: Automated Cytometry Gating and Annotation,Given the hypothesis of a bi-modal distribution of cells for
    each marker, the algorithm constructs a binary tree, the nodes of which are
    subpopulations of cells. At each node, observed cells and markers are modeled
    by both a family of normal distributions and a family of bi-modal normal mixture
    distributions. Splitting is done according to a normalized difference of AIC
    between the two families.
SSLASSO,2017-09-21,SSLASSO: The Spike-and-Slab LASSO,Efficient coordinate ascent algorithm for fitting regularization paths for linear models penalized by Spike-and-Slab LASSO of Rockova and George (2018) <doi:10.1080/01621459.2016.1260469>.
eDMA,2016-11-12,eDMA: Dynamic Model Averaging with Grid Search,Perform dynamic model averaging with grid search as in Dangl and Halling (2012) <doi:10.1016/j.jfineco.2012.04.003> using parallel computing.
MCMCvis,2016-10-06,MCMCvis: Tools to Visualize, Manipulate, and Summarize MCMC Output,Performs key functions for MCMC analysis using minimal code - visualizes, manipulates, and summarizes MCMC output. Functions support simple and straightforward subsetting of model parameters within the calls, and produce presentable and 'publication-ready' output. MCMC output may be derived from Bayesian model output fit with JAGS, Stan, or other MCMC samplers.
tidycensus,2017-06-20,tidycensus: Load US Census Boundary and Attribute Data as 'tidyverse' and
'sf'-Ready Data Frames,An integrated R interface to the decennial US Census and American Community Survey APIs and
    the US Census Bureau's geographic boundary files.  Allows R users to return Census and ACS data as
    tidyverse-ready data frames, and optionally returns a list-column with feature geometry for many 
    geographies. 
vpc,2017-09-22,vpc: Create Visual Predictive Checks,Visual predictive checks are a commonly used diagnostic plot in pharmacometrics, showing how certain statistics (percentiles) for observed data compare to those same statistics for data simulated from a model. The package can generate VPCs for continuous, categorical, censored, and (repeated) time-to-event data.
bgsmtr,2016-10-04,bgsmtr: Bayesian Group Sparse Multi-Task Regression,Fits a Bayesian group-sparse multi-task regression model using Gibbs
    sampling. The hierarchical prior encourages shrinkage of the estimated regression
    coefficients at both the gene and SNP level. The model has been extended to a 
    spatial model that allows for two type correlation in neuroimaging genetics data and 
    been applied successfully to imaging phenotypes of dimension up to 100; it can be used
    more generally for multivariate (non-imaging) phenotypes.
mclustcomp,2017-09-11,mclustcomp: Measures for Comparing Clusters,Given a set of data points, a clustering is defined as a disjoint partition
    where each pair of sets in a partition has no overlapping elements. 
    This package provides 25 methods that play a role somewhat similar to 
    distance or metric that measures similarity of two clusterings - or partitions.
    For a more detailed description, see Meila, M. (2005) <doi:10.1145/1102351.1102424>.
supc,2017-03-19,supc: The Self-Updating Process Clustering Algorithms,Implements the self-updating process clustering algorithms proposed
    in Shiu and Chen (2016) <doi:10.1080/00949655.2015.1049605>.
startup,2016-11-21,startup: Friendly R Startup Configuration,Adds support for R startup configuration via '.Renviron.d' and '.Rprofile.d' directories in addition to '.Renviron' and '.Rprofile' files.  This makes it possible to keep private / secret environment variables separate from other environment variables.  It also makes it easier to share specific startup settings by simply copying a file to a directory.
symDMatrix,2017-05-08,symDMatrix: Partitioned Symmetric Matrices,A matrix-like class to represent a symmetric matrix partitioned
    into file-backed blocks.
TeXCheckR,2017-04-09,TeXCheckR: Parses LaTeX Documents for Errors,Checks LaTeX documents and .bib files for typing errors, such as spelling errors, incorrect quotation marks. Also provides useful functions for parsing and linting bibliography files.
tfruns,2017-07-23,tfruns: Training Run Tools for 'TensorFlow',Create and manage unique directories for each 'TensorFlow' 
  training run. Provides a unique, time stamped directory for each run
  along with functions to retrieve the directory of the latest run or 
  latest several runs. 
adiv,2017-07-19,adiv: Analysis of Diversity,Includes functions, data sets and examples for the calculation of various indices of biodiversity including species, functional and phylogenetic diversity. Part of the indices are expressed in terms of equivalent numbers of species. It also provides ways to partition biodiversity across spatial or temporal scales (alpha, beta, gamma diversities). In addition to the quantification of biodiversity, ordination approaches are available which rely on diversity indices and allow the detailed identification of species, functional or phylogenetic differences between communities.
BGData,2017-05-11,BGData: A Suite of Packages for Analysis of Big Genomic Data,An umbrella package providing a phenotype/genotype data structure
    and scalable and efficient computational methods for large genomic datasets
    in combination with several other packages: 'BEDMatrix', 'LinkedMatrix',
    and 'symDMatrix'.
gsynth,2017-03-12,gsynth: Generalized Synthetic Control Method,Provides causal inference with interactive fixed-effect models. It imputes counterfactuals for each treated unit using control group information based on a linear interactive fixed effects model that incorporates unit-specific intercepts interacted with time-varying coefficients. This method generalizes the synthetic control method to the case of multiple treated units and variable treatment periods, and improves efficiency and interpretability. This version supports unbalanced panels and implements the matrix completion method. Main reference: Yiqing Xu (2017) <doi:10.1017/pan.2016.2>.
keras,2017-07-30,keras: R Interface to 'Keras',Interface to 'Keras' <https://keras.io>, a high-level neural
  networks 'API'. 'Keras' was developed with a focus on enabling fast experimentation,
  supports both convolution based networks and recurrent networks (as well as
  combinations of the two), and runs seamlessly on both 'CPU' and 'GPU' devices.
perccalc,2017-09-14,perccalc: Estimate Percentiles from an Ordered Categorical Variable,An implementation of two functions that estimate values for percentiles from an ordered categorical variable as described by Reardon (2011, isbn:978-0-87154-372-1). One function estimates percentile differences from two percentiles while the other returns the values for every percentile from 1 to 100.
quickmatch,2017-05-20,quickmatch: Quick Generalized Full Matching,
    Provides functions for constructing near-optimal generalized full matching.
    Generalized full matching is an extension of the original full matching method
    to situations with more intricate study designs. The package is made with
    large data sets in mind and derives matches more than an order of magnitude
    quicker than other methods.
rtrim,2016-11-28,rtrim: Trends and Indices for Monitoring Data,The TRIM model is widely used for estimating growth and decline of
    animal populations based on (possibly sparsely available) count data. The
    current package is a reimplementation of the original TRIM software developed
    at Statistics Netherlands by Jeroen Pannekoek. See
    <https://www.cbs.nl/en-gb/society/nature-and-environment/indices-and-trends%2d%2dtrim%2d%2d>
    for more information about TRIM.
scclust,2017-03-28,scclust: Size-Constrained Clustering,
    Provides wrappers for 'scclust', a C library for computationally efficient
    size-constrained clustering with near-optimal performance.
    See <https://github.com/fsavje/scclust> for more information.
stepPenal,2016-12-23,stepPenal: Stepwise Forward Variable Selection in Penalized Regression,Model Selection Based on Combined Penalties. This package implements a stepwise forward variable selection algorithm based on a penalized likelihood criterion that combines the L0 with L2 or L1 norms.
CINNA,2017-07-15,CINNA: Deciphering Central Informative Nodes in Network Analysis,Functions for computing, comparing and demonstrating top informative centrality measures within a network.
manet,2017-09-19,manet: Multiple Allocation Model for Actor-Event Networks,Mixture model with overlapping clusters for binary actor-event data. Parameters are estimated in a Bayesian framework. Model and inference are described in Ranciati, Vinciotti, Wit (2017) Modelling actor-event network data via a mixture model under overlapping clusters. Submitted.
micemd,2017-05-13,micemd: Multiple Imputation by Chained Equations with Multilevel Data,Addons for the 'mice' package to perform multiple imputation using chained equations with two-level data. Includes imputation methods dedicated to sporadically and systematically missing values. Imputation of continuous, binary or count variables are available. Following the recommendations of Audigier, V. et al (2018) <doi:10.1214/18-STS646>, the choice of the imputation method for each variable can be facilitated by a default choice tuned according to the structure of the incomplete dataset. Allows parallel calculation and overimputation for 'mice'.
sarima,2017-02-06,sarima: Simulation and Prediction with Seasonal ARIMA Models,Functions, classes and methods for time series modelling with ARIMA
    and related models. The aim of the package is to provide consistent
    interface for the user. For example, a single function autocorrelations()
    computes various kinds of theoretical and sample autocorrelations. This is
    work in progress, see the documentation and vignettes for the current
    functionality.  Function sarima() fits extended multiplicative seasonal
    ARIMA models with trends, exogenous variables and arbitrary roots on the
    unit circle, which can be fixed or estimated.
BayesNetBP,2017-05-09,BayesNetBP: Bayesian Network Belief Propagation,Belief propagation methods in Bayesian Networks to propagate evidence through the network. The implementation of these methods are based on the article: Cowell, RG (2005). Local Propagation in Conditional Gaussian Bayesian Networks <http://www.jmlr.org/papers/volume6/cowell05a/>.
BioInstaller,2017-03-16,BioInstaller: Integrator of Bioinformatics Resources,
    Can be used to integrate massive bioinformatics resources, such as tool/script and database. It provides the R functions and Shiny web application. Hundreds of bioinformatics tool/script and database have been included.
collapsibleTree,2017-03-22,collapsibleTree: Interactive Collapsible Tree Diagrams using 'D3.js',
    Interactive Reingold-Tilford tree diagrams created using 'D3.js', where every node can be expanded and collapsed by clicking on it.
    Tooltips and color gradients can be mapped to nodes using a numeric column in the source data frame.
    See 'collapsibleTree' website for more information and examples.
Eagle,2017-08-28,Eagle: Multiple Locus Association Mapping on a Genome-Wide Scale,An implementation of multiple-locus association mapping on a genome-wide scale. 'Eagle' can handle inbred and  outbred study populations, populations of arbitrary unknown complexity, and data larger than the memory capacity of the computer. Since 'Eagle' is based on linear mixed models, it is best suited to the analysis of data on continuous traits. However, it can tolerate non-normal data. 'Eagle' reports, as its findings, the best set of snp in strongest association with a trait. For users unfamiliar with R, to perform an analysis, run 'OpenGUI()'. This  opens a web browser to the menu-driven user interface for the input of data, and for performing genome-wide analysis.
geometa,2017-05-25,geometa: Tools for Reading and Writing ISO/OGC Geographic Metadata,Provides facilities to handle reading and writing of geographic metadata 
 defined with OGC/ISO 19115, 11119 and 19110 geographic information metadata standards,
 and encoded using the ISO 19139 (XML) standard. It includes also a facility to check
 the validity of ISO 19139 XML encoded metadata.
GMSE,2017-06-30,GMSE: Generalised Management Strategy Evaluation Simulator,Integrates game theory and ecological theory to construct 
    social-ecological models that simulate the management of populations and 
    stakeholder actions. These models build off of a previously developed 
    management strategy evaluation (MSE) framework to simulate all aspects of 
    management: population dynamics, manager observation of populations, manager
    decision making, and stakeholder responses to management decisions. The 
    newly developed generalised management strategy evaluation (GMSE) 
    framework uses genetic algorithms to mimic the decision-making process of 
    managers and stakeholders under conditions of change, uncertainty, and 
    conflict. Simulations can be run using gmse(), gmse_apply(), and
    gmse_gui() functions.
lidR,2016-12-31,lidR: Airborne LiDAR Data Manipulation and Visualization for Forestry
Applications,Airborne LiDAR (Light Detection and Ranging) interface for data
    manipulation and visualization. Read/write 'las' and 'laz' files, computation
    of metrics in area based approach, point filtering, artificial point reduction,
    classification from geographic data, normalization, individual tree segmentation
    and other manipulations.
lmridge,2016-11-22,lmridge: Linear Ridge Regression with Ridge Penalty and Ridge Statistics,Linear ridge regression coefficient's estimation and testing with different ridge related measures such as MSE, R-squared etc.
  REFERENCES
  i.   Hoerl and Kennard (1970) <doi:10.2307/1267351>
  ii.  Halawa and El-Bassiouni (2000) <doi:10.1080/00949650008812006>
  iii. Imdadullah, Aslam, and Saima (2017)
  iv.  Marquardt (1970) <doi:10.2307/1267205>.
rstantools,2016-11-20,rstantools: Tools for Developing R Packages Interfacing with 'Stan',Provides various tools for developers of R packages interfacing
    with 'Stan' <http://mc-stan.org>, including functions to set up the required 
    package structure, S3 generics and default methods to unify function naming 
    across 'Stan'-based R packages, and vignettes with recommendations for 
    developers.
rvinecopulib,2017-08-30,rvinecopulib: High Performance Algorithms for Vine Copula Modeling,Provides an interface to 'vinecopulib', a C++ library for vine 
 copula modeling based on 'Boost' and 'Eigen'. The 'rvinecopulib' 
 package implements the core features of the popular 'VineCopula' package, in 
 particular inference algorithms for both vine copula and bivariate copula 
 models. Advantages over 'VineCopula' are a sleeker and more modern API, 
 improved performances, especially in high dimensions, nonparametric and 
 multi-parameter families. The 'rvinecopulib' package includes 'vinecopulib' as
 header-only C++ library (currently version 0.3.0). Thus 
 users do not need to install 'vinecopulib' itself in order to use 
 'rvinecopulib'. Since their initial releases, 'vinecopulib' is licensed under 
 the MIT License, and 'rvinecopulib' is licensed under the GNU GPL version 3.
SSBtools,2016-12-29,SSBtools: Statistics Norway's Miscellaneous Tools,Functions used by other packages from Statistics Norway are gathered. Both general data manipulation functions and some more special functions for statistical disclosure control are included.
TLMoments,2017-01-17,TLMoments: Calculate TL-Moments and Convert Them to Distribution Parameters,Calculates empirical TL-moments (trimmed L-moments) of arbitrary 
    order and trimming, and converts them to distribution parameters. 
quickblock,2017-07-31,quickblock: Quick Threshold Blocking,
    Provides functions for assigning treatments in randomized experiments using
    near-optimal threshold blocking. The package is made with large data sets in
    mind and derives blocks more than an order of magnitude quicker than other
    methods.
rsolr,2017-04-10,rsolr: R to Solr Interface,A comprehensive R API for querying Apache Solr databases.
             A Solr core is represented as a data frame or list that
             supports Solr-side filtering, sorting,
             transformation and aggregation, all through the familiar
             base R API. Queries are processed
             lazily, i.e., a query is only sent to the database when
             the data are required. 
lagged,2017-05-21,lagged: Classes and Methods for Lagged Objects,Provides classes and methods for lagged objects.
RLT,2017-04-09,RLT: Reinforcement Learning Trees,Random forest with a variety of additional features for regression, classification and survival analysis. The features include: parallel computing with OpenMP, embedded model for selecting the splitting variable (based on Zhu, Zeng & Kosorok, 2015), subject weight, variable weight, tracking subjects used in each tree, etc.
shinyFeedback,2016-12-13,shinyFeedback: Displays User Feedback Next to Shiny Inputs,Easily display user feedback next to Shiny inputs.  The feedback message is displayed when the feedback condition evaluates to TRUE.
censusapi,2017-06-06,censusapi: Retrieve Data from the Census APIs,A wrapper for the U.S. Census Bureau APIs that returns data frames of 
	Census data and metadata. Available datasets include the 
	Decennial Census, American Community Survey, Small Area Health Insurance Estimates,
	Small Area Income and Poverty Estimates, and Population Estimates and Projections.
	See <https://www.census.gov/data/developers/data-sets.html> for more information.
dwapi,2017-05-18,dwapi: A Client for 'data.world' REST API,A set of wrapper functions for 'data.world' REST API endpoints <https://apidocs.data.world>.
hrbrthemes,2017-02-26,hrbrthemes: Additional Themes, Theme Components and Utilities for 'ggplot2',A compilation of extra 'ggplot2' themes, scales and utilities, including a 
    spell check function for plot label fields and an overall emphasis on typography. 
    A copy of the 'Google' font 'Roboto Condensed' <https://github.com/google/roboto/> 
    is also included along with a copy of the 'IBM' 'Plex Sans' <https://github.com/IBM/type>
    and 'Titillium Web' <https://fonts.google.com/specimen/Titillium+Web> fonts
    are also included to support their respective typography-oriented themes.
IPEC,2017-05-10,IPEC: Root Mean Square Curvature Calculation,Calculates the RMS intrinsic and parameter-effects curvatures of a nonlinear regression model. 
mockery,2016-10-25,mockery: Mocking Library for R,
    The two main functionalities of this package are creating mock
    objects (functions) and selectively intercepting calls to a given
    function that originate in some other function. It can be used
    with any testing framework available for R. Mock objects can
    be injected with either this package's own stub() function or a
    similar with_mock() facility present in the testthat package. 
sweep,2017-07-04,sweep: Tidy Tools for Forecasting,
    Tidies up the forecasting modeling and prediction work flow, 
    extends the 'broom' package 
    with 'sw_tidy', 'sw_glance', 'sw_augment', and 'sw_tidy_decomp' functions 
    for various forecasting models,
    and enables converting 'forecast' objects to 
    "tidy" data frames with 'sw_sweep'.
timetk,2017-07-25,timetk: A Tool Kit for Working with Time Series in R,
    Get the time series index, signature, and summary from time series objects and
    time-based tibbles. Create future time series based on properties of 
    existing time series index.  
    Coerce between time-based tibbles ('tbl') and 'xts', 'zoo', and 'ts'. 
narray,2016-12-07,narray: Subset- And Name-Aware Array Utility Functions,Stacking arrays according to dimension names, subset-aware
    splitting and mapping of functions, intersecting along arbitrary
    dimensions, converting to and from data.frames, and many other helper
    functions.
AbSim,2016-12-15,AbSim: Time Resolved Simulations of Antibody Repertoires,Simulation methods for the evolution of antibody repertoires. The heavy and light chain variable region of both human and C57BL/6 mice can be simulated in a time-dependent fashion. Both single lineages using one set of V-, D-, and J-genes or full repertoires can be simulated. The algorithm begins with an initial V-D-J recombination event, starting the first phylogenetic tree. Upon completion, the main loop of the algorithm begins, with each iteration representing one simulated time step. Various mutation events are possible at each time step, contributing to a diverse final repertoire.
bigstatsr,2017-09-02,bigstatsr: Statistical Tools for Filebacked Big Matrices,Easy-to-use, efficient, flexible and scalable statistical tools.
  Package bigstatsr provides and uses Filebacked Big Matrices via memory-mapping.
  It provides for instance matrix operations, Principal Component Analysis,
  sparse linear supervised models, utility functions and more
  <doi:10.1093/bioinformatics/bty185>.
DMMF,2017-03-10,DMMF: Daily Based Morgan-Morgan-Finney (DMMF) Soil Erosion Model,Implements the daily based Morgan-Morgan-Finney (DMMF) soil erosion model (Choi et al., 2017 <doi:10.3390/w9040278>) for estimating surface runoff and sediment budgets from a field or a catchment on a daily basis.
GPrank,2016-10-27,GPrank: Gaussian Process Ranking of Multiple Time Series,Implements a Gaussian process (GP)-based ranking method
    which can be used to rank multiple time series according to their
    temporal activity levels. An example is the case when expression
    levels of all genes are measured over a time course and the main
    concern is to identify the most active genes, i.e. genes which
    show significant non-random variation in their expression levels.
    This is achieved by computing Bayes factors for each time series
    by comparing the marginal likelihoods under time-dependent and
    time-independent GP models. Additional variance information from
    pre-processing of the observations is incorporated into the GP
    models, which makes the ranking more robust against model
    overfitting. The package supports exporting the results to
    'tigreBrowser' for visualisation, filtering or ranking.
haploR,2016-12-31,haploR: Query 'HaploReg', 'RegulomeDB', 'LDlink',A set of utilities for querying 
             'HaploReg' <http://archive.broadinstitute.org/mammals/haploreg/haploreg.php>, 
             'RegulomeDB' <http://www.regulomedb.org>, and LDlink <https://analysistools.nci.nih.gov/LDlink>
             web-based tools. The package connects to 
             'HaploReg', 'RegulomeDB' and 'LDlink', searches and downloads results, without 
             opening web pages, directly from R environment. 
             Results are stored in a data frame that can be directly used in various 
             kinds of downstream analyses.
optrdd,2017-08-24,optrdd: Optimized Regression Discontinuity Designs,Optimized inference in regression discontinuity designs, as proposed by Imbens and Wager (2017) <arXiv:1705.01677>.
textutils,2016-12-17,textutils: Utilities for Handling Strings and Text,Utilities for handling character vectors
  that store human-readable text (either plain or with
  markup, such as HTML or LaTeX). The package provides,
  in particular, functions that help with the
  preparation of plain-text reports (e.g. for expanding
  and aligning strings that form the lines of such
  reports); the package also provides generic functions for
  transforming R objects to HTML and to plain text.
batchtools,2016-11-08,batchtools: Tools for Computation on Batch Systems,As a successor of the packages 'BatchJobs' and 'BatchExperiments',
    this package provides a parallel implementation of the Map function for high
    performance computing systems managed by schedulers 'IBM Spectrum LSF'
    (<https://www.ibm.com/us-en/marketplace/hpc-workload-management>),
    'OpenLava' (<http://www.openlava.org/>), 'Univa Grid Engine'/'Oracle Grid
    Engine' (<http://www.univa.com/>), 'Slurm' (<http://slurm.schedmd.com/>),
    'TORQUE/PBS'
    (<http://www.adaptivecomputing.com/products/open-source/torque/>), or
    'Docker Swarm' (<https://docs.docker.com/swarm/>).
    A multicore and socket mode allow the parallelization on a local machines,
    and multiple machines can be hooked up via SSH to create a makeshift
    cluster. Moreover, the package provides an abstraction mechanism to define
    large-scale computer experiments in a well-organized and reproducible way.
castor,2017-05-20,castor: Efficient Phylogenetics on Large Trees,Efficient tree manipulations for large phylogenies, including pruning, rerooting, calculation of most-recent common ancestors, calculating distances from the tree root and calculating pairwise distances. Calculation of phylogenetic signal and mean trait depth (trait conservatism), ancestral state reconstruction and hidden character prediction of discrete characters. Simulating and fitting models of trait evolution, and generating random trees using birth-death models. Dating trees, comparing two trees, and reading/writing trees to a file. Citation: Louca, Stilianos and Doebeli, Michael (2017) <doi:10.1093/bioinformatics/btx701>.
datastructures,2017-07-09,datastructures: Implementation of Core Data Structures,Implementation of advanced data structures such as hashmaps,
    heaps, or queues. Advanced data structures are essential
    in many computer science and statistics problems, for example graph
    algorithms or string analysis. The package uses 'Boost' and 'STL' data
    types and extends these to R with 'Rcpp' modules.
mapedit,2017-06-30,mapedit: Interactive Editing of Spatial Data in R,Suite of interactive functions and helpers for selecting and editing
    geospatial data.
openEBGM,2017-05-05,openEBGM: EBGM Scores for Mining Large Contingency Tables,An implementation of DuMouchel's (1999) 
  <doi:10.1080/00031305.1999.10474456> Bayesian data mining method for the
  market basket problem. Calculates Empirical Bayes Geometric Mean (EBGM) and
  quantile scores from the posterior distribution using the Gamma-Poisson
  Shrinker (GPS) model to find unusually large cell counts in large, sparse
  contingency tables. Can be used to find unusually high reporting rates of
  adverse events associated with products. In general, can be used to mine any
  database where the co-occurrence of two variables or items is of interest.
  Also calculates relative and proportional reporting ratios. Builds on the work
  of the 'PhViD' package, from which much of the code is derived. Some of the
  added features include stratification to adjust for confounding variables and
  data squashing to improve computational efficiency. Now includes an
  implementation of the EM algorithm for hyperparameter estimation loosely
  derived from the 'mederrRank' package.
processx,2017-05-30,processx: Execute and Control System Processes,Tools to run system processes in the background.
    It can check if a background process is running; wait on a background
    process to finish; get the exit status of finished processes; kill
    background processes. It can read the standard output and error of
    the processes, using non-blocking connections. 'processx' can poll
    a process for standard output or error, with a timeout. It can also
    poll several processes at once.
BMisc,2017-06-14,BMisc: Miscellaneous Functions for Panel Data, Quantiles, and Printing
Results,These are miscellaneous functions for working with panel data, quantiles, and printing results.  For panel data, the package includes functions for making a panel data balanced (that is, dropping missing individuals that have missing observations in any time period), converting id numbers to row numbers, and to treat repeated cross sections as panel data under the assumption of rank invariance.  For quantiles, there are functions to make distribution functions from a set of data points (this is particularly useful when a distribution function is created in several steps), to combine distribution functions based on some external weights, and to invert distribution functions.  Finally, there are several other miscellaneous functions for obtaining weighted means, weighted distribution functions, and weighted quantiles; to generate summary statistics and their differences for two groups; and to add or drop covariates from formulas.
cholera,2017-08-10,cholera: Amend, Augment and Aid Analysis of John Snow's Cholera Map,Amends errors, augments data and aids analysis of John Snow's map
    of the 1854 London cholera outbreak.
civis,2017-09-16,civis: R Client for the 'Civis data science API',A set of tools around common workflows and a convenient interface to make
  requests directly to the 'Civis data science API' <https://www.civisanalytics.com/platform/>.
distances,2017-03-05,distances: Tools for Distance Metrics,Provides tools for constructing, manipulating and using distance metrics.
vetr,2017-07-07,vetr: Trust, but Verify,Declarative template-based framework for verifying that objects
  meet structural requirements, and auto-composing error messages when they do
  not.
LMfilteR,2017-09-24,LMfilteR: Filter Methods for Parameter Estimation in Linear Regression
Models,We present a method based on filtering algorithms to estimate the parameters of linear regressions, i.e. the coefficients and the variance of the error term. The proposed algorithms make use of Particle Filters following Ristic, B., Arulampalam, S., Gordon, N. (2004, ISBN: 158053631X) resampling methods.
powerlmm,2017-09-11,powerlmm: Power Analysis for Longitudinal Multilevel Models,Calculate power for the 'time x treatment' effect
    in two- and three-level multilevel longitudinal studies with missing data.
    Both the third-level factor (e.g. therapists, schools, or physicians),
    and the second-level factor (e.g. subjects), can be assigned random slopes.
    Studies with partially nested designs, unequal cluster sizes,
    unequal allocation to treatment arms, and different dropout patterns
    per treatment are supported. For all designs power can be
    calculated both analytically and via simulations. The analytical
    calculations extends the method described in Galbraith et al. (2002)
    <doi:10.1016/S0197-2456(02)00205-2>, to three-level models.
    Additionally, the simulation tools provides flexible ways to investigate
    bias, Type I errors and the consequences of model misspecification.
ProliferativeIndex,2017-02-16,ProliferativeIndex: Calculates and Analyzes the Proliferative Index,Provides functions for calculating and analyzing the proliferative 
    index (PI) from an RNA-seq dataset. As described in Ramaker & Lasseigne, 
    et al. bioRxiv, 2016 <doi:10.1101/063057>.
snakecase,2017-05-18,snakecase: Convert Strings into any Case,A consistent, flexible and easy to use tool to parse and convert strings into cases like snake or camel among others.
EL2Surv,2017-06-28,EL2Surv: Empirical Likelihood (EL) for Comparing Two Survival Functions,Functions for computing critical values and implementing the one-sided/two-sided EL tests.
kirby21.base,2017-02-28,kirby21.base: Example Data from the Multi-Modal MRI 'Reproducibility' Resource,Multi-modal magnetic resonance imaging ('MRI')
    data from the 'Kirby21' 'reproducibility' study
    <https://www.nitrc.org/projects/multimodal/>, including functional
    and structural imaging.
kirby21.fmri,2017-03-02,kirby21.fmri: Example Functional Imaging Data from the Multi-Modal MRI
'Reproducibility' Resource,Functional magnetic resonance imaging ('fMRI')
       data from the 'Kirby21' 'reproducibility' study
       <doi:10.1016/j.neuroimage.2010.11.047>.
kirby21.t1,2017-03-02,kirby21.t1: Example T1 Structural Data from the Multi-Modal MRI
'Reproducibility' Resource,Structural T1 magnetic resonance imaging ('MRI')
       data from the 'Kirby21' 'reproducibility' study
       <doi:10.1016/j.neuroimage.2010.11.047>.
sequoia,2017-02-13,sequoia: Pedigree Inference from SNPs,Fast multi-generational pedigree inference from incomplete data on
    hundreds of SNPs, including parentage assignment and sibship clustering.
    See citation('sequoia') for more information.
subprocess,2016-11-29,subprocess: Manage Sub-Processes in R,Create and handle multiple sub-processes in R, exchange
  data over standard input and output streams, control their life cycle.
genBaRcode,2017-09-21,genBaRcode: Analysis and Visualization Tools for Genetic Barcode Data,Provides the necessary functions to identify and extract a selection of already available barcode constructs (Cornils, K. et al. (2014) <doi:10.1093/nar/gku081>) and freely choosable barcode designs from next generation sequence (NGS) data. Furthermore, it offers the possibility to account for sequence errors, the calculation of barcode similarities and provides a variety of visualisation tools (Thielecke, L. et al. (2017) <doi:10.1038/srep43249>).
libstableR,2017-06-01,libstableR: Fast and Accurate Evaluation, Random Number Generation and
Parameter Estimation of Skew Stable Distributions,Tools for fast and accurate evaluation of skew stable distributions (CDF, PDF 
  and quantile functions), random number generation and parameter estimation.
MCMCprecision,2017-04-03,MCMCprecision: Precision of Discrete Parameters in Transdimensional MCMC,Estimates the precision of transdimensional Markov chain Monte Carlo 
    (MCMC) output, which is often used for Bayesian analysis of models with different 
    dimensionality (e.g., model selection). Transdimensional MCMC (e.g., reversible 
    jump MCMC) relies on sampling a discrete model-indicator variable to estimate 
    the posterior model probabilities. If only few switches occur between the models, 
    precision may be low and assessment based on the assumption of independent 
    samples misleading. Based on the observed transition matrix of the indicator 
    variable, the method of Heck, Overstall, Gronau, & Wagenmakers (2018, 
    Statistics & Computing) <doi:10.1007/s11222-018-9828-0> draws posterior samples 
    of the stationary distribution to (a) assess the uncertainty in the estimated 
    posterior model probabilities and (b) estimate the effective sample size of 
    the MCMC output.
jcolors,2017-07-07,jcolors: Colors Palettes for R and 'ggplot2', Additional Themes for
'ggplot2',Contains a selection of color palettes and 'ggplot2' themes designed by the package author.
IDmining,2016-11-25,IDmining: Intrinsic Dimension for Data Mining,Contains techniques for mining large and high-dimensional data
    sets by using the concept of Intrinsic Dimension (ID). Here the ID is
    not necessarily an integer. It is extended to fractal dimensions. And
    the Morisita estimator is used for the ID estimation, but other
    tools are included as well.
PRISMAstatement,2016-10-12,PRISMAstatement: Plot Flow Charts According to the "PRISMA" Statement,Plot a PRISMA <http://prisma-statement.org/> flow
    chart describing the identification, screening, eligibility and
    inclusion or studies in systematic reviews. PRISMA is an
    evidence-based minimum set of items for reporting in systematic
    reviews and meta-analyses. PRISMA focuses on the reporting of reviews
    evaluating randomized trials, but can also be used as a basis for
    reporting systematic reviews of other types of research, particularly
    evaluations of interventions.
taxa,2017-07-16,taxa: Taxonomic Classes,Provides taxonomic classes for
    groupings of taxonomic names without data, and those
    with data. Methods provided are "taxonomically aware", in
    that they know about ordering of ranks, and methods that
    filter based on taxonomy also filter associated data.
gridsample,2016-11-24,gridsample: Tools for Grid-Based Survey Sampling Design,Multi-stage cluster surveys of households are commonly performed by
  governments and programmes to monitor population-level demographic, social,
  economic, and health outcomes. Generally, communities are sampled from
  subpopulations (strata) in a first stage, and then households are listed and
  sampled in a second stage. In this typical two-stage design, sampled
  communities are the Primary Sampling Units (PSUs) and households are the
  Secondary Sampling Units (SSUs). Census data typically serve as the sample
  frame from which PSUs are selected. However, if census data are outdated
  inaccurate, or too geographically course, gridded population data (such as
  <http://www.worldpop.org.uk>) can be used as a sample frame instead.
  GridSample (<doi:10.1186/s12942-017-0098-4>) generates PSUs from
  gridded population data according to user-specified complex survey design
  characteristics and household sample size. In gridded population sampling,
  like census sampling, PSUs are selected within each stratum using a
  serpentine sampling method, and can be oversampled in urban or rural areas to
  ensure a minimum sample size in each of these important sub-domains.
  Furthermore, because grid cells are uniform in size and shape, gridded
  population sampling allows for samples to be representative of both the
  population and of space, which is not possible with a census sample frame.
nsROC,2017-06-23,nsROC: Non-Standard ROC Curve Analysis,Tools for estimating Receiver Operating Characteristic (ROC) curves,
        building confidence bands, comparing several curves both for dependent and 
        independent data, estimating the cumulative-dynamic ROC curve in presence of
        censored data, and performing meta-analysis studies, among others.
roadoi,2017-04-06,roadoi: Find Free Versions of Scholarly Publications via Unpaywall,This web client interfaces Unpaywall <https://unpaywall.org/products/api>, formerly
    oaDOI, a service finding free full-texts of academic papers by linking DOIs with 
    open access journals and repositories. It provides unified access to various data sources 
    for open access full-text links including Crossref and the Directory of Open Access 
    Journals (DOAJ). API usage is free and no registration is required.
tmaptools,2017-01-03,tmaptools: Thematic Map Tools,Set of tools for reading and processing spatial data. The aim is to supply the workflow to create thematic maps. This package also facilitates 'tmap', the package for visualizing thematic maps.
coda.base,2017-07-18,coda.base: A Basic Set of Functions for Compositional Data Analysis,A minimum set of functions to perform compositional data analysis
    using the log-ratio approach introduced by John Aitchison (1982) <http://www.jstor.org/stable/2345821>. Main functions
    have been implemented in c++ for better performance.
crochet,2017-05-06,crochet: Implementation Helper for [ and [<- Of Custom Matrix-Like Types,Functions to help implement the extraction / subsetting / indexing
    function [ and replacement function [<- of custom matrix-like types (based
    on S3, S4, etc.), modeled as closely to the base matrix class as possible
    (with tests to prove it).
DSAIDE,2017-03-02,DSAIDE: Dynamical Systems Approach to Infectious Disease Epidemiology,A collection of Shiny apps that allow for the simulation and
    exploration of various infectious disease transmission dynamics scenarios.
    The purpose of the package is to help individuals learn 
    about infectious disease epidemiology from a dynamical systems perspective.
    All apps include explanations of the underlying models and instructions on
    what to do with the models. 
gasfluxes,2016-12-23,gasfluxes: Greenhouse Gas Flux Calculation from Chamber Measurements,Functions for greenhouse gas flux calculation from chamber
    measurements.
MatrixLDA,2016-10-29,MatrixLDA: Penalized Matrix-Normal Linear Discriminant Analysis,Fits the penalized matrix-normal model to be used for linear discriminant analysis with matrix-valued predictors. For a description of the method, see Molstad and Rothman (2018) <doi:10.1080/10618600.2018.1476249>. 
reticulate,2017-03-14,reticulate: Interface to 'Python',Interface to 'Python' modules, classes, and functions. When calling
    into 'Python', R data types are automatically converted to their equivalent 'Python'
    types. When values are returned from 'Python' to R they are converted back to R
    types. Compatible with all versions of 'Python' >= 2.7.
rPraat,2017-07-16,rPraat: Interface to Praat,Read, write and manipulate 'Praat' TextGrid, PitchTier, Pitch and Intensity files <http://www.fon.hum.uva.nl/praat/>.
simmer.plot,2016-12-28,simmer.plot: Plotting Methods for 'simmer',A set of plotting methods for 'simmer' trajectories and simulations.
ggformula,2017-06-22,ggformula: Formula Interface to the Grammar of Graphics,Provides a formula interface to 'ggplot2' graphics.
icesTAF,2017-06-03,icesTAF: Functions to Support the ICES Transparent Assessment Framework,Functions to support the ICES Transparent Assessment Framework
  <http://taf.ices.dk> to organize data, methods, and results used in ICES
  assessments. ICES is an organization facilitating international collaboration
  in marine science.
pre,2016-12-24,pre: Prediction Rule Ensembles,Derives prediction rule ensembles (PREs). Largely follows the
    procedure for deriving PREs as described in Friedman & Popescu (2008; 
    <doi:10.1214/07-AOAS148>), with adjustments and improvements. The 
    main function pre() derives prediction rule ensembles consisting of 
    rules and/or linear terms for continuous, binary, count, multinomial, 
    and multivariate continuous responses. Function gpe() derives 
    generalized prediction ensembles, consisting of rules, hinge and linear 
    functions of the predictor variables.
TOSTER,2016-12-08,TOSTER: Two One-Sided Tests (TOST) Equivalence Testing,Two one-sided tests (TOST) procedure to test equivalence for t-tests, correlations, differences between proportions, and meta-analyses, including power analysis for t-tests and correlations. Allows you to specify equivalence bounds in raw scale units or in terms of effect sizes. See: Lakens (2017) <doi:10.1177/1948550617697177>.
bayesplot,2016-11-18,bayesplot: Plotting for Bayesian Models,Plotting functions for posterior analysis, model checking,
    and MCMC diagnostics. The package is designed not only to provide convenient
    functionality for users, but also a common set of functions that can be
    easily used by developers working on a variety of R packages for Bayesian
    modeling, particularly (but not exclusively) packages interfacing with 'Stan'.
LncFinder,2017-02-06,LncFinder: LncRNA Identification and Analysis Using Heterologous Features,Long non-coding RNAs identification and analysis. Default models are trained with human, mouse and wheat datasets by employing SVM. Features are based on intrinsic composition of sequence, EIIP value (electron-ion interaction pseudopotential), and secondary structure. This package can also extract other classic features and build new classifiers. Reference: Han SY., Liang YC., Li Y., et al. (2018) <doi:10.1093/bib/bby065>.
colourvision,2016-11-10,colourvision: Colour Vision Models,Colour vision models, colour spaces and colour thresholds. Provides flexibility to build user-defined colour vision models for n number of photoreceptor types. Also includes Vorobyev & Osorio (1998) Receptor Noise Limited models, Chittka (1992) colour hexagon, and Endler & Mielke (2005) model. Models have been extended to accept any number of photoreceptor types. 
hyper2,2017-06-28,hyper2: The Hyperdirichlet Distribution, Mark 2,A suite of routines for the hyperdirichlet distribution; supersedes the 'hyperdirichlet' package for most purposes.
flifo,2017-01-14,flifo: Don't Get Stuck with Stacks in R,Functions to create and manipulate 
    FIFO (First In First Out), LIFO (Last In First Out), and NINO (Not In or Never Out) 
    stacks in R.
gcKrig,2016-11-10,gcKrig: Analysis of Geostatistical Count Data using Gaussian Copulas,Provides a variety of functions to analyze and model
    geostatistical count data with Gaussian copulas, including
 1) data simulation and visualization; 
 2) correlation structure assessment (here also known as the Normal To Anything); 
 3) calculate multivariate normal rectangle probabilities; 
 4) likelihood inference and parallel prediction at predictive locations.
geomerge,2017-08-29,geomerge: Geospatial Data Integration,Geospatial data integration framework that merges raster, spatial polygon, and (dynamic) spatial points data into a spatial (panel) data frame at any geographical resolution.
janitor,2016-10-03,janitor: Simple Tools for Examining and Cleaning Dirty Data,The main janitor functions can: perfectly format data.frame column
    names; provide quick counts of variable combinations (i.e., frequency
    tables and crosstabs); and isolate duplicate records. Other janitor functions
    nicely format the tabulation results. These tabulate-and-report functions
    approximate popular features of SPSS and Microsoft Excel. This package
    follows the principles of the "tidyverse" and works well with the pipe function
    %>%. janitor was built with beginning-to-intermediate R users in mind and is
    optimized for user-friendliness. Advanced R users can already do everything
    covered here, but with janitor they can do it faster and save their thinking for
    the fun stuff.
statip,2017-01-29,statip: Statistical Functions for Probability Distributions and
Regression,A collection of miscellaneous statistical functions for 
    probability distributions: dbern(), pbern(), qbern(), rbern() for 
    the Bernoulli distribution, and distr2name(), name2distr() for 
    distribution names; 
    probability density estimation: densityfun(); 
    most frequent value estimation: mfv(), mfv1(); 
    calculation of the Hellinger distance: hellinger(); 
    use of classical kernels: kernelfun(), kernel_properties(); 
    univariate piecewise-constant regression: picor(). 
dotCall64,2016-10-07,dotCall64: Enhanced Foreign Function Interface Supporting Long Vectors,Provides .C64(), which is an enhanced version of .C()
    and .Fortran() from the foreign function interface. .C64() supports long
    vectors, arguments of type 64-bit integer, and provides a mechanism to
    avoid unnecessary copies of read-only and write-only arguments. This
    makes it a convenient and fast interface to C/C++ and Fortran code.
reghelper,2017-04-08,reghelper: Helper Functions for Regression Analysis,A set of functions used to automate commonly used methods in
    regression analysis. This includes plotting interactions, calculating simple
    slopes, calculating standardized coefficients, etc. See the reghelper
    documentation for more information, documentation, and examples.
sylly,2017-09-12,sylly: Hyphenation and Syllable Counting for Text Analysis,Provides the hyphenation algorithm used for 'TeX'/'LaTeX'
        and similar software, as proposed by Liang (1983,
        <https://tug.org/docs/liang/>). Mainly contains the function
        hyphen() to be used for hyphenation/syllable counting of text
        objects. It was originally developed for and part of the
        'koRpus' package, but later released as a separate package so
        it's lighter to have this particular functionality available
        for other packages. Support for various languages needs be
        added on-the-fly or by plugin packages
        (<https://undocumeantit.github.io/repos>); this package does
        not include any language specific data. Due to some
        restrictions on CRAN, the full package sources are only
        available from the project homepage. To ask for help, report
        bugs, request features, or discuss the development of the
        package, please subscribe to the koRpus-dev mailing list
        (<http://korpusml.reaktanz.de>).
makedummies,2017-01-02,makedummies: Create Dummy Variables from Categorical Data,Create dummy variables from categorical data.
    This package can convert categorical data (factor and ordered) into
    dummy variables and handle multiple columns simultaneously.
    This package enables to select whether a dummy variable for base group
    is included (for principal component analysis/factor analysis) or
    excluded (for regression analysis) by an option.
woeBinning,2017-02-21,woeBinning: Supervised Weight of Evidence Binning of Numeric Variables and
Factors,Implements an automated binning of numeric variables and factors with
 respect to a dichotomous target variable.
 Two approaches are provided: An implementation of fine and coarse classing that
 merges granular classes and levels step by step. And a tree-like approach that
 iteratively segments the initial bins via binary splits. Both procedures merge,
 respectively split, bins based on similar weight of evidence (WOE) values and
 stop via an information value (IV) based criteria.
 The package can be used with single variables or an entire data frame. It provides
 flexible tools for exploring different binning solutions and for deploying them to
 (new) data.
CBCgrps,2017-07-30,CBCgrps: Compare Baseline Characteristics Between Groups,Compare baseline characteristics between two or more groups. The variables being compared can be factor and numeric variables. The function will automatically judge the type and distribution of the variables, and make statistical description and bivariate analysis. 
CSeqpat,2017-03-20,CSeqpat: Frequent Contiguous Sequential Pattern Mining of Text,Mines contiguous sequential patterns in text.
aws.ec2metadata,2016-12-20,aws.ec2metadata: Get EC2 Instance Metadata,Retrieve Amazon EC2 instance metadata from within the running instance.
errors,2017-04-24,errors: Uncertainty Propagation for R Vectors,Support for measurement errors in R vectors, matrices and arrays: 
  automatic uncertainty propagation and reporting.
GPoM,2017-04-04,GPoM: Generalized Polynomial Modelling,Platform dedicated to the Global Modelling technique. Its aim is to
    obtain ordinary differential equations of polynomial form directly from
    time series. It can be applied to single or multiple time series under various
    conditions of noise, time series lengths, sampling, etc. This platform
    is developped at the Centre d'Etudes Spatiales de la Biosphere (CESBIO), UMR 5126
    UPS/CNRS/CNES/IRD, 18 av. Edouard Belin, 31401 TOULOUSE, FRANCE.
    The developments were funded by the French program Les Enveloppes
    Fluides et l'Environnement (LEFE, MANU, projets GloMo, SpatioGloMo and MoMu).
    The French program Defi InFiNiTi (CNRS) and PNTS are also acknowledged
    (projects Crops'IChaos and Musc & SlowFast).
projmanr,2017-08-23,projmanr: Project Management Tools,Calculates the critical path for a series of tasks, 
	creates Gantt charts and generates network diagrams in order to 
	provide similar functionality to the basic tools offered by 'MS Project'.
regplot,2017-09-27,regplot: Enhanced Regression Nomogram Plot,A function to plot a regression nomogram of coxph, lm and glm regression 
    objects. Covariate distributions are superimposed on nomogram scales and the plot
	is animated to allow on the fly changes to distribution representation and to 
	enable outcome calculation. 
dbplyr,2017-06-09,dbplyr: A 'dplyr' Back End for Databases,A 'dplyr' back end for databases that allows you to work with 
    remote database tables as if they are in-memory data frames. Basic features
    works with any database that has a 'DBI' back end; more advanced features 
    require 'SQL' translation to be provided by the package author.
netCoin,2016-12-21,netCoin: Interactive Analytic Networks,Create interactive analytic networks. It joins the data analysis power of R to obtain coincidences, co-occurrences and correlations, and the visualization libraries of 'JavaScript' in one package.
oddsratio,2016-10-12,oddsratio: Odds Ratio Calculation for GAM(M)s & GLM(M)s,Simplified odds ratio calculation of GAM(M)s & GLM(M)s. 
    Provides structured output (data frame) of all predictors and their corresponding odds ratios and confident intervals for further analyses. 
    It helps to avoid false references of predictors and increments by specifying these parameters in a list instead of using 'exp(coef(model))' (standard approach of odds ratio calculation for GLMs) which just returns a plain numeric output. 
    For GAM(M)s, odds ratio calculation is highly simplified with this package since it takes care of the multiple 'predict()' calls of the chosen predictor while holding other predictors constant.
    Also, this package allows odds ratio calculation of percentage steps across the whole predictor distribution range for GAM(M)s. 
    In both cases, confident intervals are returned additionally.
    Calculated odds ratio of GAM(M)s can be inserted into the smooth function plot. 
shinyjqui,2017-03-04,shinyjqui: 'jQuery UI' Interactions and Effects for Shiny,An extension to shiny that brings interactions and animation effects from
    'jQuery UI' library.
simglm,2017-05-25,simglm: Simulate Models Based on the Generalized Linear Model,Easily simulates regression models,
    including both simple regression and generalized linear mixed
    models with up to three level of nesting. Power simulations that are
    flexible allowing the specification of missing data, unbalanced designs,
    and different random error distributions are built into the package.
textTinyR,2017-01-07,textTinyR: Text Processing for Small or Big Data Files,It offers functions for splitting, parsing, tokenizing and creating a vocabulary for big text data files. Moreover, it includes functions for building a document-term matrix and extracting information from those (term-associations, most frequent terms). It also embodies functions for calculating token statistics (collocations, look-up tables, string dissimilarities) and functions to work with sparse matrices. Lastly, it includes functions for Word Vector Representations (i.e. 'GloVe', 'fasttext') and incorporates functions for the calculation of (pairwise) text document dissimilarities. The source code is based on 'C++11' and exported in R through the 'Rcpp', 'RcppArmadillo' and 'BH' packages.
anMC,2017-05-05,anMC: Compute High Dimensional Orthant Probabilities,Computationally efficient method to estimate orthant probabilities of high-dimensional Gaussian vectors. Further implements a function to compute conservative estimates of excursion sets under Gaussian random field priors. 
safer,2017-04-21,safer: Encrypt and Decrypt Strings, R Objects and Files,A consistent interface to encrypt and decrypt strings, R objects and files using symmetric and asymmetric key encryption.
mapsapi,2017-09-27,mapsapi: 'sf'-Compatible Interface to 'Google Maps' APIs,Interface to the 'Google Maps' APIs: (1) routing directions based on the 'Directions' API, returned as 'sf' objects, either as single feature per alternative route, or a single feature per segment per alternative route; (2) travel distance or time matrices based on the 'Distance Matrix' API; (3) geocoded locations based on the 'Geocode' API, returned as 'sf' objects, either points or bounds.
nmaINLA,2017-06-20,nmaINLA: Network Meta-Analysis using Integrated Nested Laplace
Approximations,Performs network meta-analysis using integrated nested Laplace approximations ('INLA'). Includes methods to assess the heterogeneity and inconsistency in the network. Contains more than ten different network meta-analysis data. 'INLA' package can be obtained from <http://www.r-inla.org>. We recommend the testing version.
officer,2017-03-01,officer: Manipulation of Microsoft Word and PowerPoint Documents,Access and manipulate 'Microsoft Word' and 'Microsoft PowerPoint' documents from R. 
  The package focuses on tabular and graphical reporting from R; it also provides two functions
  that let users get document content into data objects. A set of functions 
  lets add and remove images, tables and paragraphs of text in new or existing documents. 
  When working with 'PowerPoint' presentations, slides can be added or removed; shapes inside 
  slides can also be added or removed. When working with 'Word' documents, a cursor can be 
  used to help insert or delete content at a specific location in the document. The package 
  does not require any installation of Microsoft products to be able to write Microsoft files.
textclean,2017-01-10,textclean: Text Cleaning Tools,Tools to clean and process text.  Tools are geared at checking for substrings that
          are not optimal for analysis and replacing or removing them (normalizing) with more
          analysis friendly substrings (see Sproat, Black, Chen, Kumar, Ostendorf, & Richards
          (2001) <doi:10.1006/csla.2001.0169>) or extracting them into new variables. For
          example, emoticons are often used in text but not always easily handled by analysis
          algorithms.  The replace_emoticon() function replaces emoticons with word
          equivalents.
WordR,2017-08-29,WordR: Rendering Word Documents with R Inline Code,Serves for rendering MS Word documents with R inline code and inserting tables and plots.
ggiraphExtra,2016-12-03,ggiraphExtra: Make Interactive 'ggplot2'. Extension to 'ggplot2' and 'ggiraph',Collection of functions to enhance 'ggplot2' and 'ggiraph'. Provides functions for exploratory plots.
    All plot can be a 'static' plot or an 'interactive' plot using 'ggiraph'.
MSbox,2017-08-28,MSbox: Mass Spectrometry Tools,Common mass spectrometry tools described in John Roboz (2013) <doi:10.1201/b15436>. It allows checking element
 isotopes, calculating (isotope labelled) exact monoisitopic mass, m/z values and mass accuracy, and inspecting possible contaminant mass peaks,
 examining possible adducts in electrospray ionization (ESI) and matrix-assisted laser desorption ionization (MALDI)
 ion sources. 
survutils,2017-03-22,survutils: Utility Functions for Survival Analysis,Functional programming principles to iteratively run Cox 
    regression and plot its results. The results are reported in tidy data 
    frames. Additional utility functions are available for working with 
    other aspects of survival analysis such as survival curves, C-statistics, 
    etc.
BAMBI,2017-01-01,BAMBI: Bivariate Angular Mixture Models,Fit (using Bayesian methods) and simulate mixtures of univariate and bivariate angular distributions. Chakraborty and Wong (2017) <arXiv:1708.07804> .
ggpval,2017-06-13,ggpval: Annotate Statistical Tests for 'ggplot2',Automatically performs desired statistical tests (e.g. wilcox.test(), t.test()) to compare between groups, 
    and adds the resulting p-values to the plot with an annotation bar.
    Visualizing group differences are frequently performed by boxplots, bar plots, etc.
    Statistical test results are often needed to be annotated on these plots. 
    This package provides a convenient function that works on 'ggplot2' objects, 
    performs the desired statistical test between groups of interest and annotates the test results on the plot.
wdman,2017-01-18,wdman: 'Webdriver'/'Selenium' Binary Manager,There are a number of binary files associated with the
    'Webdriver'/'Selenium' project (see <http://www.seleniumhq.org/download/>,
    <https://sites.google.com/a/chromium.org/chromedriver/>,
    <https://github.com/mozilla/geckodriver>,
    <http://phantomjs.org/download.html> and
    <https://github.com/SeleniumHQ/selenium/wiki/InternetExplorerDriver> for
    more information). This package provides functions to download these
    binaries and to manage processes involving them.
BALCONY,2017-08-03,BALCONY: Better ALignment CONsensus analYsis,Facilitates the evolutionary analysis and structure conservation study of specified amino acids in proteins.
ggstance,2016-11-16,ggstance: Horizontal 'ggplot2' Components,A 'ggplot2' extension that provides flipped components:
    horizontal versions of 'Stats' and 'Geoms', and vertical versions
    of 'Positions'.
lumberjack,2017-06-14,lumberjack: Track Changes in Data,A function composition ('pipe') operator and extensible 
    framework that allows for easy logging of changes in data.
Seurat,2017-08-22,Seurat: Tools for Single Cell Genomics,A toolkit for quality control, analysis, and exploration of single cell RNA sequencing data. 'Seurat' aims to enable users to identify and interpret sources of heterogeneity from single cell transcriptomic measurements, and to integrate diverse types of single cell data. See Satija R, Farrell J, Gennert D, et al (2015) <doi:10.1038/nbt.3192>, Macosko E, Basu A, Satija R, et al (2015) <doi:10.1016/j.cell.2015.05.002>, and Butler A and Satija R (2017) <doi:10.1101/164889> for more details.
spind,2017-04-04,spind: Spatial Methods and Indices,Functions for spatial methods based on generalized estimating equations (GEE) and
  wavelet-revised methods (WRM), functions for scaling by wavelet multiresolution regression (WMRR),
  conducting multi-model inference, and stepwise model selection. Further, contains functions 
  for spatially corrected model accuracy measures.
spm,2017-08-25,spm: Spatial Predictive Modeling,Introduction to some novel accurate hybrid methods of geostatistical and machine learning methods for spatial predictive modelling. It contains two commonly used geostatistical methods, two machine learning methods, four hybrid methods and two averaging methods. For each method, two functions are provided. One function is for assessing the predictive errors and accuracy of the method based on cross-validation. The other one is for generating spatial predictions using the method. For details please see: Li, J., Potter, A., Huang, Z., Daniell, J. J. and Heap, A. (2010) <https:www.ga.gov.au/metadata-gateway/metadata/record/gcat_71407>
  Li, J., Heap, A. D., Potter, A., Huang, Z. and Daniell, J. (2011) <doi:10.1016/j.csr.2011.05.015>
  Li, J., Heap, A. D., Potter, A. and Daniell, J. (2011) <doi:10.1016/j.envsoft.2011.07.004>
  Li, J., Potter, A., Huang, Z. and Heap, A. (2012) <https:www.ga.gov.au/metadata-gateway/metadata/record/74030>.
vagalumeR,2017-09-30,vagalumeR: Access to the 'Vagalume' API,Provides access to the 'Vagalume' API <https://api.vagalume.com.br>. 
    The data extracted is basically lyrics of songs and information about
    artists/bands.
blastula,2017-08-21,blastula: Easily Send HTML Email Messages,Compose and send out responsive HTML email messages that render
    perfectly across a range of email clients and device sizes. Messages are
    composed using 'Markdown' and a text interpolation system that allows for
    the injection of evaluated R code within the message body, footer, and
    subject line. Helper functions let the user insert embedded images, web
    link buttons, and 'ggplot2' plot objects into the message body. Messages
    can be sent through an 'SMTP' server or through the 'Mailgun' API service
    <http://mailgun.com/>.
ncar,2017-01-25,ncar: Noncompartmental Analysis for Pharmacokinetic Report,Conduct a noncompartmental analysis as closely as possible to the most widely used commercial software for pharmacokinetic analysis, i.e. 'Phoenix(R) WinNonlin(R)' <https://www.certara.com/software/pkpd-modeling-and-simulation/phoenix-winnonlin/>.
             Some features are
             1) CDISC SDTM terms
             2) Automatic slope selection with the same criterion of WinNonlin(R)
             3) Supporting both 'linear-up linear-down' and 'linear-up log-down' method
             4) Interval(partial) AUCs with 'linear' or 'log' interpolation method
             5) Produce pdf, rtf, text report files.
             * Reference: Gabrielsson J, Weiner D. Pharmacokinetic and Pharmacodynamic Data Analysis - Concepts and Applications. 5th ed. 2016. (ISBN:9198299107).
NonCompart,2016-11-27,NonCompart: Noncompartmental Analysis for Pharmacokinetic Data,Conduct a noncompartmental analysis as closely as possible to the most widely used commercial software for pharmacokinetic analysis, i.e. 'Phoenix(R) WinNonlin(R)' <https://www.certara.com/software/pkpd-modeling-and-simulation/phoenix-winnonlin/>.
             Some features are
             1) Use of CDISC SDTM terms
             2) Automatic slope selection with the same criterion of WinNonlin(R)
             3) Supporting both 'linear-up linear-down' and 'linear-up log-down' method
             4) Interval(partial) AUCs with 'linear' or 'log' interpolation method
             * Reference: Gabrielsson J, Weiner D. Pharmacokinetic and Pharmacodynamic Data Analysis - Concepts and Applications. 5th ed. 2016. (ISBN:9198299107).
rwalkr,2017-08-01,rwalkr: API to Melbourne Pedestrian Data,Provides API to Melbourne pedestrian data in tidy data form.
binman,2016-12-11,binman: A Binary Download Manager,Tools and functions for managing the download of binary files.
    Binary repositories are defined in 'YAML' format. Defining new 
    pre-download, download and post-download templates allow additional 
    repositories to be added.
CNLTreg,2017-03-04,CNLTreg: Complex-Valued Wavelet Lifting for Signal Denoising,Implementations of recent complex-valued wavelet shrinkage procedures for smoothing irregularly sampled signals, see Hamilton et al (2018) <doi:10.1080/00401706.2017.1281846>.
CNLTtsa,2017-03-08,CNLTtsa: Complex-Valued Wavelet Lifting for Univariate and Bivariate Time
Series Analysis,Implementations of recent complex-valued wavelet spectral procedures for analysis of irregularly sampled signals, see Hamilton et al (2018) <doi:10.1080/00401706.2017.1281846>.
future.batchtools,2017-06-03,future.batchtools: A Future API for Parallel and Distributed Processing using
'batchtools',Implementation of the Future API on top of the 'batchtools' package.
    This allows you to process futures, as defined by the 'future' package,
    in parallel out of the box, not only on your local machine or ad-hoc
    cluster of machines, but also via high-performance compute ('HPC') job
    schedulers such as 'LSF', 'OpenLava', 'Slurm', 'SGE', and 'TORQUE' / 'PBS',
    e.g. 'y <- future.apply::future_lapply(files, FUN = process)'.
qqplotr,2017-07-25,qqplotr: Quantile-Quantile Plot Extensions for 'ggplot2',Extensions of 'ggplot2' Q-Q plot functionalities.
rmpw,2017-02-27,rmpw: Causal Mediation Analysis Using Weighting Approach,We implement causal mediation analysis using the methods proposed by Hong (2010) and Hong, Deutsch & Hill (2015) <doi:10.3102/1076998615583902>. It allows the estimation and hypothesis testing of causal mediation effects through ratio of mediator probability weights (RMPW). This strategy conveniently relaxes the assumption of no treatment-by-mediator interaction while greatly simplifying the outcome model specification without invoking strong distributional assumptions. We also implement a sensitivity analysis by extending the RMPW method to assess potential bias in the presence of omitted pretreatment or posttreatment covariates. The sensitivity analysis strategy was proposed by Hong, Qin, and Yang (2018) <doi:10.3102/1076998617749561>.
SmoothWin,2017-09-06,SmoothWin: Soft Windowing on Linear Regression,The main function in the package utilizes a windowing function in the form of an exponential weighting function to linear models. The bandwidth and sharpness of the window are controlled by two parameters. Then, a series of tests are used to identify the right parameters of the window (see Charles Kervrann (2004) <doi:10.1007/978-3-540-24672-5_11>).
CATkit,2017-02-11,CATkit: Chronomics Analysis Toolkit (CAT): Periodicity Analysis,Calculates auto- and cross-correlation functions and plots an actogram and a smoothing function from a time series to identify and visualize periodic components. Tests presence of anticipated rhythm and estimates rhythm parameters; fits model consisting of multiple rhythmic components to data; performs least squares spectral analysis and other cosinor-based analyses, including population-mean cosinor (PMC) and population-mean cosinor parameter tests (PMCtest). 
CodeDepends,2017-05-29,CodeDepends: Analysis of R Code for Reproducible Research and Code
Comprehension,Tools for analyzing R expressions
  or blocks of code and determining the dependencies between them.
  It focuses on R scripts, but can be used on the bodies of functions.
  There are many facilities including the ability to summarize  or get a high-level
  view of code, determining dependencies between variables,  code improvement
  suggestions.
dgo,2017-05-23,dgo: Dynamic Estimation of Group-Level Opinion,Fit dynamic group-level item response theory (IRT) and multilevel
    regression and poststratification (MRP) models from item response data. dgo
    models latent traits at the level of demographic and geographic groups,
    rather than individuals, in a Bayesian group-level IRT approach developed by
    Caughey and Warshaw (2015) <doi:10.1093/pan/mpu021>. The package also
    estimates subpopulations' average responses to single survey items with a
    dynamic MRP model proposed by Park, Gelman, and Bafumi (2004)
    <doi:10.11126/stanford/9780804753005.003.0011>.
easyDes,2017-01-03,easyDes: An Easy Way to Descriptive Analysis,
  Descriptive analysis is essential for publishing medical articles.
  This package provides an easy way to conduct the descriptive analysis.
  1. Both numeric and factor variables can be handled. For numeric variables, normality test will be applied to choose the parametric and nonparametric test.
  2. Both two or more groups can be handled. For groups more than two, the post hoc test will be applied, 'Tukey' for the numeric variables and 'FDR' for the factor variables.
  3. T test, ANOVA or Fisher test can be forced to apply.
  4. Mean and standard deviation can be forced to display.
glue,2017-04-18,glue: Interpreted String Literals,An implementation of interpreted string literals, inspired by
  Python's Literal String Interpolation <https://www.python.org/dev/peps/pep-0498/> and Docstrings
  <https://www.python.org/dev/peps/pep-0257/> and Julia's Triple-Quoted String Literals
  <https://docs.julialang.org/en/stable/manual/strings/#triple-quoted-string-literals>.
pinp,2017-09-16,pinp: 'pinp' is not 'PNAS',A 'PNAS'-alike style for 'rmarkdown', derived from the
 'Proceedings of the National Academy of Sciences of the United States
 of America' ('PNAS', see <https://www.pnas.org>) 'LaTeX' style, and
 adapted for use with 'markdown' and 'pandoc'.
rmda,2017-08-01,rmda: Risk Model Decision Analysis,Provides tools to evaluate the value of using a risk prediction instrument to decide treatment or intervention (versus no treatment or intervention).  Given one or more risk prediction instruments (risk models) that estimate the probability of a binary outcome, rmda provides functions to estimate and display decision curves and other figures that help assess the population impact of using a risk model for clinical decision making.   Here, "population" refers to the relevant patient population. Decision curves display estimates of the (standardized) net benefit over a range of probability thresholds used to categorize observations as 'high risk'. The curves help evaluate a treatment policy that recommends treatment for patients who are estimated to be 'high risk' by comparing the population impact of a risk-based policy to "treat all" and "treat none" intervention policies.  Curves can be estimated using data from a prospective cohort.  In addition, rmda can estimate decision curves using data from a case-control study if an estimate of the population outcome prevalence is available.  Version 1.4 of the package provides an alternative framing of the decision problem for situations where treatment is the standard-of-care and a risk model might be used to recommend that low-risk patients (i.e., patients below some risk threshold) opt out of treatment. Confidence intervals calculated using the bootstrap can be computed and displayed. A wrapper function to calculate cross-validated curves using k-fold cross-validation is also provided. 
RTransProb,2017-04-11,RTransProb: Analyze and Forecast Credit Migrations,A set of functions used to automate commonly used methods in credit risk to estimate migration (transition) matrices. The package includes multiple methods for bootstrapping default rates and forecasting/stress testing credit exposures migrations, via Econometric and Machine Learning approaches.  More information can be found at <https://analyticsrusers.blog>.
scatterpie,2016-12-02,scatterpie: Scatter Pie Plot,Creates scatterpie plots, especially useful for plotting pies on a map.
BayesianTools,2017-02-06,BayesianTools: General-Purpose MCMC and SMC Samplers and Tools for Bayesian
Statistics,General-purpose MCMC and SMC samplers, as well as plot and
    diagnostic functions for Bayesian statistics, with a particular focus on
    calibrating complex system models. Implemented samplers include various
    Metropolis MCMC variants (including adaptive and/or delayed rejection MH), the
    T-walk, two differential evolution MCMCs, two DREAM MCMCs, and a sequential
    Monte Carlo (SMC) particle filter.
beyondWhittle,2017-01-23,beyondWhittle: Bayesian Spectral Inference for Stationary Time Series,Implementations of Bayesian parametric, nonparametric and semiparametric procedures for univariate and multivariate time series. The package is based on the methods presented in C. Kirch et al (2018) <doi:10.1214/18-BA1126> and A. Meier (2018) <https://opendata.uni-halle.de//handle/1981185920/13470>. It was supported by DFG grant KI 1443/3-1.
DendroSync,2017-05-22,DendroSync: A Set of Tools for Calculating Spatial Synchrony Between
Tree-Ring Chronologies,Provides functions for the calculation and plotting of synchrony in 
      tree growth from tree-ring width chronologies (TRW index). It combines
      variance-covariance (VCOV) mixed modelling with functions that quantify 
      the degree to which the TRW chronologies contain a common temporal 
      signal. It also implements temporal trends in spatial synchrony using a 
      moving window. These methods can also be used with other kind of ecological
      variables that have temporal autocorrelation corrected.
GCalignR,2017-02-06,GCalignR: Simple Peak Alignment for Gas-Chromatography Data,Aligns peak based on peak retention times and matches homologous peaks
    across samples. The underlying alignment procedure comprises three sequential steps.
    (1) Full alignment of samples by linear transformation of retention times to 
    maximise similarity among homologous peaks (2) Partial alignment of peaks within 
    a user-defined retention time window to cluster homologous peaks (3) Merging rows
    that are likely representing homologous substances (i.e. no sample shows peaks in 
    both rows and the rows have similar retention time means). The algorithm is described in detail
    in Ottensmann et al., 2018 <doi:10.1371/journal.pone.0198311>. 
keyring,2017-09-09,keyring: Access the System Credential Store from R,Platform independent 'API' to access the operating system's
    credential store. Currently supports: 'Keychain' on 'macOS', Credential
    Store on 'Windows', the Secret Service 'API' on 'Linux', and a simple,
    platform independent store implemented with environment variables.
    Additional storage back-ends can be added easily.
ordinalForest,2017-04-13,ordinalForest: Ordinal Forests: Prediction and Variable Ranking with Ordinal
Target Variables,The ordinal forest (OF) method allows ordinal regression with high-dimensional
  and low-dimensional data. After having constructed an OF prediction rule using a training dataset, 
  it can be used to predict the values of the ordinal target variable for new observations.
  Moreover, by means of the (permutation-based) variable importance measure of OF, it is also
  possible to rank the covariates with respect to their importances in the prediction of the 
  values of the ordinal target variable.
  OF is presented in Hornung (2017).
  The main functions of the package are: ordfor() (construction of OF) and predict.ordfor() 
  (prediction of the target variable values of new observations).
  References:
  Hornung R. (2017) Ordinal Forests. Tech. Rep. 212, Department of Statistics, 
  University of Munich.
spacyr,2017-05-20,spacyr: Wrapper to the 'spaCy' 'NLP' Library,An R wrapper to the 'Python' 'spaCy' 'NLP' library,
    from <http://spacy.io>.
WRTDStidal,2016-11-08,WRTDStidal: Weighted Regression for Water Quality Evaluation in Tidal Waters,An adaptation for estuaries (tidal waters) of weighted regression
    on time, discharge, and season to evaluate trends in water quality time series.
benchr,2016-11-20,benchr: High Precise Measurement of R Expressions Execution Time,Provides infrastructure to accurately measure and compare
    the execution time of R expressions.
GreedyExperimentalDesign,2016-12-08,GreedyExperimentalDesign: Greedy Experimental Design Construction,Computes experimental designs for a
    two-arm experiment with covariates by greedily optimizing a
    balance objective function. This optimization provides lower
    variance for the treatment effect estimator (and higher power) 
    while preserving a design that is close to complete randomization.
    We return all iterations of the designs for use in a permutation test.
    Additional functionality includes using branch and bound optimization 
    (via Gurobi) and exhaustive enumeration. 
MODIStsp,2017-04-15,MODIStsp: A Tool for Automating Download and Preprocessing of MODIS Land
Products Data,Allows automating the creation of time series of rasters derived
    from MODIS Satellite Land Products data. It performs several typical
    preprocessing steps such as download, mosaicking, reprojection and resize
    of data acquired on a specified time period. All processing parameters
    can be set using a user-friendly GUI. Users can select which layers of
    the original MODIS HDF files they want to process, which additional
    Quality Indicators should be extracted from aggregated MODIS Quality
    Assurance layers and, in the case of Surface Reflectance products
    , which Spectral Indexes should be computed from the original reflectance
    bands. For each output layer, outputs are saved as single-band raster
    files corresponding to each available acquisition date. Virtual files
    allowing access to the entire time series as a single file are also created.
    Command-line execution exploiting a previously saved processing options
    file is also possible, allowing to automatically update time series
    related to a MODIS product whenever a new image is available.
Rlinsolve,2017-09-28,Rlinsolve: Iterative Solvers for (Sparse) Linear System of Equations,Solving a system of linear equations is one of the most fundamental
    computational problems for many fields of mathematical studies, such as
    regression problems from statistics or numerical partial differential equations.
    We provide basic stationary iterative solvers such as Jacobi, Gauss-Seidel,
    Successive Over-Relaxation and SSOR methods. Nonstationary, also known as
	Krylov subspace methods are also provided. Sparse matrix computation is also supported
    in that solving large and sparse linear systems can be manageable using 'Matrix' package
    along with 'RcppArmadillo'. For a more detailed description, see a book by Saad (2003)
    <doi:10.1137/1.9780898718003>.
SpaDES.tools,2017-08-12,SpaDES.tools: Additional Tools for Developing Spatially Explicit Discrete
Event Simulation (SpaDES) Models,Provides GIS and map utilities, plus additional modeling tools for
    developing cellular automata, dynamic raster models,  and agent based models
    in 'SpaDES'.
    Included are various methods for spatial spreading, spatial agents, GIS
    operations, random map generation, and others.
    See '?SpaDES.tools' for an categorized overview of these additional tools.
FRK,2017-03-07,FRK: Fixed Rank Kriging,Fixed Rank Kriging is a tool for spatial/spatio-temporal modelling
    and prediction with large datasets. The approach, discussed in Cressie and
    Johannesson (2008) <doi:10.1111/j.1467-9868.2007.00633.x>, decomposes the field, 
    and hence the covariance function, using a fixed set of n basis functions, 
    where n is typically much smaller than the number of data points (or polygons) m. 
    The method naturally allows for non-stationary, anisotropic covariance functions 
    and the use of observations with varying support (with known error variance). The 
    projected field is a key building block of the Spatial Random Effects (SRE) model, 
    on which this package is based. The package FRK provides helper functions to model, 
    fit, and predict using an SRE with relative ease.
htree,2017-04-26,htree: Historical Tree Ensembles for Longitudinal Data,Historical regression trees are an extension of standard trees, 
	producing a non-parametric estimate of how the response depends on 
	all of its prior realizations as well as that of any time-varying predictor 
	variables. The method applies equally to regularly as well as irregularly 
	sampled data. The package implements random forest and boosting ensembles 
	based on historical regression trees, suitable for longitudinal data. 
	Standard error estimation and Z-score variable importance is also implemented.
incadata,2017-02-15,incadata: Recognize and Handle Data in Formats Used by Swedish Cancer
Centers,
  Handle data in formats used by cancer centers in Sweden, both from 'INCA' 
  (the current register platform, (see <http://rcc.incanet.se> for more 
  information) and 
  by the older register platform 'Rockan' (used in the Western and Northern part 
  of the country). 
  All variables are coerced to suitable classes based on their 
  format. 
  Dates (from various formats such as with missing month or day, with or 
  without century prefix or with just a week number) are all recognized as
  dates and coerced to the ISO 8601 standard (Y-m-d).
  Boolean variables (internally stored either as 0/1 or "True"/"False"/blanks 
  when exported) are coerced to logical. 
  Variable names ending in '_Beskrivning' and '_Varde' will be character, 
  and 'PERSNR' will be coerced (if possible) to a valid personal identification 
  number 'pin' (by the 'sweidnumbr' package).
  The package also allow the user to interactively choose if a variable should 
  be coerced into a potential format even though not all of its values might 
  conform to the recognized pattern.
  It also contain a caching mechanism in order to temporarily store data sets 
  with its newly decided formats in order to not rerun the identification 
  process each time. 
  And finally, it also include a mechanism to aid the documentation process 
  connected to projects build on data from 'INCA'.
Rlda,2017-03-16,Rlda: Bayesian LDA for Mixed-Membership Clustering Analysis,Estimates the Bayesian LDA model for mixed-membership clustering based on different types of data
    (i.e., Multinomial, Bernoulli, and Binomial entries). Albuquerque, Valle and Li (2017) <doi:10.13140/RG.2.2.34599.96164>.
gemlog,2016-11-10,gemlog: File Conversion for 'Gem Infrasound Logger',Reads data files from the 'Gem infrasound logger' for analysis and converts to segy format (which is convenient for reading with traditional seismic analysis software). The Gem infrasound logger is an in-development low-cost, lightweight, low-power instrument for recording infrasound in field campaigns; email the maintainer for more information.
MAGNAMWAR,2017-04-26,MAGNAMWAR: A Pipeline for Meta-Genome Wide Association,Correlates variation within the meta-genome to target species
    phenotype variations in meta-genome with association studies. Follows
    the pipeline described in Chaston, J.M. et al. (2014) <doi:10.1128/mBio.01631-14>.
qGaussian,2017-03-08,qGaussian: The q-Gaussian Distribution,Density, distribution function, quantile function and 
  random generation for the q-gaussian distribution with parameters mu and sig.
spass,2016-10-01,spass: Study Planning and Adaptation of Sample Size,Sample size estimation and blinded sample size reestimation in Adaptive Study Design.
desctable,2017-05-15,desctable: Produce Descriptive and Comparative Tables Easily,Easily create descriptive and comparative tables.
    It makes use and integrates directly with the tidyverse family of packages, and pipes.
    Tables are produced as data frames/lists of data frames for easy manipulation after creation,
    and ready to be saved as csv, or piped to DT::datatable() or pander::pander() to integrate into reports.
polyPK,2017-07-04,polyPK: The Pharmacokinetics (PK) of Multi-Component Drugs Using a
Metabolomics Approach,Poly-PK strategy is a new strategy of pharmacokinetic analysis of multi-component drugs (Guoxiang Xie, Tianlu Chen, Wei Jia, et al. (2012)<doi:10.1021/pr300318m>; Ke Lan, Guoxiang Xie and Wei Jia. (2013)<doi:10.1155/2013/819147>). This package is the first implementation of the Poly-PK strategy with 10 easy-to-use functions. 
bayesDP,2017-03-22,bayesDP: Tools for the Bayesian Discount Prior Function,Functions for data augmentation using the
    Bayesian discount prior function for 1 arm and 2 arm clinical trials.
cetcolor,2017-08-05,cetcolor: CET Perceptually Uniform Colour Maps,Collection of perceptually uniform colour maps made by Peter Kovesi
    (2015) "Good Colour Maps: How to Design Them" <arXiv:1509.03700> 
    at the Centre for Exploration Targeting (CET).
crul,2016-11-09,crul: HTTP Client,A simple HTTP client, with tools for making HTTP requests,
    and mocking HTTP requests. The package is built on R6, and takes
    inspiration from Ruby's 'faraday' gem (<https://rubygems.org/gems/faraday>).
    The package name is a play on curl, the widely used command line tool
    for HTTP, and this package is built on top of the R package 'curl', an
    interface to 'libcurl' (<https://curl.haxx.se/libcurl>).
MetaSubtract,2017-07-11,MetaSubtract: Subtracting Summary Statistics of One or more Cohorts from
Meta-GWAS Results,If results from a meta-GWAS are used for validation in one of the cohorts that was included in the meta-analysis, this will yield biased (i.e. too optimistic) results. The validation cohort needs to be independent from the meta-Genome-Wide-Association-Study (meta-GWAS) results. 'MetaSubtract' will subtract the results of the respective cohort from the meta-GWAS results analytically without having to redo the meta-GWAS analysis using the leave-one-out methodology. It can handle different meta-analyses methods and takes into account if single or double genomic control correction was applied to the original meta-analysis. It can also handle different meta-analysis methods. It can be used for whole GWAS, but also for a limited set of genetic markers.
pdfsearch,2016-12-16,pdfsearch: Search Tools for PDF Files,Includes functions for keyword search of pdf files. There is
    also a wrapper that includes searching of all files within a single
    directory.
qicharts2,2017-08-28,qicharts2: Quality Improvement Charts,Functions for making run charts, Shewhart control charts and
    Pareto charts for continuous quality improvement. Included control charts are:
    I, MR, Xbar, S, T, C, U, U', P, P', and G charts. Non-random variation in the
    form of minor to moderate persistent shifts in data over time is identified by
    the Anhoej rules for unusually long runs and unusually few crossing 
    [Anhoej, Olesen (2014) <doi:10.1371/journal.pone.0113825>].
    Non-random variation in the form of larger, possibly transient, shifts is
    identified by Shewhart's 3-sigma rule [Mohammed, Worthington, Woodall (2008)
    <doi:10.1136/qshc.2004.012047>].
rhoR,2016-10-18,rhoR: Rho for Inter Rater Reliability,Rho is used to test the generalization of inter rater reliability
    (IRR) statistics. Calculating rho starts by generating a large number of
    simulated, fully-coded data sets: a sizable collection of hypothetical
    populations, all of which have a kappa value below a given threshold – which
    indicates unacceptable agreement. Then kappa is calculated on a sample from
    each of those sets in the collection to see if it is equal to or higher than
    the kappa in then real sample. If less than five percent of the distribution
    of samples from the simulated data sets is greater than actual observed kappa,
    the null hypothesis is rejected and one can conclude that if the two raters had
    coded the rest of the data, we would have acceptable agreement (kappa above the
    threshold).
spelling,2017-08-28,spelling: Tools for Spell Checking in R,Spell checking common document formats including latex, markdown, manual pages,
    and description files. Includes utilities to automate checking of documentation and 
    vignettes as a unit test during 'R CMD check'. Both British and American English are 
    supported out of the box and other languages can be added. In addition, packages may
    define a 'wordlist' to allow custom terminology without having to abuse punctuation.
phylopath,2016-10-05,phylopath: Perform Phylogenetic Path Analysis,A comprehensive and easy to use R implementation of confirmatory
    phylogenetic path analysis as described by Von Hardenberg and Gonzalez-Voyer
    (2012) <doi:10.1111/j.1558-5646.2012.01790.x>.
ggforce,2016-11-22,ggforce: Accelerating 'ggplot2',The aim of 'ggplot2' is to aid in visual data investigations. This
    focus has led to a lack of facilities for composing specialised plots.
    'ggforce' aims to be a collection of mainly new stats and geoms that fills
    this gap. All additional functionality is aimed to come through the official
    extension system so using 'ggforce' should be a stable experience.
ggraph,2017-02-24,ggraph: An Implementation of Grammar of Graphics for Graphs and Networks,The grammar of graphics as implemented in ggplot2 is a poor fit for
    graph and network visualizations due to its reliance on tabular data input.
    ggraph is an extension of the ggplot2 API tailored to graph visualizations
    and provides the same flexible approach to building up plots layer by layer.
AcousticNDLCodeR,2017-03-17,AcousticNDLCodeR: Coding Sound Files for Use with NDL,Make acoustic cues to use with the R packages 'ndl' or 'ndl2'. The package implements functions used
              in the PLoS ONE paper:
              Denis Arnold, Fabian Tomaschek, Konstantin Sering, Florence Lopez, and R. Harald Baayen (2017).
              Words from spontaneous conversational speech can be recognized with human-like accuracy by 
              an error-driven learning algorithm that discriminates between meanings straight from smart 
              acoustic features, bypassing the phoneme as recognition unit.  PLoS ONE 12(4):e0174623
              <doi:10.1371/journal.pone.0174623>
              More details can be found in the paper and the supplement.
              'ndl' is available on CRAN. 'ndl2' is available by request from <konstantin.sering@uni-tuebingen.de>.
CytobankAPI,2017-01-12,CytobankAPI: Cytobank API Wrapper for R,Tools to interface with Cytobank's API via R, organized by various
    endpoints that represent various areas of Cytobank functionality. Learn more
    about Cytobank at <https://www.cytobank.org>.
docxtools,2016-12-28,docxtools: Tools for R Markdown to Docx Documents,A set of helper functions for using R Markdown to create documents
    in docx format, especially documents for use in a classroom or workshop
    setting.
ggfittext,2017-08-21,ggfittext: Fit Text Inside a Box in 'ggplot2',Provides 'ggplot2' geoms to fit text into a box by growing, shrinking
    or wrapping the text.
bmixture,2017-01-09,bmixture: Bayesian Estimation for Finite Mixture of Distributions,Provides statistical tools for Bayesian estimation for finite mixture of distributions, mainly mixture of Gamma, Normal and t-distributions. The package is implemented the recent improvements in Bayesian literature for the finite mixture of distributions, including Mohammadi and et al. (2013) <doi:10.1007/s00180-012-0323-3> and Mohammadi and Salehi-Rad (2012) <doi:10.1080/03610918.2011.588358>.
permDep,2017-04-29,permDep: Permutation Tests for General Dependent Truncation,Implementations of permutation approach to hypothesis testing for quasi-independence of truncation time and failure time. The implemented approaches are powerful against non-monotone alternatives and thereby offer protection against erroneous assumptions of quasi-independence. The proposed tests use either a conditional or an unconditional method to evaluate the permutation p-value. The conditional method was first developed in Tsai (1980) <doi:10.2307/2336059> and Efron and Petrosian (1992) <doi:10.1086/171931>. The unconditional method provides a valid approximation to the conditional method, yet computationally simpler and does not hold fixed the size of each risk sets. Users also have an option to carry out the proposed permutation tests in a parallel computing fashion.
satscanMapper,2017-06-15,satscanMapper: 'SaTScan' (TM) Results Mapper,Supports the generation of maps based on the results from 
     'SaTScan' (TM) cluster analysis.
     The package handles mapping of Spatial and Spatial-Time analysis using
     the discrete Poisson, Bernoulli, and exponential models of case data generating
     cluster and location ('GIS') records containing observed, expected and observed/expected
     ratio for U. S. states (and DC), counties or census tracts of individual 
     states based on the U. S. 'FIPS' codes for state, county and census tracts 
     (locations) using 2000 or 2010 Census areas, 'FIPS' codes, and boundary data.
     'satscanMapper' uses the 'SeerMapper' package for the boundary data and 
     mapping of locations.  Not all of the 'SaTScan' (TM) analysis and models generate
     the observed, expected and observed/expected ratio values for the clusters and 
     locations.
     The user can map the observed/expected ratios for locations 
     (states, counties, or census tracts) for each cluster with a p-value less than 0.05 
     or a user specified p-value.  
     The locations are categorized and colored based on either the cluster's Observed/Expected 
     ratio or the locations' Observed/Expected ratio. 
     The place names are provided for each census tract using data from 'NCI', the 'HUD' crossover 
     tables (Tract to Zip code) as of December, 2013, the USPS Zip code 5 database for 1999, 
     and manual look ups on the USPS.gov web site.
GADMTools,2017-03-11,GADMTools: Easy Use of 'GADM' Shapefiles,Manipulate, assemble, export <http://www.gadm.org> shapefiles. Create choropleth, heatmaps, dots plot, proportional dots and more.
kernelboot,2017-04-20,kernelboot: Smoothed Bootstrap and Random Generation from Kernel Densities,Smoothed bootstrap and functions for random generation from
             univariate and multivariate kernel densities. It does not
             estimate kernel densities.
visdat,2017-07-11,visdat: Preliminary Visualisation of Data,Create preliminary exploratory data visualisations of an entire 
    dataset to identify problems or unexpected features using 'ggplot2'.
DatabionicSwarm,2017-08-20,DatabionicSwarm: Swarm Intelligence for Self-Organized Clustering,Algorithms implementing populations of agents that interact with one another and sense their environment may exhibit emergent behavior such as self-organization and swarm intelligence. Here, a swarm system called databionic swarm (DBS) is introduced. DBS is able to adapt itself to structures of high-dimensional data such as natural clusters characterized by distance and/or density based structures in the data space. The first module is the parameter-free projection method called Pswarm (Pswarm()), which exploits the concepts of self-organization and emergence, game theory, swarm intelligence and symmetry considerations. The second module is the parameter-free high-dimensional data visualization technique, which generates projected points on the topographic map with hypsometric tints defined by the generalized U-matrix (GeneratePswarmVisualization()). The third module is the clustering method itself with non-critical parameters (DBSclustering()). Clustering can be verified by the visualization and vice versa. The term DBS refers to the method as a whole. It enables even a non-professional in the field of data mining to apply its algorithms for visualization and/or clustering to data sets with completely different structures drawn from diverse research fields. The package is based on the book of Thrun, M.C.: "Projection Based Clustering through Self-Organization and Swarm Intelligence" (2018) <doi:10.1007/978-3-658-20540-9>. A comparison to 26 common clustering algorithms on 15 datasets is presented on the website.
GeneralizedUmatrix,2017-05-18,GeneralizedUmatrix: Credible Visualization for Two-Dimensional Projections of Data,Projections are common dimensionality reduction methods, which represent high-dimensional data in a two-dimensional space. However, when restricting the output space to two dimensions, which results in a two dimensional scatter plot (projection) of the data, low dimensional similarities do not represent high dimensional distances coercively [Thrun, 2018]. This could lead to a misleading interpretation of the underlying structures [Thrun, 2018]. By means of the 3D topographic map the generalized Umatrix is able to depict errors of these two-dimensional scatter plots. The package is based on the book of Thrun, M.C.: "Projection Based Clustering through Self-Organization and Swarm Intelligence" (2018) <doi:10.1007/978-3-658-20540-9>.
ggedit,2017-03-31,ggedit: Interactive 'ggplot2' Layer and Theme Aesthetic Editor,Interactively edit 'ggplot2' layer and theme aesthetics definitions.
glmmTMB,2017-02-20,glmmTMB: Generalized Linear Mixed Models using Template Model Builder,Fit linear and generalized linear mixed models with various
    extensions, including zero-inflation. The models are fitted using maximum
    likelihood estimation via 'TMB' (Template Model Builder). Random effects are
    assumed to be Gaussian on the scale of the linear predictor and are integrated
    out using the Laplace approximation. Gradients are calculated using automatic
    differentiation.
processmapR,2017-06-19,processmapR: Construct Process Maps Using Event Data,Visualize of process maps based on
    event logs, in the form of directed graphs. Part of the 'bupaR' framework.
spup,2017-04-13,spup: Spatial Uncertainty Propagation Analysis,Uncertainty propagation analysis in spatial environmental  modelling following methodology
         described in Heuvelink et al. (2007) <doi:10.1080/13658810601063951> 
         and Brown and Heuvelink (2007) <doi:10.1016/j.cageo.2006.06.015>. The package provides functions
         for examining the uncertainty propagation starting from input data and model parameters,
         via the environmental model onto model outputs. The functions include uncertainty model specification,
         stochastic simulation and propagation of uncertainty using Monte Carlo (MC) techniques.
         Uncertain variables are described by probability distributions. Both numerical and categorical data types are handled.
         Spatial auto-correlation within an attribute and cross-correlation between attributes is accommodated for.
         The MC realizations may be used as input to the environmental models called from R, or externally.
disco,2017-03-03,disco: Discordance and Concordance of Transcriptomic Responses,Concordance and discordance of homologous gene regulation allows comparing
  reaction to stimuli in different organisms, 
  for example human patients and animal models of a disease. The package
  contains functions to calculate discordance and concordance score
  for homologous gene pairs, identify concordantly or
  discordantly regulated transcriptional modules and visualize the results.
  It is intended for analysis of transcriptional data.
drtmle,2017-08-17,drtmle: Doubly-Robust Nonparametric Estimation and Inference,Targeted minimum loss-based estimators of counterfactual means and
    causal effects that are doubly-robust with respect both to consistency and
    asymptotic normality (Benkeser et al (2017), <doi:10.1093/biomet/asx053>; MJ
    van der Laan (2014), <doi:10.1515/ijb-2012-0038>).
neatmaps,2017-08-06,neatmaps: Heatmaps for Multiple Network Data,Simplify the exploratory data analysis process for multiple network data sets with the help
             of hierarchical clustering and heatmaps. Multiple network data consists of multiple disjoint
             networks that share common graph, node and edge variables. Contains the tools necessary to 
             convert this raw data into a single dynamic report, summarizing the relationships
             of the graph, node and structural characteristics of the networks.
simule,2017-04-19,simule: A Constrained L1 Minimization Approach for Estimating Multiple
Sparse Gaussian or Nonparanormal Graphical Models,This is an R implementation of a constrained l1 minimization approach for estimating multiple Sparse Gaussian or Nonparanormal Graphical Models (SIMULE). The SIMULE algorithm can be used to estimate multiple related precision matrices. For instance, it can identify context-specific gene networks from multi-context gene expression datasets. By performing data-driven network inference from high-dimensional and heterogenous data sets, this tool can help users effectively translate aggregated data into knowledge that take the form of graphs among entities. Please run demo(simuleDemo) to learn the basic functions provided by this package. For further details, please read the original paper: Beilun Wang, Ritambhara Singh, Yanjun Qi (2017) <doi:10.1007/s10994-017-5635-7>.
bupaR,2017-03-26,bupaR: Business Process Analysis in R,Comprehensive Business Process Analysis toolkit. Creates S3-class for event log objects, and related handler functions. Imports related packages for filtering event data, computation of descriptive statistics, handling of 'Petri Net' objects and visualization of process maps. See also packages 'edeaR','processmapR', 'eventdataR' and 'processmonitR'.
GenomicMating,2017-03-31,GenomicMating: Efficient Breeding by Genomic Mating,Implements the genomic mating approach in the recently published article: Akdemir, D., & Sanchez, J. I. (2016). Efficient Breeding by Genomic Mating. Frontiers in Genetics, 7. <doi:10.3389/fgene.2016.00210>. 
ImputeRobust,2017-02-23,ImputeRobust: Robust Multiple Imputation with Generalized Additive Models for
Location Scale and Shape,Provides new imputation methods for the 'mice' package based on generalized additive models for location, scale, and shape (GAMLSS) as described in de Jong, van Buuren and Spiess <doi:10.1080/03610918.2014.911894>.
biolink,2017-03-07,biolink: Create Hyperlinks to Biological Databases and Resources,Generate urls and hyperlinks to commonly used biological databases
    and resources based on standard identifiers. This is primarily useful when
    writing dynamic reports that reference things like gene symbols in text or
    tables, allowing you to, for example, convert gene identifiers to hyperlinks
    pointing to their entry in the NCBI Gene database. Currently supports NCBI
    Gene, PubMed, Gene Ontology, CRAN and Bioconductor.
crplyr,2017-05-05,crplyr: A 'dplyr' Interface for Crunch,In order to facilitate analysis of datasets hosted on the Crunch
    data platform <http://crunch.io/>, the 'crplyr' package implements 'dplyr'
    methods on top of the Crunch backend. The usual methods 'select', 'filter',
    'mutate', 'group_by', and 'summarize' are implemented in such a way as to
    perform as much computation on the server and pull as little data locally
    as possible.
expint,2016-12-20,expint: Exponential Integral and Incomplete Gamma Function,The exponential integrals E_1(x), E_2(x), E_n(x) and
  Ei(x), and the incomplete gamma function G(a, x) defined for
  negative values of its first argument. The package also gives easy
  access to the underlying C routines through an API; see the package
  vignette for details. A test package included in sub-directory
  example_API provides an implementation. C routines derived from the
  GNU Scientific Library <https://www.gnu.org/software/gsl/>.
learnr,2017-05-08,learnr: Interactive Tutorials for R,Create interactive tutorials using R Markdown. Use a combination 
  of narrative, figures, videos, exercises, and quizzes to create self-paced
  tutorials for learning about R and R packages.
mfe,2017-01-31,mfe: Meta-Feature Extractor,Extracts meta-features from datasets to support the design of 
  recommendation systems based on Meta-Learning. The meta-features, also called 
  characterization measures, are able to characterize the complexity of datasets
  and to provide estimates of algorithm performance. The package contains not 
  only the standard characterization measures, but also more recent 
  characterization measures. By making available a large set of meta-feature 
  extraction functions, tasks like comprehensive data characterization, deep 
  data exploration and large number of Meta-Learning based data analysis can be
  performed. These concepts are described in the paper: Fabio Pinto, Carlos 
  Soares, and Joao Mendes-Moreira. Towards automatic generation of metafeatures.
  In Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), 
  pages 215 - 226, 2016, <doi:10.1007/978-3-319-31753-3_18>.
multicmp,2017-05-22,multicmp: Flexible Modeling of Multivariate Count Data via the
Multivariate Conway-Maxwell-Poisson Distribution,A toolkit containing statistical analysis models motivated by multivariate forms of the Conway-Maxwell-Poisson (COM-Poisson) distribution for flexible modeling of multivariate count data, especially in the presence of data dispersion. Currently the package only supports bivariate data, via the bivariate COM-Poisson distribution described in Sellers et al. (2016) <doi:10.1016/j.jmva.2016.04.007>. Future development will extend the package to higher-dimensional data.
pool,2017-09-23,pool: Object Pooling,Enables the creation of object pools, which make it less
    computationally expensive to fetch a new object. Currently the
    only supported pooled objects are 'DBI' connections.
SCORPIUS,2017-09-15,SCORPIUS: Inferring Developmental Chronologies from Single-Cell RNA
Sequencing Data,An accurate and easy tool for performing trajectory inference on
  single cells using single-cell RNA sequencing data. In addition, SCORPIUS
  provides functions for discovering the most important genes with respect to
  the reconstructed trajectory, as well as nice visualisation tools.
  Cannoodt et al. (2016) <doi:10.1101/079509>.
support.BWS2,2017-01-18,support.BWS2: Basic Functions for Supporting an Implementation of Case 2
Best-Worst Scaling,Provides three basic functions that support an implementation of Case 2 (profile case) best-worst scaling. The first is to convert an orthogonal main-effect design into questions, the second is to create a dataset suitable for analysis, and the third is to calculate count-based scores. 
taxlist,2017-06-15,taxlist: Handling Taxonomic Lists,Handling taxonomic lists through objects of class 'taxlist'.
    This package provides functions to import species lists from 'Turboveg'
    (<https://www.synbiosys.alterra.nl/turboveg>) and the possibility to create
    backups from resulting R-objects.
    Also quick displays are implemented as summary-methods.
vegtable,2017-08-08,vegtable: Handling Vegetation Data Sets,Import and handling data from vegetation-plot databases, especially
    data stored in 'Turboveg' (<https://www.synbiosys.alterra.nl/turboveg>).
    Also import/export routines for exchange of data with 'Juice'
    (<http://www.sci.muni.cz/botany/juice>) are implemented.
cld3,2017-06-08,cld3: Google's Compact Language Detector 3,Google's Compact Language Detector 3 is a neural network model for language 
    identification and the successor of 'cld2' (available from CRAN). The algorithm is still
    experimental and takes a novel approach to language detection with different properties
    and outcomes. It can be useful to combine this with the Bayesian classifier results 
    from 'cld2'. See <https://github.com/google/cld3#readme> for more information.
dynOmics,2016-11-10,dynOmics: Fast Fourier Transform to Identify Associations Between Time
Course Omics Data,Implements a method based on the fast Fourier transform to estimate delays of expression initiation between trajectories to integrate and
    analyse time course omics data.
prioritizr,2016-12-01,prioritizr: Systematic Conservation Prioritization in R,Conservation prioritization using integer
    programming techniques. To solve large-scale problems, users
    should install the 'gurobi' optimizer
    (available from <http://www.gurobi.com/>).
raptr,2016-10-28,raptr: Representative and Adequate Prioritization Toolkit in R,Biodiversity is in crisis. The overarching aim of conservation
    is to preserve biodiversity patterns and processes. To this end, protected
    areas are established to buffer species and preserve biodiversity processes.
    But resources are limited and so protected areas must be cost-effective.
    This package contains tools to generate plans for protected areas
    (prioritizations), using spatially explicit targets for biodiversity
    patterns and processes. To obtain solutions in a feasible amount  of time,
    this package uses the commercial 'Gurobi' software package (obtained from
    <http://www.gurobi.com/>). For more information on using
    this package, see Hanson et al. (2017) <doi:10.1111/2041-210X.12862>.
ropercenter,2017-03-17,ropercenter: Reproducible Data Retrieval from the Roper Center Data Archive,Reproducible, programmatic retrieval of datasets from the
    Roper Center data archive.  The Roper Center for Public Opinion
    Research <https://ropercenter.cornell.edu> maintains the largest 
    archive of public opinion data in existence, but researchers using
    these datasets are caught in a bind.  The Center's terms and conditions
    bar redistribution of downloaded datasets, but to ensure that one's 
    work can be reproduced, assessed, and built upon by others, one must
    provide access to the raw data one employed.  The 'ropercenter'
    package cuts this knot by providing registered users with programmatic,
    reproducible access to Roper Center datasets from within R.
SimMultiCorrData,2017-06-30,SimMultiCorrData: Simulation of Correlated Data with Multiple Variable Types,Generate continuous (normal or non-normal), binary, ordinal, and count (Poisson or Negative 
    Binomial) variables with a specified correlation matrix.  It can also produce a single continuous 
    variable.  This package can be used to simulate data sets that mimic real-world situations (i.e. 
    clinical or genetic data sets, plasmodes).  All variables are generated from standard normal 
    variables with an imposed intermediate correlation matrix.  Continuous variables are simulated 
    by specifying mean, variance, skewness, standardized kurtosis, and fifth and sixth standardized 
    cumulants using either Fleishman's third-order (<doi:10.1007/BF02293811>) or Headrick's 
    fifth-order (<doi:10.1016/S0167-9473(02)00072-5>) polynomial transformation.  Binary and 
    ordinal variables are simulated using a modification of the ordsample() function from 'GenOrd'.  
    Count variables are simulated using the inverse cdf method.  There are two simulation pathways 
    which differ primarily according to the calculation of the intermediate correlation matrix.  In 
    Correlation Method 1, the intercorrelations involving count variables are determined using a 
    simulation based, logarithmic correlation correction (adapting Yahav and Shmueli's 2012 method, 
    <doi:10.1002/asmb.901>).  In Correlation Method 2, the count variables are treated as ordinal 
    (adapting Barbiero and Ferrari's 2015 modification of GenOrd, <doi:10.1002/asmb.2072>).  
    There is an optional error loop that corrects the final correlation matrix to be within a 
    user-specified precision value of the target matrix.  The package also includes functions to 
    calculate standardized cumulants for theoretical distributions or from real data sets, check 
    if a target correlation matrix is within the possible correlation bounds (given the distributions 
    of the simulated variables), summarize results (numerically or graphically), to verify valid power 
    method pdfs, and to calculate lower standardized kurtosis bounds.
colordistance,2017-06-03,colordistance: Distance Metrics for Image Color Similarity,Loads and displays images, selectively masks specified background
    colors, bins pixels by color using either data-dependent or
    automatically generated color bins, quantitatively measures color
    similarity among images using one of several distance metrics for
    comparing pixel color clusters, and clusters images by object color
    similarity. Uses CIELAB, RGB, or HSV color spaces. Originally written
    for use with organism coloration (reef fish color diversity, butterfly
    mimicry, etc), but easily applicable for any image set.
CytobankAPIstats,2017-09-01,CytobankAPIstats: Computes Signaling and Population Stats for Cytometry Data on
Cytobank using 'CytobankAPI',Tools to process cytometry data from Cytobank into easily usable form for analysis of populations, markers, and signaling using the 'CytobankAPI' package. Learn more about Cytobank at <https://www.cytobank.org>. For more information about types of cytometry data that can be analyzed, please see: Bendall, S. C., Simonds, E. F., Qiu, P., Amir, E. D., Krutzik, P. O., Finck, R.,... Nolan, G. P. (2011) <doi:10.1126/science.1198704> and Adan, A., Alizada, G., Kiraz, Y., Baran, Y., Nalbant, A. (2017). <doi:10.3109/07388551.2015.1128876>.  
dng,2017-09-20,dng: Distributions and Gradients,Provides density, distribution function, quantile function and random
             generation for the split normal and split-t distributions, and computes their
             mean, variance, skewness and kurtosis for the two distributions (Li, F,
             Villani, M. and Kohn, R. (2010) <doi:10.1016/j.jspi.2010.04.031>).
GBJ,2017-08-30,GBJ: Generalized Berk-Jones Test for Set-Based Inference in Genetic
Association Studies,Offers the Generalized Berk-Jones (GBJ) test for set-based inference in genetic
	association studies. The GBJ is designed as an alternative to tests such as Berk-Jones (BJ),
    Higher Criticism (HC), Generalized Higher Criticism (GHC), Minimum p-value (minP), and Sequence
    Kernel Association Test (SKAT). All of these other methods (except for SKAT) are also implemented 
    in this package, and we additionally provide an omnibus test (OMNI) which integrates information from each of the tests.
    The GBJ has been shown to outperform other tests in genetic association studies when signals
    are correlated and moderately sparse. Please see the vignette for a quickstart guide or Sun and Lin
    (2017) <arXiv:1710.02469> for more details.
ClusterBootstrap,2017-06-12,ClusterBootstrap: Analyze Clustered Data with Generalized Linear Models using the
Cluster Bootstrap,Provides functionality for the analysis of clustered data using the cluster bootstrap. 
fetchR,2017-03-16,fetchR: Calculate Wind Fetch,Wind fetch is the unobstructed length of water over which wind can
    blow from a certain direction. The wind fetch is typically calculated for many directions
    around the compass rose for a given location, which can then be incorporated 
    into a larger model (such as the InVEST coastal vulnerability model;
    <http://data.naturalcapitalproject.org/invest-releases/documentation/2_2_0/coastal_vulnerability.html>),
    or simply averaged for a reasonable measure of 
    the overall wind exposure for a specific marine location. The process of calculating
    wind fetch can be extremely time-consuming and tedious, particularly if a large
    number of fetch vectors are required at many locations. The 'fetchR' package
    calculates wind fetch and summarises the information efficiently. There are 
    also plot methods to help visualise the wind exposure at the various
    locations, and methods to output the fetch vectors to a KML file for further
    investigation.
jpmesh,2016-11-12,jpmesh: Utilities for Japanese Mesh Code,Helpful functions for using mesh code (80km to 125m) data in Japan. Visualize mesh code using 'ggplot2' and 'leaflet', etc.
padr,2017-01-17,padr: Quickly Get Datetime Data Ready for Analysis,Transforms datetime data into a format ready for analysis.
    It offers two core functionalities; aggregating data to a higher level interval
    (thicken) and imputing records where observations were absent (pad). 
treeDA,2017-07-25,treeDA: Tree-Based Discriminant Analysis,Performs sparse discriminant analysis on a combination of
    node and leaf predictors when the predictor variables are
    structured according to a tree, as described in Fukuyama et
    al. (2017) <doi:10.1371/journal.pcbi.1005706>.
unpivotr,2017-01-31,unpivotr: Unpivot Complex and Irregular Data Layouts,Tools for converting data from complex or irregular layouts to a
    columnar structure.  For example, tables with multilevel column or row
    headers, or spreadsheets.  Header and data cells are selected by their
    contents and position, as well as formatting and comments where available,
    and are associated with one other by their proximity in given directions.
    Functions for data frames and HTML tables are provided.
catcont,2017-09-28,catcont: Test, Identify, Select and Mutate Categorical or Continuous
Values,Methods and utilities for testing, identifying, selecting and  
    mutating objects as categorical or continous types. These functions work on both 
    atomic vectors as well as recursive objects: data.frames, data.tables, 
    tibbles, lists, etc.. 
cellWise,2016-12-07,cellWise: Analyzing Data with Cellwise Outliers,Tools for detecting cellwise outliers and robust methods to analyze data which may contain them. 
multinet,2017-01-17,multinet: Analysis and Mining of Multilayer Social Networks,Functions for the creation/generation and analysis of multilayer social networks.
phylogram,2017-06-12,phylogram: Dendrograms for Evolutionary Analysis,Contains functions for developing phylogenetic trees as
    deeply-nested lists ("dendrogram" objects).
    Enables bi-directional conversion between dendrogram and
    "phylo" objects
    (see Paradis et al (2004) <doi:10.1093/bioinformatics/btg412>),
    and features several tools for command-line tree
    manipulation and import/export via Newick parenthetic text.
coreCT,2017-08-14,coreCT: Programmatic Analysis of Sediment Cores Using Computed
Tomography Imaging,Computed tomography (CT) imaging is a powerful tool for understanding the composition of sediment cores. This package streamlines and accelerates the analysis of CT data generated in the context of environmental science. Included are tools for processing raw DICOM images to characterize sediment composition (sand, peat, etc.). Root analyses are also enabled, including measures of external surface area and volumes for user-defined root size classes. For a detailed description of the application of computed tomography imaging for sediment characterization, see: Davey, E., C. Wigand, R. Johnson, K. Sundberg, J. Morris, and C. Roman. (2011) <doi:10.1890/10-2037.1>.
mosaicCore,2017-07-24,mosaicCore: Common Utilities for Other MOSAIC-Family Packages,Common utilities used in other MOSAIC-family packages are 
    collected here.
patternplot,2016-12-20,patternplot: Versatile Pie Charts, Bar Charts and Box Plots using Patterns,
Colors and Images,Creates aesthetically pleasing and informative pie charts, bar charts and box plots with colors, patterns, and images. 
RIA,2017-03-19,RIA: Radiomics Image Analysis Toolbox for Medial Images,Radiomics image analysis toolbox for 2D and 3D radiological images. RIA supports DICOM, NIfTI and
             nrrd file formats. RIA calculates first-order, gray level co-occurrence matrix,
             gray level run length matrix and geometry-based statistics. Almost all calculations are done
             using vectorized formulas to optimize run speeds. Calculation of several thousands of parameters
             only takes minutes on a single core of a conventional PC.
splot,2017-09-07,splot: Split Plot,Automates common plotting tasks to ease data exploration.
  Makes density plots (potentially overlaid on histograms),
  scatter plots with prediction lines, or bar or line plots with error bars.
  For each type, y, or x and y variables can be plotted at levels of other variables,
  all with minimal specification.
hexSticker,2017-03-30,hexSticker: Create Hexagon Sticker in R,Helper functions for creating reproducible hexagon sticker purely in R.
KnowBR,2017-01-01,KnowBR: Discriminating Well Surveyed Spatial Units from Exhaustive
Biodiversity Databases,It uses species accumulation curves and diverse estimators to assess, at the same time, the levels of survey coverage in multiple geographic cells of a size defined by the user or polygons. It also enables the geographical depiction of observed species richness, survey effort and completeness values including a background with administrative areas.
subscreen,2017-07-19,subscreen: Systematic Screening of Study Data for Subgroup Effects,Identifying outcome relevant subgroups has now become as simple as possible! The formerly lengthy and tedious search for the needle in a haystack will be replaced by a single, comprehensive and coherent presentation.
 The central result of a subgroup screening is a diagram in which each single dot stands for a subgroup.
 The diagram may show thousands of them. The position of the dot in the diagram is determined by the
 sample size of the subgroup and the statistical measure of the treatment effect in that subgroup. The
 sample size is shown on the horizontal axis while the treatment effect is displayed on the vertical axis. Furthermore,
 the diagram shows the line of no effect and the overall study results. For small subgroups, which
 are found on the left side of the plot, larger random deviations from the mean study effect are expected,
 while for larger subgroups only small deviations from the study mean can be expected to be chance findings.
 So for a study with no conspicuous subgroup effects, the dots in the figure are expected to form a
 kind of funnel. Any deviations from this funnel shape hint to conspicuous subgroups.
BUCSS,2016-12-13,BUCSS: Bias and Uncertainty Corrected Sample Size,Implements a method of correcting for publication bias and
    uncertainty when planning sample sizes in a future study from an original study. See Anderson, Kelley, & Maxwell (2017; Psychological Science, 28, 1547-1562). 
fastDummies,2017-04-21,fastDummies: Fast Creation of Dummy (Binary) Columns and Rows from
Categorical Variables,Creates dummy columns from columns that have categorical variables (character or factor types). You can also specify which columns to make dummies out of, or which columns to ignore. Also creates dummy rows from character, factor, and Date columns. This package provides a significant speed increase from creating dummy variables through model.matrix().
googleLanguageR,2017-09-22,googleLanguageR: Call Google's 'Natural Language' API, 'Cloud Translation' API,
'Cloud Speech' API and 'Cloud Text-to-Speech' API,Call 'Google Cloud' machine learning APIs for text and speech tasks.
  Call the 'Cloud Translation' API <https://cloud.google.com/translate/> for detection 
  and translation of text, the 'Natural Language' API <https://cloud.google.com/natural-language/> to 
  analyse text for sentiment, entities or syntax, the 'Cloud Speech' API 
  <https://cloud.google.com/speech/> to transcribe sound files to text and 
  the 'Cloud Text-to-Speech' API <https://cloud.google.com/text-to-speech/> to turn text 
  into sound files.
LEGIT,2017-02-13,LEGIT: Latent Environmental & Genetic InTeraction (LEGIT) Model,Constructs genotype x environment interaction (GxE) models where
    G is a weighted sum of genetic variants (genetic score) and E is a weighted
    sum of environments (environmental score) using the alternating optimization algorithm 
    by Jolicoeur-Martineau et al. (2017) <arXiv:1703.08111>. This approach has greatly 
    enhanced predictive power over traditional GxE models which include only a single 
    genetic variant and a single environmental exposure. Although this approach was 
    originally made for GxE modelling, it is flexible and does not require the use of 
    genetic and environmental variables. It can also handle more than 2 latent variables 
    (rather than just G and E) and 3-way interactions or more. The LEGIT model produces 
    highly interpretable results and is very parameter-efficient thus it can even be 
    used with small sample sizes (n < 250). Tools to determine the type of interaction
    (vantage sensitivity, diathesis-stress or differential susceptibility), with any 
    number of genetic variants or environments, are available <arXiv:1712.04058>.
mlrMBO,2017-03-12,mlrMBO: Bayesian Optimization and Model-Based Optimization of Expensive
Black-Box Functions,Flexible and comprehensive R toolbox for model-based optimization
    ('MBO'), also known as Bayesian optimization. It implements the Efficient
    Global Optimization Algorithm and is designed for both single- and multi-
    objective optimization with mixed continuous, categorical and conditional
    parameters. The machine learning toolbox 'mlr' provide dozens of regression
    learners to model the performance of the target algorithm with respect to
    the parameter settings. It provides many different infill criteria to guide
    the search process. Additional features include multi-point batch proposal,
    parallel execution as well as visualization and sophisticated logging
    mechanisms, which is especially useful for teaching and understanding of
    algorithm behavior. 'mlrMBO' is implemented in a modular fashion, such that
    single components can be easily replaced or adapted by the user for specific
    use cases.
tidyxl,2017-01-29,tidyxl: Read Untidy Excel Files,Imports non-tabular from Excel files into R.  Exposes cell content,
    position and formatting in a tidy structure for further manipulation.
    Tokenizes Excel formulas.  Supports '.xlsx' and '.xlsm' via the embedded
    'RapidXML' C++ library <http://rapidxml.sourceforge.net>.  Does not support
    '.xlsb' or '.xls'.
momentuHMM,2017-06-16,momentuHMM: Maximum Likelihood Analysis of Animal Movement Behavior Using
Multivariate Hidden Markov Models,Extended tools for analyzing telemetry data using generalized hidden Markov models. Features of momentuHMM (pronounced “momentum”) include data pre-processing and visualization, fitting HMMs to location and auxiliary biotelemetry or environmental data, biased and correlated random walk movement models, multiple imputation for incorporating location measurement error and missing data, user-specified design matrices and constraints for covariate modelling of parameters, decoding of the state process, visualization of fitted models, model checking and selection, and simulation. See McClintock and Michelot (2018) <doi:10.1111/2041-210X.12995>.
womblR,2017-06-17,womblR: Spatiotemporal Boundary Detection Model for Areal Unit Data,Implements a spatiotemporal boundary detection model with a dissimilarity
    metric for areal data with inference in a Bayesian setting using Markov chain
    Monte Carlo (MCMC). The response variable can be modeled as Gaussian (no nugget),
    probit or Tobit link and spatial correlation is introduced at each time point
    through a conditional autoregressive (CAR) prior. Temporal correlation is introduced
    through a hierarchical structure and can be specified as exponential or first-order
    autoregressive. Full details of the package can be found in the accompanying vignette.
    Furthermore, the details of the package can be found in the corresponding paper on arXiv
    by Berchuck et al (2018): "Diagnosing Glaucoma Progression with Visual Field Data Using a 
    Spatiotemporal Boundary Detection Method", <arXiv:1805.11636>.
chinese.misc,2017-02-16,chinese.misc: Miscellaneous Tools for Chinese Text Mining and More,Efforts are made to make Chinese text mining easier, faster, and robust to errors. 
    Document term matrix can be generated by only one line of code; detecting encoding, 
    segmenting and removing stop words are done automatically. 
	Some convenient tools are also supplied.
cstab,2016-12-01,cstab: Selection of Number of Clusters via Normalized Clustering
Instability,Selection of the number of clusters in cluster analysis using
    stability methods.
ggimage,2017-02-21,ggimage: Use Image in 'ggplot2',Supports image files and graphic objects to be visualized in
    'ggplot2' graphic system.
prodest,2017-07-05,prodest: Production Function Estimation,Implements the methods proposed by Olley, G.S. and Pakes, A. (1996) <doi:10.2307/2171831>, Levinsohn, J. and Petrin, A. (2003) <doi:10.1111/1467-937X.00246>, Ackerberg, D.A. and Caves, K. and Frazer, G. (2015) <doi:10.3982/ECTA13408> and Wooldridge, J.M. (2009) <doi:10.1016/j.econlet.2009.04.026> for structural productivity estimation .
rdiversity,2017-06-27,rdiversity: Measurement and Partitioning of Similarity-Sensitive
Biodiversity,Provides a framework for the measurement and partitioning of
    the (similarity-sensitive) biodiversity of a metacommunity and its
    constituent subcommunities. Richard Reeve, et al. (2016) 
    <arXiv:1404.6520v3>.
spam64,2017-07-03,spam64: 64-Bit Extension of the SPArse Matrix R Package 'spam',Provides the Fortran code of the R package 'spam'
    with 64-bit integers. Loading this package together with the R package
    spam enables the sparse matrix class spam to handle huge sparse matrices
    with more than 2^31-1 non-zero elements.
uptasticsearch,2017-07-18,uptasticsearch: Get Data Frame Representations of 'Elasticsearch' Results,
    'Elasticsearch' is an open-source, distributed, document-based datastore
    (<https://www.elastic.co/products/elasticsearch>).
    It provides an 'HTTP' 'API' for querying the database and extracting datasets, but that
    'API' was not designed for common data science workflows like pulling large batches of
    records and normalizing those documents into a data frame that can be used as a training
    dataset for statistical models. 'uptasticsearch' provides an interface for 'Elasticsearch'
    that is explicitly designed to make these data science workflows easy and fun.
ahnr,2017-07-08,ahnr: An Implementation of the Artificial Hydrocarbon Networks,Implementation of the Artificial Hydrocarbon Networks for data
    modeling.
asciiSetupReader,2017-09-07,asciiSetupReader: Reads 'SPSS' and 'SAS' Files from ASCII Data Files (.txt) and
Setup Files (.sps or .sas),Lets you open an 'SPSS' or 'SAS' data file using a .txt file that has the data and a .sps or .sas file with setup instructions. This will only run in a txt-sps or txt-sas pair in which the setup file contains instructions to open that text file. It will NOT open other text files, .sav, .por, or 'SAS' files. 
bayeslm,2017-07-14,bayeslm: Efficient Sampling for Gaussian Linear Regression with Arbitrary
Priors,Efficient sampling for Gaussian linear regression with arbitrary priors, Hahn, He and Hedibert (2018) <arXiv:1806.05738>.
CircularDDM,2017-03-30,CircularDDM: Circular Drift-Diffusion Model,Circular drift-diffusion model for continuous reports.
MetaComp,2017-03-02,MetaComp: EDGE Taxonomy Assignments Visualization,Implements routines for metagenome sample taxonomy assignments collection, 
    aggregation, and visualization. Accepts the EDGE-formatted output from GOTTCHA/GOTTCHA2, 
    BWA, Kraken, MetaPhlAn, DIAMOND, and Pangia. Produces SVG and PDF heatmap-like plots 
    comparing taxa abundances across projects. 
fuser,2017-08-18,fuser: Fused Lasso for High-Dimensional Regression over Groups,Enables high-dimensional penalized regression across heterogeneous 
    subgroups. Fusion penalties are used to share information about the linear 
    parameters across subgroups. The underlying model is described 
    in detail in Dondelinger and Mukherjee (2017) <arXiv:1611.00953>.
walrus,2017-05-26,walrus: Robust Statistical Methods,A toolbox of common robust statistical tests, including robust
  descriptives, robust t-tests, and robust ANOVA. It is also available as a
  module for 'jamovi' (see <https://www.jamovi.org> for more information).
  Walrus is based on the WRS2 package by Patrick Mair, which is in turn based on
  the scripts and work of Rand Wilcox. These analyses are described in depth in
  the book 'Introduction to Robust Estimation & Hypothesis Testing'.
AdhereR,2017-04-27,AdhereR: Adherence to Medications,Computation of adherence to medications from Electronic Health care 
    Data and visualization of individual medication histories and adherence 
    patterns. The package implements a set of S3 classes and
    functions consistent with current adherence guidelines and definitions. 
    It allows the computation of different measures of
    adherence (as defined in the literature, but also several original ones), 
    their publication-quality plotting,
    the estimation of event duration and time to initiation,
    the interactive exploration of patient medication history and 
    the real-time estimation of adherence given various parameter settings.
    It scales from very small datasets stored in flat CSV files to very large 
    databases and from single-thread processing on mid-range consumer
    laptops to parallel processing on large heterogeneous computing clusters.
    It exposes a standardized interface allowing it to be used from other
    programming languages and platforms, such as Python.
bsamGP,2017-08-05,bsamGP: Bayesian Spectral Analysis Models using Gaussian Process Priors,Contains functions to perform Bayesian inference
    using a spectral analysis of Gaussian process priors.
    Gaussian processes are represented with a Fourier series 
    based on cosine basis functions. Currently the package
    includes parametric linear models, partial linear additive
    models with/without shape restrictions, generalized linear
    additive models with/without shape restrictions, and  
    density estimation model. To maximize computational 
    efficiency, the actual Markov chain Monte Carlo sampling 
    for each model is done using codes written in FORTRAN 90.
    This software has been developed using funding supported by
    Basic Science Research Program through the National Research
    Foundation of Korea (NRF) funded by the Ministry of Education
    (no. NRF-2016R1D1A1B03932178 and no. NRF-2017R1D1A3B03035235).
loder,2017-05-05,loder: Dependency-Free Access to PNG Image Files,Read and write access to PNG image files using the LodePNG
    library. The package has no external dependencies.
MultisiteMediation,2017-02-26,MultisiteMediation: Causal Mediation Analysis in Multisite Trials,We implement multisite causal mediation analysis using the methods proposed by Qin and Hong (2017) <doi:10.3102/1076998617694879> and Qin, Hong, Deutsch, and Bein (under review). It enables causal mediation analysis in multisite trials, in which individuals are assigned to a treatment or a control group at each site. It allows for estimation and hypothesis testing for not only the population average but also the between-site variance of direct and indirect effects. This strategy conveniently relaxes the assumption of no treatment-by-mediator interaction while greatly simplifying the outcome model specification without invoking strong distributional assumptions. This package also provides a function that can further incorporate a sample weight and a nonresponse weight for multisite causal mediation analysis in the presence of complex sample and survey designs and non-random nonresponse, to enhance both the internal validity and external validity. Because the identification assumptions are not always warranted, the package also provides a weighting-based balance checking function for assessing the remaining overt bias, as well as a weighting-based sensitivity analysis function for further evaluating the potential bias related to omitted confounding or to propensity score model misspecification. 
prophet,2017-02-01,prophet: Automatic Forecasting Procedure,Implements a procedure for forecasting time series data based on
    an additive model where non-linear trends are fit with yearly, weekly, and
    daily seasonality, plus holiday effects. It works best with time series
    that have strong seasonal effects and several seasons of historical data.
    Prophet is robust to missing data and shifts in the trend, and typically
    handles outliers well.
jpndistrict,2016-12-03,jpndistrict: Create Japanese Administration Area and Office Maps,Utilizing the data that Japanese administration area provided 
    by the National Land Numerical Information download service (<http://nlftp.mlit.go.jp/ksj/index.html>). 
    This package provide map data is based on the Digital Map 25000 (Map Image) published 
    by Geospatial Information Authority of Japan (Approval No.603FY2017 information usage <http://www.gsi.go.jp>).
lingtypology,2016-12-29,lingtypology: Linguistic Typology and Mapping,Provides R with the Glottolog database <http://glottolog.org> and some more abilities for purposes of linguistic mapping. The Glottolog database contains the catalogue of languages of the world. This package helps researchers to make a linguistic maps, using philosophy of the Cross-Linguistic Linked Data project <http://clld.org/>, which allows for while at the same time facilitating uniform access to the data across publications. A tutorial for this package is available on GitHub pages <https://ropensci.github.io/lingtypology/> and package vignette. Maps created by this package can be used both for the investigation and linguistic teaching. In addition, package provides an ability to download data from typological databases such as WALS, AUTOTYP and some others and to create your own database website.
tuckerR.mmgg,2017-02-23,tuckerR.mmgg: Three-Mode Principal Components Analysis,Performs Three-Mode Principal Components Analysis,
    which carries out Tucker Models.
ROpenDota,2017-05-04,ROpenDota: Access OpenDota Services in R,Provides a client for the API of OpenDota. OpenDota is a web service which is provide DOTA2 real time data. Data is collected through the Steam WebAPI. With ROpenDota you can easily grab the latest DOTA2 statistics in R programming such as latest match on official international competition, analyzing your or enemy performance to learn their strategies,etc. Please see <https://github.com/rosdyana/ROpenDota> for more information.
beginr,2017-06-23,beginr: Functions for R Beginners,Useful functions for R beginners, including hints for the arguments of the 'plot()' function, self-defined functions for error bars, user-customized pair plots and hist plots, enhanced linear regression figures, etc.. This package could be helpful to R experts as well.
diceR,2017-06-22,diceR: Diverse Cluster Ensemble in R,Performs cluster analysis using an ensemble clustering framework.
    Results from a diverse set of algorithms are pooled together using methods
    such as majority voting, K-Modes, LinkCluE, and CSPA. There are options to
    compare cluster assignments across algorithms using internal and external
    indices, visualizations such as heatmaps, and significance testing for the
    existence of clusters.
jwutil,2016-10-18,jwutil: Tools for Data Manipulation and Testing,This is a set of simple utilities for various data manipulation and testing tasks.
    The goal is to use core R tools well, without bringing in many
    dependencies. Main areas of interest are semi-automated data frame manipulation, such as
    converting factors in multiple binary indicator columns. There are testing
    functions which provide 'testthat' expectations to permute arguments to
    function calls. There are functions and data to test extreme numbers, dates,
    and bad input of various kinds which should allow testing failure and corner
    cases, which can be used for fuzzing your functions. The test suite has many examples of usage.
leaflet.minicharts,2017-04-19,leaflet.minicharts: Mini Charts for Interactive Maps,Add and modify small charts on an interactive map created with 
    package 'leaflet'. These charts can be used to represent at same time multiple 
    variables on a single map.
manipulateWidget,2017-01-05,manipulateWidget: Add Even More Interactivity to Interactive Charts,Like package 'manipulate' does for static graphics, this package
    helps to easily add controls like sliders, pickers, checkboxes, etc. that 
    can be used to modify the input data or the parameters of an interactive 
    chart created with package 'htmlwidgets'.
ompr,2017-04-17,ompr: Model and Solve Mixed Integer Linear Programs,Model mixed integer linear programs in an algebraic way directly in R.
             The model is solver-independent and thus offers the possibility
             to solve a model with different solvers. It currently only supports
             linear constraints and objective functions. See the 'ompr'
             website <https://dirkschumacher.github.io/ompr> for more information, 
             documentation and examples.
ompr.roi,2017-04-19,ompr.roi: A Solver for 'ompr' that Uses the R Optimization Infrastructure
('ROI'),A solver for 'ompr' based on the R Optimization Infrastructure ('ROI').
  The package makes all solvers in 'ROI' available to solve 'ompr' models. Please see the
  'ompr' website <https://dirkschumacher.github.io/ompr> and package docs for more information
  and examples on how to use it.
rclimateca,2016-12-07,rclimateca: Fetch Climate Data from Environment Canada,The Environment Canada climate archives <http://climate.weather.gc.ca/>
  are an important source of data for climate researchers in Canada and world wide.
  The repository contains temperature, precipitation, and wind data for more than
  8,000 locations. The functions in this package simplify the process of downloading,
  subsetting, and manipulating these data for the purposes of more efficient workflows
  in climate research.
StatCharrms,2017-05-08,StatCharrms: Statistical Analysis of Chemistry, Histopathology, and
Reproduction Endpoints Including Repeated Measures and
Multi-Generation Studies,A front end for the statistical analyses involved in the tier II endocrine 
	disruptor screening program. The analyses available to this package are: 
	Rao-Scott adjusted Cochran-Armitage test for trend By Slices (RSCABS), 
	a Standard Cochran-Armitage test for trend By Slices (SCABS), 
	mixed effects Cox proportional model, Jonckheere-Terpstra step down trend test 
	Dunn test, one way ANOVA, weighted ANOVA, mixed effects ANOVA, repeated 
	measures ANOVA, and Dunnett test. 		
teachingApps,2017-07-07,teachingApps: Apps for Teaching Statistics, R Programming, and Shiny App
Development,Contains apps and gadgets for teaching data analysis and 
    statistics concepts along with how to implement them in R.  Includes 
    tools to make app development easier and faster by nesting apps together.
odbc,2017-02-05,odbc: Connect to ODBC Compatible Databases (using the DBI Interface),A DBI-compatible interface to ODBC databases.
bivrp,2016-12-16,bivrp: Bivariate Residual Plots with Simulation Polygons,Generates bivariate residual plots with simulation polygons for any diagnostics and bivariate model from which functions to extract the desired diagnostics, simulate new data and refit the models are available.
briskaR,2016-10-11,briskaR: Biological Risk Assessment,A spatio-temporal exposure-hazard model for assessing biological
    risk and impact. The model is based on stochastic geometry for describing
    the landscape and the exposed individuals, a dispersal kernel for the
    dissemination of contaminants and an ecotoxicological equation.
    Walker E, Leclerc M, Rey JF, Beaudouin R, Soubeyrand S, and Messean A, (2017),
    A Spatio-Temporal Exposure-Hazard Model for Assessing Biological Risk and Impact,
    Risk Analysis, <doi:10.1111/risa.12941>.
ConR,2016-10-31,ConR: Computation of Parameters Used in Preliminary Assessment of
Conservation Status,Multi-species estimation of geographical range parameters
	for preliminary assessment of conservation status following Criterion B of the 
	International Union for Conservation of Nature (IUCN, 
	see <http://www.iucnredlist.org>).
fst,2017-01-12,fst: Lightning Fast Serialization of Data Frames for R,Multithreaded serialization of compressed data frames using the
    'fst' format. The 'fst' format allows for random access of stored data and
    compression with the LZ4 and ZSTD compressors created by Yann Collet. The ZSTD
    compression library is owned by Facebook Inc.
LAM,2017-05-11,LAM: Some Latent Variable Models,
    Includes some procedures for latent variable modeling with a 
    particular focus on multilevel data.
    The 'LAM' package contains mean and covariance structure modelling
    for multivariate normally distributed data (mlnormal(); Longford, 1987;
    <doi:10.1093/biomet/74.4.817>), a general Metropolis-Hastings algorithm 
    (amh(); Roberts & Rosenthal, 2001, <doi:10.1214/ss/1015346320>) and 
    penalized maximum likelihood estimation (pmle(); Cole, Chu & Greenland, 
    2014; <doi:10.1093/aje/kwt245>).
mixR,2017-02-25,mixR: Finite Mixture Modeling for Raw and Binned Data,Performs maximum likelihood estimation for finite mixture models for families including Normal, Weibull, Gamma and Lognormal by using EM algorithm, together with Newton-Raphson algorithm or bisection method when necessary. It also conducts mixture model selection by using information criteria or bootstrap likelihood ratio test. The data used for mixture model fitting can be raw data or binned data. The model fitting process is accelerated by using R package 'Rcpp'.
RegularizedSCA,2017-06-25,RegularizedSCA: Regularized Simultaneous Component Based Data Integration,It performs regularized simultaneous component based data
    integration for multiblock data.
textshape,2016-12-31,textshape: Tools for Reshaping Text,Tools that can be used to reshape and restructure text data.
tigreBrowserWriter,2016-10-26,tigreBrowserWriter: 'tigreBrowser' Database Writer,Write modelling results into a database for
    'tigreBrowser', a web-based tool for browsing figures and summary
    data of independent model fits, such as Gaussian process models
    fitted for each gene or other genomic element. The browser is
    available at <https://github.com/PROBIC/tigreBrowser>.
wikilake,2017-01-07,wikilake: Scrape Lake Metadata Tables from Wikipedia,Scrape lake metadata tables from Wikipedia <http://www.wikipedia.org>. 
SPAtest,2017-02-21,SPAtest: Score Test and Meta-Analysis Based on Saddlepoint Approximation,Performs score test using saddlepoint approximation to estimate the null distribution. Also prepares summary statistics for meta-analysis and performs meta-analysis to combine multiple association results. For the latest version, please check <https://github.com/leeshawn/SPAtest>.
alterryx,2017-03-22,alterryx: An 'API' Client for the 'Alteryx' Gallery,A tool to access each of the 'Alteryx' Gallery 'API' endpoints.
    Users can queue jobs, poll job status, and retrieve application output as
    a data frame. You will need an 'Alteryx' Server license and have 'Alteryx'
    Gallery running to utilize this package. The 'API' is accessed through the
    'URL' that you setup for the server running 'Alteryx' Gallery and more
    information on the endpoints can be found at
    <https://gallery.alteryx.com/api-docs/>.
networktools,2017-04-14,networktools: Tools for Identifying Important Nodes in Networks,Includes assorted tools for network analysis. Bridge centrality, impact, & goldbricker.
powerCompRisk,2017-05-12,powerCompRisk: Power Analysis Tool for Joint Testing Hazards with Competing
Risks Data,A power analysis tool for jointly testing the cause-1 cause-specific hazard and the any-cause hazard with competing risks data.
Tcomp,2016-10-17,Tcomp: Data from the 2010 Tourism Forecasting Competition,The 1311 time series from the tourism forecasting competition conducted in 2010 and described in Athanasopoulos et al. (2011) <doi:10.1016/j.ijforecast.2010.04.009>.
pkr,2017-03-14,pkr: Pharmacokinetics in R,Conduct a noncompartmental analysis as closely as possible to the most widely used commercial software for pharmacokinetic analysis, i.e. 'Phoenix(R) WinNonlin(R)' <https://www.certara.com/software/pkpd-modeling-and-simulation/phoenix-winnonlin/>.
             Some features are
             1) CDISC SDTM terms
             2) Automatic slope selection with the same criterion of WinNonlin(R)
             3) Supporting both 'linear-up linear-down' and 'linear-up log-down' method
             4) Interval(partial) AUCs with 'linear' or 'log' interpolation method
             * Reference: Gabrielsson J, Weiner D. Pharmacokinetic and Pharmacodynamic Data Analysis - Concepts and Applications. 5th ed. 2016. (ISBN:9198299107).
qrcmNP,2017-09-22,qrcmNP: Nonlinear and Penalized Quantile Regression Coefficients
Modeling,Nonlinear and Penalized parametric modeling of quantile regression coefficient functions. Frumento P and Bottai M (2016) <doi:10.1111/biom.12410>.
rwc,2017-09-07,rwc: Random Walk Covariance Models,Code to facilitate simulation and inference when connectivity is defined by underlying random walks. Methods for spatially-correlated pairwise distance data are especially considered. This provides core code to conduct analyses similar to that in Hanks and Hooten (2013) <doi:10.1080/01621459.2012.724647>.
tangram,2017-05-03,tangram: The Grammar of Tables,Provides an extensible formula system to quickly and easily create
    production quality tables. The steps of the process are formula parser,
    statistical content generation from data, to rendering. Each step of the process
    is separate and user definable thus creating a set of building blocks for
    highly extensible table generation. A user is not limited by any of the 
    choices of the package creator other than the formula grammar. For example,
    one could chose to add a different S3 rendering function and output a format
    not provided in the default package. Or possibly one would rather have Gini
    coefficients for their statistical content. Routines to achieve New England
    Journal of Medicine style, Lancet style and Hmisc::summaryM() statistics are
    provided. The package contains rendering for HTML5, Rmarkdown and an indexing
    format for use in tracing and tracking are provided.
excerptr,2017-04-25,excerptr: Excerpt Structuring Comments from Your Code File and Set a Table
of Contents,This is an R interface to the
    python package 'excerpts' (<https://pypi.python.org/pypi/excerpts>).
LocalControl,2017-05-16,LocalControl: Nonparametric Methods for Generating High Quality Comparative
Effectiveness Evidence,Implements novel nonparametric approaches to address
    biases and confounding when comparing treatments or exposures in
    observational studies of outcomes. While designed and appropriate for use
    in studies involving medicine and the life sciences, the package can be
    used in other situations involving outcomes with multiple confounders.
    The package implements a family of methods for nonparametric bias
    correction when comparing treatments in cross-sectional, case-control,
    and survival analysis settings, including competing risks with censoring.
    The approach extends to bias-corrected personalized predictions of
    treatment outcome differences, and analysis of heterogeneity of treatment
    effect-sizes across patient subgroups.
shinymaterial,2017-04-15,shinymaterial: Implement Material Design in Shiny Applications,Allows shiny developers to incorporate UI elements based on Google's Material design. See <https://material.io/guidelines/> for more information.
hmi,2017-03-27,hmi: Hierarchical Multiple Imputation,Runs single level and multilevel imputation models. The user just has to pass the data to the main function and, optionally, his analysis model. Basically the package then translates this analysis model into commands to impute the data according to it with functions from 'mice', 'MCMCglmm' or routines build for this package.
PSTR,2017-09-13,PSTR: Panel Smooth Transition Regression Modelling,Provides the Panel Smooth Transition Regression (PSTR) modelling.
    The modelling procedure consists of three stages: Specification, Estimation and Evaluation.
    The package offers sharp tools helping the package user(s) to conduct model specification tests,
    to do PSTR model estimation, and to do model evaluation.
    The tests implemented in the package allow for cluster-dependency and are heteroskedasticity-consistent.
    The wild bootstrap and wild cluster bootstrap tests are also implemented.
    Parallel computation (as an option) is implemented in some functions, especially the bootstrap tests.
    The package suits tasks running many cores on super-computation servers.
sitreeE,2017-07-14,sitreeE: Sitree Extensions,Provides extensions for package 'sitree' for allometric variables, growth, mortality, recruitment, management, tree removal and external modifiers functions.
welchADF,2017-04-23,welchADF: Welch-James Statistic for Robust Hypothesis Testing under
Heterocedasticity and Non-Normality,Implementation of Johansen's general formulation of Welch-James's statistic with Approximate Degrees of Freedom, which makes it suitable for testing 
    any linear hypothesis concerning cell means in univariate and multivariate mixed model designs when the data pose non-normality and non-homogeneous variance. Some 
    improvements, namely trimmed means and Winsorized variances, and bootstrapping for calculating an empirical critical value, have been added to the classical formulation. 
    The code departs from a previous SAS implementation by L.M. Lix and H.J. Keselman, available at <http://supp.apa.org/psycarticles/supplemental/met_13_2_110/SAS_Program.pdf> and
    published in Keselman, H.J., Wilcox, R.R., and Lix, L.M. (2003) <doi:10.1111/1469-8986.00060>.
metaforest,2017-09-09,metaforest: Exploring Heterogeneity in Meta-Analysis using Random Forests,Conduct random forests-based meta-analysis, obtain partial dependence plots for metaforest and classic meta-analyses, and cross-validate and tune metaforest- and classic meta-analyses in conjunction with the caret package. A requirement of classic meta-analysis is that the studies being aggregated are conceptually similar, and ideally, close replications. However, in many fields, there is substantial heterogeneity between studies on the same topic. Classic meta-analysis lacks the power to assess more than a handful of univariate moderators. MetaForest, by contrast, has substantial power to explore heterogeneity in meta-analysis. It can identify important moderators from a larger set of potential candidates, even with as little as 20 studies (Van Lissa, in preparation). This is an appealing quality, because many meta-analyses have small sample sizes. Moreover, MetaForest yields a measure of variable importance which can be used to identify important moderators, and offers partial prediction plots to explore the shape of the marginal relationship between moderators and effect size.
redux,2017-05-15,redux: R Bindings to 'hiredis',A 'hiredis' wrapper that includes support for
    transactions, pipelining, blocking subscription, serialisation of
    all keys and values, 'Redis' error handling with R errors.
    Includes an automatically generated 'R6' interface to the full
    'hiredis' 'API'.  Generated functions are faithful to the
    'hiredis' documentation while attempting to match R's argument
    semantics.  Serialisation must be explicitly done by the user, but
    both binary and text-mode serialisation is supported.
graphkernels,2017-03-16,graphkernels: Graph Kernels,A fast C++ implementation for computing various graph kernels including (1) simple kernels between vertex and/or edge label histograms, (2) graphlet kernels, (3) random walk kernels (popular baselines), and (4) the Weisfeiler-Lehman graph kernel (state-of-the-art).
purrrlyr,2017-04-29,purrrlyr: Tools at the Intersection of 'purrr' and 'dplyr',Some functions at the intersection of 'dplyr' and 'purrr' that 
  formerly lived in 'purrr'.
ramcmc,2016-11-30,ramcmc: Robust Adaptive Metropolis Algorithm,Function for adapting the shape of the random walk Metropolis proposal
    as specified by robust adaptive Metropolis algorithm by Vihola (2012) <doi:10.1007/s11222-011-9269-5>. 
    Package also includes fast functions for rank-one Cholesky update and downdate.
    These functions can be used directly from R or the corresponding C++ header files 
    can be easily linked to other R packages.
RatingScaleReduction,2017-02-11,RatingScaleReduction: Rating Scale Reduction Procedure,Describes a new procedure of reducing items in a rating scale called Rating Scale Reduction (RSR). The new stop criterion in RSR procedure is added (stop global max). Data sets are added.
RchivalTag,2017-03-21,RchivalTag: Analyzing Archival Tagging Data,A set of functions to generate, access and analyze standard data products from archival tagging data.
rdwd,2017-01-25,rdwd: Select and Download Climate Data from 'DWD' (German Weather
Service),Handle climate data from the 'DWD' ('Deutscher Wetterdienst', see 
             <https://www.dwd.de/EN/climate_environment/cdc/cdc.html> for more information).
             Choose files with 'selectDWD()', download and process data sets with 'dataDWD()' and 'readDWD()'.
StructFDR,2016-11-01,StructFDR: False Discovery Control Procedure Integrating the Prior
Structure Information,Perform more powerful false discovery control (FDR) for microbiome data, taking into account the prior phylogenetic relationship among bacteria species.  As a general methodology, it is applicable to any type of (genomic) data with prior structure information.
DClusterm,2017-02-12,DClusterm: Model-Based Detection of Disease Clusters,Model-based methods for the detection of disease clusters
  using GLMs, GLMMs and zero-inflated models.
joineRML,2016-12-27,joineRML: Joint Modelling of Multivariate Longitudinal Data and
Time-to-Event Outcomes,Fits the joint model proposed by Henderson and colleagues (2000) 
    <doi:10.1093/biostatistics/1.4.465>, but extended to the case of multiple 
    continuous longitudinal measures. The time-to-event data is modelled using a 
    Cox proportional hazards regression model with time-varying covariates. The 
    multiple longitudinal outcomes are modelled using a multivariate version of the 
    Laird and Ware linear mixed model. The association is captured by a multivariate
    latent Gaussian process. The model is estimated using a Monte Carlo Expectation 
    Maximization algorithm. This project is funded by the Medical Research Council 
    (Grant number MR/M013227/1).
qgam,2017-08-29,qgam: Smooth Additive Quantile Regression Models,Smooth additive quantile regression models, fitted using
    the methods of Fasiolo et al. (2017) <arXiv:1707.03307>. Differently from
    'quantreg', the smoothing parameters are estimated automatically by marginal
    loss minimization, while the regression coefficients are estimated using either
    PIRLS or Newton algorithm. The learning rate is determined so that the Bayesian
    credible intervals of the estimated effects have approximately the correct
    coverage. The main function is qgam() which is similar to gam() in 'mgcv', but
    fits non-parametric quantile regression models.
RHMS,2017-04-21,RHMS: Hydrologic Modelling System for R Users,Hydrologic modelling system is an object oriented tool which enables R users to simulate and analyze hydrologic events. The package proposes functions and methods for construction, simulation, visualization, and calibration of hydrologic systems.
MetaLonDA,2017-07-28,MetaLonDA: Metagenomics Longitudinal Differential Abundance Method,Identify time intervals of differentially abundant metagenomics features in longitudinal studies.
aws.s3,2017-04-29,aws.s3: 'AWS S3' Client Package,A simple client package for the Amazon Web Services ('AWS') Simple
    Storage Service ('S3') 'REST' 'API' <https://aws.amazon.com/s3/>.
clampSeg,2017-06-07,clampSeg: Idealisation of Patch Clamp Recordings,Allows for idealisation of patch clamp recordings by implementing the non-parametric JUmp Local dEconvolution Segmentation (JULES) filter, see F. Pein, I. Tecuapetla-Gómez, O. Schütte, C. Steinem, and A. Munk (2017) <arXiv:1706.03671>.
DisHet,2017-03-16,DisHet: Estimate the Gene Expression Levels and Component Proportions of
the Normal, Stroma (Immune) and Tumor Components of Bulk Tumor
Samples,Model cell type heterogeneity of bulk renal cell carcinoma. The observed gene expression in bulk tumor sample is modeled by a log-normal distribution with the location parameter structured as a linear combination of the component-specific gene expressions. 
edgarWebR,2017-08-16,edgarWebR: SEC Filings Access,A set of methods to access and parse live filing information from the
    U.S. Securities and Exchange Commission (SEC - <https://sec.gov>) including
    company and fund filings along with all associated metadata.
PeakSegOptimal,2017-06-21,PeakSegOptimal: Optimal Segmentation Subject to Up-Down Constraints,Computes optimal changepoint models using the
 Poisson likelihood for non-negative count data,
 subject to the PeakSeg constraint:
 the first change must be up, second change down, third change up, etc.
 For more info about the models and algorithms,
 read "A log-linear time algorithm for constrained changepoint detection"
 <arXiv:1703.03352> by TD Hocking et al.
BiDAG,2017-07-19,BiDAG: Bayesian Inference for Directed Acyclic Graphs (BiDAG),Implementation of a collection of MCMC methods for Bayesian structure learning
    of directed acyclic graphs (DAGs), both from continuous and discrete data. For efficient
    inference on larger DAGs, the space of DAGs is pruned according to the data. To filter
    the search space, the algorithm employs a hybrid approach, combining constraint-based 
    learning with search and score. A reduced search space is initially defined on the basis
    of a skeleton obtained by means of the PC-algorithm, and then iteratively improved with
    search and score. Search and score is then performed following two approaches:
    Order MCMC, or Partition MCMC.
    The BGe score is implemented for continuous data and the BDe score is implemented
    for binary data. The algorithms may provide the maximum a posteriori (MAP) graph or
    a sample (a collection of DAGs) from the posterior distribution given the data.
    References:
    N. Friedman and D. Koller (2003) <doi:10.1023/A:1020249912095>, 
    D. Geiger and D. Heckerman (2002) <doi:10.1214/aos/1035844981>, 
    J. Kuipers and G. Moffa (2016) <doi:10.1080/01621459.2015.1133426>, 
    M. Kalisch et al.(2012) <doi:10.18637/jss.v047.i11>.
DPP,2017-09-27,DPP: Inference of Parameters of Normal Distributions from a Mixture
of Normals,This MCMC method takes a data numeric vector (Y) and assigns the elements of Y
  to a (potentially infinite) number of normal distributions. The individual normal distributions from a mixture of normals can be inferred.
  Following the method described in Escobar (1994) <doi:10.2307/2291223> we use a Dirichlet Process Prior (DPP) to describe stochastically our prior assumptions about the dimensionality of the data.
lvec,2017-07-13,lvec: Out of Memory Vectors,Core functionality for working with vectors (numeric, integer,
    logical and character) that are too large to keep in memory. The vectors are
    kept (partially) on disk using memory mapping. This package contains the
    basic functionality for working with these memory mapped vectors (e.g.
    creating, indexing, ordering and sorting) and provides C++ headers which can
    be used by other packages to extend the functionality provided in this
    package.
neurohcp,2017-05-14,neurohcp: Human 'Connectome' Project Interface,Downloads and reads data from Human 'Connectome' Project 
    <https://db.humanconnectome.org> using Amazon Web Services ('AWS') 
    'S3' buckets.
bssm,2017-06-25,bssm: Bayesian Inference of Non-Linear and Non-Gaussian State Space
Models,Efficient methods for Bayesian inference of state space models 
    via particle Markov chain Monte Carlo and parallel importance sampling type weighted 
    Markov chain Monte Carlo (Vihola, Helske, and Franks, 2017, <arXiv:1609.02541>). 
    Gaussian, Poisson, binomial, or negative binomial 
    observation densities and basic stochastic volatility models with Gaussian state 
    dynamics, as well as general non-linear Gaussian models and discretised diffusion models 
    are supported.
frailtyEM,2017-03-22,frailtyEM: Fitting Frailty Models with the EM Algorithm,Contains functions for fitting shared frailty models with a semi-parametric
    baseline hazard with the Expectation-Maximization algorithm. Supported data formats 
    include clustered failures with left truncation and recurrent events in gap-time
    or Andersen-Gill format. Several frailty distributions, such as the the gamma, positive stable
    and the Power Variance Family are supported. 
ukbtools,2017-06-30,ukbtools: Manipulate and Explore UK Biobank Data,A set of tools to create a UK Biobank <http://www.ukbiobank.ac.uk/> dataset from a UKB fileset (.tab, .r, .html),
    visualize primary demographic data for a sample subset, query ICD diagnoses,
    retrieve genetic metadata, read and write standard file formats for genetic analyses.
unsystation,2016-10-17,unsystation: Stationarity Test Based on Unsystematic Sub-Sampling,Performs a test for second-order stationarity of time series based
    on unsystematic sub-samples.
ALA4R,2016-11-09,ALA4R: Atlas of Living Australia (ALA) Data and Resources in R,The Atlas of Living Australia (ALA) provides tools to enable users
    of biodiversity information to find, access, combine and visualise data on
    Australian plants and animals; these have been made available from
    <http://ala.org.au/>. ALA4R provides a subset of the tools to be
    directly used within R. It enables the R community to directly access data
    and resources hosted by the ALA.
genotypeR,2017-08-23,genotypeR: SNP Genotype Marker Design and Analysis,We implement a common genotyping workflow with a standardized software interface. 'genotypeR' designs genotyping markers from vcf files, outputs markers for multiplexing suitability on various platforms (Sequenom and Illumina GoldenGate), and provides various QA/QC and analysis functions. We developed this package to analyze data in Stevison LS, SA Sefick, CA Rushton, and RM Graze. 2017. Invited Review: Recombination rate plasticity: revealing mechanisms by design. Philosophical Transactions Royal Society London B Biol Sci 372:1-14. <doi:10.1098/rstb.2016.0459>, and have published it here Sefick, S.A., M.A. Castronova, and L.S. Stevison. 2017. GENOTYPER: An integrated R packages for single nuleotide polymorphism genotype marker design and data analysis. Methods in Ecology and Evolution 9: 1318-1323. <doi:10.1111/2041-210X.12965>.  
ICtest,2016-12-19,ICtest: Estimating and Testing the Number of Interesting Components in
Linear Dimension Reduction,For different linear dimension reduction methods like principal components analysis (PCA), independent components analysis (ICA) and supervised linear dimension reduction tests and estimates for the number of interesting components (ICs) are provided.
margins,2017-03-22,margins: Marginal Effects for Model Objects,An R port of Stata's 'margins' command, which can be used to
    calculate marginal (or partial) effects from model objects.
microPop,2017-03-29,microPop: Modelling Microbial Populations,Modelling interacting microbial populations - example applications
    include human gut microbiota, rumen microbiota and phytoplankton. Solves a
    system of ordinary differential equations to simulate microbial growth and
    resource uptake over time.
philentropy,2017-04-26,philentropy: Similarity and Distance Quantification Between Probability
Functions,Computes 46 optimized distance and similarity measures for comparing probability functions. These comparisons between probability functions have their foundations in a broad range of scientific disciplines from mathematics to ecology. The aim of this package is to provide a core framework for clustering, classification, statistical inference, goodness-of-fit, non-parametric statistics, information theory, and machine learning tasks that are based on comparing univariate or multivariate probability functions.
prediction,2016-10-30,prediction: Tidy, Type-Safe 'prediction()' Methods,A one-function package containing 'prediction()', a type-safe alternative to 'predict()' that always returns a data frame. The package currently supports common model types (e.g., "lm", "glm") from the 'stats' package, as well as numerous other model classes from other add-on packages. See the README or main package documentation page for a complete listing.
quadprogXT,2017-05-30,quadprogXT: Quadratic Programming with Absolute Value Constraints,Extends the quadprog package to solve quadratic programs with
    absolute value constraints and absolute values in the objective function.
regnet,2017-05-21,regnet: Network-Based Regularization for Generalized Linear Models,Network-based regularization has achieved success in variable selection for 
    high-dimensional biological data due to its ability to incorporate correlations 
    among genomic features. This package provides procedures of network-based variable 
    selection for generalized linear models. Two recent additions are the robust network 
    regularization for the survival response and the network regularization for continuous 
    response. Functions for other regularization methods will be included in the forthcoming 
    upgraded versions. 
templates,2017-01-07,templates: A System for Working with Templates,Provides tools to work with template code and text in R. It aims to
    provide a simple substitution mechanism for R-expressions inside these
    templates. Templates can be written in other languages like 'SQL', can
    simply be represented by characters in R, or can themselves be R-expressions
    or functions.
ziphsmm,2017-01-14,ziphsmm: Zero-Inflated Poisson Hidden (Semi-)Markov Models,Fit zero-inflated Poisson hidden (semi-)Markov models with or without covariates by directly minimizing the negative log likelihood function using the gradient descent algorithm. Multiple starting values should be used to avoid local minima.
AIG,2016-12-19,AIG: Automatic Item Generator,A collection of Automatic Item Generators used mainly for
    psychological research. This package can generate linear syllogistic reasoning,
    arithmetic and 2D/3D/Double 3D spatial reasoning items. It is recommended for research
    purpose only.
easycsv,2017-08-08,easycsv: Load Multiple 'csv' and 'txt' Tables,Allows users to easily read multiple comma separated tables and create a data frame under the same name.
    Is able to read multiple comma separated tables from a local directory, a zip file or a zip file on a remote directory. 
kableExtra,2017-03-02,kableExtra: Construct Complex Table with 'kable' and Pipe Syntax,Build complex HTML or 'LaTeX' tables using 'kable()' from 'knitr' 
    and the piping syntax from 'magrittr'. Function 'kable()' is a light weight 
    table generator coming from 'knitr'. This package simplifies the way to 
    manipulate the HTML or 'LaTeX' codes generated by 'kable()' and allows 
    users to construct complex tables and customize styles using a readable 
    syntax. 
tabularaster,2017-08-05,tabularaster: Tidy Tools for 'Raster' Data,Facilities to work with vector and raster data in efficient 
 repeatable and systematic work flow. Missing functionality in existing packages 
 is included here to allow extraction from raster data with 'simple features' and 
 'Spatial' types and to make extraction consistent and straightforward. Extract cell 
 numbers from raster data and  return the cells, values and weights as a data frame 
 rather than as lists of matrices or vectors. The functions here allow spatial data 
 to be used without special handling for the format currently in use. 
MAVE,2017-01-29,MAVE: Methods for Dimension Reduction,Functions for dimension reduction, using MAVE (Minimum Average Variance Estimation), OPG (Outer Product of Gradient) and KSIR (sliced inverse regression of kernel version). Methods for selecting the best dimension are also included.
HURDAT,2017-05-15,HURDAT: Hurricane Re-Analysis Project,Scraped dataset of the Hurricane Research Division's Hurricane 
    Re-Analysis Project known as HURDAT. Storm details are available for most 
    known hurricanes and tropical storms for the Atlantic and northeastern 
    Pacific ocean (northwestern hemisphere). See <http://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html> 
    for more information.
kutils,2016-12-23,kutils: Project Management Tools,Tools for data importation, recoding, and inspection that
    are used at the University of Kansas Center for Research Methods
    and Data Analysis. There are functions to create new project
    folders, R code templates, create uniquely named output
    directories, and to quickly obtain a visual summary for each
    variable in a data frame.  The main feature here is the systematic
    implementation of the "variable key" framework for data
    importation and recoding.  We are eager to have community feedback
    about the variable key and the vignette about it.
StepSignalMargiLike,2017-08-23,StepSignalMargiLike: Step-Wise Signal Extraction via Marginal Likelihood,Provides function to estimate multiple change points
    using marginal likelihood method. See the Manual file in data folder for
    a detailed description of all functions, and a walk through tutorial.
    For more information of the method, please see Du, Kao and Kou (2016) 
    <doi:10.1080/01621459.2015.1006365>.
CrossValidate,2017-07-28,CrossValidate: Classes and Methods for Cross Validation of "Class Prediction"
Algorithms,Defines classes and methods to cross-validate various
  binary classification algorithms used for "class prediction"
  problems.
GAparsimony,2017-08-04,GAparsimony: Searching Parsimony Models with Genetic Algorithms,Methodology that combines feature selection, model tuning, and parsimonious model selection with Genetic Algorithms (GA) proposed in {Martinez-de-Pison} (2015) <doi:10.1016/j.asoc.2015.06.012>. To this objective, a novel GA selection procedure is introduced based on separate cost and complexity evaluations.
ggjoy,2017-07-14,ggjoy: Joyplots in 'ggplot2',Joyplots provide a convenient way of visualizing changes in distributions over time or space. This package enables the creation of such plots in 'ggplot2'.
Modeler,2017-07-13,Modeler: Classes and Methods for Training and Using Binary Prediction
Models,Defines classes and methods to learn models and use them
  to predict binary outcomes.  These are generic tools, but we also
  include specific examples for many common classifiers.
randgeo,2017-02-18,randgeo: Generate Random 'WKT' or 'GeoJSON',Generate random positions (latitude/longitude), 
    Well-known text ('WKT') points or polygons, or 'GeoJSON' points or 
    polygons. 
rdist,2017-03-05,rdist: Calculate Pairwise Distances,A common framework for calculating distance matrices.
rsurface,2017-09-26,rsurface: Design of Rotatable Central Composite Experiments and Response
Surface Analysis,Produces tables with the level of replication (number of replicates) and the
    experimental uncoded values of the quantitative factors to be used for rotatable Central
    Composite Design (CCD) experimentation and a 2-D contour plot of the corresponding
    variance of the predicted response according to
    Mead et al. (2012) <doi:10.1017/CBO9781139020879> design_ccd(), and analyzes
    CCD data with response surface methodology ccd_analysis(). A rotatable CCD
    provides values of the variance of the predicted response that are concentrically
    distributed around the average treatment combination used in the experimentation, which
    with uniform precision (implied by the use of several replicates at the average
    treatment combination) improves greatly the search and finding of an optimum response.
    These properties of a rotatable CCD represent undeniable advantages over the classical
    factorial design, as discussed by Panneton et al. (1999) <doi:10.13031/2013.13267> and
    Mead et al. (2012) <doi:10.1017/CBO9781139020879.018> among others.
SIBERG,2017-07-11,SIBERG: Systematic Identification of Bimodally Expressed Genes Using
RNAseq Data,Provides models to identify bimodally expressed genes from
 RNAseq data based on the Bimodality Index. SIBERG models the  RNAseq data in
 the finite mixture modeling framework and incorporates mechanisms  for
 dealing with RNAseq normalization. Three types of mixture models are
 implemented,  namely, the mixture of log normal, negative binomial, or 
 generalized Poisson distribution. See Tong et al. (2013)
 <doi:10.1093/bioinformatics/bts713>.
simsurv,2017-07-27,simsurv: Simulate Survival Data,Simulate survival times from standard parametric survival 
    distributions (exponential, Weibull, Gompertz), 2-component mixture 
    distributions, or a user-defined hazard, log hazard, cumulative hazard,
    or log cumulative hazard function. Baseline covariates can be included 
    under a proportional hazards assumption. 
    Time dependent effects (i.e. non-proportional hazards) can be included by 
    interacting covariates with linear time or a user-defined function of time.
    Clustered event times are also accommodated. 
    The 2-component mixture distributions can allow for a variety of flexible
    baseline hazard functions reflecting those seen in practice. 
    If the user wishes to provide a user-defined 
    hazard or log hazard function then this is possible, and the resulting
    cumulative hazard function does not need to have a closed-form solution. 
    Note that this package is modelled on the 'survsim' package available in 
    the 'Stata' software (see Crowther and Lambert (2012) 
    <http://www.stata-journal.com/sjpdf.html?articlenum=st0275> or 
    Crowther and Lambert (2013) <doi:10.1002/sim.5823>).
Umpire,2017-07-11,Umpire: Simulating Realistic Gene Expression Data,The Ultimate Microrray Prediction, Reality and Inference
  Engine (UMPIRE) is a package to facilitate the simulation of realistic
  microarray data sets with link to associate outcomes. See Zhang and
  Coombes (2012) <doi:10.1186/1471-2105-13-S13-S1>.
ClassComparison,2017-07-11,ClassComparison: Classes and Methods for "Class Comparison" Problems on
Microarrays,Defines the classes used for "class comparison" problems
  in the OOMPA project (<http://oompa.r-forge.r-project.org/>). Class
  comparison includes tests for differential expression; see Simon's
  book for details on typical problem types.
datadogr,2017-05-31,datadogr: R Client for 'Datadog' API,Query for metrics from 'Datadog' (<https://www.datadoghq.com/>) via its API.
diffusr,2016-11-28,diffusr: Network Diffusion Algorithms,Implementation of network diffusion algorithms such as
  heat diffusion or Markov random walks. Network diffusion algorithms generally
  spread information in the form of node weights along the edges of a graph to other nodes.
  These weights can for example be interpreted as temperature, an initial amount
  of water, the activation of neurons in the brain, or the location of a random
  surfer in the internet. The information (node weights) is iteratively propagated
  to other nodes until a equilibrium state or stop criterion occurs.
implyr,2017-03-24,implyr: R Interface for Apache Impala,'SQL' back-end to 'dplyr' for Apache Impala, the massively
    parallel processing query engine for Apache 'Hadoop'. Impala enables
    low-latency 'SQL' queries on data stored in the 'Hadoop' Distributed
    File System '(HDFS)', Apache 'HBase', Apache 'Kudu', Amazon Simple 
    Storage Service '(S3)', Microsoft Azure Data Lake Store '(ADLS)', 
    and Dell 'EMC' 'Isilon'. See <https://impala.apache.org> for more
    information about Impala.
oompaBase,2017-07-11,oompaBase: Class Unions, Matrix Operations, and Color Schemes for OOMPA,Provides the class unions that must be
  preloaded in order for the basic tools in the OOMPA (Object-Oriented 
  Microarray and Proteomics Analysis) project to be defined and loaded.
  It also includes vectorized operations for row-by-row means,
  variances, and t-tests. Finally, it provides new color schemes.
  Details on the packages in the OOMPA project can be found at
  <http://oompa.r-forge.r-project.org/>.
Polychrome,2017-03-17,Polychrome: Qualitative Palettes with Many Colors,Tools for creating, viewing, and assessing qualitative
 palettes with many (20-30 or more) colors.
PreProcess,2017-07-13,PreProcess: Basic Functions for Pre-Processing Microarrays,Provides classes to pre-process microarray gene
  expression data as part of the OOMPA collection of packages
  described at <http://oompa.r-forge.r-project.org/>.
TailRank,2017-07-11,TailRank: The Tail-Rank Statistic,Implements the tail-rank statistic for selecting biomarkers
  from a microarray data set, an efficient nonparametric test focused
  on the distributional tails. See
  <http://bioinformatics.mdanderson.org/TailRank/tolstoy-new.pdf>.
tukeytrend,2017-06-20,tukeytrend: Tukeys Trend Test via Multiple Marginal Models,Provides wrapper functions to the multiple marginal model function mmm() of package 'multcomp' to implement the trend test of Tukey, Ciminera and Heyse (1985) <doi:10.2307/2530666> for general parametric models.
ChoR,2017-02-20,ChoR: Chordalysis R Package,
    Learning the structure of graphical models from datasets with thousands of variables.
    More information about the research papers detailing the theory behind Chordalysis is available at
    <http://www.francois-petitjean.com/Research> (KDD 2016, SDM 2015, ICDM 2014, ICDM 2013).
    The R package development site is <https://github.com/HerrmannM/Monash-ChoR>.
datasus,2017-06-12,datasus: An Interface to DATASUS System,It allows the user to retrieve the data from the systems of 
    DATASUS (SUS IT department related to the Brazilian Ministry of Health, 
    see <http://datasus.saude.gov.br/informacoes-de-saude/tabnet/> for more
    information) much in the same way that is done in the online portal.
    For now the package allows access to the SINASC and SIM's (ICD-10) 
    systems, that is, the 'Estatísticas Vitais'.
rust,2016-10-10,rust: Ratio-of-Uniforms Simulation with Transformation,Uses the generalized ratio-of-uniforms (RU) method to simulate
    from univariate and (low-dimensional) multivariate continuous distributions.
    The user specifies the log-density, up to an additive constant. The RU
    algorithm is applied after relocation of mode of the density to zero, and
    the user can choose a tuning parameter r. For details see Wakefield, Gelfand
    and Smith (1991) <doi:10.1007/BF01889987>, Efficient generation of random
    variates via the ratio-of-uniforms method, Statistics and Computing (1991)
    1, 129-133.  A Box-Cox variable transformation can be used to make the input
    density suitable for the RU method and to improve efficiency.  In the
    multivariate case rotation of axes can also be used to improve efficiency.
    From version 1.2.0 the 'Rcpp' package 
    <https://cran.r-project.org/package=Rcpp> can be used to improve efficiency.
HTSSIP,2016-11-01,HTSSIP: High Throughput Sequencing of Stable Isotope Probing Data
Analysis,Functions for analyzing high throughput sequencing 
    stable isotope probing (HTS-SIP) data.
    Analyses include high resolution stable isotope probing (HR-SIP),
    multi-window high resolution stable isotope probing (MW-HR-SIP), 
    and quantitative stable isotope probing (q-SIP). 
missRanger,2017-08-25,missRanger: Fast Imputation of Missing Values,Alternative implementation of the beautiful 'MissForest' algorithm used to impute mixed-type data sets by chaining tree ensembles, introduced by Stekhoven, D.J. and Buehlmann, P. (2012) <doi:10.1093/bioinformatics/btr597>. Under the hood, it uses the lightning fast random jungle package 'ranger'. Between the iterative model fitting, we offer the option of using predictive mean matching. This firstly avoids imputation with values not already present in the original data (like a value 0.3334 in 0-1 coded variable). Secondly, predictive mean matching tries to raise the variance in the resulting conditional distributions to a realistic level. This would allow e.g. to do multiple imputation when repeating the call to missRanger().
PBNPA,2016-12-20,PBNPA: Permutation Based Non-Parametric Analysis of CRISPR Screen Data,Permutation based
    non-parametric analysis of CRISPR screen data. Details about this algorithm are published in the following paper published on BMC genomics, Jia et al. (2017) <doi:10.1186/s12864-017-3938-5>: A permutation-based non-parametric analysis of CRISPR screen data. Please cite this paper if you use this algorithm for your paper.
vortexR,2017-03-28,vortexR: Post Vortex Simulation Analysis,Facilitate Post Vortex Simulation Analysis by offering
    tools to collate multiple Vortex (v10) output files into one R object, and
    analyse the collated output statistically. Vortex is a software for
    the development of individual-based model for population dynamic simulation
    (see <http://www.vortex10.org/Vortex10.aspx>).
base64url,2016-10-04,base64url: Fast and URL-Safe Base64 Encoder and Decoder,In contrast to RFC3548, the 62nd character ("+") is replaced with
    "-", the 63rd character ("/") is replaced with "_". Furthermore, the encoder
    does not fill the string with trailing "=". The resulting encoded strings
    comply to the regular expression pattern "[A-Za-z0-9_-]" and thus are
    safe to use in URLs or for file names.
    The package also comes with a simple base32 encoder/decoder suited for
    case insensitive file systems.
ffstream,2016-11-13,ffstream: Forgetting Factor Methods for Change Detection in Streaming Data,An implementation of the adaptive forgetting factor scheme described in Bodenham and Adams (2016) <doi:10.1007/s11222-016-9684-8> which adaptively estimates the mean and variance of a stream in order to detect multiple changepoints in streaming data. The implementation is in C++ and uses Rcpp. Additionally, implementations of the fixed forgetting factor scheme from the same paper, as well as the classic CUSUM and EWMA methods, are included.
MTA,2017-03-06,MTA: Multiscalar Territorial Analysis,Build multiscalar territorial analysis based on various contexts.
rbi,2016-10-18,rbi: R Interface to LibBi,Provides a complete R interface to LibBi, a library for Bayesian inference (see <http://libbi.org> and <doi:10.18637/jss.v067.i10> for more information). This includes functions for manipulating LibBi models, for reading and writing LibBi input/output files, for converting LibBi output to provide traces for use with the coda package, and for running LibBi from R.
treespace,2017-03-17,treespace: Statistical Exploration of Landscapes of Phylogenetic Trees,Tools for the exploration of distributions of phylogenetic trees.
    This package includes a 'shiny' interface which can be started from R using
    treespaceServer(). 
    For further details see Jombart et al. (2017) <doi:10.1111/1755-0998.12676>.
mltools,2016-11-27,mltools: Machine Learning Tools,A collection of machine learning helper functions, particularly assisting in the Exploratory Data Analysis phase. Makes heavy use of the 'data.table' package for optimal speed and memory efficiency. Highlights include a versatile bin_data() function, sparsify() for converting a data.table to sparse matrix format with one-hot encoding, fast evaluation metrics, and empirical_cdf() for calculating empirical Multivariate Cumulative Distribution Functions.
ASIP,2017-07-20,ASIP: Automated Satellite Image Processing,Efficiently perform complex satellite image processes automatically with minimum inputs. 
  Functions are providing more control on the user to specify how the function needs to be executed by offering more customization options and facilitate more functionalities. 
  The functions are designed to identify the type of input satellite images and perform accordingly. 
  Also, some functions are giving options to perform multiple satellite data (even from different types) in single run.
  Package currently supports satellite images from most widely used Landsat 4,5,7 and 8 and Sentinel-2 MSI data. 
  The primary applications of this package are given below.
  1. Conversion of optical bands to top of atmosphere reflectance.
  2. Conversion of thermal bands to corresponding temperature images. 
  3. Derive application oriented products directly from source satellite image bands.
  4. Compute user defined equation and produce corresponding image product.
  5. Other basic tools for satellite image processing.
  REFERENCES.
  i. Chander and Markham (2003) <doi:10.1109/TGRS.2003.818464>.
  ii. Roy et.al, (2014) <doi:10.1016/j.rse.2014.02.001>.
  iii. Abrams (2000) <doi:10.1080/014311600210326>.
cld2,2017-06-03,cld2: Google's Compact Language Detector 2,Bindings to Google's C++ library Compact Language Detector 2
    (see <https://github.com/cld2owners/cld2#readme> for more information). Probabilistically
    detects over 80 languages in plain text or HTML. For mixed-language input it returns the
    top three detected languages and their approximate proportion of the total classified 
    text bytes (e.g. 80% English and 20% French out of 1000 bytes). There is also a 'cld3'
    package on CRAN which uses a neural network model instead.
dartR,2017-06-23,dartR: Importing and Analysing SNP and Silicodart Data Generated by
Genome-Wide Restriction Fragment Analysis,Functions are provided that facilitate the import and analysis of
    SNP (single nucleotide polymorphism) and silicodart (presence/absence) data. The main focus is on data generated
    by DarT (Diversity Arrays Technology). However, once SNP or related fragment
    presence/absence data from any source is imported into a genlight object many
    of the functions can be used. Functions are available for input and output of
    SNP and silicodart data, for reporting on and filtering on various criteria
    (e.g. CallRate, Heterozygosity, Reproducibility, maximum allele frequency).
    Advanced filtering is based on Linkage Disequilibrium and HWE (Hardy-Weinberg equilibrium). Other functions
    are available for visualization after PCoA (Principle Coordinate Analysis), or to facilitate transfer of data
    between genlight/genind objects and newhybrids, related, phylip, structure, faststructure packages.
Knoema,2017-08-22,Knoema: Interface to the Knoema API,Using this package, users can access to the largest collection of public data and statistics on the Internet featuring about 2.5 billion time series from thousands of sources collected in 'Knoema' repository and use rich R calculations in order to analyze the data. Because data in 'Knoema' is time series data, 'Knoema' function offers data in a number of formats usable in R such as 'ts', 'xts' or 'zoo'. For more information about 'Knoema' API go to <https://knoema.com/dev/docs>.
MEclustnet,2016-10-13,MEclustnet: Fitting the Mixture of Experts Latent Position Cluster Model to
Network Data,Fits the mixture of experts latent position cluster model to network data to cluster nodes into subgroups, while incorporating covariate information, in a mixture of experts model setting.
openSTARS,2017-08-09,openSTARS: An Open Source Implementation of the 'ArcGIS' Toolbox 'STARS',An open source implementation of the 'STARS' toolbox
    (Peterson & Ver Hoef, 2014, <doi:10.18637/jss.v056.i02>) using 'R' and 'GRASS GIS'.
    It prepares the *.ssn object needed for the 'SSN' package.
    A Digital Elevation Model (DEM) is used to derive stream networks 
    (in contrast to 'STARS' that can clean an existing stream network).
Select,2017-01-26,Select: Determines Species Probabilities Based on Functional Traits,The objective of these functions is to derive a species assemblage
    that satisfies a functional trait profile. Restoring resilient ecosystems
    requires a flexible framework for selecting assemblages that are based on the
    functional traits of species. However, current trait-based models have been
    limited to algorithms that can only select species by optimising specific trait
    values, and could not elegantly accommodate the common desire among restoration
    ecologists to produce functionally diverse assemblages. We have solved this
    problem by applying a non-linear optimisation algorithm that optimises Rao Q,
    a closed-form functional trait diversity index that incorporates species
    abundances, subject to other linear constraints. This framework generalises
    previous models that only optimised the entropy of the community, and can
    optimise both functional diversity and entropy simultaneously. This package
    can also be used to generate experimental assemblages to test the effects
    of community-level traits on community dynamics and ecosystem function. The
    method is based on theory discussed in Laughlin (2014, Ecology Letters)
    <doi.org/10.1111/ele.12288>.
shiny.semantic,2017-05-29,shiny.semantic: Semantic UI Support for Shiny,Creating a great user interface for your Shiny apps
    can be a hassle, especially if you want to work purely in R
    and don't want to use, for instance HTML templates. This
    package adds support for a powerful UI library Semantic UI -
    <http://semantic-ui.com/>. It also supports universal UI input 
    binding that works with various DOM elements.
blandr,2017-07-29,blandr: Bland-Altman Method Comparison,Carries out Bland Altman analyses (also known as a Tukey
    mean-difference plot) as described by JM Bland and DG Altman in
    1986 <doi:10.1016/S0140-6736(86)90837-8>. This package was created in 
    2015 as existing Bland-Altman analysis functions did not calculate 
    confidence intervals. This package was created to rectify this, 
    and create reproducible plots. This package is also available as a module
    for the 'jamovi' statistical spreadsheet (see <https://www.jamovi.org>
    for more information).
MVisAGe,2017-05-28,MVisAGe: Compute and Visualize Bivariate Associations,Pearson and Spearman correlation coefficients are commonly used to quantify the strength
	of bivariate associations of genomic variables.  For example, correlations of gene-level 
	DNA copy number and gene expression measurements may be used to assess the impact of 
	DNA copy number changes on gene expression in tumor tissue.  'MVisAGe' enables users to 
	quickly compute and visualize the correlations in order to assess the effect of regional 
	genomic events such as changes in DNA copy number or DNA methylation level.  Please see
	Walter V, Du Y, Danilova L, Hayward MC, Hayes DN, 2018. Cancer Research 
	<doi:10.1158/0008-5472.CAN-17-3464>.
readtext,2017-05-22,readtext: Import and Handling for Plain and Formatted Text Files,Functions for importing and handling text files and formatted text
    files with additional meta-data, such including '.csv', '.tab', '.json', '.xml',
    '.html', '.pdf', '.doc', '.docx', '.xls', '.xlsx', and others.
ROI.plugin.alabama,2017-05-18,ROI.plugin.alabama: 'alabama' Plug-in for the 'R' Optimization Infrastructure,Enhances the R Optimization Infrastructure ('ROI') package
        with the 'alabama' solver for solving nonlinear optimization problems.
writexl,2017-08-30,writexl: Export Data Frames to Excel 'xlsx' Format,Zero-dependency and data frame to xlsx exporter based on 'libxlsxwriter'. 
    Fast and no Java or Excel required.
BIEN,2017-01-12,BIEN: Tools for Accessing the Botanical Information and Ecology
Network Database,Provides Tools for Accessing the Botanical Information and Ecology Network Database.  The BIEN database contains cleaned and standardized botanical data including occurrence, trait, plot and taxonomic data (See <http://Bien.nceas.ucsb.edu/bien/> for more Information).  This package provides functions that query the BIEN database by constructing and executing optimized SQL queries.
tidyquant,2016-12-31,tidyquant: Tidy Quantitative Financial Analysis,Bringing financial analysis to the 'tidyverse'. The 'tidyquant' 
    package provides a convenient wrapper to various 'xts', 'zoo', 'quantmod', 'TTR' 
    and 'PerformanceAnalytics' package 
    functions and returns the objects in the tidy 'tibble' format. The main 
    advantage is being able to use quantitative functions with the 'tidyverse'
    functions including 'purrr', 'dplyr', 'tidyr', 'ggplot2', 'lubridate', etc. See 
    the 'tidyquant' website for more information, documentation and examples.
coga,2017-05-25,coga: Convolution of Gamma Distributions,Evaluation for density and distribution function of convolution of gamma
    distributions in R. Two related exact methods and one approximate method are
    implemented with efficient algorithm and C++ code. A quick guide for choosing
    correct method and usage of this package is given in package vignette.
DescriptiveStats.OBeu,2017-09-17,DescriptiveStats.OBeu: Descriptive Statistics 'OpenBudgets.eu',Estimate and return the needed parameters for visualizations designed for 'OpenBudgets.eu' <http://openbudgets.eu/> datasets. Calculate descriptive statistical measures in budget data of municipalities across Europe, according to the 'OpenBudgets.eu' data model. There are functions for measuring central tendency and dispersion of amount variables along with their distributions and correlations and the frequencies of categorical variables for a given dataset of the input 'OpenBudgets.eu' fiscal datasets. Also, can be used generally to extract visualization parameters convert them to 'JSON' format and use them as input in a different graphical interface. 
gdpc,2016-11-10,gdpc: Generalized Dynamic Principal Components,Functions to compute the Generalized Dynamic Principal Components
    introduced in Peña and Yohai (2016) <doi:10.1080/01621459.2015.1072542>.
LeArEst,2017-03-25,LeArEst: Border and Area Estimation of Data Measured with Additive Error,Provides methods for estimating borders of uniform distribution on
  the interval (one-dimensional) and on the elliptical domain (two-dimensional)
  under measurement errors. For one-dimensional case, it also estimates the
  length of underlying uniform domain and tests the hypothesized length against
  two-sided or one-sided alternatives. For two-dimensional case, it estimates
  the area of underlying uniform domain. It works with numerical inputs as well
  as with pictures in JPG format.
preference,2017-06-16,preference: 2-Stage Preference Trial Design and Analysis,Design and analyze two-stage randomized trials with a continuous
    outcome measure. The package contains functions to compute the required 
    sample size needed to detect a given preference, treatment, and selection 
    effect; alternatively, the package contains functions that can report the 
    study power given a fixed sample size. Finally, analysis functions are 
    provided to test each effect using either summary data (i.e. means, 
    variances) or raw study data.
CondIndTests,2017-06-29,CondIndTests: Nonlinear Conditional Independence Tests,Code for a variety of nonlinear conditional independence tests: 
  Kernel conditional independence test (Zhang et al., UAI 2011, <arXiv:1202.3775>),
  Residual Prediction test (based on Shah and Buehlmann, <arXiv:1511.03334>),
  Invariant environment prediction,
  Invariant target prediction,
  Invariant residual distribution test,
  Invariant conditional quantile prediction (all from Heinze-Deml et al., <arXiv:1706.08576>).
dlib,2017-02-20,dlib: Allow Access to the 'Dlib' C++ Library,Interface for 'Rcpp' users to 'dlib' <http://dlib.net> which is a
    'C++' toolkit containing machine learning algorithms and computer vision tools.
    It is used in a wide range of domains including robotics, embedded devices,
    mobile phones, and large high performance computing environments. This package
    allows R users to use 'dlib' through 'Rcpp'.
gWQS,2016-10-21,gWQS: Generalized Weighted Quantile Sum Regression,Fits Weighted Quantile Sum (WQS) regressions for continuous or binomial outcomes.
lmvar,2017-02-17,lmvar: Linear Regression with Non-Constant Variances,Runs a linear-like regression with in which both the expected value and the variance can vary per observation. The expected values mu follows the standard linear model mu = X_mu * beta_mu. The standard deviation sigma follows the model log(sigma) = X_sigma * beta_sigma. The package comes with two vignettes: 'Intro' gives an introduction, 'Math' gives mathematical details.
nardl,2017-07-04,nardl: Nonlinear Cointegrating Autoregressive Distributed Lag Model,Computes the nonlinear cointegrating autoregressive distributed lag model with p lags of the dependent variables and q lags of independent variables proposed by (Shin, Yu & Greenwood-Nimmo, 2014 <doi:10.1007/978-1-4899-8008-3_9>).
sensors4plumes,2017-04-03,sensors4plumes: Test and Optimise Sampling Designs Based on Plume Simulations,Test sampling designs by several flexible cost functions, usually based on the simulations, and optimise sampling designs using different optimisation algorithms; load plume simulations (on lattice or points) even if they do not fit into memory.
imagine,2016-12-01,imagine: IMAGing engINE, Tools for Application of Image Filters to Data
Matrices,Provides fast application of image filters to data matrices,
    using R and C++ algorithms.
optional,2017-07-31,optional: Optional Types and Pattern Matching,Introduces optional types with some() and none, as well as match_with() from functional languages.
FactoInvestigate,2017-04-11,FactoInvestigate: Automatic Description of Factorial Analysis,Brings a set of tools to help and automatically realise the description of principal component analyses (from 'FactoMineR' functions). Detection of existing outliers, identification of the informative components, graphical views and dimensions description are performed threw dedicated functions. The Investigate() function performs all these functions in one, and returns the result as a report document (Word, PDF or HTML).
pbdRPC,2017-01-01,pbdRPC: Programming with Big Data – Remote Procedure Call,A very light implementation yet secure for remote procedure calls
        with unified interface via ssh (OpenSSH) or plink/plink.exe (PuTTY).
rpms,2016-10-21,rpms: Recursive Partitioning for Modeling Survey Data,Fits a linear model to survey data in each node obtained by 
    recursively partitioning the data.  The splitting variables and splits
    selected are obtained using a procedure which adjusts for complex sample
    design features used to obtain the data. Likewise the model fitting
    algorithm produces design-consistent coefficients to the least squares
    linear model between the dependent and independent variables.
    The first stage of the design is accounted for in the provided variance 
    estimates. The main function returns the resulting binary tree with the 
    linear model fit at every end-node. The package provides a number of 
    functions and methods for these trees.
DAC,2017-09-08,DAC: Calculating Data Agreement Criterion Scores to Rank Experts
Based on Their Beliefs,Allows to calculate Data Agreement Criterion (DAC) scores. This can be done to determine prior-data conflict or to evaluate and compare multiple priors, which can be experts' predictions. Bousquet (2008) <doi.org/10.1080/02664760802192981>.
olsrr,2017-05-11,olsrr: Tools for Building OLS Regression Models,Tools designed to make it easier for users, particularly beginner/intermediate R users 
    to build ordinary least squares regression models. Includes comprehensive regression output, 
    heteroskedasticity tests, collinearity diagnostics, residual diagnostics, measures of influence, 
    model fit assessment and variable selection procedures.
ProjectionBasedClustering,2017-07-23,ProjectionBasedClustering: Projection Based Clustering,A clustering approach applicable to every projection method is proposed here [Thrun/Ultsch,2017] <doi:10.13140/RG.2.2.13124.53124>. The two-dimensional scatter plot of any projection method can construct a topographic map which displays unapparent data structures by using distance and density information of the data. The generalized U*-matrix renders this visualization in the form of a topographic map, which can be used to automatically define the clusters of high-dimensional data. The whole system is based on the book "Projection-Based Clustering through Self-Organization and Swarm Intelligence" <doi:10.1007/978-3-658-20540-9>. Selecting the correct projection method will result in a visualization in which mountains surround each cluster. The number of clusters can be determined by counting valleys on the topographic map. Most projection methods are wrappers for already available methods in R. By contrast, the neighbor retrieval visualizer (NeRV) is based on C++ source code of the 'dredviz' software package, and the Curvilinear Component Analysis (CCA) is translated from 'MATLAB' ('SOM Toolbox' 2.0) to R.
SurvDisc,2016-10-05,SurvDisc: Discrete Time Survival and Longitudinal Data Analysis,Various functions for discrete time survival analysis and longitudinal analysis. SIMEX method for correcting for bias for errors-in-variables
  in a mixed effects model. Asymptotic mean and variance of different proportional hazards test statistics using different ties methods given two
  survival curves and censoring distributions. Score test and Wald test for regression analysis of grouped survival data. Calculation of survival
  curves for events defined by the response variable in a mixed effects model crossing a threshold with or without confirmation.
glm.predict,2016-10-06,glm.predict: Predicted Values and Discrete Changes for GLM,Functions to calculate predicted values and the difference between
    the two cases with confidence interval for glm(), glm.nb(), polr() and multinom().
jsonld,2016-12-09,jsonld: JSON for Linking Data,JSON-LD is a light-weight syntax for expressing linked data. It is primarily
    intended for web-based programming environments, interoperable web services and for 
    storing linked data in JSON-based databases. This package provides bindings to the 
    JavaScript library for converting, expanding and compacting JSON-LD documents.
weco,2016-11-21,weco: Western Electric Company Rules (WECO) for Shewhart Control Chart,Western Electric Company Rules (WECO) have been widely used for
    Shewhart control charts in order to increase the sensitivity of detecting
    assignable causes of process change. This package implements eight commonly
    used WECO rules and allow to apply the combination of these individual rules
    for detecting the deviation from a stable process. The package also provides
    a web-based graphical user interface to help users conduct the analysis. 
AR,2017-05-18,AR: Another Look at the Acceptance-Rejection Method,In mathematics, 'rejection sampling' is a basic technique used to generate observations from a distribution. It is also commonly called 'the Acceptance-Rejection method' or 'Accept-Reject algorithm' and is a type of Monte Carlo method. 'Acceptance-Rejection method' is based on the observation that to sample a random variable one can perform a uniformly random sampling of the 2D cartesian graph, and keep the samples in the region under the graph of its density function. Package 'AR' is able to generate/simulate random data from a probability density function by Acceptance-Rejection method. Moreover, this package is a useful teaching resource for graphical presentation of Acceptance-Rejection method. From the practical point of view, the user needs to calculate a constant in Acceptance-Rejection method, which package 'AR' is able to compute this constant by optimization tools. Several numerical examples are provided to illustrate the graphical presentation for the Acceptance-Rejection Method.
mrbsizeR,2017-04-03,mrbsizeR: Scale Space Multiresolution Analysis of Random Signals,A method for the multiresolution analysis of spatial fields and images to capture scale-dependent features.
    mrbsizeR is based on scale space smoothing and uses differences of smooths at neighbouring scales for finding features on different scales.
    To infer which of the captured features are credible, Bayesian analysis is used.
    The scale space multiresolution analysis has three steps: (1) Bayesian signal reconstruction.
    (2) Using differences of smooths, scale-dependent features of the reconstructed signal can be found.
    (3) Posterior credibility analysis of the differences of smooths created.
    The method has first been proposed by Holmstrom, Pasanen, Furrer, Sain (2011) <doi:10.1016/j.csda.2011.04.011>.
PLMIX,2016-12-21,PLMIX: Bayesian Analysis of Finite Mixtures of Plackett-Luce Models for
Partial Rankings/Orderings,Fit finite mixtures of Plackett-Luce models for partial top rankings/orderings within the Bayesian framework. It provides MAP point estimates via EM algorithm and posterior MCMC simulations via Gibbs Sampling. It also fits MLE as a special case of the noninformative Bayesian analysis with vague priors. In addition to inferential techniques, the package assists other fundamental phases of a model-based analysis for partial rankings/orderings, by including functions for data manipulation, simulation, descriptive summary, model selection and goodness-of-fit evaluation.
PLmixed,2017-07-18,PLmixed: Estimate (Generalized) Linear Mixed Models with Factor
Structures,Utilizes the 'lme4' package and the optim() function from 'stats'
    to estimate (generalized) linear mixed models (GLMM) with factor
    structures using a profile likelihood approach, as outlined in
    Jeon and Rabe-Hesketh (2012) <doi:10.3102/1076998611417628>.
    Factor analysis and item response models can be extended to allow
    for an arbitrary number of nested and crossed random effects,
    making it useful for multilevel and cross-classified models.
pointblank,2017-08-22,pointblank: Validation of Local and Remote Data Tables,Validate data in data frames,
    'tibble' objects, in 'CSV' and 'TSV' files,
    and in database tables ('PostgreSQL' and 'MySQL').
    Validation pipelines can be made using
    easily-readable, consecutive validation steps
    and such pipelines allow for switching of the
    data table context. Upon execution of the
    validation plan, several reporting options are
    available. User-defined thresholds for failure
    rates allow for the determination of appropriate
    reporting actions.
RAC,2016-10-15,RAC: R Package for Aqua Culture,Solves the individual bioenergetic balance for different aquaculture sea fish (Sea Bream and Sea Bass; Brigolin et al., 2014 <doi:10.3354/aei00093>) and shellfish (Mussel and Clam; Brigolin et al., 2009 <doi:10.1016/j.ecss.2009.01.029>; Solidoro et al., 2000 <doi:10.3354/meps199137>). Allows for spatialized model runs and population simulations.
brt,2017-03-03,brt: Biological Relevance Testing,Analyses of large-scale -omics datasets commonly use p-values as the indicators of statistical significance. However, considering p-value alone neglects the importance of effect size (i.e., the mean difference between groups) in determining the biological relevance of a significant difference. Here, we present a novel algorithm for computing a new statistic, the biological relevance testing (BRT) index, in the frequentist hypothesis testing framework to address this problem. 
estprod,2017-07-24,estprod: Estimation of Production Functions,Estimation of production functions by the Olley-Pakes, Levinsohn-Petrin and Wooldridge methodologies. 
    The package aims to reproduce the results obtained with the Stata's user written opreg <http://www.stata-journal.com/article.html?article=st0145> and levpet <http://www.stata-journal.com/article.html?article=st0060> commands. 
    The first was originally proposed by Olley, G.S. and Pakes, A. (1996) <doi:10.2307/2171831>.
    The second by Levinsohn, J. and Petrin, A. (2003) <doi:10.1111/1467-937X.00246>.
	And the third by Wooldridge (2009) <doi.org/10.1016/j.econlet.2009.04.026>.
IMIFA,2017-02-05,IMIFA: Infinite Mixtures of Infinite Factor Analysers and Related
Models,Provides flexible Bayesian estimation of Infinite Mixtures of Infinite Factor Analysers and related models, for nonparametrically clustering high-dimensional data, introduced by Murphy et al. (2017) <arXiv:1701.07010v4>. The IMIFA model conducts Bayesian nonparametric model-based clustering with factor analytic covariance structures without recourse to model selection criteria to choose the number of clusters or cluster-specific latent factors, mostly via efficient Gibbs updates. Model-specific diagnostic tools are also provided, as well as many options for plotting results, conducting posterior inference on parameters of interest, and quantifying uncertainty.
Jdmbs,2017-02-15,Jdmbs: Monte Carlo Option Pricing Algorithms for Jump Diffusion Models
with Correlational Companies,Black-Scholes model [Black (1973) <doi:10.1086/260062>] is important to calculate option prices in the stock market and a variety of improved models are studied. In this package, I propose methods in order to calculate both Black-Scholes model and Jump diffusion model [Kou (2002) <doi:10.1287/mnsc.48.8.1086.166>] by Monte Carlo methods. This package can be used for computational finance.
nprobust,2016-11-07,nprobust: Nonparametric Robust Estimation and Inference Methods using
Local Polynomial Regression and Kernel Density Estimation,Tools for data-driven statistical analysis using local polynomial regression and kernel density estimation methods as described in Calonico, Cattaneo and Farrell (2018): lprobust() for local polynomial point estimation and robust bias-corrected inference and kdrobust() for kernel density point estimation and robust bias-corrected inference. Several optimal bandwidth selection procedures are computed by lpbwselect() and kdbwselect() for local polynomial and kernel density estimation, respectively. Finally, nprobust.plot() for density and regression plots with robust confidence interval.   
sbart,2017-03-23,sbart: Sequential BART for Imputation of Missing Covariates,Implements the sequential BART (Bayesian Additive
     Regression Trees) approach to impute the missing covariates. The
     algorithm applies a Bayesian nonparametric approach on factored
     sets of sequential conditionals of the joint distribution of the
     covariates and the missingness and applying the Bayesian additive
     regression trees to model each of these univariate
     conditionals. Each conditional distribution is then sampled using
     MCMC algorithm. The published journal can be found at
     <https://doi.org/10.1093/biostatistics/kxw009> Package provides a
     function, seqBART(), which computes and returns the imputed
     values.
BBMV,2017-05-02,BBMV: Models for Continuous Traits Evolving in Macroevolutionary
Landscapes of any Shape,Provides a set of functions to fit general macroevolutionary models for continuous traits evolving in adaptive landscapes of any shape. This package implements the Fokker-Planck-Kolmogorov model (FPK), in which the trait evolves under random diffusion but is also subject to a force that pulls it towards specific values - this force can be of any shape. FPK has a version in which hard reflective bounds exist at the extremes of the trait interval: this second model is called BBMV. 
convexjlr,2017-06-20,convexjlr: Disciplined Convex Programming in R using 'Convex.jl',Provides a simple high-level wrapper for
    'Julia' package 'Convex.jl' (see <https://github.com/JuliaOpt/Convex.jl> for
    more information),
    which makes it easy to describe and solve convex optimization problems in R.
    The problems can be dealt with include:
    linear programs,
    second-order cone programs,
    semidefinite programs,
    exponential cone programs.
predtoolsTS,2017-09-19,predtoolsTS: Time Series Prediction Tools,Makes the time series prediction easier by automatizing this process
  using four main functions: prep(), modl(), pred() and postp(). Features different
  preprocessing methods to homogenize variance and to remove trend and seasonality.
  Also has the potential to bring together different predictive models to make comparatives.
  Features ARIMA and Data Mining Regression models (using caret).
sqlscore,2016-12-11,sqlscore: Utilities for Generating SQL Queries from Model Objects,Provides utilities for generating SQL queries (particularly CREATE
    TABLE statements) from R model objects. The most important use case is
    generating SQL to score a generalized linear model or related model
    represented as an R object, in which case the package handles parsing
    formula operators and including the model's response function.
mathpix,2017-09-27,mathpix: Support for the 'Mathpix' API (Image to 'LaTeX'),Given an image of a formula (typeset or handwritten) this package
    provides calls to the 'Mathpix' service to produce the 'LaTeX' code which should
    generate that image, and pastes it into a (e.g. an 'rmarkdown') document. 
    See <https://docs.mathpix.com/> for full details. 'Mathpix' is an external service 
    and use of the API is subject to their terms and conditions.
mrgsolve,2017-03-11,mrgsolve: Simulate from ODE-Based Population PK/PD and Systems
Pharmacology Models,Facilitates simulation from hierarchical, ordinary
    differential equation (ODE) based models typically employed in drug development.
    A model specification file is created consisting of R and C++ code that
    is parsed, compiled, and dynamically loaded into the R session. Input data are
    passed in and simulated data are returned as R objects.  A dosing event engine
    allows interventions (bolus and infusion) to be managed separately from the 
    model code. Differential equations are solved with the 'DLSODA' routine 
    in 'ODEPACK' (<https://computation.llnl.gov/casc/odepack/>). 
vdiffr,2016-11-08,vdiffr: Visual Regression Testing and Graphical Diffing,An extension to the 'testthat' package that makes it easy
    to add graphical unit tests. It provides a Shiny application to
    manage the test cases.
FHDI,2017-05-18,FHDI: Fractional Hot Deck and Fully Efficient Fractional Imputation,Impute general multivariate missing data with the fractional hot deck imputation based on Jaekwang Kim (2011) <doi:10.1093/biomet/asq073>.
SpatialFloor,2017-08-30,SpatialFloor: Spatial Floor Simulation (Isotropic),Spatial floor simulation with exponential/Gaussian variance-covariance function (isotropic), with specification of distance function, nugget, sill, range. The methodology follows Nole A.C. Cressie (2015) <doi:10.1002/9781119115151>. The original release is 2017-08-29.
edpclient,2017-05-28,edpclient: Empirical Data Platform Client,R client for Empirical Data Platform. More information is at <https://empirical.com>. For support, contact support@empirical.com.
enviGCMS,2016-11-30,enviGCMS: GC/LC-MS Data Analysis for Environmental Science,Gas/Liquid Chromatography-Mass Spectrometer(GC/LC-MS) Data Analysis for Environmental Science. This package covered topics such as raw data process, molecular isotope ratio, matrix effects and Short-Chain Chlorinated Paraffins analysis etc. in environmental analysis.
lavaanPlot,2017-06-10,lavaanPlot: Path Diagrams for Lavaan Models via DiagrammeR,Plots path diagrams from models in lavaan using the plotting
    functionality from the DiagrammeR package. DiagrammeR provides nice path diagrams 
    via Graphviz, and these functions make it easy to generate these diagrams from a
    lavaan path model without having to write the DOT language graph specification.
MiRKAT,2017-07-25,MiRKAT: Microbiome Regression-Based Kernel Association Test,Test for overall association between microbiome composition data with a continuous or dichotomous outcome via phylogenetic kernels. The phenotype can be univariate continuous or binary phenotypes (Zhao et al. (2015) <doi:10.1016/j.ajhg.2015.04.003>), survival outcomes (Plantinga et al. (2017) <doi:10.1186/s40168-017-0239-9>), multivariate (Zhan et al. (2017) <doi:10.1002/gepi.22030>) and structured phenotypes (Zhan et al. (2017) <doi:10.1111/biom.12684>). For all these effect, the microbiome community effect was modeled nonparametrically through a kernel function, which can incorporate the phylogenetic tree information.
MittagLeffleR,2017-06-15,MittagLeffleR: Mittag-Leffler Family of Distributions,Implements the Mittag-Leffler function, distribution,
  random variate generation, and estimation. Based on the Laplace-Inversion
  algorithm by Garrappa, R. (2015) <doi:10.1137/140971191>.
nowcasting,2017-08-18,nowcasting: Predicting Economic Variables using Dynamic Factor Models,It contains the tools to implement dynamic factor models to forecast economic variables. The user will be able to construct pseudo real time vintages, use information criteria for determining the number of factors and shocks, estimate the model, and visualize results among other things.
survivALL,2017-08-11,survivALL: Continuous Biomarker Assessment by Exhaustive Survival Analysis,In routine practice, biomarker performance is calculated by 
    splitting a patient cohort at some arbitrary level, often by median gene 
    expression. The logic behind this is to divide patients into “high” or “low”
    expression groups that in turn correlate with either good or poor prognosis.
    However, this median-split approach assumes that the data set composition 
    adheres to a strict 1:1 proportion of high vs. low expression, that for 
    every one “low” there is an equivalent “high”. In reality, data sets are 
    often heterogeneous in their composition (Perou, CM et al., 2000 
    <doi:10.1038/35021093>)- i.e. this 1:1 relationship is unlikely to exist and
    the true relationship unknown. Given this limitation, it remains difficult 
    to determine where the most significant separation should be made. For 
    example, estrogen receptor (ER) status determined by immunohistochemistry is
    standard practice in predicting hormone therapy response, where ER is found 
    in an ~1:3 ratio (-:+) in the population (Selli, C et al., 2016 
    <doi:10.1186/s13058-016-0779-0>). We would expect therefore, upon dividing 
    patients by ER expression, 25% to be classified “low” and 75% “high”, and 
    an otherwise 50-50 split to incorrectly classify 25% of our patient cohort,
    rendering our survival estimate under powered. 'survivALL' is a data-driven 
    approach to calculate the relative survival estimates for all possible 
    points of separation - i.e. at all possible ratios of “high” vs. “low” - 
    allowing a measure’s relationship with survival to be more reliably 
    determined and quantified. We see this as a solution to a flaw in common 
    research practice, namely the failure of a true biomarker as part of a 
    meta-analysis.
worms,2017-06-18,worms: Retriving Aphia Information from World Register of Marine
Species,Retrieves taxonomic information from  <http://www.marinespecies.org> using WoRMS' RESTful Webservice. Utility functions aim at taxonomic consistency.
EpiCurve,2017-03-14,EpiCurve: Plot an Epidemic Curve,Creates simple or stacked epidemic curves for hourly, daily, weekly or monthly outcome data.
MARX,2017-06-16,MARX: Simulation, Estimation, Model Selection and Forecasting for MARX
Models,Simulate, estimate (by t-MLE), select and forecast mixed causal-noncausal autoregressive models with possibly exogenous regressors, using methods proposed in Lanne and Saikkonen (2011) <doi:10.2202/1941-1928.1080> and Hecq et al. (2016) <doi:10.15609/annaeconstat2009.123-124.0307>.
VarReg,2017-03-21,VarReg: Semi-Parametric Variance Regression,Methods for fitting semi-parametric mean and variance models, with normal or censored data. Also extended to allow a regression in the location, scale and shape parameters.
APML0,2017-07-17,APML0: Augmented and Penalized Minimization Method L0,Fit linear, logistic and Cox models regularized with L0, lasso (L1), elastic-net (L1 and L2), or net (L1 and Laplacian) penalty, and their adaptive forms, such as adaptive lasso / elastic-net and net adjusting for signs of linked coefficients. It solves L0 penalty problem by simultaneously selecting regularization parameters and the number of non-zero coefficients. This augmented and penalized minimization method provides an approximation solution to the L0 penalty problem, but runs as fast as L1 regularization problem. The package uses one-step coordinate descent algorithm and runs extremely fast by taking into account the sparsity structure of coefficients. It could deal with very high dimensional data and has superior selection performance. 
komadown,2017-08-21,komadown: R Markdown Templates for the 'KOMA-Script' Classes,R Markdown templates based on the 'KOMA-Script' classes for
  LaTeX, additionally offering cross-referencing via the 'bookdown' package.
leaflet.esri,2017-06-25,leaflet.esri: 'ESRI' Bindings for the 'leaflet' Package,An add-on package to the 'leaflet' package, which provides bindings for 'ESRI' services. This package allows a user to add 'ESRI' provided services such as 'MapService', 'ImageMapService', 'TiledMapService' etc. to a 'leaflet' map.
rpql,2016-10-07,rpql: Regularized PQL for Joint Selection in GLMMs,Performs joint selection in Generalized Linear Mixed Models (GLMMs) using penalized likelihood methods. Specifically, the Penalized Quasi-Likelihood (PQL) is used as a loss function, and penalties are then "added on" to perform simultaneous fixed and random effects selection. Regularized PQL avoids the need for integration (or approximations such as the Laplace's method) during the estimation process, and so the full solution path for model selection can be constructed relatively quickly. 
leaflet.extras,2017-06-25,leaflet.extras: Extra Functionality for 'leaflet' Package,The 'leaflet' JavaScript library provides many plugins some of which
    are available in the core 'leaflet' package, but there are many more. It is not
    possible to support them all in the core 'leaflet' package. This package serves
    as an add-on to the 'leaflet' package by providing extra functionality via 'leaflet'
    plugins.
s2,2016-11-04,s2: Google's S2 Library for Geometry on the Sphere,R bindings for Google's s2 library for geometric calculations on
    the sphere.
interflex,2017-02-27,interflex: Multiplicative Interaction Models Diagnostics and Visualization,Performs diagnostic tests of multiplicative interaction models and plots non-linear marginal effects of a treatment on an outcome across different values of a moderator.
utilsIPEA,2017-09-15,utilsIPEA: IPEA Common Functions,The most used functions on IPEA (Instituto de Pesquisa Economica Aplicada). 
             Most of functions deal with brazilian names. 
             It can guess the women single's name, extract prepositions or extract the first name.
wiqid,2016-10-05,wiqid: Quick and Dirty Estimates for Wildlife Populations,Provides simple, fast functions for maximum likelihood and Bayesian estimates of wildlife population parameters, suitable for use with simulated data or bootstraps. Early versions were indeed quick and dirty, but optional error-checking routines and meaningful error messages have been added. Includes single and multi-season occupancy, closed capture population estimation, survival, species richness and distance measures.
ClusVis,2017-07-13,ClusVis: Gaussian-Based Visualization of Gaussian and Non-Gaussian
Model-Based Clustering,Gaussian-Based Visualization of Gaussian and Non-Gaussian Model-Based Clustering done on any type of data. Visualization is based on the probabilities of classification.
denseFLMM,2017-03-17,denseFLMM: Functional Linear Mixed Models for Densely Sampled Data,Estimation of functional linear mixed models for densely sampled data based on functional principal component analysis.
mschart,2017-09-08,mschart: Chart Generation for 'Microsoft Word' and 'Microsoft PowerPoint'
Documents,Create native charts for 'Microsoft PowerPoint' and 'Microsoft Word' documents. 
 These can then be edited and annotated. Functions are provided to let users create charts, modify 
 and format their content. The chart's underlying data is automatically saved within the 
 'Word' document or 'PowerPoint' presentation. It extends package 'officer' that does 
 not contain any feature for 'Microsoft' native charts production. 
esmprep,2017-08-30,esmprep: Data Preparation During and After the Use of the Experience
Sampling Methodology (ESM),Support in preparing a raw ESM dataset for statistical analysis. Preparation includes the handling of errors (mostly due to technological reasons) and the generating of new variables that are necessary and/or helpful in meeting the conditions when statistically analyzing ESM data. The functions in 'esmprep' are meant to hierarchically lead from bottom, i.e. the raw (separated) ESM dataset(s), to top, i.e. a single ESM dataset ready for statistical analysis. This hierarchy evolved out of my personal experience in working with ESM data.
HiCblock,2017-06-08,HiCblock: Systematic Analysis of Architectural Proteins and Functional
Elements in Blocking Long-Range Contacts Between Loci,Here we propose a model to systematically analyze the roles of architectural proteins and functional elements in blocking long-range contacts between loci. The proposed model does not rely on topologically associating domain (TAD) mapping from Hi-C data. Instead of testing the enrichment or influence of protein binding at TAD borders, the model directly estimates the blocking effect of proteins on long-range contacts between flanking loci, making the model intuitive and biologically meaningful.
HiCglmi,2016-10-17,HiCglmi: Probing Factor-Dependent Long-Range Contacts using Regression
with Higher-Order Interaction Terms,We propose a generalized linear regression with higher-order interaction terms to assess the influences of genomic features such as DNA-binding proteins and functional elements on long-range contacts from Hi-C experiments. 
stampr,2017-01-12,stampr: Spatial Temporal Analysis of Moving Polygons,Perform spatial temporal analysis of moving polygons; a
    longstanding analysis problem in Geographic Information Systems. Facilitates
    directional analysis, shape analysis, and some other simple functionality for
    examining spatial-temporal patterns of moving polygons.
bioOED,2017-03-13,bioOED: Sensitivity Analysis and Optimum Experiment Design for Microbial
Inactivation,Extends the bioinactivation package with functions for Sensitivity
    Analysis and Optimum Experiment Design.
genderBR,2017-09-05,genderBR: Predict Gender from Brazilian First Names,A method to predict and report gender from Brazilian first names
    using the Brazilian Institute of Geography and Statistics' Census data.
uncmbb,2017-05-18,uncmbb: UNC Men's Basketball Match Results Since 1949-1950 Season,Dataset contains select attributes for each match result since 1949-1950 season for UNC men's basketball team.
brglm2,2017-04-04,brglm2: Bias Reduction in Generalized Linear Models,Estimation and inference from generalized linear models based on various methods for bias reduction. The 'brglmFit' fitting method can achieve reduction of estimation bias by solving either the mean bias-reducing adjusted score equations in Firth (1993) <doi:10.1093/biomet/80.1.27> and Kosmidis and Firth (2009) <doi:10.1093/biomet/asp055>, or the median bias-reduction adjusted score equations in Kenne et al. (2016) <arXiv:1604.04768>, or through the direct subtraction of an estimate of the bias of the maximum likelihood estimator from the maximum likelihood estimates as in Cordeiro and McCullagh (1991) <http://www.jstor.org/stable/2345592>. Estimation in all cases takes place via a quasi Fisher scoring algorithm, and S3 methods for the construction of of confidence intervals for the reduced-bias estimates are provided. In the special case of generalized linear models for binomial and multinomial responses, the adjusted score approaches return estimates with improved frequentist properties, that are also always finite, even in cases where the maximum likelihood estimates are infinite (e.g. complete and quasi-complete separation). 'brglm2' also provides pre-fit and post-fit methods for detecting separation and infinite maximum likelihood estimates in binomial response generalized linear models.
classiFunc,2017-05-29,classiFunc: Classification of Functional Data,Efficient implementation of k-nearest neighbor estimation and kernel estimation for functional data classification.
corehunter,2016-10-04,corehunter: Multi-Purpose Core Subset Selection,Core Hunter is a tool to sample diverse, representative subsets from large germplasm
    collections, with minimum redundancy. Such so-called core collections have applications in plant
    breeding and genetic resource management in general. Core Hunter can construct cores based on
    genetic marker data, phenotypic traits or precomputed distance matrices, optimizing one of many
    provided evaluation measures depending on the precise purpose of the core (e.g. high diversity,
    representativeness, or allelic richness). In addition, multiple measures can be simultaneously
    optimized as part of a weighted index to bring the different perspectives closer together.
    The Core Hunter library is implemented in Java 8 as an open source project (see
    <http://www.corehunter.org>).
meltt,2017-05-18,meltt: Matching Event Data by Location, Time and Type,Framework for merging and disambiguating event data based on spatiotemporal co-occurrence and secondary event characteristics. It can account for intrinsic "fuzziness" in the coding of events, varying event taxonomies and different geo-precision codes.
sglg,2017-09-22,sglg: Fitting Semi-Parametric Generalized log-Gamma Regression Models,Set of tools to fit a linear multiple or semi-parametric regression
    models and non-informative right-censoring may be considered. Under this setup, the localization parameter of the response variable distribution is modeled by using linear multiple regression
    or semi-parametric functions, whose non-parametric components may be approximated
    by natural cubic spline or P-splines. The supported distribution for the model error is a generalized log-gamma distribution which includes
    the generalized extreme value distribution as an important special case.  
foghorn,2017-02-08,foghorn: Summarize CRAN Check Results in the Terminal,The CRAN check results in your R terminal.
yesno,2017-02-15,yesno: Ask Yes-No Questions,Asks Yes-No questions with variable or custom responses.
fpp2,2017-02-23,fpp2: Data for "Forecasting: Principles and Practice" (2nd Edition),All data sets required for the examples and exercises 
  in the book "Forecasting: principles and practice" 
  by Rob J Hyndman and George Athanasopoulos <https://OTexts.org/fpp2/>. 
  All packages required to run the examples are also loaded.
gldrm,2017-06-28,gldrm: Generalized Linear Density Ratio Models,Fits a generalized linear density ratio model (GLDRM).
    A GLDRM is a semiparametric generalized linear model.
    In contrast to a GLM, which assumes a particular exponential family distribution, 
    the GLDRM uses a semiparametric likelihood to estimate the reference distribution. 
    The reference distribution may be any discrete, continuous, or mixed exponential 
    family distribution. The model parameters, which include both the regression 
    coefficients and the cdf of the unspecified reference distribution, are estimated 
    by maximizing a semiparametric likelihood. Regression coefficients are estimated 
    with no loss of efficiency, i.e. the asymptotic variance is the same as if the 
    true exponential family distribution were known.
    Huang (2014) <doi:10.1080/01621459.2013.824892>.
    Huang and Rathouz (2012) <doi:10.1093/biomet/asr075>.
    Rathouz and Gao (2008) <doi:10.1093/biostatistics/kxn030>.
MultiVarSel,2017-04-04,MultiVarSel: Variable Selection in a Multivariate Linear Model,It performs variable selection in a multivariate linear model by estimating the covariance matrix 
 of the residuals then use it to remove the dependence that may exist among the responses and eventually performs variable selection by using the Lasso criterion.
 The method is described in the paper Perrot-Dockès et al. (2017) <arXiv:1704.00076>.
survtmle,2017-07-14,survtmle: Compute Targeted Minimum Loss-Based Estimates in Right-Censored
Survival Settings,Targeted estimates of marginal cumulative incidence in survival
    settings with and without competing risks, including estimators that respect
    bounds (Benkeser, Carone, and Gilbert. Statistics in Medicine, 2017.
    <doi:10.1002/sim.7337>).
tsensembler,2017-08-28,tsensembler: Dynamic Ensembles for Time Series Forecasting,A framework for dynamically combining forecasting models for time series forecasting predictive tasks. It leverages machine learning models from other packages to automatically combine expert advice using metalearning and other state-of-the-art forecasting combination approaches. The predictive methods receive a data matrix as input, representing an embedded time series, and return a predictive ensemble model. The ensemble use generic functions 'predict()' and 'forecast()' to forecast future values of the time series. Moreover, an ensemble can be updated using methods, such as 'update_weights()' or 'update_base_models()'. A complete description of the methods can be found in: Cerqueira, V., Torgo, L., Pinto, F., and Soares, C. "Arbitrated Ensemble for Time Series Forecasting." to appear at: Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer International Publishing, 2017; and Cerqueira, V., Torgo, L., and Soares, C.: "Arbitrated Ensemble for Solar Radiation Forecasting." International Work-Conference on Artificial Neural Networks. Springer, 2017 <doi:10.1007/978-3-319-59153-7_62>.
bioimagetools,2016-10-14,bioimagetools: Tools for Microscopy Imaging,Tools for 3D imaging, mostly for biology/microscopy. 
    Read and write TIFF stacks. Functions for segmentation, filtering and analysing 3D point patterns.
di,2017-06-12,di: Deficit Index (DI),A set of utilities for calculating the Deficit (frailty) Index (DI) in gerontological studies. 
             The deficit index was first proposed by Arnold Mitnitski and Kenneth Rockwood 
             and represents a proxy measure of aging and also can be served as
             a sensitive predictor of survival. For more information, see 
             (i)"Accumulation of Deficits as a Proxy Measure of Aging" 
             by Arnold B. Mitnitski et al. (2001), 
             The Scientific World Journal 1, <doi:10.1100/tsw.2001.58>;
             (ii) "Frailty, fitness and late-life mortality in relation to chronological and biological age" 
             by Arnold B Mitnitski et al. (2001), 
             BMC Geriatrics2002 2(1), <doi:10.1186/1471-2318-2-1>.
snpReady,2017-08-02,snpReady: Preparing Genotypic Datasets in Order to Run Genomic Analysis,Three functions to clean, summarize and prepare genomic datasets to Genome
    Selection and Genome Association analysis and to estimate population genetic parameters.
nmw,2017-03-14,nmw: Understanding Nonlinear Mixed Effects Modeling for Population
Pharmacokinetics,This shows how NONMEM(R) <http://www.iconplc.com/innovation/nonmem/> software works. NONMEM's classical estimation methods like 'First Order(FO) approximation', 'First Order Conditional Estimation(FOCE)', and 'Laplacian approximation' are explained.
swmmr,2017-07-13,swmmr: R Interface for US EPA's SWMM,Functions to connect the widely used Storm Water Management Model (SWMM)
  of the United States Environmental Protection Agency (US EPA) 
  <https://www.epa.gov/water-research/storm-water-management-model-swmm> to R with
  currently two main goals: (1) Run a SWMM simulation from R and (2) provide fast 
  access to simulation results, i.e. SWMM's binary '.out'-files. High performance is achieved
  with help of Rcpp. Additionally, reading SWMM's '.inp' and '.rpt' files is supported to 
  glance model structures and to get direct access to simulation summaries.
AnnotationBustR,2017-03-02,AnnotationBustR: Extract Subsequences from GenBank Annotations,Extraction of subsequences into FASTA files from GenBank annotations where gene names may vary among accessions.
esvis,2017-08-13,esvis: Visualization and Estimation of Effect Sizes,A variety of methods are provided to estimate and visualize
    distributional differences in terms of effect sizes. Particular emphasis
    is upon evaluating differences between two or more distributions across
    the entire scale, rather than at a single point (e.g., differences in
    means). For example, Probability-Probability (PP) plots display the
    difference between two or more distributions, matched by their empirical
    CDFs (see Ho and Reardon, 2012; <doi:10.3102/1076998611411918>), allowing
    for examinations of where on the scale distributional differences are
    largest or smallest. The area under the PP curve (AUC) is an effect-size
    metric, corresponding to the probability that a randomly selected
    observation from the x-axis distribution will have a higher value
    than a randomly selected observation from the y-axis distribution. 
    Binned effect size plots are also available, in which the distributions
    are split into bins (set by the user) and separate effect sizes (Cohen's
    d) are produced for each bin - again providing a means to evaluate the
    consistency (or lack thereof) of the difference between two or more 
    distributions at different points on the scale. Evaluation of empirical 
    CDFs is also provided, with  built-in arguments for providing annotations 
    to help evaluate distributional differences at specific points (e.g., 
    semi-transparent shading). All function take a consistent argument 
    structure. Calculation of specific effect sizes is also possible. The
    following effect sizes are estimable: (a) Cohen's d, (b) Hedges' g, 
    (c) percentage above a cut, (d) transformed (normalized) percentage above 
    a cut, (e)  area under the PP curve, and (f) the V statistic (see Ho, 
    2009; <doi:10.3102/1076998609332755>), which essentially transforms the 
    area under the curve to standard deviation units. By default, effect sizes 
    are calculated for all possible pairwise comparisons, but a reference 
    group (distribution) can be specified.
SentimentAnalysis,2017-06-02,SentimentAnalysis: Dictionary-Based Sentiment Analysis,Performs a sentiment analysis of textual contents in R. This implementation
    utilizes various existing dictionaries, such as Harvard IV, or finance-specific 
    dictionaries. Furthermore, it can also create customized dictionaries. The latter 
    uses LASSO regularization as a statistical approach to select relevant terms based on 
    an exogenous response variable. 
spc4sts,2017-07-08,spc4sts: Statistical Process Control for Stochastic Textured Surfaces,Provides statistical process control tools for stochastic 
    textured surfaces. The current version supports the following tools: 
    (1) monitors and diagnoses for local defects on stochastic 
        textured surfaces, which was proposed by Bui and Apley (2018a) 
        <doi:10.1080/00401706.2017.1302362>.
    (2) monitors for global changes in the nature of stochastic 
        textured surfaces.
textstem,2017-02-27,textstem: Tools for Stemming and Lemmatizing Text,Tools that stem and lemmatize text.  Stemming is a process that removes
         endings such as affixes.  Lemmatization is the process of grouping inflected
         forms together as a single base form.
ggconf,2017-08-29,ggconf: Simpler Appearance Modification of 'ggplot2',A flexible interface for ggplot2::theme(), potentially saving 50% of your typing.
liureg,2017-03-08,liureg: Liu Regression with Liu Biasing Parameters and Statistics,Linear Liu regression coefficient's estimation and testing with different Liu related measures such as MSE, R-squared etc.
  REFERENCES
  i.   Akdeniz and Kaciranlar (1995) <doi:10.1080/03610929508831585>
  ii.  Druilhet and Mom (2008) <doi:10.1016/j.jmva.2006.06.011>
  iii. Imdadullah, Aslam, and Saima (2017)
  iv.  Liu (1993) <doi:10.1080/03610929308831027>
  v.   Liu (2001) <doi:10.1016/j.jspi.2010.05.030>.
ReinforcementLearning,2017-04-18,ReinforcementLearning: Model-Free Reinforcement Learning,Performs model-free reinforcement learning in R. This implementation enables the learning
    of an optimal policy based on sample sequences consisting of states, actions and rewards. In 
    addition, it supplies multiple predefined reinforcement learning algorithms, such as experience 
    replay.
tint,2016-10-07,tint: 'tint' is not 'Tufte',A 'tufte'-alike style for 'rmarkdown'.
alfred,2017-06-06,alfred: Downloading Time Series from ALFRED Database for Various
Vintages,Provides direct access to the ALFRED (<https://alfred.stlouisfed.org>) and FRED (<https://fred.stlouisfed.org>) databases.
    Its functions return tidy data frames for different releases of the specified time series. 
    Note that this product uses the FRED© API but is not endorsed or certified by the Federal Reserve Bank of St. Louis.
eply,2017-01-27,eply: Apply a Function Over Expressions,Evaluate a function over a data frame of expressions.
RWildbook,2016-12-01,RWildbook: Interface for the 'Wildbook' Wildlife Data Management Framework,Provides an interface with the 'Wildbook' mark-recapture ecological database framework. It 
    helps users to pull data from the 'Wildbook' framework and format data for further analysis
    with mark-recapture applications like 'Program MARK' (which can be accessed via the 'RMark' package in 'R').
    Further information on the 'Wildbook' framework is available at: <http://www.wildbook.org/doku.php>. 
bsplus,2017-01-26,bsplus: Adds Functionality to the R Markdown + Shiny Bootstrap Framework,The Bootstrap framework lets you add some JavaScript functionality to your web site by
  adding attributes to your HTML tags - Bootstrap takes care of the JavaScript
  <https://getbootstrap.com/javascript>. If you are using R Markdown or Shiny, you can
  use these functions to create collapsible sections, accordion panels, modals, tooltips,
  popovers, and an accordion sidebar framework (not described at Bootstrap site).
kernplus,2017-06-08,kernplus: A Kernel Regression-Based Multidimensional Wind Turbine Power
Curve,Provides wind energy practitioners with an effective machine learning-based
    tool that estimates a multivariate power curve and predicts the wind power output
    for a specific environmental condition.
bigKRLS,2017-04-15,bigKRLS: Optimized Kernel Regularized Least Squares,Functions for Kernel-Regularized Least Squares optimized for speed and memory usage are provided along with visualization tools. For working papers, sample code, and recent presentations visit <https://sites.google.com/site/petemohanty/software/>. bigKRLS, as well its dependencies, require current versions of R and its compilers (and RStudio if used). For details, see <https://github.com/rdrr1990/bigKRLS/blob/master/INSTALL.md>.
data.world,2017-06-23,data.world: Functions and Add-Ins for Working with 'data.world' Data Sets
and Projects,High-level tools for working with 'data.world' data sets. 'data.world' is a platform 
    where you can find interesting data, store and showcase your own data and data projects, 
    and find and collaborate with other members. In addition to exploring, querying and 
    charting data on the data.world site, you can access data via 'API' endpoints and 
    integrations. Use this package to access, query and explore data sets, and to 
    publish your insights. Visit <https://data.world>, for additional information.
factorMerger,2017-06-25,factorMerger: The Merging Path Plot,
    The Merging Path Plot is a methodology for adaptive fusing of k-groups 
    with likelihood-based model selection. This package contains tools for 
    exploration and visualization of k-group dissimilarities. 
    Comparison of k-groups is one of the most important issues
    in exploratory analyses and it has zillions of applications. 
    The traditional approach is to use pairwise post hoc tests
    in order to verify which groups differ significantly. However, 
    this approach fails with a large number of groups in both interpretation 
    and visualization layer.
    The Merging Path Plot solves this problem by using an easy-to-understand 
    description of dissimilarity among groups based on Likelihood Ratio Test (LRT) statistic.
    Work on this package was financially
    supported by the 'NCN Opus grant 2016/21/B/ST6/02176'.
fbar,2016-12-20,fbar: An Extensible Approach to Flux Balance Analysis,A simple package for Flux Balance Analysis and related
    metabolic modeling techniques. Functions are provided for: parsing
    models in tabular format, converting parsed metabolic models to input
    formats for common linear programming solvers, and
    evaluating and applying gene-protein-reaction mappings. In addition, there
    are wrappers to parse a model, select a solver, find the metabolic fluxes,
    and return the results applied to the original model. Compared to other
    packages in this field, this package puts a much heavier focus on
    providing reusable components that can be used in the design of new
    implementation of new techniques, in particular those that involve large
    parameter sweeps.
ForestTools,2017-01-21,ForestTools: Analyzing Remotely Sensed Forest Data,Provides tools for analyzing remotely sensed forest data, including functions for detecting treetops from canopy models, outlining tree crowns and generating spatial statistics.
APfun,2017-01-15,APfun: Geo-Processing Helper Functions,Helper tools for facilitating basic geo-processing tasks, such as reading/writing
  Shapefiles, merging polygons or generating terrain contours.
epidata,2017-01-08,epidata: Tools to Retrieve Economic Policy Institute Data Library
Extracts,The Economic Policy Institute (<http://www.epi.org/>) provides
    researchers, media, and the public with easily accessible, up-to-date, and
    comprehensive historical data on the American labor force. It is compiled
    from Economic Policy Institute analysis of government data sources. Use
    it to research wages, inequality, and other economic indicators over time
    and among demographic groups. Data is usually updated monthly.
toxplot,2017-09-20,toxplot: Batch Processing, Modeling and Visualizing the Dose-Response of
High-Throughput Screening Bioassay,A convenient interface to batch process high-throughput toxicology bioassay screening data. It's designed specifically for screening experiment that features a primary inhibition-type assay and a companion cytotoxicity assay. This package provides functions for data normalization, quality-control analysis, dose-response curve fitting (using the Hill model provided in the 'tcpl' package), visualization, and a unique toxicity-adjusted potency ranking system.  
UncertainInterval,2017-01-19,UncertainInterval: Uncertain Interval Methods for Cut-Point Determination in Tests,Functions for the determination of an uncertain interval, i.e., a
    range of test scores that are inconclusive and do not allow a diagnosis, other
    than 'Uncertain' (Reference: J.A. Landsheer (2016) <doi:10.1371/journal.pone.0166007>).
sparseFLMM,2017-01-14,sparseFLMM: Functional Linear Mixed Models for Irregularly or Sparsely
Sampled Data,Estimation of functional linear mixed models for irregularly or
    sparsely sampled data based on functional principal component analysis.
cvequality,2016-12-27,cvequality: Tests for the Equality of Coefficients of Variation from
Multiple Groups,Contains functions for testing for significant differences between multiple coefficients of variation. Includes Feltz and Miller's (1996) <doi:10.1002/(SICI)1097-0258(19960330)15:6%3C647::AID-SIM184%3E3.0.CO;2-P> asymptotic test and Krishnamoorthy and Lee's (2014) <doi:10.1007/s00180-013-0445-2> modified signed-likelihood ratio test. See the vignette for more, including full details of citations.
errorlocate,2016-12-30,errorlocate: Locate Errors with Validation Rules,Errors in data can be located and removed using validation rules from package 'validate'.
mstR,2017-03-30,mstR: Procedures to Generate Patterns under Multistage Testing,Generation of response patterns under dichotomous and polytomous computerized multistage testing (MST) framework. It holds various item response theory (IRT) and score-based methods to select the next module and estimate ability levels (Magis, Yan and von Davier (2017, ISBN:978-3-319-69218-0)). 
normalr,2016-12-20,normalr: Normalisation of Multiple Variables in Large-Scale Datasets,The robustness of many of the statistical techniques, such as factor analysis, applied in 
          the social sciences rests upon the assumption of item-level normality. However, when dealing 
          with real data, these assumptions are often not met. The Box-Cox transformation (Box & Cox, 1964)
          <http://www.jstor.org/stable/2984418> provides an optimal transformation for non-normal variables. Yet, for 
          large datasets of continuous variables, its application in current software programs is cumbersome
          with analysts having to take several steps to normalise each variable. We present an R package 
          'normalr' that enables researchers to make convenient optimal transformations of multiple variables
          in datasets. This R package enables users to quickly and accurately: (1) anchor all of their 
          variables at 1.00, (2) select the desired precision with which the optimal lambda is estimated, 
          (3) apply each unique exponent to its variable, (4) rescale resultant values to within their 
          original X1 and X(n) ranges, and (5) provide original and transformed estimates of skewness, 
          kurtosis, and other inferential assessments of normality.
bindrcpp,2016-12-11,bindrcpp: An 'Rcpp' Interface to Active Bindings,Provides an easy way to fill an environment with active bindings
    that call a C++ function.
geofacet,2017-06-20,geofacet: 'ggplot2' Faceting Utilities for Geographical Data,Provides geofaceting functionality for 'ggplot2'. Geofaceting arranges a sequence of plots of data for different geographical entities into a grid that preserves some of the geographical orientation.
phantom,2017-04-13,phantom: Gene Set Pareto Heterogeneity Analysis of Time-Course Gene
Expression Data,Pareto front based statistical tool for detecting heterogeneity in gene sets and biological modules from time-course data. Details about this method are described in Gu, J., et al. (2017) <doi:10.1093/bioinformatics/btx348>: Phantom: investigating heterogeneous gene sets in time-course data.
SeqKat,2017-06-25,SeqKat: Detection of Kataegis,Kataegis is a localized hypermutation occurring when a region is enriched in somatic SNVs. Kataegis can result from multiple cytosine deaminations catalyzed by the AID/APOBEC family of proteins. This package contains functions to detect kataegis from SNVs in BED format. This package reports two scores per kataegic event, a hypermutation score and an APOBEC mediated kataegic score. Yousif, F. et al.; The Origins and Consequences of Localized and Global Somatic Hypermutation; Biorxiv 2018 <doi:10.1101/287839>.
encode,2017-02-18,encode: Represent Ordered Lists and Pairs as Strings,Interconverts between ordered lists and compact string notation.  
 Useful for capturing code lists, and pair-wise codes and decodes, for text storage.
 Analogous to factor levels and labels. Generics encode() and decode()
 perform interconversion, while codes() and decodes() extract components of an encoding.
 The function encoded() checks whether something is interpretable as an encoding.
productivity,2016-11-14,productivity: Indices of Productivity Using Data Envelopment Analysis (DEA),
  Levels and changes of productivity and profitability are measured with various indices.
  The package contains the multiplicatively complete Färe-Primont, Fisher, Hicks-Moorsteen, 
  Laspeyres, Lowe, and Paasche indices, as well as the classic Malmquist productivity index.
  Färe-Primont and Lowe indices verify the transitivity property and can therefore be used for 
  multilateral or multitemporal comparison.
  Fisher, Hicks-Moorsteen, Laspeyres, Malmquist, and Paasche indices are not transitive and are 
  only to be used for binary comparison.
  All indices can also be decomposed into different components, providing insightful information 
  on the sources of productivity and profitability changes.
  In the use of Malmquist productivity index, the technological change index can be further 
  decomposed into bias technological change components.
  The package also allows to prohibit technological regression (negative technological change). In 
  the case of the Fisher, Hicks-Moorsteen, Laspeyres, Paasche and the transitive Färe-Primont 
  and Lowe indices, it is furthermore possible to rule out technological change. 
  Deflated shadow prices can also be obtained. Besides, the package allows parallel computing as 
  an option, depending on the user's computer configuration. 
  All computations are carried out with the nonparametric Data Envelopment Analysis (DEA), and 
  several assumptions regarding returns to scale are available.
  All DEA linear programs are implemented using 'lp_solve'.
SubTite,2017-07-11,SubTite: Subgroup Specific Optimal Dose Assignment,Contains functions for choosing subgroup specific optimal doses in a phase I dose finding clinical trial allowing for subgroup combination and simulating a clinical trial under the subgroup specific time to event continual reassessment method.
bairt,2017-09-03,bairt: Bayesian Analysis of Item Response Theory Models,Bayesian estimation of the two and three parameter models of item response theory (IRT). Also, it is possible to use a web interactive application intended for the making of an MCMC estimation and model-fit of the IRT models.
dfped,2017-08-01,dfped: Extrapolation and Bridging of Adult Information in Early Phase
Dose-Finding Paediatrics Studies,A unified method for designing and analysing dose-finding trials in paediatrics, while bridging information from adults, is proposed in the 'dfped' package. The dose range can be calculated under three extrapolation methods: linear, allometry and maturation adjustment, using pharmacokinetic (PK) data. To do this, it is assumed that target exposures are the same in both populations. The working model and prior distribution parameters of the dose-toxicity and dose-efficacy relationships can be obtained using early phase adult toxicity and efficacy data at several dose levels through 'dfped' package. Priors are used into the dose finding process through a Bayesian model selection or adaptive priors, to facilitate adjusting the amount of prior information to differences between adults and children. This calibrates the model to adjust for misspecification if the adult and paediatric data are very different. User can use his/her own Bayesian model written in Stan code through the 'dfped' package. A template of this model is proposed in the examples of the corresponding R functions in the package. Finally, in this package you can find a simulation function for one trial or for more than one trial. These methods are proposed by Petit et al, (2016) <doi:10.1177/0962280216671348>.
ssc,2016-10-05,ssc: Semi-Supervised Classification Methods,Provides a collection of self-labeled techniques for semi-supervised 
    classification. In semi-supervised classification, both labeled and unlabeled
    data are used to train a classifier. This learning paradigm has obtained promising
    results, specifically in the presence of a reduced set of labeled examples. 
    This package implements a collection of self-labeled techniques to construct a
    classification model. This family of techniques enlarges the original labeled set 
	using the most confident predictions to classify unlabeled data. The techniques 
	implemented can be applied to classification problems in several domains by the 
	specification of a supervised base classifier. At low ratios of labeled data, it 
	can be shown to perform better than classical supervised classifiers.
quotedargs,2017-06-27,quotedargs: A Way of Writing Functions that Quote their Arguments,A facility for writing functions that quote their arguments,
 may sometimes evaluate them in the environment where they were quoted,
 and may pass them as quoted to other functions.
blob,2016-12-29,blob: A Simple S3 Class for Representing Vectors of Binary Data
('BLOBS'),R's raw vector is useful for storing a single binary object.
    What if you want to put a vector of them in a data frame? The 'blob'
    package provides the blob object, a list of raw vectors, suitable for
    use as a column in data frame.
interp,2017-06-16,interp: Interpolation Methods,Bivariate data interpolation on regular and irregular
  grids, either linear or using splines are the main part of this
  package.  It is intended to provide FOSS replacement functions for
  the ACM licensed akima::interp and tripack::tri.mesh functions.
  Currently the piecewise linear interpolation part of akima::interp
  (and also akima::interpp) is implemented in interp::interp, this
  corresponds to the call akima::interp(..., linear=TRUE) which is the
  default setting and covers most of akima::interp use cases in
  depending packages.  A re-implementation of Akimas spline
  interpolation (akima::interp(..., linear=FALSE)) is currently under
  development and will complete this package in a later
  version. Estimators for partial derivatives are already available,
  these are a prerequisite for the spline interpolation.  The basic
  part is currently a GPLed triangulation algorithm (sweep hull
  algorithm by David Sinclair) providing the starting point for the
  piecewise linear interpolator. As side effect this algorithm is also
  used to provide replacements for the basic functions of the tripack
  package which also suffer from the ACM restrictions.  All functions
  are designed to be backward compatible with their akima / tripack
  counterparts.
orthoDr,2017-09-21,orthoDr: An Orthogonality Constrained Optimization Approach for
Semi-Parametric Dimension Reduction Problems,Utilize an orthogonality constrained optimization algorithm of Wen & Yin (2013) <doi:10.1007/s10107-012-0584-1> to solve a variety of dimension reduction problems in the semiparametric framework, such as Ma & Zhu (2012) <doi:10.1080/01621459.2011.646925>, Ma & Zhu (2013) <doi:10.1214/12-AOS1072>, and Sun, Zhu, Wang & Zeng (2017) <arXiv:1704.05046>. It also serves as a general purpose optimization solver for problems with orthogonality constraints. Parallel computing is enabled through ‘OpenMP’.
windfarmGA,2017-06-24,windfarmGA: Genetic Algorithm for Wind Farm Layout Optimization,The genetic algorithm is designed to optimize small wind farms with
    irregular shapes. The algorithm works with a fixed amount of turbines, a fixed
    rotor radius and a mean wind speed value for every incoming wind direction.
    If required, it can include a terrain effect model which downloads an
    'SRTM' elevation model automatically and loads a Corine Land Cover raster,
    which has to be downloaded previously. Further information can be found in the
    description of the function 'windfarmGA'. To start an optimization run, either the
    function 'windfarmGA' or 'genAlgo' can be used. The function 'windfarmGA' checks
    the user inputs interactively and then runs the function 'genAlgo'. If the input
    parameters are already known, an optimization can be run directly via the function
    'genAlgo'. Their output is identical.
DMRnet,2017-09-05,DMRnet: Delete or Merge Regressors Algorithms for Linear and Logistic
Model Selection and High-Dimensional Data,Model selection algorithms for regression and classification, where the predictors can be numerical and categorical and the number of regressors exceeds the number of observations. The selected model consists of a subset of numerical regressors and partitions of levels of factors. Aleksandra Maj-Kanska, Piotr Pokarowski and Agnieszka Prochenka (2015) <doi:10.1214/15-EJS1050>. Piotr Pokarowski and Jan Mielniczuk (2015) <http://www.jmlr.org/papers/volume16/pokarowski15a/pokarowski15a.pdf>. 
sfdct,2017-05-02,sfdct: Constrained Triangulation for Simple Features,Build a constrained Delaunay triangulation from simple features
    objects, applying constraints based on input line segments, and triangle
    properties including maximum area, minimum internal angle. The triangulation code
    in 'RTriangle' uses the method of Cheng, Dey and Shewchuk (2012, ISBN:9781584887300). 
    For a low-dependency alternative with low-quality path-based constrained 
    triangulation see <https://CRAN.R-project.org/package=decido>. 
DPWeibull,2017-06-13,DPWeibull: Dirichlet Process Weibull Mixture Model for Survival Data,Use Dirichlet process Weibull mixture model and dependent Dirichlet process Weibull mixture model for survival data with and without competing risks. Dirichlet process Weibull mixture model is used for data without covariates and dependent Dirichlet process model is used for regression data. The package is designed to handle exact/right-censored/ interval-censored observations without competing risks and exact/right-censored observations for data with competing risks. Inside each cluster of Dirichlet process, we assume a multiplicative effect of covariates as in Cox model and Fine and Gray model. In addition, we provide a wrapper for DPdensity() function from the R package 'DPpackage'. This wrapper automatically uses Low Information Omnibus prior and can model one and two dimensional data with Dirichlet mixture of Gaussian distributions.
GPGame,2017-06-10,GPGame: Solving Complex Game Problems using Gaussian Processes,Sequential strategies for finding a game equilibrium are proposed in a black-box setting (expensive pay-off evaluations, no derivatives). The algorithm handles noiseless or noisy evaluations. Two acquisition functions are available. Graphical outputs can be generated automatically. 
SetTest,2017-02-11,SetTest: Group Testing Procedures for Signal Detection and
Goodness-of-Fit,It provides cumulative distribution function (CDF),
    quantile, p-value, statistical power calculator and random number generator
    for a collection of group-testing procedures, including the Higher Criticism
    tests, the one-sided Kolmogorov-Smirnov tests, the one-sided Berk-Jones tests,
    the one-sided phi-divergence tests, etc. The input are a group of p-values.
    The null hypothesis is that they are i.i.d. Uniform(0,1). In the context of
    signal detection, the null hypothesis means no signals. In the context of the
    goodness-of-fit testing, which contrasts a group of i.i.d. random variables to
    a given continuous distribution, the input p-values can be obtained by the CDF
    transformation. The null hypothesis means that these random variables follow the
    given distribution. For reference, see Hong Zhang, Jiashun Jin and Zheyang Wu. 
    "Distributions and Statistical Power of Optimal Signal-Detection Methods In Finite Cases",
    submitted.
AdapSamp,2017-09-08,AdapSamp: Adaptive Sampling Algorithms,For distributions whose probability density functions are log-concave, the adaptive rejection sampling algorithm can be used to build envelope functions for sampling. For others, we can use the modified adaptive rejection sampling algorithm, the concave-convex adaptive rejection sampling algorithm and the adaptive slice sampling algorithm. So we designed an R package mainly including 4 functions: rARS(), rMARS(), rCCARS() and rASS(). These functions can realize sampling based on the algorithms above.
horserule,2017-04-13,horserule: Flexible Non-Linear Regression with the HorseRule Algorithm,Implementation of the HorseRule model a flexible tree based Bayesian regression method for linear and nonlinear regression described in Nalenz & Villani (2017) <arXiv:1702.05008>.
incR,2017-07-20,incR: Analysis of Incubation Data,Suite of functions to study animal incubation.
    At the core of incR 
    lies an algorithm that allows for the scoring of 
    incubation behaviour. Additionally, several functions 
    extract biologically relevant metrics of incubation such as off-bout number 
    and off-bout duration - for a review of avian incubation studies, 
    see Nests, Eggs, and Incubation: New ideas about avian reproduction (2015) 
    edited by D. Charles Deeming and S. James Reynolds <doi:10.1093/acprof:oso/9780198718666.001.0001>.
RNRCS,2017-04-06,RNRCS: Download NRCS Data,Downloads Natural Resources Conservation Service (NRCS) data for sites in the Soil Climate Analysis Network (SCAN) <https://www.wcc.nrcs.usda.gov/scan/>, and Snow Telemetry (SNOTEL and SNOLITE) <https://www.wcc.nrcs.usda.gov/snow/> networks. Metadata can be returned for all sites in the NRCS' Air and Water Data Base (AWDB) <https://www.wcc.nrcs.usda.gov/report_generator/AWDB_Network_Codes.pdf>.
descriptr,2016-12-28,descriptr: Generate Descriptive Statistics & Explore Statistical
Distributions,Generate descriptive statistics such as measures of location,
    dispersion, frequency tables, cross tables, group summaries and multiple
    one/two way tables. Visualize and compute percentiles/probabilities of 
    normal, t, f, chi square and binomial distributions.
eventdataR,2017-06-18,eventdataR: Event Data Repository,Event dataset repository including both real-life and artificial event logs. They can be used in combination with functionalities provided by the 'bupaR' packages 'edeaR', 'processmapR', etc.
rarhsmm,2017-04-13,rarhsmm: Regularized Autoregressive Hidden Semi Markov Model,Fit Gaussian hidden Markov (or semi-Markov) models with / without autoregressive coefficients and with / without regularization. The fitting algorithm for the hidden Markov model is illustrated by Rabiner (1989) <doi:10.1109/5.18626>. The shrinkage estimation on the covariance matrices is based on the method by Ledoit et al. (2004) <doi:10.1016/S0047-259X(03)00096-4>. The shrinkage estimation on the autoregressive coefficients uses the elastic net shrinkage detailed in Zou et al. (2005) <doi:10.1111/j.1467-9868.2005.00503.x>.
gamRR,2017-05-13,gamRR: Calculate the RR for the GAM,To calculate the relative risk (RR) for the generalized additive model.
metScanR,2017-01-18,metScanR: Find, Map, and Gather Environmental Data and Metadata,A tool for locating, mapping, and gathering environmental data and metadata, worldwide.  Users can search for and filter metadata from > 107,000 environmental monitoring stations among 219 countries/territories and >20 networks/organizations via elevation, location, active dates, elements measured (e.g., temperature, precipitation), country, network, and/or known identifier. Future updates to the package will allow the user to obtain datasets from stations within the database.
RNAsmc,2017-08-23,RNAsmc: RNA Secondary Structure Module Mining, Comparison and Plotting,Provides function for RNA secondary structure plotting, comparison and module mining. Given a RNA secondary structure, you can obtain stem regions, hairpin loops, internal loops, bulge loops and multibranch loops of this RNA structure using this program. They are the basic modules of RNA secondary structure. For each module you get, you can use this program to label the RNA structure with a specific color. You can also use this program to compare two RNA secondary structures to get a score that represents similarity. Reference: Reuter JS, Mathews DH (2010) <doi:10.1186/1471-2105-11-129>.
g2f,2016-10-08,g2f: Find and Fill Gaps in Metabolic Networks,For a given metabolic network, this package finds the gaps (metabolites not produced or not consumed in any other reaction), and fills it from the stoichiometric reactions of a reference metabolic reconstruction using a weighting function. Also the option to download all the set of gene-associated stoichiometric reactions for a specific organism from the KEGG database <http://www.genome.jp/kegg/> is available.
QuantTools,2016-10-14,QuantTools: Enhanced Quantitative Trading Modelling,Download and organize historical market data from multiple sources like Yahoo (<https://finance.yahoo.com>), Google (<https://www.google.com/finance>), Finam (<https://www.finam.ru/profile/moex-akcii/sberbank/export/>), MOEX (<https://www.moex.com/en/derivatives/contracts.aspx>) and IQFeed (<https://www.iqfeed.net/symbolguide/index.cfm?symbolguide=lookup>). Code your trading algorithms in modern C++11 with powerful event driven tick processing API including trading costs and exchange communication latency and transform detailed data seamlessly into R. In just few lines of code you will be able to visualize every step of your trading model from tick data to multi dimensional heat maps.
Rgb,2017-03-03,Rgb: The R Genome Browser,Classes and methods to efficiently handle (slice, annotate, draw ...) genomic features (such as genes or transcripts), and an interactive interface to browse them.
datetime,2017-05-03,datetime: Nominal Dates, Times, and Durations,Provides methods for working with nominal dates, times, and 
 durations. Base R has sophisticated facilities for handling time, but these 
 can give unexpected results if, for example, timezone is not handled properly. 
 This package provides a more casual approach to support cases which 
 do not require rigorous treatment.  It systematically deconstructs the 
 concepts origin and timezone, and de-emphasizes the display of seconds. It 
 also converts among nominal durations such as seconds, hours, days, and weeks.
 See '?datetime' and '?duration' for examples. Adapted from 'metrumrg' 
 <http://r-forge.r-project.org/R/?group_id=1215>.
splithalf,2017-04-07,splithalf: Calculate Task Split Half Reliability Estimates,A series of functions to calculate the split 
    half reliability of RT based tasks. The core function performs a Monte Carlo
    procedure to process a user defined number of random splits in order to 
    provide a better reliability estimate. The current functions target the dot-
    probe task, however, can be modified for other tasks.
survidm,2017-05-27,survidm: Inference and Prediction in an Illness-Death Model,Newly developed methods for the estimation of several probabilities
      in an illness-death model. The package can be used to obtain nonparametric and 
      semiparametric estimates for: transition probabilities, occupation probabilities, 
      cumulative incidence function and the sojourn time distributions. 
      Additionally, it is possible to fit proportional hazards regression models
      in each transition of the Illness-Death Model. Several auxiliary 
      functions are also provided which can be used for marginal 
      estimation of the survival functions.
wpp2017,2017-06-29,wpp2017: World Population Prospects 2017,Provides data from the United Nation's World Population Prospects 2017.
EthSEQ,2017-04-03,EthSEQ: Ethnicity Annotation from Whole Exome Sequencing Data,Reliable and rapid ethnicity annotation from whole exome sequencing data.
metaviz,2017-02-06,metaviz: Forest Plots, Funnel Plots, and Visual Funnel Plot Inference for
Meta-Analysis,A compilation of functions to plot meta-analytic data using 'ggplot2'. Currently allows to 
    create forest plots, funnel plots, and many of their variants, such as rainforest plots and 
    additional evidence contour enhanced funnel plots. In addition, functionalities for visual funnel 
    plot inference are provided. In the near future, the 'metaviz' package will be extended by further, 
    established as well as novel, plotting options for visualizing meta-analytic data.
MonteCarlo,2017-03-17,MonteCarlo: Automatic Parallelized Monte Carlo Simulations,Simplifies Monte Carlo simulation studies by automatically 
             setting up loops to run over parameter grids and parallelising
             the Monte Carlo repetitions. It also generates LaTeX tables.
rdlocrand,2017-04-07,rdlocrand: Local Randomization Methods for RD Designs,The regression discontinuity (RD) design is a popular quasi-experimental design for causal inference and policy evaluation. Under the local randomization approach, RD designs can be interpreted as randomized experiments inside a window around the cutoff. This package provides tools to perform randomization inference for RD designs under local randomization: rdrandinf() to perform hypothesis testing using randomization inference, rdwinselect() to select a window around the cutoff in which randomization is likely to hold, rdsensitivity() to assess the sensitivity of the results to different window lengths and null hypotheses and rdrbounds() to construct Rosenbaum bounds for sensitivity to unobserved confounders.
adaptiveGPCA,2017-05-05,adaptiveGPCA: Adaptive Generalized PCA,Implements adaptive gPCA, as described in: Fukuyama, J. (2017)
    <arXiv:1702.00501>. The package also includes functionality for applying
    the method to 'phyloseq' objects so that the method can be easily applied
    to microbiome data and a 'shiny' app for interactive visualization. 
gfmR,2017-05-20,gfmR: Implements Group Fused Multinomial Regression,Software to implement methodology to preform automatic response category
  combinations in multinomial logistic regression. There are functions for both cross validation
  and AIC for model selection.  The method provides regression coefficient estimates
  that may be useful for better understanding the true probability distribution of
  multinomial logistic regression when category probabilities are similar. These methods are not
  recommended for a large number of predictor variables.  
patentsview,2017-07-12,patentsview: An R Client to the 'PatentsView' API,Provides functions to simplify the 'PatentsView' API
    (<http://www.patentsview.org/api/doc.html>) query language,
    send GET and POST requests to the API's seven endpoints, and parse the data
    that comes back.
assignPOP,2016-12-29,assignPOP: Population Assignment using Genetic, Non-Genetic or Integrated
Data in a Machine Learning Framework,Use Monte-Carlo and K-fold cross-validation coupled with machine-learning classification algorithms to perform population assignment, with functionalities of evaluating discriminatory power of independent training samples, identifying informative loci, reducing data dimensionality for genomic data, integrating genetic and non-genetic data, and visualizing results.  
bindr,2016-11-13,bindr: Parametrized Active Bindings,Provides a simple interface for creating active bindings where the
    bound function accepts additional arguments.
pacotest,2017-02-15,pacotest: Testing for Partial Copulas and the Simplifying Assumption in
Vine Copulas,Routines for two different test types, the Constant Conditional Correlation (CCC) test and the Vectorial Independence (VI) test are provided (Kurz and Spanhel (2017) <arXiv:1706.02338>). The tests can be applied to check whether a conditional copula coincides with its partial copula. Functions to test whether a regular vine copula satisfies the so-called simplifying assumption or to test a single copula within a regular vine copula to be a (j-1)-th order partial copula are available. The CCC test comes with a decision tree approach to allow testing in high-dimensional settings.
xtractomatic,2016-10-05,xtractomatic: Accessing Environmental Data from ERD's ERDDAP Server,Contains three functions that access
    environmental data from ERD's ERDDAP service <http://coastwatch.pfeg.noaa.gov/erddap>. The xtracto() function extracts
    data along a trajectory for a given "radius" around the point. The
    xtracto_3D() function extracts data in a box. The xtractogon() function
    extracts data in a polygon. There are also two helper functions to obtain
    information about available data, and plotting functions to plot the results.
aniDom,2017-02-09,aniDom: Inferring Dominance Hierarchies and Estimating Uncertainty,Provides: (1) Tools to infer dominance hierarchies based on calculating Elo scores, but with custom functions to improve estimates in animals with relatively stable dominance ranks. (2) Tools to plot the shape of the dominance hierarchy and estimate the uncertainty of a given data set.
gfer,2016-12-19,gfer: Green Finance and Environmental Risk,Focuses on data collecting, analyzing and visualization in green finance and environmental 
  risk research and analysis. Main function includes environmental data collecting from 
  official websites such as MEP (Ministry of Environmental Protection of China, <http://www.mep.gov.cn>), water 
  related projects identification and environmental data visualization.
widyr,2017-08-14,widyr: Widen, Process, then Re-Tidy Data,Encapsulates the pattern of untidying data into a wide matrix,
  performing some processing, then turning it back into a tidy form. This
  is useful for several operations such as co-occurrence counts,
  correlations, or clustering that are mathematically convenient on wide matrices.
datetimeutils,2017-08-28,datetimeutils: Utilities for Dates and Times,Utilities for handling dates and times, such
   as selecting particular days of the week or month,
   formatting timestamps as required by RSS feeds, or
   converting timestamp representations of other software
   (such as 'MATLAB' and 'Excel') to R. The package is
   lightweight (no dependencies, pure R implementations) and
   relies only on R's standard classes to represent dates
   and times ('Date' and 'POSIXt'); it aims to provide
   efficient implementations, through vectorisation and the
   use of R's native numeric representations of timestamps
   where possible.
Rcriticor,2017-06-23,Rcriticor: Pierre-Goldwin Correlogram,Goldwin-Pierre correlogram. Research of critical periods in the past. Integrates a time series in a given window.  
rmonad,2017-07-13,rmonad: A Monadic Pipeline System,
    A monadic solution to pipeline analysis. All operations – and the errors,
    warnings and messages they emit – are merged into a directed graph. Infix
    binary operators mediate when values are stored, how exceptions are
    handled, and where pipelines branch and merge. The resulting structure may
    be queried for debugging or report generation. 'rmonad' complements, rather
    than competes with, non-monadic pipeline packages like 'magrittr' or
    'pipeR'. This work is funded by the NSF (award number 1546858).
sim1000G,2017-08-17,sim1000G: Genotype Simulations for Rare or Common Variants Using
Haplotypes from 1000 Genomes,Generates realistic simulated genetic data in families or unrelated individuals.
cronR,2017-03-03,cronR: Schedule R Scripts and Processes with the 'cron' Job Scheduler,Create, edit, and remove 'cron' jobs on your unix-alike system. The package provides a set of easy-to-use wrappers
    to 'crontab'. It also provides an RStudio add-in to easily launch and schedule your scripts.
EpiILM,2017-04-14,EpiILM: Spatial and Network Based Individual Level Models for Epidemics,Provides tools for simulating from discrete-time individual level models for infectious disease data analysis. This epidemic model class contains spatial and contact-network based models with two disease types: Susceptible-Infectious (SI) and Susceptible-Infectious-Removed (SIR).  
wgeesel,2017-04-22,wgeesel: Weighted Generalized Estimating Equations and Model Selection,Weighted generalized estimating equations (WGEE) is an extension of generalized linear models to longitudinal clustered data by incorporating the correlation within-cluster when data is missing at random (MAR). The parameters in mean, scale correlation structures are estimated based on quasi-likelihood. Multiple model selection criterion are provided for selection of mean model and working correlation structure based on WGEE/GEE.
lime,2017-09-15,lime: Local Interpretable Model-Agnostic Explanations,When building complex models, it is often difficult to explain why
    the model should be trusted. While global measures such as accuracy are
    useful, they cannot be used for explaining why a model made a specific
    prediction. 'lime' (a port of the 'lime' 'Python' package) is a method for
    explaining the outcome of black box models by fitting a local model around
    the point in question an perturbations of this point. The approach is
    described in more detail in the article by Ribeiro et al. (2016) 
    <arXiv:1602.04938>.
anomalyDetection,2017-03-20,anomalyDetection: Implementation of Augmented Network Log Anomaly Detection
Procedures,Implements procedures developed by Gutierrez et al. (2017, <https://journal.r-project.org/archive/2017/RJ-2017-039/index.html>) 
  to aid in detecting network log anomalies. By combining various multivariate 
  analytic approaches relevant to network anomaly detection, it provides cyber 
  analysts efficient means to detect suspected anomalies requiring further evaluation.
ACMEeqtl,2017-03-11,ACMEeqtl: Estimation of Interpretable eQTL Effect Sizes Using a Log of
Linear Model,We use a non-linear model, termed ACME,
        that reflects a parsimonious biological model for
        allelic contributions of cis-acting eQTLs.
        With non-linear least-squares algorithm we
        estimate maximum likelihood parameters. The ACME model
        provides interpretable effect size estimates and
        p-values with well controlled Type-I error.
        Includes both R and (much faster) C implementations.
        For more details see Palowitch et al. (2017) <doi:10.1111/biom.12810>.
KraljicMatrix,2016-12-15,KraljicMatrix: A Quantified Implementation of the Kraljic Matrix,Implements a quantified approach to the Kraljic Matrix (Kraljic, 1983, <https://hbr.org/1983/09/purchasing-must-become-supply-management>)
    for strategically analyzing a firm’s purchasing portfolio. It combines multi-objective decision analysis to measure purchasing characteristics and
    uses this information to place products and services within the Kraljic Matrix.
origami,2017-06-23,origami: Generalized Framework for Cross-Validation,Provides a general framework for the application of
    cross-validation schemes to particular functions. By allowing arbitrary
    lists of results, origami accommodates a range of cross-validation
    applications.
robets,2016-11-23,robets: Forecasting Time Series with Robust Exponential Smoothing,We provide an outlier robust alternative of the function ets() in the 'forecast' package of Hyndman and Khandakar (2008) <doi:10.18637/jss.v027.i03>. For each method of a class of exponential smoothing variants we made a robust alternative. The class includes methods with a damped trend and/or seasonal components. The robust method is developed by robustifying every aspect of the original exponential smoothing variant. We provide robust forecasting equations, robust initial values, robust smoothing parameter estimation and a robust information criterion. The method is described in more detail in Crevits and Croux (2016) <doi:10.13140/RG.2.2.11791.18080>.
slickR,2017-04-01,slickR: Create Interactive Carousels with the JavaScript 'Slick' Library,Create and customize interactive carousels using the 'Slick'
    JavaScript library and the 'htmlwidgets' package. The carousels can contain plots
    produced in R, images, 'iframes', videos and other 'htmlwidgets'.
    These carousels can be used directly from the R console, from 'RStudio', 
    in Shiny apps and R Markdown documents.
adeba,2017-07-03,adeba: Adaptive Density Estimation by Bayesian Averaging,Univariate and multivariate non-parametric kernel density
    estimation with adaptive bandwidth using a Bayesian approach to Abramson's
    square root law.
hansard,2016-11-12,hansard: Provides Easy Downloading Capabilities for the UK Parliament API,Provides functions to download data from the 
  <http://www.data.parliament.uk/> APIs. Because of the structure of the API, 
  there is a named function for each type of available data for ease of use, 
  as well as some functions designed to retrieve specific pieces of commonly 
  used data. Functions for each new API will be added as and when they become
  available.
RcmdrPlugin.aRnova,2017-08-08,RcmdrPlugin.aRnova: R Commander Plug-in for Repeated-Measures ANOVA,R Commander plug-in for repeated-measures and mixed-design
    ('split-plot') ANOVA.
    It adds a new menu entry for repeated measures that allows
    to deal with up to three within-subject factors and optionally with
    one or several between-subject factors.
    It also provides supplementary options to oneWayAnova() and
    multiWayAnova() functions, such as choice of ANOVA type, display of
    effect sizes and post hoc analysis for multiWayAnova().
tmcn,2017-06-12,tmcn: A Text Mining Toolkit for Chinese,A Text mining toolkit for Chinese, which includes facilities for 
    Chinese string processing, Chinese NLP supporting, encoding detecting and 
    converting. Moreover, it provides some functions to support 'tm' package 
    in Chinese.
OpenML,2016-11-12,OpenML: Open Machine Learning and Open Data Platform,We provide an R interface to 'OpenML.org' which is an online machine learning platform where researchers can access open data, download and upload data sets, share their machine learning tasks and experiments and organize them online to work and collaborate with other researchers. 
    The R interface allows to query for data sets with specific properties, and allows the downloading and uploading of data sets, tasks, flows and runs. 
    See <https://www.openml.org/guide/api> for more information.
rpostgisLT,2016-11-01,rpostgisLT: Managing Animal Movement Data with 'PostGIS' and R,Integrates R and the 'PostgreSQL/PostGIS' database 
    system to build and manage animal trajectory (movement) data sets. 
    The package relies on 'ltraj' objects from the R package 'adehabitatLT',
    building the analogous 'pgtraj' data structure in 'PostGIS'. Functions
    allow users to seamlessly transfer between 'ltraj' and 'pgtraj', as
    well as build new 'pgtraj' directly from location data stored in the 
    database.
ashr,2016-12-27,ashr: Methods for Adaptive Shrinkage, using Empirical Bayes,The R package 'ashr' implements an Empirical Bayes
    approach for large-scale hypothesis testing and false discovery
    rate (FDR) estimation based on the methods proposed in
    M. Stephens, 2016, "False discovery rates: a new deal",
    <doi:10.1093/biostatistics/kxw041>. These methods can be applied
    whenever two sets of summary statistics—estimated effects and
    standard errors—are available, just as 'qvalue' can be applied
    to previously computed p-values. Two main interfaces are
    provided: ash(), which is more user-friendly; and ash.workhorse(),
    which has more options and is geared toward advanced users. The
    ash() and ash.workhorse() also provides a flexible modeling
    interface that can accomodate a variety of likelihoods (e.g.,
    normal, Poisson) and mixture priors (e.g., uniform, normal).
DoE.MIParray,2017-09-28,DoE.MIParray: Creation of Arrays by Mixed Integer Programming,'CRAN' package 'DoE.base' and non-'CRAN' packages 'gurobi' and 'Rmosek' are enhanced with functionality for the creation of optimized arrays for experimentation, where optimization is in terms of generalized minimum aberration. It is also possible to optimally extend existing arrays to larger run size. Optimization requires the availability of at least one of the commercial products 'Gurobi' or 'Mosek' (free academic licenses available for both). For installing 'Gurobi' and its R package 'gurobi', follow instructions at <http://www.gurobi.com/downloads/gurobi-optimizer> and <http://www.gurobi.com/documentation/7.5/refman/r_api_overview.html>. For installing 'Mosek' and its R package 'Rmosek', follow instructions at <https://www.mosek.com/downloads/> and <http://docs.mosek.com/8.1/rmosek/install-interface.html>.
fauxpas,2016-11-16,fauxpas: HTTP Error Helpers,HTTP error helpers. Methods included for general purpose HTTP 
    error handling, as well as individual methods for every HTTP status
    code, both via status code numbers as well as their descriptive names.
    Supports ability to adjust behavior to stop, message or warning.
    Includes ability to use custom whisker template to have any configuration
    of status code, short description, and verbose message. Currently 
    supports integration with 'crul', 'curl', and 'httr'.
GetITRData,2017-09-30,GetITRData: Reading Financial Reports from Bovespa's ITR System,Reads quarterly and annual financial reports including assets, liabilities, income and cash flow statements from Bovespa's ITR (informacoes trimestrais) system <http://www.bmfbovespa.com.br/en_us/products/listed-equities-and-derivatives/equities/listed-companies.htm>.
 The ITR/DFP system is a web based interface for all financial reports of companies traded at Bovespa. The package is especially designed for large scale data importation, keeping a tabular (long) structure for easier processing.  
ldhmm,2017-04-13,ldhmm: Hidden Markov Model for Financial Time-Series Based on Lambda
Distribution,Hidden Markov Model (HMM) based on symmetric lambda distribution
    framework is implemented for the study of return time-series in the financial
    market. Major features in the S&P500 index, such as regime identification,
    volatility clustering, and anti-correlation between return and volatility,
    can be extracted from HMM cleanly. Univariate symmetric lambda distribution
    is essentially a location-scale family of exponential power distribution.
    Such distribution is suitable for describing highly leptokurtic time series
    obtained from the financial market. It provides a theoretically solid foundation
    to explore such data where the normal distribution is not adequate. The HMM
    implementation follows closely the book: "Hidden Markov Models for Time Series",
    by Zucchini, MacDonald, Langrock (2016).
idmTPreg,2017-07-28,idmTPreg: Regression Model for Progressive Illness Death Data,Modeling of regression effects for transition probabilities in a 
   progressive illness-death model. Azarang, Scheike, and de Una-Alvarez (2017) <doi:10.1002/sim.7245>.
projector,2017-09-28,projector: Project Dense Vectors Representation of Texts on a 2D Plan,Display dense vector representation of texts on a 2D plan to better
  understand embeddings by observing the neighbors of a selected text.
  It also includes an interactive application to change dynamically the pivot text.
worldmet,2017-01-26,worldmet: Import Surface Meteorological Data from NOAA Integrated Surface
Database (ISD),Functions to import data from more than 30,000 surface
    meteorological sites around the world managed by the National Oceanic and Atmospheric Administration (NOAA) Integrated Surface
    Database (ISD, see <https://www.ncdc.noaa.gov/isd>).
zenplots,2016-12-16,zenplots: Zigzag Expanded Navigation Plots,Graphical tools for visualizing high-dimensional data with a path
 of pairs. Note that this requires 'graph' from Bioconductor. Furthermore,
 if you want to use dynamic graphics based on 'loon', you need to have R
 configured with Tcl/Tk support and you need to have 'loon' installed,
 for example, from <https://github.com/waddella/loon>.
fuzzywuzzyR,2017-04-11,fuzzywuzzyR: Fuzzy String Matching,Fuzzy string matching implementation of the 'fuzzywuzzy' <https://github.com/seatgeek/fuzzywuzzy> 'python' package. It uses the Levenshtein Distance <https://en.wikipedia.org/wiki/Levenshtein_distance> to calculate the differences between sequences. 
photobiologyLamps,2016-10-23,photobiologyLamps: Spectral Irradiance Data for Lamps,Spectral emission data for some frequently used lamps excluding 
    led emitting diodes (LEDs) available as electronic components. Original 
    spectral irradiance data for incandescent-, LED- and discharge lamps are 
    included. They are complemented by data on the effect of temperature on
    the emission by fluorescent tubes.
rospca,2017-01-16,rospca: Robust Sparse PCA using the ROSPCA Algorithm,Implementation of robust sparse PCA using the ROSPCA algorithm 
             of Hubert et al. (2016) <doi:10.1080/00401706.2015.1093962>.
nzpullover,2017-01-29,nzpullover: Driving Offences in New Zealand Between 2009 and 2016,Datasets of driving offences and fines in New Zealand between 2009 and 2017.
    Originally published by the New Zealand Police at
    <http://www.police.govt.nz/about-us/publication/road-policing-driver-offence-data-january-2009-december-2017>.
Rcssplot,2017-03-06,Rcssplot: Styling of Graphics using Cascading Style Sheets,Provides a means to style plots through cascading style sheets.
    This separates the aesthetics from the data crunching in plots and charts.
rpgm,2017-02-28,rpgm: Fast Simulation of Normal/Exponential Random Variables and
Stochastic Differential Equations / Poisson Processes,Fast simulation of some random variables than the usual native functions, including rnorm() and rexp(), using Ziggurat method, reference: MARSAGLIA, George, TSANG, Wai Wan, and al. (2000) <doi:10.18637/jss.v005.i08>, and fast simulation of stochastic differential equations / Poisson processes.
stoRy,2017-05-09,stoRy: Functions for the Analysis of Star Trek Thematic Data,An implementation of 1) the hypergeometric test for over-representation of literary themes in a storyset (a list of stories) relative to a background list of stories, and 2) a recommendation system that takes a user-selected story as input and returns a ranked list of similar stories on the basis of shared themes. The package is currently implemented for the episodes of the Star Trek television franchise series The Original Series (TOS), The Animated Series (TAS), The Next Generation (TNG), and Voyager (VOY).
bea.R,2016-12-02,bea.R: Bureau of Economic Analysis API,Provides an R interface for the Bureau of Economic Analysis (BEA) 
		API (see <http://www.bea.gov/API/bea_web_service_api_user_guide.htm> for 
		more information) that serves two core purposes - 
    1. To Extract/Transform/Load data [beaGet()] from the BEA API as R-friendly 
		formats in the user's work space [transformation done by default in beaGet() 
		can be modified using optional parameters; see, too, bea2List(), bea2Tab()].
		2. To enable the search of descriptive meta data [beaSearch()].
		Other features of the library exist mainly as intermediate methods 
		or are in early stages of development.
		Important Note - You must have an API key to use this library.  
		Register for a key at <http://www.bea.gov/API/signup/index.cfm> .
CPBayes,2017-01-23,CPBayes: Bayesian Meta Analysis for Studying Cross-Phenotype Genetic
Associations,A Bayesian meta-analysis method for studying cross-phenotype
    genetic associations. It uses summary-level data across multiple phenotypes to
    simultaneously measure the evidence of aggregate-level pleiotropic association
    and estimate an optimal subset of traits associated with the risk locus. CPBayes
    is based on a spike and slab prior and is implemented by Markov chain Monte
    Carlo technique Gibbs sampling.
multfisher,2017-04-27,multfisher: Optimal Exact Tests for Multiple Binary Endpoints,Calculates exact hypothesis tests to compare a treatment and a reference group with respect to multiple binary endpoints.
    The tested null hypothesis is an identical multidimensional distribution of successes and failures in both groups. The alternative
    hypothesis is a larger success proportion in the treatment group in at least one endpoint. The tests are based on the multivariate
    permutation distribution of subjects between the two groups. For this permutation distribution, rejection regions are calculated 
    that satisfy one of different possible optimization criteria. In particular, regions with maximal exhaustion of the nominal
    significance level, maximal power under a specified alternative or maximal number of elements can be found. Optimization is achieved
    by a branch-and-bound algorithm. By application of the closed testing principle, the global hypothesis tests are extended to multiple
    testing procedures.
BEACH,2016-10-06,BEACH: Biometric Exploratory Analysis Creation House,A platform is provided for interactive analyses with a goal of totally easy to develop, deploy, interact, and explore (TEDDIE). Using this package, users can create customized analyses and make them available to end users who can perform interactive analyses and save analyses to RTF or HTML files. It allows developers to focus on R code for analysis, instead of dealing with html or shiny code.
lassopv,2017-01-21,lassopv: Nonparametric P-Value Estimation for Predictors in Lasso,Estimate the p-values for predictors x against target variable y in lasso regression, using the regularization strength when each predictor enters the active set of regularization path for the first time as the statistic. This is based on the assumption that predictors (of the same variance) that (first) become active earlier tend to be more significant. Three null distributions are supported: normal and spherical, which are computed separately for each predictor and analytically under approximation, which aims at efficiency and accuracy for small p-values.
suncalc,2017-05-15,suncalc: Compute Sun Position, Sunlight Phases, Moon Position and Lunar
Phase,R interface to 'suncalc.js' library, part of the 'SunCalc.net' project <http://suncalc.net>, 
        for calculating sun position, sunlight phases (times for sunrise, sunset, dusk, etc.), 
        moon position and lunar phase for the given location and time.
VeryLargeIntegers,2017-09-04,VeryLargeIntegers: Store and Operate with Arbitrarily Large Integers,Multi-precission library that allows to store and operate with arbitrarily big integers without
    loss of precision. It includes a large list of tools to work with them, like:
      - Arithmetic and logic operators
      - Modular-arithmetic operators
      - Computer Number Theory utilities
      - Probabilistic primality tests
      - Factorization algorithms
      - Random generators of diferent types of integers.
CircMLE,2017-05-13,CircMLE: Maximum Likelihood Analysis of Circular Data,A series of wrapper functions to
    implement the 10 maximum likelihood models of animal orientation
    described by Schnute and Groot (1992) <doi:10.1016/S0003-3472(05)80068-5>. The
    functions also include the ability to use different optimizer
    methods and calculate various model selection metrics (i.e., AIC,
    AICc, BIC).
sNPLS,2016-10-09,sNPLS: NPLS Regression with L1 Penalization,Tools for performing variable selection in three-way data using N-PLS 
    in combination with L1 penalization. The N-PLS model (Rasmus Bro, 1996 
    <doi:10.1002/(SICI)1099-128X(199601)10:1%3C47::AID-CEM400%3E3.0.CO;2-C>) is the 
    natural extension of PLS (Partial Least Squares) to N-way structures, and tries 
    to maximize the covariance between X and Y data arrays. The package also adds
    variable selection through L1 penalization.
confSAM,2017-01-18,confSAM: Estimates and Bounds for the False Discovery Proportion, by
Permutation,For multiple testing.
    Computes estimates and confidence bounds for the
    False Discovery Proportion (FDP), the fraction of false positives among
    all rejected hypotheses.
    The methods in the package use permutations of the data. Doing so, they
    take into account the dependence structure in the data.
ratios,2017-06-25,ratios: Calculating Ratios Between Two Data Sets and Correction for
Adhering Particles on Plants,Calculation of ratios between two data sets containing environmental data like
    element concentrations by different methods. Additionally plant element 
    concentrations can be corrected for adhering particles (soil, airborne dust).
ggmuller,2017-09-01,ggmuller: Create Muller Plots of Evolutionary Dynamics,Create plots that combine a phylogeny and frequency dynamics.
    Phylogenetic input can be a generic adjacency matrix or a tree of class "phylo".
    Inspired by similar plots in publications of the labs of RE Lenski and JE
    Barrick. Named for HJ Muller (who popularised such plots) and H Wickham (whose
    code this package exploits).
PakPC2017,2017-09-05,PakPC2017: Pakistan Population Census 2017,Provides data sets and functions for exploration of Pakistan Population Census 2017 (<http://www.pbscensus.gov.pk/>).
Brundle,2017-09-19,Brundle: Normalisation Tools for Inter-Condition Variability of ChIP-Seq
Data,Inter-sample condition variability is a key challenge of normalising ChIP-seq data. This implementation uses either spike-in or a second factor as a control for normalisation. Input can either be from 'DiffBind' or a matrix formatted for 'DESeq2'. The output is either a 'DiffBind' object or the default 'DESeq2' output. Either can then be processed as normal. Supporting manuscript Guertin, Markowetz and Holding (2017) <doi:10.1101/182261>.
clust.bin.pair,2016-10-26,clust.bin.pair: Statistical Methods for Analyzing Clustered Matched Pair Data,Tests, utilities, and case studies for analyzing significance in
  clustered binary matched-pair data. The central function clust.bin.pair uses
  one of several tests to calculate a Chi-square statistic. Implemented are the
  tests Eliasziw (1991) <doi:10.1002/sim.4780101211>, Obuchowski (1998)
  <doi:10.1002/(SICI)1097-0258(19980715)17:13%3C1495::AID-SIM863%3E3.0.CO;2-I>,
  Durkalski (2003) <doi:10.1002/sim.1438>, and Yang (2010)
  <doi:10.1002/bimj.201000035> with McNemar (1947) <doi:10.1007/BF02295996>
  included for comparison. The utility functions nested.to.contingency and
  paired.to.contingency convert data between various useful formats. Thyroids
  and psychiatry are the canonical datasets from Obuchowski and Petryshen (1989)
  <doi:10.1016/0165-1781(89)90196-0> respectively.
ratesci,2016-11-13,ratesci: Confidence Intervals for Comparisons of Binomial or Poisson
Rates,Computes confidence intervals for the rate (or risk)
    difference ('RD') or rate ratio (or relative risk, 'RR') for 
    binomial proportions or Poisson rates, or for odds ratio 
    ('OR', binomial only). Also confidence intervals for a single 
    binomial or Poisson rate, and intervals for matched pairs. 
    Includes skewness-corrected asymptotic score ('SCAS') methods, 
    which have been developed in Laud (2017) <doi:10.1002/pst.1813>
    from Miettinen & Nurminen (1985) <doi:10.1002/sim.4780040211> and 
    Gart & Nam (1988) <doi:10.2307/2531848>. Also includes MOVER methods
    (Method Of Variance Estimates Recovery) for all contrasts, derived 
    from the Newcombe method but using equal-tailed Jeffreys intervals,
    and generalised for Bayesian applications incorporating prior 
    information. So-called 'exact' methods for strictly conservative 
    coverage are approximated using continuity corrections.
    Also includes methods for stratified calculations (e.g. meta-analysis),
    either assuming fixed effects or incorporating stratum
    heterogeneity.
EMMIXcskew,2017-02-08,EMMIXcskew: Fitting Mixtures of CFUST Distributions,Functions to fit finite mixture of multivariate canonical fundamental skew t (FM-CFUST) distributions, random sample generation, 2D and 3D contour plots. See Lee and McLachlan (2017) <doi:10.18637/jss.v083.i03> for more information and examples.   
inferr,2017-02-14,inferr: Inferential Statistics,Select set of parametric and non-parametric statistical tests. 'inferr' builds upon the solid set of
    statistical tests provided in 'stats' package by including additional data types as inputs, expanding and
    restructuring the test results. The tests included are t tests, variance tests, proportion tests, chi square tests, Levene's test, McNemar Test, Cochran's Q test and Runs test.
mopa,2017-06-06,mopa: Species Distribution MOdeling with Pseudo-Absences,Tools for transferable species distribution modeling and pseudo-absence 
    data generation allowing the straightforward design of relatively complex experiments 
    with multiple factors affecting the uncertainty (variability) of SDM outputs 
    (pseudo-absence sample, climate projection, modeling algorithm, etc.), and the 
    quantification of the contribution of different factors to the final variability 
    following the method described in Deque el al. (2010) <doi:10.1007/s00382-011-1053-x>. 
    Multiple methods for pseudo-absence data generation can be applied, including the novel 
    Three-step method as described in Iturbide et al. (2015) <doi:10.1016/j.ecolmodel.2015.05.018>.
    Additionally, a function for niche overlap calculation is provided, considering the metrics 
    described in Warren et al. (2008) <10.1111/j.1558-5646.2008.00482.x> and in
    Pianka (1973) <10.1146/annurev.es.04.110173.000413>.
Rilostat,2017-08-30,Rilostat: ILO Open Data via Ilostat Bulk Download Facility or SDMX Web
Service,Tools to download data from the ilostat database
    <http://www.ilo.org/ilostat> together with search and
    manipulation utilities.
revdbayes,2016-11-23,revdbayes: Ratio-of-Uniforms Sampling for Bayesian Extreme Value Analysis,Provides functions for the Bayesian analysis of extreme value
    models.  The 'rust' package <https://cran.r-project.org/package=rust> is
    used to simulate a random sample from the required posterior distribution.
    The functionality of 'revdbayes' is similar to the 'evdbayes' package
    <https://cran.r-project.org/package=evdbayes>, which uses Markov Chain
    Monte Carlo ('MCMC') methods for posterior simulation.  Also provided
    are functions for making inferences about the extremal index, using 
    the K-gaps model of Suveges and Davison (2010) <doi:10.1214/09-AOAS292>.
swCRTdesign,2016-12-23,swCRTdesign: Stepped Wedge Cluster Randomized Trial (SW CRT) Design,A set of tools for examining the design and analysis aspects of stepped wedge cluster randomized trials (SW CRT) based on a repeated cross-sectional sampling scheme (Hussey MA and Hughes JP (2007) Contemporary Clinical Trials 28:182-191. <doi:10.1016/j.cct.2006.05.007>).
tatoo,2017-05-03,tatoo: Combine and Export Data Frames,
  Functions to combine data.frames in ways that require additional effort in 
  base R, and to add metadata (id, title, ...) that can be used for printing and 
  xlsx export. The 'Tatoo_report' class is provided as a 
  convenient helper to write several such tables to a workbook, one table per 
  worksheet. Tatoo is built on top of 'openxlsx', but intimate knowledge of 
  that package is not required to use tatoo.
fivethirtyeight,2017-01-09,fivethirtyeight: Data and Code Behind the Stories and Interactives at
'FiveThirtyEight',Datasets and code published by the data journalism website 
    'FiveThirtyEight' available at <https://github.com/fivethirtyeight/data>. 
    Note that while we received guidance from editors at 'FiveThirtyEight', this 
    package is not officially published by 'FiveThirtyEight'.
tidygraph,2017-07-07,tidygraph: A Tidy API for Graph Manipulation,A graph, while not "tidy" in itself, can be thought of as two tidy
    data frames describing node and edge data respectively. 'tidygraph'
    provides an approach to manipulate these two virtual data frames using the
    API defined in the 'dplyr' package, as well as provides tidy interfaces to 
    a lot of common graph algorithms.
npcopTest,2017-01-09,npcopTest: Non Parametric Test for Detecting Changes in the Copula,A non parametric test for change points detection in the dependence between the components of multivariate data, with or without (multiple) changes in the marginal distributions. The full details, justification and examples are published in Rohmer (2016) <doi:10.1016/j.spl.2016.06.026>.
vote,2017-02-21,vote: Election Vote Counting,Counting election votes and determining election results by different methods, including the single transferable vote, approval, score and plurality methods.
adepro,2017-07-12,adepro: A 'shiny' Application for the (Audio-)Visualization of Adverse
Event Profiles,Contains a 'shiny' application called AdEPro (Animation of Adverse Event Profiles) which (audio-)visualizes adverse events occurring in clinical trials. As this data is usually considered sensitive, this tool is provided as a stand-alone application that can be launched from any local machine on which the data is stored.
OutliersO3,2017-09-26,OutliersO3: Draws Overview of Outliers (O3) Plots,Potential outliers are identified for all combinations of a dataset's variables. The available methods are HDoutliers() from the package 'HDoutliers', FastPCS() from the package 'FastPCS', mvBACON() from 'robustX', adjOutlyingness() from 'robustbase', DectectDeviatingCells() from 'cellWise', covMcd() from 'robustbase'.
PTXQC,2016-10-11,PTXQC: Quality Report Generation for MaxQuant Results,Generates Proteomics (PTX) quality control (QC) reports for shotgun LC-MS data analyzed with the 
             MaxQuant software suite (see <http://www.maxquant.org>).
             Reports are customizable (target thresholds, subsetting) and available in HTML or PDF format.
             Published in J. Proteome Res., Proteomics Quality Control: Quality Control Software for MaxQuant Results (2015) <doi:10.1021/acs.jproteome.5b00780>.
valuer,2016-12-12,valuer: Pricing of Variable Annuities,Pricing of variable annuity life insurance
    contracts by means of Monte Carlo methods. Monte Carlo is used to price
    the contract in case the policyholder cannot surrender while
    Least Squares Monte Carlo is used if the insured can surrender.
    This package implements the pricing framework and algorithm described in
    Bacinello et al. (2011) <doi:10.1016/j.insmatheco.2011.05.003>.
    It also implements the state-dependent fee structure
    discussed in Bernard et al. (2014) <doi:10.1017/asb.2014.13> as well as 
    a function which prices the contract by resolving the partial differential equation 
    described in MacKay et al. (2017) <doi:10.1111/jori.12094>.
MBC,2016-10-13,MBC: Multivariate Bias Correction of Climate Model Outputs,Calibrate and apply multivariate bias correction algorithms
    for climate model simulations of multiple climate variables. Three methods
    described by Cannon (2016) <doi:10.1175/JCLI-D-15-0679.1> and 
    Cannon (2018) <doi:10.1007/s00382-017-3580-6> are implemented:
    (i) MBC Pearson correlation (MBCp), (ii) MBC rank correlation (MBCr),
    and (iii) MBC N-dimensional PDF transform (MBCn).
multiApply,2017-07-18,multiApply: Apply Functions to Multiple Multidimensional Arrays or Vectors,The base apply function and its variants, as well as the related
    functions in the 'plyr' package, typically apply user-defined functions to a
    single argument (or a list of vectorized arguments in the case of mapply). The
    'multiApply' package extends this paradigm with its only function, Apply, which
    efficiently applies functions taking one or a list of multiple unidimensional
    or multidimensional numeric arrays (or combinations thereof) as input. The input
    arrays can have different numbers of dimensions as well as different dimension
    lengths, and the applied function can return one or a list of unidimensional or
    multidimensional arrays as output. This saves development time by preventing the
    R user from writing often error-prone and memory-inefficient loops dealing with
    multiple complex arrays. Also, a remarkable feature of Apply is the transparent
    use of multi-core through its parameter 'ncores'. In contrast to the base apply
    function, this package suggests the use of 'target dimensions' as opposite
    to the 'margins' for specifying the dimensions relevant to the function to be
    applied.
quantoptr,2017-03-11,quantoptr: Algorithms for Quantile- And Mean-Optimal Treatment Regimes,Estimation methods for optimal treatment regimes under three different criteria, namely marginal quantile, marginal mean, and mean absolute difference. For the first two criteria, both one-stage and two-stage estimation method are implemented. A doubly robust estimator for estimating the quantile-optimal treatment regime is also included. 
survivalsvm,2017-06-15,survivalsvm: Survival Support Vector Analysis,Performs support vectors analysis for data sets with survival
    outcome. Three approaches are available in the package: The regression approach
    takes censoring into account when formulating the inequality constraints of
    the support vector problem. In the ranking approach, the inequality constraints
    set the objective to maximize the concordance index for comparable pairs
    of observations. The hybrid approach combines the regression and ranking
    constraints in the same model.
aVirtualTwins,2016-10-09,aVirtualTwins: Adaptation of Virtual Twins Method from Jared Foster,Research of subgroups in random clinical trials with binary outcome and two treatments groups. This is an adaptation of the Jared Foster method (<https://www.ncbi.nlm.nih.gov/pubmed/21815180>).
gk,2017-02-05,gk: g-and-k and g-and-h Distribution Functions,Functions for the g-and-k and generalised g-and-h distributions.
pcev,2016-12-05,pcev: Principal Component of Explained Variance,Principal component of explained variance (PCEV) is a statistical
    tool for the analysis of a multivariate response vector. It is a dimension-
    reduction technique, similar to Principal component analysis (PCA), that seeks
    to maximize the proportion of variance (in the response vector) being explained
    by a set of covariates.
ICSOutlier,2016-12-20,ICSOutlier: Outlier Detection Using Invariant Coordinate Selection,Multivariate outlier detection is performed using invariant coordinates where the package offers different methods to choose the appropriate components.
pipeGS,2016-11-17,pipeGS: Permutation p-Value Estimation for Gene Set Tests,Code for various permutation p-values estimation methods for gene set test. The description of corresponding methods can be found in the dissertation of Yu He(2016) "Efficient permutation P-value estimation for gene set tests" <https://searchworks.stanford.edu/view/11849351>. One of the methods also corresponds to the paper "Permutation p-value approximation via generalized Stolarsky invariance" <arXiv:1603.02757>.
SpaDES.addins,2017-09-02,SpaDES.addins: Development Tools for 'SpaDES' and 'SpaDES' Modules,Provides 'RStudio' addins for 'SpaDES' packages and 'SpaDES' module
    development. See '?SpaDES.addins' for an overview of the tools provided.
cifti,2017-05-05,cifti: Toolbox for Connectivity Informatics Technology Initiative
('CIFTI') Files,Functions for the input/output and visualization of
    medical imaging data in the form of 'CIFTI' files 
    <https://www.nitrc.org/projects/cifti/>.
gifti,2017-05-05,gifti: Reads in 'Neuroimaging' 'GIFTI' Files with Geometry Information,Functions to read in the geometry format under the 
    'Neuroimaging' 'Informatics' Technology Initiative ('NIfTI'), called 
    'GIFTI' <https://www.nitrc.org/projects/gifti/>. 
    These files contain surfaces of brain imaging data.
modmarg,2017-06-05,modmarg: Calculating Marginal Effects and Levels with Errors,Calculate predicted levels and marginal effects,
    using the delta method to calculate standard errors. This is an R-based
    version of the 'margins' command from Stata.
opticut,2016-12-17,opticut: Likelihood Based Optimal Partitioning and Indicator Species
Analysis,Likelihood based optimal partitioning and indicator
  species analysis. Finding the best binary partition for each species
  based on model selection, with the possibility to take into account
  modifying/confounding variables as described
  in Kemencei et al. (2014) <doi:10.1556/ComEc.15.2014.2.6>.
  The package implements binary and multi-level response models,
  various measures of uncertainty, Lorenz-curve based thresholding,
  with native support for parallel computations.
denoiSeq,2017-07-18,denoiSeq: Differential Expression Analysis Using a Bottom-Up Model,Given count data from two conditions, it determines which transcripts are differentially expressed across the two conditions using Bayesian inference of the parameters of  a bottom-up model for PCR amplification. This model is  developed in Ndifon Wilfred, Hilah Gal, Eric Shifrut, Rina Aharoni, Nissan Yissachar, Nir Waysbort, Shlomit Reich Zeliger, Ruth Arnon, and Nir Friedman (2012), <http://www.pnas.org/content/109/39/15865.full>, and results in a distribution for the counts that is a superposition of the binomial and negative binomial distribution.
nlsr,2017-02-13,nlsr: Functions for Nonlinear Least Squares Solutions,Provides tools for working with nonlinear least squares problems.
      It is intended to eventually supersede the 'nls()' function in the R
      distribution. For example, 'nls()' specifically does NOT deal with small 
      or zero residual problems as its Gauss-Newton method frequently stops with
      'singular gradient' messages. 'nlsr' is based on the now-deprecated package
      'nlmrt', and has refactored functions and R-language symbolic derivative
      features.
OOR,2017-02-03,OOR: Optimistic Optimization in R,Implementation of optimistic optimization methods for global optimization of deterministic or stochastic functions. The algorithms feature guarantees of the convergence to a global optimum. They require minimal assumptions on the (only local) smoothness, where the smoothness parameter does not need to be known. They are expected to be useful for the most difficult functions when we have no information on smoothness and the gradients are unknown or do not exist. Due to the weak assumptions, however, they can be mostly effective only in small dimensions, for example, for hyperparameter tuning.
BeSS,2017-04-20,BeSS: Best Subset Selection in Linear, Logistic and CoxPH Models,An implementation of best subset selection in generalized linear model and Cox proportional hazard model via the primal dual active set algorithm proposed by Wen, C., Zhang, A., Quan, S. and Wang, X. (2017) <arXiv:1709.06254>. The algorithm formulates coefficient parameters and residuals as primal and dual variables and utilizes efficient active set selection strategies based on the complementarity of the primal and dual variables.
ggQC,2017-03-29,ggQC: Quality Control Charts for 'ggplot',Plot single and faceted type quality control charts
  for 'ggplot'.  
RBMRB,2016-11-18,RBMRB: BMRB Data Access and Visualization,The Biological Magnetic Resonance Data Bank (BMRB,<http://
    www.bmrb.wisc.edu/>) collects, annotates, archives, and disseminates (worldwide
    in the public domain) the important spectral and quantitative data derived
    from NMR(Nuclear Magnetic Resonance) spectroscopic investigations of biological
    macromolecules and metabolites. This package provides an interface to BMRB
    database for easy data access and includes a minimal set of data visualization
    functions. Users are encouraged to make their own data visualizations using BMRB
    data.
robustBLME,2017-06-08,robustBLME: Robust Bayesian Linear Mixed-Effects Models using ABC,Bayesian robust fitting of linear mixed effects models through weighted likelihood equations and approximate Bayesian computation as proposed by Ruli et al. (2017) <arXiv:1706.01752>.
spatstat.local,2017-03-30,spatstat.local: Extension to 'spatstat' for Local Composite Likelihood,Extension to the 'spatstat' package, enabling the user
	     to fit point process models to point pattern data
	     by local composite likelihood ('geographically weighted
	     regression').
tibbletime,2017-09-07,tibbletime: Time Aware Tibbles,Built on top of the 'tibble' package, 'tibbletime' is an extension
  that allows for the creation of time aware tibbles. Some immediate
  advantages of this include: the ability to perform time-based subsetting
  on tibbles, quickly summarising and aggregating results by time periods,
  and creating columns that can be used as 'dplyr' time-based groups.
atsd,2016-12-05,atsd: Support Querying Axibase Time-Series Database,Provides functions for retrieving time-series and related
    meta-data such as entities, metrics, and tags from the Axibase
    Time-Series Database (ATSD). ATSD is a non-relational clustered
    database used for storing performance measurements from IT infrastructure
    resources: servers, network devices, storage systems, and applications.
ludic,2016-12-28,ludic: Linkage Using Diagnosis Codes,Probabilistic record linkage without direct identifiers using only diagnosis codes.
phylotate,2017-01-03,phylotate: Phylogenies with Annotations,Functions to read and write APE-compatible phylogenetic
  trees in NEXUS and Newick formats, while preserving annotations.
tRophicPosition,2017-06-12,tRophicPosition: Bayesian Trophic Position Calculation with Stable Isotopes,Estimates the trophic position of a consumer relative 
    to a baseline species. It implements a Bayesian approach which combines an 
    interface to the 'JAGS' MCMC library of 'rjags' and stable isotopes. Users are
    encouraged to test the package and send bugs and/or errors to
    trophicposition-support@googlegroups.com.
waver,2017-01-16,waver: Calculate Fetch and Wave Energy,Functions for calculating the
    fetch (length of open water distance along given directions)
    and estimating wave energy from wind and wave monitoring data.
clustRcompaR,2017-01-07,clustRcompaR: Easy Interface for Clustering a Set of Documents and Exploring
Group- Based Patterns,Provides an interface to perform cluster analysis on a corpus of
    text. Interfaces to Quanteda to assemble text corpuses easily. Deviationalizes
    text vectors prior to clustering using technique described by Sherin (Sherin,
    B. [2013]. A computational study of commonsense science: An exploration in the
    automated analysis of clinical interview data. Journal of the Learning Sciences,
    22(4), 600-638. Chicago. <doi:10.1080/10508406.2013.836654>). Uses
    cosine similarity as distance metric for two stage clustering process, involving
    Ward's algorithm hierarchical agglomerative clustering, and k-means clustering.
    Selects optimal number of clusters to maximize "variance explained" by clusters,
    adjusted by the number of clusters. Provides plotted output of clustering
    results as well as printed output. Assesses "model fit" of clustering solution
    to a set of preexisting groups in dataset.
libsoc,2017-02-11,libsoc: Read, Create and Write 'PharmML' Standard Output (so) XML Files,Handle 'PharmML' (Pharmacometrics Markup Language) standard output (SO) XML files.
    SO files can be created, read, manipulated and written through a
    data binding from the XML structure to a tree structure of R objects.
zeallot,2017-01-27,zeallot: Multiple, Unpacking, and Destructuring Assignment,Provides a %<-% operator to perform multiple,
    unpacking, and destructuring assignment in R. The 
    operator unpacks the right-hand side of an assignment
    into multiple values and assigns these values to 
    variables on the left-hand side of the assignment.
ANOVAreplication,2017-04-24,ANOVAreplication: Test ANOVA Replications by Means of the Prior Predictive p-Value,Allows for the computation of a prior predictive p-value to test replication of relevant features of original ANOVA studies. Relevant features are captured in informative hypotheses. The package also allows for the computation of sample sizes for new studies, post-hoc power calculations, and comes with a Shiny application in which all calculations can be conducted as well. 
bigtcr,2016-10-30,bigtcr: Nonparametric Analysis of Bivariate Gap Time with Competing
Risks,For studying recurrent disease and death with competing
    risks, comparisons based on the well-known cumulative incidence function
    can be confounded by different prevalence rates of the competing events.
    Alternatively, comparisons of the conditional distribution of the survival
    time given the failure event type are more relevant for investigating the
    prognosis of different patterns of recurrence disease. This package implements
    a nonparametric estimator for the conditional cumulative incidence function
    and a nonparametric conditional bivariate cumulative incidence function for the
    bivariate gap times proposed in Huang et al. (2016) <doi:10.1111/biom.12494>.
kokudosuuchi,2016-11-07,kokudosuuchi: R Interface to 'Kokudo Suuchi' API,Provides an interface to 'Kokudo Suuchi' API, the GIS data service of the Japanese government.
    See <http://nlftp.mlit.go.jp/ksj-e/index.html> for more information.
languagelayeR,2016-12-20,languagelayeR: Access the 'languagelayer' API,Improve your text analysis with languagelayer
        <https://languagelayer.com>, a powerful language detection
        API.
censusr,2016-12-05,censusr: Collect Data from the Census API,Use the US Census API to collect summary data tables
    for SF1 and ACS datasets at arbitrary geographies.
diagis,2016-10-29,diagis: Diagnostic Plot and Multivariate Summary Statistics of Weighted
Samples from Importance Sampling,Fast functions for effective sample size, weighted multivariate mean and variance computation, 
    and weight diagnostic plot for generic importance sampling type results.
finch,2016-12-23,finch: Parse Darwin Core Files,Parse and create Darwin Core (<http://rs.tdwg.org/dwc/>) Simple
    and Archives. Functionality includes reading and parsing all the
    files in a Darwin Core Archive, including the datasets and metadata;
    read and parse simple Darwin Core files; and validation of Darwin
    Core Archives.
gradDescent,2016-12-29,gradDescent: Gradient Descent for Regression Tasks,An implementation of various learning algorithms based on Gradient Descent for dealing with regression tasks. 
	The variants of gradient descent algorithm are :
	Mini-Batch Gradient Descent (MBGD), which is an optimization to use training data partially to reduce the computation load.
	Stochastic Gradient Descent (SGD), which is an optimization to use a random data in learning to reduce the computation load drastically.
	Stochastic Average Gradient (SAG), which is a SGD-based algorithm to minimize stochastic step to average.
	Momentum Gradient Descent (MGD), which is an optimization to speed-up gradient descent learning.
	Accelerated Gradient Descent (AGD), which is an optimization to accelerate gradient descent learning.
	Adagrad, which is a gradient-descent-based algorithm that accumulate previous cost to do adaptive learning.
	Adadelta, which is a gradient-descent-based algorithm that use hessian approximation to do adaptive learning.
	RMSprop, which is a gradient-descent-based algorithm that combine Adagrad and Adadelta adaptive learning ability.
	Adam, which is a gradient-descent-based algorithm that mean and variance moment to do adaptive learning.
	Stochastic Variance Reduce Gradient (SVRG), which is an optimization SGD-based algorithm to accelerates the process toward converging by reducing the gradient.
	Semi Stochastic Gradient Descent (SSGD),which is a SGD-based algorithm that combine GD and SGD to accelerates the process toward converging by choosing one of the gradients at a time.
	Stochastic Recursive Gradient Algorithm (SARAH), which is an optimization algorithm similarly SVRG to accelerates the process toward converging by accumulated stochastic information.
	Stochastic Recursive Gradient Algorithm+ (SARAHPlus), which is a SARAH practical variant algorithm to accelerates the process toward converging provides a possibility of earlier termination.
heims,2017-06-21,heims: Decode and Validate HEIMS Data from Department of Education,
Australia,Decode elements of the Australian Higher Education Information Management System (HEIMS) data for clarity and performance. HEIMS is the record system of the Department of Education, Australia to record enrolments and completions in Australia's higher education system, as well as a range of relevant information. For more information, including the source of the data dictionary, see <http://heimshelp.education.gov.au/sites/heimshelp/dictionary/pages/data-element-dictionary>.
datapasta,2016-11-29,datapasta: R Tools for Data Copy-Pasta,RStudio addins and R functions that make copy-pasting vectors and tables to text painless.
highlightHTML,2017-01-02,highlightHTML: Highlight HTML Text and Tables,A tool to format R markdown with CSS ids for HTML output. 
    The tool may be most helpful for those using markdown to create reproducible
    documents. The biggest limitations in formatting is the knowledge of CSS
    by the document authors.
TCIApathfinder,2017-08-20,TCIApathfinder: Client for the Cancer Imaging Archive REST API,A wrapper for The Cancer Imaging Archive's REST API. The Cancer
    Imaging Archive (TCIA) hosts de-identified medical images of cancer
    available for public download, as well as rich metadata for each image
    series. TCIA provides a REST API for programmatic access to the data.
    This package provides simple functions to access each API endpoint.
    For more information, see <https://github.com/pamelarussell/TCIApathfinder>
    and TCIA's website.
BibPlots,2017-07-14,BibPlots: Plot Functions for Use in Bibliometrics,Currently, the package provides two functions for plotting and analyzing bibliometric data (JIF, Journal Impact Factor, and paper percentile values) and a plot function to visualize the result of a reference publication year spectroscopy (RPYS) analysis performed in the free software 'CRExplorer' (see <http://crexplorer.net>). Further extension to more plot variants is planned.
Xplortext,2017-05-25,Xplortext: Statistical Analysis of Textual Data,Provides a set of functions devoted to multivariate exploratory statistics on textual data. Classical methods such as correspondence analysis and agglomerative hierarchical clustering are available. Chronologically constrained agglomerative hierarchical clustering enriched with labelled-by-words trees is offered. Given a division of the corpus into parts, their characteristic words and documents are identified. Further, accessing to 'FactoMineR' functions is very easy. Two of them are relevant in textual domain. MFA() addresses multiple lexical table allowing applications such as dealing with multilingual corpora as well as simultaneously analyzing both open-ended and closed questions in surveys. CaGalt() helps to explore the relationships between lexical choices and contextual variables. See <http://www.Xplortext.org> for examples.
gLRTH,2017-01-05,gLRTH: Genome-Wide Association and Linkage Analysis under Heterogeneity,Likelihood ratio tests for genome-wide association and genome-wide linkage analysis under heterogeneity. 
OmicsPLS,2017-05-09,OmicsPLS: Perform Two-Way Orthogonal Partial Least Squares,Performs the O2PLS data integration method for two datasets yielding joint and data-specific parts for each dataset.
    The algorithm automatically switches to a memory-efficient approach to fit O2PLS to high dimensional data.
    It provides a rigorous and a faster alternative cross-validation method to select the number of components,
    as well as functions to report proportions of explained variation and to construct plots of the results.
    See Trygg and Wold (2003) <doi:10.1002/cem.775> and el Bouhaddani et al (2016) <doi:10.1186/s12859-015-0854-z>.
pals,2016-12-14,pals: Color Palettes, Colormaps, and Tools to Evaluate Them,A comprehensive collection of color palettes, colormaps, and tools to evaluate them.
CreditRisk,2017-09-12,CreditRisk: Evaluation of Credit Risk with Structural and Reduced Form
Models,Evaluation of default probability of sovereign and corporate entities based on structural or intensity based models and calibration on market Credit Default Swap quotes. Damiano Brigo, Massimo Morini, Andrea Pallavicini (2013): "Counterparty Credit Risk, Collateral and Funding. With Pricing Cases for All Asset Classes".
LinkageMapView,2017-02-06,LinkageMapView: Plot Linkage Group Maps with Quantitative Trait Loci,Produces high resolution, publication ready linkage maps
    and quantitative trait loci maps. Input can be output from 'R/qtl',
    simple text or comma delimited files. Output is currently
    a portable document file.
nofrills,2017-07-23,nofrills: Low-Cost Anonymous Functions,Provides a compact variation of the usual syntax of function
  declaration, in order to support tidyverse-style quasiquotation of a
  function's arguments and body.
rMR,2017-01-06,rMR: Importing Data from Loligo Systems Software, Calculating
Metabolic Rates and Critical Tensions,Analysis of oxygen consumption data generated by Loligo (R) Systems respirometry equipment. The package includes a function for loading data output by Loligo's 'AutoResp' software (get.witrox.data()), functions for calculating metabolic rates over user-specified time intervals, extracting critical points from data using broken stick regressions based on Yeager and Ultsch (<doi:10.1086/physzool.62.4.30157935>), and easy functions for converting between different units of barometric pressure.
tropAlgebra,2017-08-01,tropAlgebra: Tropical Algebraic Functions,It includes functions like tropical addition, tropical multiplication for vectors and matrices. In tropical algebra, the tropical sum of two numbers is their minimum and the tropical product of two numbers is their ordinary sum. For more information see also I. Simon (1988) Recognizable sets with multiplicities in the tropical semi ring: Volume 324 Lecture Notes I Computer Science, pages 107-120 <doi:10.1007/BFb0017135>.
dat,2017-01-07,dat: Tools for Data Manipulation,An implementation of common higher order functions with syntactic
    sugar for anonymous function. Provides also a link to 'dplyr' for common
    transformations on data frames to work around non standard evaluation by
    default.
equSA,2017-02-22,equSA: Estimate Directed and Undirected Graphical Models and Construct
Networks,Provides an equivalent measure of partial correlation coefficients for high-dimensional Gaussian Graphical Models to learn and visualize the underlying relationships between variables from single or multiple datasets. You can refer to Liang, F., Song, Q. and Qiu, P. (2015) <doi:10.1080/01621459.2015.1012391> for more detail. Based on this method, the package also provides the method for constructing networks for Next Generation Sequencing Data, for jointly estimating multiple Gaussian Graphical Models and constructing directed acyclic graph (Bayesian Network).
abjutils,2017-01-04,abjutils: Useful Tools for Jurimetrical Analysis Used by the Brazilian
Jurimetrics Association,The Brazilian Jurimetrics Association (ABJ in Portuguese,
  see <http://www.abjur.org.br/en/> for more information) is a non-profit
  organization which aims to investigate and promote the use of
  statistics and probability in the study of Law and its institutions.
  This package implements general purpose tools used by ABJ, such as functions
  for sampling and basic manipulation of Brazilian lawsuits identification
  number. It also implements functions for text cleaning, such as accentuation removal.
lbreg,2016-12-20,lbreg: Log-Binomial Regression with Constrained Optimization,Maximum likelihood estimation of log-binomial regression with special functionality when the MLE is on the boundary of the parameter space.
PSW,2017-09-22,PSW: Propensity Score Weighting Methods for Dichotomous Treatments,Provides propensity score weighting methods to control for confounding in causal inference with dichotomous treatments and continuous/binary outcomes. It includes the following functional modules: (1) visualization of the propensity score distribution in both treatment groups with mirror histogram, (2) covariate balance diagnosis, (3) propensity score model specification test, (4) weighted estimation of treatment effect, and (5) augmented estimation of treatment effect with outcome regression. The weighting methods include the inverse probability weight (IPW) for estimating the average treatment effect (ATE), the IPW for average treatment effect of the treated (ATT), the IPW for the average treatment effect of the controls (ATC), the matching weight (MW), the overlap weight (OVERLAP), and the trapezoidal weight (TRAPEZOIDAL). Sandwich variance estimation is provided to adjust for the sampling variability of the estimated propensity score. These methods are discussed by Hirano et al (2003) <doi:10.1111/1468-0262.00442>, Lunceford and Davidian (2004) <doi:10.1002/sim.1903>, Li and Greene (2013) <doi:10.1515/ijb-2012-0030>, and Li et al (2016) <doi:10.1080/01621459.2016.1260466>.
RNAseqNet,2017-04-19,RNAseqNet: Log-Linear Poisson Graphical Model with Hot-Deck Multiple
Imputation,Infer log-linear Poisson Graphical Model with an auxiliary data
    set. Hot-deck multiple imputation method is used to improve the reliability
    of the inference with an auxiliary dataset. Standard log-linear Poisson 
    graphical model can also be used for the inference and the Stability 
    Approach for Regularization Selection (StARS) is implemented to drive the 
    selection of the regularization parameter. The method is fully described in
    <doi:10.1093/bioinformatics/btx819>.
rrpack,2017-06-22,rrpack: Reduced-Rank Regression,Multivariate regression methodologies including reduced-rank
    regression (RRR), reduced-rank ridge regression (RRS), robust reduced-rank
    regression (R4), generalized/mixed-response reduced-rank regression (mRRR),
    row-sparse reduced-rank regression (SRRR), reduced-rank regression with a
    sparse singular value decomposition (RSSVD), and sparse and orthogonal
    factor regression (SOFAR).
canprot,2017-06-13,canprot: Chemical Composition of Differential Protein Expression,Datasets are collected here for differentially (up- and down-)
        expressed proteins identified in proteomic studies of cancer and in cell
        culture experiments. Tables of amino acid compositions of proteins are
        used for calculations of chemical composition, projected into selected
        basis species. Plotting functions are used to visualize the compositional
        differences and thermodynamic potentials for proteomic transformations.
dtree,2017-04-20,dtree: Decision Trees,Combines various decision tree algorithms, plus both
             linear regression and ensemble methods into one package.
             Allows for the use of both continuous and categorical outcomes.
             An optional feature is to quantify the (in)stability to the
             decision tree methods, indicating when results can be trusted
             and when ensemble methods may be preferential.
SMMA,2017-03-30,SMMA: Soft Maximin Estimation for Large Scale Array-Tensor Models,Efficient design matrix free procedure for solving a soft maximin problem for  large scale array-tensor structured models. Currently Lasso and SCAD penalized estimation is implemented.
mau,2017-07-18,mau: Decision Models with Multi Attribute Utility Theory,Provides functions for the creation, evaluation and test of decision models based in
    Multi Attribute Utility Theory (MAUT). Can process and evaluate local risk aversion utilities
    for a set of indexes, compute utilities and weights for the whole decision tree defining the
    decision model and simulate weights employing Dirichlet distributions under addition constraints 
    in weights.
optimus,2017-03-24,optimus: Model Based Diagnostics for Multivariate Cluster Analysis,Assessment and diagnostics for comparing competing
    clustering solutions, using predictive models. The main intended
    use is for comparing clustering/classification solutions of
    ecological data (e.g. presence/absence, counts, ordinal scores) to
    1) find an optimal partitioning solution, 2) identify
    characteristic species and 3) refine a classification by merging
    clusters that increase predictive performance. However, in a more
    general sense, this package can do the above for any set of
    clustering solutions for i observations of j variables.
ROI.plugin.lpsolve,2016-12-19,ROI.plugin.lpsolve: 'lp_solve' Plugin for the 'R' Optimization Infrastructure,Enhances the 'R' Optimization Infrastructure ('ROI') package
             with the 'lp_solve' solver.
splashr,2017-08-29,splashr: Tools to Work with the 'Splash' 'JavaScript' Rendering and
Scraping Service,'Splash' <https://github.com/scrapinghub/splash> is a 'JavaScript' rendering service.
    It is a lightweight web browser with an 'HTTP' API, implemented in 'Python' using 'Twisted' 
    and 'QT' and provides some of the core functionality of the 'RSelenium' or 'seleniumPipes'
    R packages in a lightweight footprint. Some of 'Splash' features include the ability to process 
    multiple web pages in parallel; retrieving 'HTML' results and/or take screen shots; disabling 
    images or use 'Adblock Plus' rules to make rendering faster; executing custom 'JavaScript' in 
    page context; getting detailed rendering info in 'HAR' format.
easySdcTable,2016-12-30,easySdcTable: Easy Interface to the Statistical Disclosure Control Package
'sdcTable',The main function, ProtectTable(), performs table suppression according to a 
 frequency rule with a data set as the only required input. Within this function, 
 protectTable(), protectLinkedTables() or runArgusBatchFile() in package 'sdcTable' is called. 
 Lists of level-hierarchy (parameter 'dimList') and other required input to these functions 
 are created automatically. 
 The function, PTgui(), starts a graphical user interface based on the shiny package.
COMBAT,2017-01-11,COMBAT: A Combined Association Test for Genes using Summary Statistics,Genome-wide association studies (GWAS) have been widely used for identifying common variants associated with complex diseases. Due to the small effect sizes of common variants, the power to detect individual risk variants is generally low. Complementary to SNP-level analysis, a variety of gene-based association tests have been proposed. However, the power of existing gene-based tests is often dependent on the underlying genetic models, and it is not known a priori which test is optimal.  Here we proposed COMBined Association Test (COMBAT) to incorporate strengths from multiple existing gene-based tests, including VEGAS, GATES and simpleM. Compared to individual tests, COMBAT shows higher overall performance and robustness across a wide range of genetic models. The algorithm behind this method is described in Wang et al (2017) <doi:10.1534/genetics.117.300257>.
cordillera,2017-07-25,cordillera: Calculation of the OPTICS Cordillera,Functions for calculating the OPTICS Cordillera. The OPTICS Cordillera measures the amount of 'clusteredness' in a numeric data matrix within a distance-density based framework for a given minimum number of points comprising a cluster, as described in Rusch, Hornik, Mair (2017) <doi:10.1080/10618600.2017.1349664>. There is an R native version and a version that uses 'ELKI', with methods for printing, summarizing, and plotting the result. There also is an interface to the reference implementation of OPTICS in 'ELKI'.
photobiologyLEDs,2016-10-23,photobiologyLEDs: Spectral Data for Light-Emitting-Diodes,Spectral emission data for some frequently used light emitting
    diodes.
Emcdf,2017-06-02,Emcdf: Computation and Visualization of Empirical Joint Distribution
(Empirical Joint CDF),Computes and visualizes empirical joint distribution of multivariate data with optimized algorithms and multi-thread computation. There is a faster algorithm using dynamic programming to compute the whole empirical joint distribution of a bivariate data. There are optimized algorithms for computing empirical joint CDF function values for other multivariate data. Visualization is focused on bivariate data. Levelplots and wireframes are included.
preText,2016-10-08,preText: Diagnostics to Assess the Effects of Text Preprocessing
Decisions,Functions to assess the effects of different text preprocessing decisions on the inferences drawn from the resulting document-term matrices they generate.
PRIMME,2017-04-13,PRIMME: Eigenvalues and Singular Values and Vectors from Large Matrices,
    R interface to PRIMME, a C library for computing a few
    eigenvalues and their corresponding eigenvectors of a real symmetric or complex
    Hermitian matrix.  It can also compute singular values and vectors of a square
    or rectangular matrix.  It can find largest, smallest, or interior
    singular/eigenvalues and can use preconditioning to accelerate convergence. 
rSQM,2017-09-25,rSQM: Statistical Downscaling Toolkit for Climate Change Scenario
using Non Parametric Quantile Mapping,Conducts statistical downscaling of daily CMIP5 (Coupled Model Intercomparison Project 5) climate change scenario data at a station level using empirical quantile mapping method by Jaepil Cho et al. (2016) <doi:10.1002/ird.2035>.
tsdf,2017-09-06,tsdf: Two-/Three-Stage Designs for Phase 1&2 Clinical Trials,Calculate optimal Zhong's two-/three-stage Phase II designs (see Zhong (2012) <doi:10.1016/j.cct.2012.07.006>). Generate Target Toxicity decision table for Phase I dose-finding (Two-/three-stage). This package also allows users to run dose-finding simulations based on customized decision table. 
brant,2017-03-18,brant: Test for Parallel Regression Assumption,Tests the parallel regression assumption for ordinal logit models generated with the function polr() from the package 'MASS'.
IATScore,2017-04-26,IATScore: Scoring Algorithm for the Implicit Association Test (IAT),This minimalist package is designed to quickly score raw data outputted from an Implicit Association Test (IAT; Greenwald, McGhee, & Schwartz, 1998) <doi:10.1037/0022-3514.74.6.1464>. IAT scores are calculated as specified by Greenwald, Nosek, and Banaji (2003) <doi:10.1037/0022-3514.85.2.197>. Outputted values can be interpreted as effect sizes. The input function consists of three arguments. First, indicate the name of the dataset to be analyzed. This is the only required input. Second, indicate the number of trials in your entire IAT (the default is set to 219, which is typical for most IATs). Last, indicate whether congruent trials (e.g., flowers and pleasant) or incongruent trials (e.g., guns and pleasant) were presented first for this participant (the default is set to congruent). The script will tell you how long it took to run the code, the effect size for the participant, and whether that participant should be excluded based on the criteria outlined by Greenwald et al. (2003). Data files should consist of six columns organized in order as follows: Block (0-6), trial (0-19 for training blocks, 0-39 for test blocks), category (dependent on your IAT), the type of item within that category (dependent on your IAT), a dummy variable indicating whether the participant was correct or incorrect on that trial (0=correct, 1=incorrect), and the participant’s reaction time (in milliseconds). Three sample datasets are included in this package (labeled 'IAT', 'TooFastIAT', and 'BriefIAT') to practice with.
influxdbr,2017-07-13,influxdbr: R Interface to InfluxDB,An R interface to the InfluxDB time series database <https://www.influxdata.com>. This package allows you to fetch and write time series data from/to an InfluxDB server. Additionally, handy wrappers for the Influx Query Language (IQL) to manage and explore a remote database are provided. 
MultiRNG,2017-06-04,MultiRNG: Multivariate Pseudo-Random Number Generation,Pseudo-random number generation for 11 multivariate distributions: Normal, t, Uniform, Bernoulli, Hypergeometric, Beta (Dirichlet), Multinomial, Dirichlet-Multinomial, Laplace, Wishart, and Inverted Wishart.
RandPro,2017-01-11,RandPro: Random Projection with Classification,Performs random projection using Johnson-Lindenstrauss (JL) Lemma (see William B.Johnson and Joram Lindenstrauss (1984) <doi:10.1090/conm/026/737400>). Random Projection is a dimension reduction technique, where the data in the high dimensional space is projected into the low dimensional space using JL transform. The original high dimensional data matrix is multiplied with the low dimensional projection matrix which results in reduced matrix. The projection matrix can be generated using the projection function that is independent to the original data. Then finally apply the classification task on the projected data.  
rFSA,2016-10-18,rFSA: Feasible Solution Algorithm for Finding Best Subsets and
Interactions,Assists in statistical model building to find optimal and semi-optimal higher order interactions
    and best subsets. Uses the lm(), glm(), and other R functions to fit models generated from a feasible 
    solution algorithm. Discussed in Subset Selection in Regression, A Miller (2002). Applied and explained
    for least median of squares in Hawkins (1993) <doi:10.1016/0167-9473(93)90246-P>. The feasible solution 
    algorithm comes up with model forms of a specific type that can have fixed variables, higher order 
    interactions and their lower order terms.
UnivRNG,2017-05-23,UnivRNG: Univariate Pseudo-Random Number Generation,Pseudo-random number generation of 17 univariate distributions.
elevatr,2017-01-26,elevatr: Access Elevation Data from Various APIs,Several web services are available that provide access to elevation
             data. This package provides access to several of those services and 
             returns elevation data either as a SpatialPointsDataFrame from 
             point elevation services or as a raster object from raster 
             elevation services.  Currently, the package supports access to the
             Mapzen Elevation Service <https://mapzen.com/documentation/elevation/elevation-service/>, 
             Mapzen Terrain Service <https://mapzen.com/documentation/terrain-tiles/>,
             Amazon Web Services Terrain Tiles <https://aws.amazon.com/public-datasets/terrain/> and the USGS
             Elevation Point Query Service <http://ned.usgs.gov/epqs/>.
Rbgs,2017-06-06,Rbgs: Reading and Background Subtraction in Videos,Methods that allow video reading and loading in R. Also provides nine different methods for  background subtraction.
RGBM,2017-02-21,RGBM: LS-TreeBoost and LAD-TreeBoost for Gene Regulatory Network
Reconstruction,Provides an implementation of Regularized LS-TreeBoost & LAD-TreeBoost algorithm for Regulatory Network inference from any type of expression data (Microarray/RNA-seq etc). See Mall et al (2017) <doi:10.1101/132670>.
univOutl,2017-06-13,univOutl: Detection of Univariate Outliers,Well known outlier detection techniques in the univariate case. Methods to deal with skewed distribution are included too. The Hidiroglou-Berthelot (1986) method to search for outliers in ratios of historical data is implemented as well. When available, survey weights can be used in outliers detection.
constants,2017-07-17,constants: Reference on Constants, Units and Uncertainty,CODATA internationally recommended values of the fundamental physical 
    constants, provided as symbols for direct use within the R language. Optionally, 
    the values with errors and/or the values with units are also provided if the 
    'errors' and/or the 'units' packages are installed. The Committee on Data
    for Science and Technology (CODATA) is an interdisciplinary committee of the
    International Council for Science which periodically provides the internationally 
    accepted set of values of the fundamental physical constants. This package 
    contains the "2014 CODATA" version, published on 25 June 2015:
    Mohr, P. J., Newell, D. B. and Taylor, B. N. (2016)
    <doi:10.1103/RevModPhys.88.035009>, <doi:10.1063/1.4954402>.
csv,2017-02-18,csv: Read and Write CSV Files with Selected Conventions,Reads and writes CSV with selected conventions.
 Uses the same generic function for reading and writing to promote consistent formats.
dynsbm,2017-02-24,dynsbm: Dynamic Stochastic Block Models,Dynamic stochastic block model that combines a stochastic block model (SBM) for its static part with independent Markov chains for the evolution of the nodes groups through time, developed in  Matias and Miele (2016) <doi:10.1111/rssb.12200>.
sgee,2016-10-17,sgee: Stagewise Generalized Estimating Equations,Stagewise techniques implemented with Generalized Estimating Equations to handle individual, group, bi-level, and interaction selection. Stagewise approaches start with an empty model and slowly build the model over several iterations, which yields a 'path' of candidate models from which model selection can be performed. This 'slow brewing' approach gives stagewise techniques a unique flexibility that allows simple incorporation of Generalized Estimating Equations; see Vaughan, G., Aseltine, R., Chen, K., Yan, J., (2017) <doi:10.1111/biom.12669> for details.
grove,2017-02-05,grove: Wavelet Functional ANOVA Through Markov Groves,Functional denoising and functional ANOVA through wavelet-domain 
  Markov groves. Fore more details see: Ma L. and Soriano J. (2016) 
  Efficient functional ANOVA through wavelet-domain Markov groves. 
  <arXiv:1602.03990v2 [stat.ME]>.
fmbasics,2017-02-12,fmbasics: Financial Market Building Blocks,Implements basic financial market objects like currencies, currency
  pairs, interest rates and interest rate indices. You will be able to use
  Benchmark instances of these objects which have been defined using their most
  common conventions or those defined by International Swap Dealer Association
  (ISDA, <https://www.isda.org>) legal documentation. 
MatManlyMix,2017-08-05,MatManlyMix: Matrix Clustering with Gaussian and Manly Mixture Models,Matrix clustering with finite mixture models.
fastrtext,2017-09-15,fastrtext: 'fastText' Wrapper for Text Classification and Word
Representation,Learning text representations and text classifiers may rely
  on the same simple and efficient approach. 'fastText' is an open-source, free, 
  lightweight library that allows users to perform both tasks.
  It transforms text into continuous vectors that can later
  be used on many language related task.
  It works on standard, generic hardware (no 'GPU' required).
  It also includes model size reduction feature.
  'fastText' original source code is available 
  at <https://github.com/facebookresearch/fastText>.
fmdates,2017-01-08,fmdates: Financial Market Date Calculations,Implements common date calculations relevant for specifying
  the economic nature of financial market contracts that are typically defined
  by International Swap Dealer Association (ISDA, <http://www2.isda.org>) legal
  documentation. This includes methods to check whether dates are business
  days in certain locales, functions to adjust and shift dates and time length
  (or day counter) calculations.
ipft,2017-02-15,ipft: Indoor Positioning Fingerprinting Toolset,Algorithms and utility functions for indoor positioning using fingerprinting techniques. 
    These functions are designed for manipulation of RSSI (Received Signal Strength Intensity) data 
    sets, estimation of positions,comparison of the performance of different models, and graphical 
    visualization of data. Machine learning algorithms and methods such as k-nearest neighbors or
    probabilistic fingerprinting are implemented in this package to perform analysis
    and estimations over RSSI data sets.
SparseDC,2017-05-02,SparseDC: Implementation of SparseDC Algorithm,Implements the algorithm described in 
    Barron, M., Zhang, S. and Li, J. 2017, "A sparse differential
    clustering algorithm for tracing cell type changes via single-cell
    RNA-sequencing data", Nucleic Acids Research, gkx1113,
    <doi:10.1093/nar/gkx1113>. This algorithm clusters samples from two
    different populations, links the clusters across the conditions and
    identifies marker genes for these changes. The package was designed for
    scRNA-Seq data but is also applicable to many other data types, just
    replace cells with samples and genes with variables. The package also
    contains functions for estimating the parameters for SparseDC as outlined
    in the paper. We recommend that users further select their marker genes
    using the magnitude of the cluster centers.
tidystringdist,2017-09-29,tidystringdist: String Distance Calculation with Tidy Data Principles,Calculation of string distance following the tidy data principles. Built on top 
  of the 'stringdist' package.
Biolinv,2017-02-03,Biolinv: Modelling and Forecasting Biological Invasions,Analysing and forecasting biological invasions time series
    with a stochastic, non-mechanistic approach that gives proper weight
    to the anthropic component, accounts for habitat suitability and
    provides measures of precision for its estimates.
miRNAss,2017-05-06,miRNAss: Genome-Wide Discovery of Pre-miRNAs with few Labeled Examples,Machine learning method specifically designed for
    pre-miRNA prediction. It takes advantage of unlabeled sequences to improve
    the prediction rates even when there are just a few positive examples, when
    the negative examples are unreliable or are not good representatives of
    its class. Furthermore, the method can automatically search for negative
    examples if the user is unable to provide them. MiRNAss can find a good
    boundary to divide the pre-miRNAs from other groups of sequences; it
    automatically optimizes the threshold that defines the classes boundaries,
    and thus, it is robust to high class imbalance. Each step of the method is
    scalable and can handle large volumes of data.
naivebayes,2017-01-05,naivebayes: High Performance Implementation of the Naive Bayes Algorithm,High performance implementation of the Naive Bayes algorithm.
sofa,2016-10-13,sofa: Connector to 'CouchDB',Provides an interface to the 'NoSQL' database 'CouchDB'
    (<http://couchdb.apache.org>). Methods are provided for managing
    databases within 'CouchDB', including creating/deleting/updating/transferring,
    and managing documents within databases. One can connect with a local
    'CouchDB' instance, or a remote 'CouchDB' databases such as 'Cloudant'
    (<https://docs.cloudant.com>). Documents can be inserted directly from
    vectors, lists, data.frames, and 'JSON'. Targeted at 'CouchDB' v2 or
    greater.
bhm,2016-10-12,bhm: Biomarker Threshold Models,Contains tools to fit both predictive and prognostic biomarker effects using biomarker threshold models. Evaluate the treatment effect, biomarker effect and treatment-biomarker interaction using probability index measurement. Test for treatment-biomarker interaction using residual bootstrap method.
rxylib,2017-06-30,rxylib: Import XY-Data into R,Provides access to the 'xylib' C library for to import xy 
  data from powder diffraction, spectroscopy and other experimental methods.
widgetframe,2017-02-27,widgetframe: 'Htmlwidgets' in Responsive 'iframes',Provides two functions 'frameableWidget()', and 'frameWidget()'.
  The 'frameableWidget()' is used to add extra code to a 'htmlwidget' which
  allows is to be rendered correctly inside a responsive 'iframe'.
  The 'frameWidget()' is a 'htmlwidget' which displays content of another 'htmlwidget'
  inside a responsive 'iframe'.
  These functions allow for easier embedding of 'htmlwidgets' in content management systems
  such as 'wordpress', 'blogger' etc.
  They also allow for separation of widget content from main HTML content where
  CSS of the main HTML could interfere with the widget.
msde,2017-07-06,msde: Bayesian Inference for Multivariate Stochastic Differential
Equations,Implements an MCMC sampler for the posterior distribution of arbitrary time-homogeneous multivariate stochastic differential equation (SDE) models with possibly latent components.  The package provides a simple entry point to integrate user-defined models directly with the sampler's C++ code, and parallelizes large portions of the calculations when compiled with 'OpenMP'.
mudfold,2017-03-30,mudfold: Multiple UniDimensional unFOLDing,Nonparametric item response theory (IRT) model for nonmonotonic IRFs, which is fruitful for scale analysis of proximity items.
AmesHousing,2017-09-26,AmesHousing: The Ames Iowa Housing Data,Raw and processed versions of the data from De Cock (2011) <http://ww2.amstat.org/publications/jse> are included in the package. 
PKPDmisc,2017-08-22,PKPDmisc: Pharmacokinetic and Pharmacodynamic Data Management Functions,A toolbox for data management common to pharmacokinetic and
  pharmacokinetic modeling and simulation, such as resampling,
  area-under-the-curve calculation, data chunking, custom csv
  output, and project scaffolding.
stringformattr,2016-12-05,stringformattr: Dynamic String Formatting,Pass named and unnamed character vectors into specified positions
    in strings. This represents an attempt to replicate some of python's string
    formatting.
SyncRNG,2016-10-16,SyncRNG: A Synchronized Tausworthe RNG for R and Python,Random number generation designed for cross-language usage.
zonator,2017-07-09,zonator: Utilities for Zonation Spatial Conservation Prioritization
Software,Create new analysis setups and deal with results of 
    Zonation conservation prioritization software <https://github.com/cbig/zonation-core>. 
    This package uses data available in the 'zdat' (7.7 MB) package 
    for building the vignettes.
cleanEHR,2017-02-02,cleanEHR: The Critical Care Clinical Data Processing Tools,An electronic health care record (EHR) data cleaning and processing
    platform. It focus on heterogeneous high resolution longitudinal data. It works with 
    Critical Care Health Informatics Collaborative (CCHIC) dataset. It is
    created to address various data reliability and accessibility problems of
    EHRs as such. 
gofastr,2017-01-01,gofastr: Fast DocumentTermMatrix and TermDocumentMatrix Creation,Harness the power of 'quanteda', 'data.table' & 'stringi' to quickly generate 'tm' DocumentTermMatrix
             and TermDocumentMatrix data structures.
BisRNA,2017-04-12,BisRNA: Analysis of RNA Cytosine-5 Methylation,Bisulfite-treated RNA non-conversion in a set of samples is
  analysed as follows : each sample's non-conversion distribution is
  identified to a Poisson distribution. P-values adjusted for multiple
  testing are calculated in each sample. Combined non-conversion P-values
  and standard errors are calculated on the intersection of the set of
  samples. For further details, see C Legrand, F Tuorto, M Hartmann, 
  R Liebers, D Jakob, M Helm and F Lyko (2017) <doi:10.1101/gr.210666.116>.
clustEff,2017-09-26,clustEff: Clusters of Effects Curves in Quantile Regression Models,Clustering method to cluster both effects curves, through quantile regression coefficient modeling, and curves in functional data analysis. Sottile G. and Adelfio G. (2017) <https://iwsm2017.webhosting.rug.nl/IWSM_2017_V2.pdf>.
GMAC,2017-04-09,GMAC: Genomic Mediation Analysis with Adaptive Confounding Adjustment,Performs genomic mediation
    analysis with adaptive confounding adjustment (GMAC) proposed by Yang et al. (2017) <doi:10.1101/078683>. It implements large scale
    mediation analysis and adaptively selects potential confounding variables to
    adjust for each mediation test from a pool of candidate confounders. The package
    is tailored for but not limited to genomic mediation analysis (e.g., cis-gene
    mediating trans-gene regulation pattern where an eQTL, its cis-linking gene
    transcript, and its trans-gene transcript play the roles as treatment, mediator
    and the outcome, respectively), restricting to scenarios with the presence of
    cis-association (i.e., treatment-mediator association) and random eQTL (i.e.,
    treatment).
elo,2017-08-16,elo: Elo Ratings,A flexible framework for calculating Elo ratings and resulting
    rankings of any two-team-per-matchup system (chess, sports leagues, 'Go',
    etc.). This implementation is capable of evaluating a variety of matchups,
    Elo rating updates, and win probabilities, all based on the basic Elo
    rating system.
libcoin,2016-12-09,libcoin: Linear Test Statistics for Permutation Inference,Basic infrastructure for linear test statistics and permutation
  inference in the framework of Strasser and Weber (1999) <http://epub.wu.ac.at/102/>. 
  This package must not be used by end-users. CRAN package 'coin' implements all 
  user interfaces and is ready to be used by anyone.
corpus,2017-04-16,corpus: Text Corpus Analysis,Text corpus data analysis, with full support for international text (Unicode).  Functions for reading data from newline-delimited 'JSON' files, for normalizing and tokenizing text, for searching for term occurrences, and for computing term occurrence frequencies, including n-grams.
inum,2016-12-09,inum: Interval and Enum-Type Representation of Vectors,Enum-type representation of vectors and representation
  of intervals, including a method of coercing variables in data frames.
refset,2016-12-05,refset: Subsets with Reference Semantics,Provides subsets with reference semantics, i.e. subsets
    which automatically reflect changes in the original object, and which
    optionally update the original object when they are changed.
parsemsf,2017-01-24,parsemsf: Parse ThermoFisher MSF Files and Estimate Protein Abundances,Provides functions for parsing ThermoFisher MSF files produced by Proteome Discoverer 1.4.x (see <https://thermofisher.com> for more information). This package makes it easy to view individual peptide information, including peak areas, and to map peptides to locations within the parent protein sequence. This package also estimates protein abundances from peak areas and across multiple technical replicates. The author of this package is not affiliated with ThermoFisher Scientific in any way.
Inventorymodel,2017-04-17,Inventorymodel: Inventory Models,Determination of the optimal policy in inventory problems from a game-theoretic perspective.
plotrr,2017-02-12,plotrr: Making Visual Exploratory Data Analysis with Nested Data Easier,Functions for making visual exploratory data analysis with nested data easier.
mazeGen,2017-01-05,mazeGen: Elithorn Maze Generator,A maze generator that creates the Elithorn Maze (HTML file) and the functions to calculate the associated maze parameters (i.e. Difficulty and Ability). 
mdw,2017-08-28,mdw: Maximum Diversity Weighting,Dimension-reduction methods aim at defining a score that maximizes signal diversity. Two approaches, namely maximum entropy weights and maximum variance weights, are provided.
networkGen,2017-07-05,networkGen: Network Maze Generator,A network Maze generator that creates different types of network mazes. 
striprtf,2016-12-16,striprtf: Extract Text from RTF File,Extracts plain text from RTF (Rich Text Format) file.
xesreadR,2017-06-19,xesreadR: Read and Write XES Files,Read and write XES Files to create event log objects used by the 'bupaR' framework. XES (Extensible Event Stream) is the 'IEEE' standard for storing and sharing event data (see <http://standards.ieee.org/findstds/standard/1849-2016.html> for more info).
EAinference,2017-09-16,EAinference: Estimator Augmentation and Simulation-Based Inference,Estimator augmentation methods for statistical inference on high-dimensional data, 
    as described in Zhou, Q. (2014) <arXiv:1401.4425v2>
    and Zhou, Q. and Min, S. (2017) <doi:10.1214/17-EJS1309>.
    It provides several simulation-based inference methods: (a) Gaussian and 
    wild multiplier bootstrap for lasso, group lasso, scaled lasso, scaled group
    lasso and their de-biased estimators, (b) importance sampler for approximating
    p-values in these methods, (c) Markov chain Monte Carlo lasso sampler with 
    applications in post-selection inference.
harrietr,2017-02-22,harrietr: Wrangle Phylogenetic Distance Matrices and Other Utilities,Harriet was Charles Darwin's pet tortoise (possibly). 'harrietr'
    implements some function to manipulate distance matrices and phylogenetic trees
    to make it easier to plot with 'ggplot2' and to manipulate using 'tidyverse'
    tools.
NestedCategBayesImpute,2016-11-17,NestedCategBayesImpute: Modeling and Generating Synthetic Versions of Nested Categorical
Data in the Presence of Impossible Combinations,This tool set provides a set of functions to fit the nested Dirichlet process mixture of products of multinomial distributions (NDPMPM) model for nested categorical household data in the presence of impossible combinations. It has direct applications in generating synthetic nested household data.
adapr,2016-11-07,adapr: Implementation of an Accountable Data Analysis Process,Tracks reading and writing within R scripts that are organized into
    a directed acyclic graph. Contains an interactive shiny application adaprApp().
    Uses git2r package, Git and file hashes to track version histories of input
    and output. See package vignette for how to get started. V1.02 adds parallel
    execution of project scripts and function map in vignette. Makes project
    specification argument last in order. V2.0 adds project specific libraries, packrat option, and adaprSheet().
goftte,2017-05-15,goftte: Goodness-of-Fit for Time-to-Event Data,Extension of 'gof' package to survival models.
passport,2017-07-09,passport: Travel Smoothly Between Country Name and Code Formats,Smooths the process of working with country names and codes via 
    powerful parsing, standardization, and conversion utilities arranged in a 
    simple, consistent API. Country name formats include multiple sources 
    including the Unicode Common Locale Data 
    Repository (CLDR, <http://cldr.unicode.org/>) common-sense standardized 
    names in hundreds of languages.
SASmarkdown,2017-07-10,SASmarkdown: 'SAS' Markdown,Settings and functions to extend the 'knitr' 'SAS' engine.
MUS,2017-05-29,MUS: Monetary Unit Sampling and Estimation Methods, Widely Used in
Auditing,Sampling and evaluation methods to apply Monetary Unit Sampling (or in older literature Dollar Unit Sampling) during an audit of financial statements.
Dforest,2017-06-26,Dforest: Decision Forest,Provides R-implementation of Decision forest algorithm, which combines the predictions of
    multiple independent decision tree models for a consensus decision. In particular, Decision Forest is a novel 
    pattern-recognition method which can be used to analyze: (1) DNA microarray data; 
    (2) Surface-Enhanced Laser Desorption/Ionization Time-of-Flight Mass Spectrometry  (SELDI-TOF-MS) data; and 
    (3) Structure-Activity Relation (SAR) data.
    In this package, three fundamental functions are provided, as (1)DF_train, (2)DF_pred, and (3)DF_CV.  
    run Dforest() to see more instructions.
    Weida Tong (2003) <doi:10.1021/ci020058s>.
phase1RMD,2017-03-23,phase1RMD: Repeated Measurement Design for Phase I Clinical Trial,Implements our Bayesian phase I repeated measurement design that accounts for multidimensional toxicity endpoints from multiple treatment cycles. The package also provides a novel design to account for both multidimensional toxicity endpoints and early-stage efficacy endpoints in the phase I design. For both designs, functions are provided to recommend the next dosage selection based on the data collected in the available patient cohorts and to simulate trial characteristics given design parameters. Yin, Jun, et al. (2017) <doi:10.1002/sim.7134>.
simEd,2017-05-10,simEd: Simulation Education,Contains various functions to be used for simulation education, 
    including simple Monte Carlo simulation functions, queueing simulation
    functions, variate generation functions capable of producing independent
    streams and antithetic variates, functions for illustrating random variate
    generation for various discrete and continuous distributions, and functions
    to compute time-persistent statistics.  Also contains two queueing data sets
    (one fabricated, one real-world) to facilitate input modeling.
cctools,2017-04-26,cctools: Tools for the Continuous Convolution Trick in Nonparametric
Estimation,Implements the uniform scaled beta distribution and
  the continuous convolution kernel density estimator.
unitizer,2017-04-03,unitizer: Interactive R Unit Tests,Simplifies regression tests by comparing objects produced by test
    code with earlier versions of those same objects.  If objects are unchanged
    the tests pass, otherwise execution stops with error details.  If in
    interactive mode, tests can be reviewed through the provided interactive
    environment.
CorporaCoCo,2017-03-27,CorporaCoCo: Corpora Co-Occurrence Comparison,A set of functions used to compare co-occurrence between two corpora.
IDCard,2017-09-08,IDCard: Update Chinese ID Card Number to Eighteen Digits,The digits of the old version (before 2000 year) of 'Chinese ID Card Number' is 15, this package aims to update to the current version of 18 digits. Besides, this package can help check whether the given 'ID' is right or not.
MHTdiscrete,2016-10-20,MHTdiscrete: Multiple Hypotheses Testing for Discrete Data,A comprehensive tool for almost all existing multiple testing
    methods for discrete data. The package also provides some novel multiple testing
    procedures controlling FWER/FDR for discrete data. Given discrete p-values
    and their domains, the [method].p.adjust function returns adjusted p-values,
    which can be used to compare with the nominal significant level alpha and make
    decisions. For users' convenience, the functions also provide the output option 
    for printing decision rules.
powdist,2017-08-05,powdist: Power and Reversal Power Distributions,Density, distribution function, quantile function and random generation for the family of power and reversal power distributions.
futility,2017-07-29,futility: Interim Analysis of Operational Futility in Randomized Trials
with Time-to-Event Endpoints and Fixed Follow-Up,Randomized clinical trials commonly follow participants for a time-to-event efficacy endpoint for a fixed period of time. Consequently, at the time when the last enrolled participant completes their follow-up, the number of observed endpoints is a random variable. Assuming data collected through an interim timepoint, simulation-based estimation and inferential procedures in the standard right-censored failure time analysis framework are conducted for the distribution of the number of endpoints–in total as well as by treatment arm–at the end of the follow-up period. The future (i.e., yet unobserved) enrollment, endpoint, and dropout times are generated according to mechanisms specified in the simTrial() function in the 'seqDesign' package. A Bayesian model for the endpoint rate, offering the option to specify a robust mixture prior distribution, is used for generating future data (see the vignette for details).
KMgene,2017-09-26,KMgene: Gene-Based Association Analysis for Complex Traits,Gene based association test between a group of SNPs and traits
    including familial (both continuous and binary) traits, multivariate
    continuous (both independent and familial) traits, longitudinal continuous
    traits and survival traits. Part of methods were previously published in
    Maity et al (2012) <doi:10.1002/gepi.21663>, Chen et al (2013)
    <doi:10.1002/gepi.21703>, Chen et al (2014) <doi:10.1002/gepi.21791>, Yan
    et al (2015) <doi:10.1159/000375409>, Yan et al (2015)
    <doi:10.1534/genetics.115.178590> and Yan et al (2015)
    <doi:10.1159/000445057>.
LCF,2017-02-17,LCF: Linear Combination Fitting,Baseline correction, normalization and linear combination fitting (LCF) 
    of X-ray absorption near edge structure (XANES) spectra.
    The package includes data loading of .xmu files exported from 'ATHENA' (Ravel and Newville, 2005) <doi:10.1107/S0909049505012719>. 
    Loaded spectra can be background corrected and all standards can be fitted at once.
    Two linear combination fitting functions can be used:
    (1) fit_athena(): Simply fitting combinations of standards as in ATHENA, 
    (2) fit_float(): Fitting all standards with changing baseline correction and edge-step normalization parameters. 
ManifoldOptim,2016-11-05,ManifoldOptim: An R Interface to the 'ROPTLIB' Library for Riemannian Manifold
Optimization,An R interface to version 0.3 of the 'ROPTLIB' optimization library
    (see <http://www.math.fsu.edu/~whuang2> for more information). Optimize real-
    valued functions over manifolds such as Stiefel, Grassmann, and Symmetric
    Positive Definite matrices.
epicontacts,2017-04-27,epicontacts: Handling, Visualisation and Analysis of Epidemiological Contacts,A collection of tools for representing epidemiological contact data, composed of case line lists and contacts between cases. Also contains procedures for data handling, interactive graphics, and statistics.
ICRanks,2017-08-08,ICRanks: Simultaneous Confidence Intervals for Ranks,Algorithms to construct confidence intervals for the ranks of centers mu_1,...,mu_n based on an independent Gaussian sample using multiple testing techniques. 
RcppHMM,2017-02-08,RcppHMM: Rcpp Hidden Markov Model,Collection of functions to evaluate sequences, decode hidden states and estimate parameters from a single or multiple sequences of a discrete time Hidden Markov Model. The observed values can be modeled by a multinomial distribution for categorical/labeled emissions, a mixture of Gaussians for continuous data and also a mixture of Poissons for discrete values. It includes functions for random initialization, simulation, backward or forward sequence evaluation, Viterbi or forward-backward decoding and parameter estimation using an Expectation-Maximization approach.
RcppTN,2017-07-09,RcppTN: Rcpp-Based Truncated Normal Distribution RNG and Family,R-level and C++-level functionality
    to generate random deviates from and calculate moments of a
    Truncated Normal distribution using the algorithm of Robert (1995) <doi:10.1007/BF00143942>.
    In addition to RNG, functions for calculating moments, densities,
    and entropies are provided at both levels.
AWR.Athena,2017-06-16,AWR.Athena: 'AWS' Athena 'DBI' Wrapper,'RJDBC' based 'DBI' driver to Amazon Athena, which is an interactive
    query service to analyze data in Amazon 'S3' using standard 'SQL'.
wicket,2017-01-21,wicket: Utilities to Handle WKT Spatial Data,Utilities to generate bounding boxes from 'WKT' (Well-Known Text) objects and R data types, validate
             'WKT' objects and convert object types from the 'sp' package into 'WKT' representations.
easyAHP,2017-07-29,easyAHP: Analytic Hierarchy Process (AHP),Given the scores from decision makers, the analytic hierarchy process can be conducted easily.
xslt,2017-01-07,xslt: Extensible Style-Sheet Language Transformations,An extension for the 'xml2' package to transform XML documents
    by applying an 'xslt' style-sheet.
gamreg,2016-10-07,gamreg: Robust and Sparse Regression via Gamma-Divergence,Robust regression via gamma-divergence with L1, elastic net and ridge.
revgeo,2017-05-04,revgeo: Reverse Geocoding with the Photon Geocoder for OpenStreetMap,
Google Maps, and Bing,Function revgeo() allows you to use the Photon geocoder for OpenStreetMap <http://photon.komoot.de>, Google Maps <http://maps.google.com>, and Bing <https://www.bingmapsportal.com> to reverse geocode coordinate pairs with minimal hassle. 
spiderbar,2017-09-25,spiderbar: Parse and Test Robots Exclusion Protocol Files and Rules,The 'Robots Exclusion Protocol' <http://www.robotstxt.org/orig.html> documents
    a set of standards for allowing or excluding robot/spider crawling of different areas of
    site content. Tools are provided which wrap The 'rep-cpp' <https://github.com/seomoz/rep-cpp>
    C++ library for processing these 'robots.txt' files.
sppmix,2017-02-23,sppmix: Modeling Spatial Poisson and Related Point Processes,Implements classes and methods for modeling spatial point patterns using inhomogeneous Poisson point processes, where the intensity surface is assumed to be analogous to a finite additive mixture of normal components and the number of components is a finite, fixed or random integer. Extensions to the marked inhomogeneous Poisson point processes case are also presented. We provide an extensive suite of R functions that can be used to simulate, visualize and model point patterns, estimate the parameters of the models, assess convergence of the algorithms and perform model selection and checking in the proposed modeling context.
modest,2017-06-28,modest: Model-Based Dose-Escalation Trials,User-friendly Shiny apps for designing and evaluating phase I cancer clinical trials, with the aim to estimate the maximum tolerated dose (MTD) of a novel drug, using a Bayesian decision procedure based on logistic regression.
ICCbin,2016-12-11,ICCbin: Facilitates Clustered Binary Data Generation, and Estimation of
Intracluster Correlation Coefficient (ICC) for Binary Data,Assists in generating binary clustered data, estimates of Intracluster Correlation coefficient (ICC) for binary response in 16 different methods, and 5 different types of confidence intervals.
dparser,2017-04-29,dparser: Port of 'Dparser' Package,A Scannerless GLR parser/parser generator.  Note that GLR standing for "generalized LR", where L stands for "left-to-right" and
   R stands for "rightmost (derivation)".  For more information see <https://en.wikipedia.org/wiki/GLR_parser>. This parser is based on the Tomita
   (1987) algorithm. (Paper can be found at <http://acl-arc.comp.nus.edu.sg/archives/acl-arc-090501d3/data/pdf/anthology-PDF/J/J87/J87-1004.pdf>).
   The original 'dparser' package documentation can be found at <http://dparser.sourceforge.net/>.  This allows you to add mini-languages to R (like
   RxODE's ODE mini-language Wang, Hallow, and James 2015 <doi:10.1002/psp4.12052>) or to parse other languages like 'NONMEM' to automatically translate
   them to R code.   To use this in your code, add a LinkingTo dparser in your DESCRIPTION file and instead of using #include <dparse.h> use
   #include <dparser.h>.  This also provides a R-based port of the make_dparser <http://dparser.sourceforge.net/d/make_dparser.cat> command called
   mkdparser().  Additionally you can parse an arbitrary grammar within R using the dparse() function, which works on most OSes and is mainly for grammar
   testing.  The fastest parsing, of course, occurs at the C level, and is suggested.
StakeholderAnalysis,2017-09-01,StakeholderAnalysis: Measuring Stakeholder Influence,Proposes an original instrument for measuring stakeholder influence on the development of an infrastructure project that is carried through by a municipality, drawing on stakeholder classifications (Mitchell, Agle, & Wood, 1997) and input-output modelling (Hester & Adams, 2013). Mitchell R., Agle B.R., & Wood D.J. <doi:10.2307/259247> Hester, P.T., & Adams, K.M. (2013) <doi:10.1016/j.procs.2013.09.282>.
qboxplot,2017-03-22,qboxplot: Quantile-Based Boxplot,Produce quantile-based box-and-whisker plot(s).
rsample,2017-07-08,rsample: General Resampling Infrastructure,Classes and functions to create and summarize different types of resampling objects (e.g. bootstrap, cross-validation). 
ThankYouStars,2017-09-17,ThankYouStars: Give your Dependencies Stars on GitHub!,A tool for starring GitHub repositories.
BatchMap,2017-03-27,BatchMap: Software for the Creation of High Density Linkage Maps in
Outcrossing Species,Algorithms that build on the 'OneMap' package to create linkage
    maps from high density data in outcrossing species in reasonable time frames.
anocva,2016-12-28,anocva: A Non-Parametric Statistical Test to Compare Clustering
Structures,Provides ANOCVA (ANalysis Of Cluster VAriability), a non-parametric statistical test
    to compare clustering structures with applications in functional magnetic resonance imaging
    data (fMRI). The ANOCVA allows us to compare the clustering structure of multiple groups
    simultaneously and also to identify features that contribute to the differential clustering.
PdPDB,2016-11-18,PdPDB: Pattern Discovery in PDB Structures of Metalloproteins,Looks for amino acid and/or nucleotide patterns and/or small
    ligands coordinated to a given prosthetic centre. Files have to be in the local
    file system and contain proper extension.
rGoodData,2017-03-22,rGoodData: GoodData API Client Package,Export raw reports from 'GoodData' business intelligence platform 
    (see <http://www.gooddata.com> for more information).
rLDCP,2016-12-23,rLDCP: Text Generation from Data,Linguistic Descriptions of Complex Phenomena (LDCP) is an architecture and methodology that allows us to model complex phenomena, interpreting input data, and generating automatic text reports customized to the user needs (see <doi:10.1016/j.ins.2016.11.002> and <doi:10.1007/s00500-016-2430-5>). The proposed package contains a set of methods that facilitates the development of LDCP systems. It main goal is increasing the visibility and practical use of this research line.
rODE,2017-05-28,rODE: Ordinary Differential Equation (ODE) Solvers Written in R Using
S4 Classes,Show physics, math and engineering students how an ODE solver
    is made and how effective R classes can be for the construction of
    the equations that describe natural phenomena. Inspiration for this work 
    comes from the book on "Computer Simulations in Physics" 
    by Harvey Gould, Jan Tobochnik, and Wolfgang Christian. 
    Book link: <http://www.compadre.org/osp/items/detail.cfm?ID=7375>.
geojson,2016-11-16,geojson: Classes for 'GeoJSON',Classes for 'GeoJSON' to make working with 'GeoJSON' easier.
    Includes S3 classes for 'GeoJSON' classes with brief summary output,
    and a few methods such as extracting and adding bounding boxes,
    properties, and coordinate reference systems; linting through
    the 'geojsonlint' package; and serializing to/from 'Geobuf' binary
    'GeoJSON' format.
epxToR,2017-02-14,epxToR: Import 'Epidata' XML Files '.epx',Import data from 'Epidata' XML files '.epx' and convert it to R data structures.
Diderot,2017-09-01,Diderot: Bibliographic Network Analysis,Enables the user to build a citation network/graph from bibliographic data and, based on modularity and heterocitation metrics, assess the degree of awareness/cross-fertilization between two corpora/communities. This toolset is optimized for Scopus data. 
RcppQuantuccia,2017-04-18,RcppQuantuccia: R Bindings to the 'Quantuccia' Header-Only Essentials of
'QuantLib','QuantLib' bindings are provided for R using 'Rcpp' and the
 header-only 'Quantuccia' variant (put together by Peter Caspers) offering
 an essential subset of 'QuantLib'. See the included file 'AUTHORS' for a full
 list of contributors to both 'QuantLib' and 'Quantuccia'.
ArCo,2017-04-04,ArCo: Artificial Counterfactual Package,Set of functions to analyse and estimate Artificial Counterfactual models from Carvalho, Masini and Medeiros (2016) <doi:10.2139/ssrn.2823687>.
lplyr,2017-01-25,lplyr: 'dplyr' Verbs for Lists and Other Verbs for Data Frames,Provides 'dplyr' verbs for lists and other useful 
    verbs for manipulation of data frames. In particular, it includes a 
    mutate_which() function that mutates columns for a specific subset of 
    rows defined by a condition, and fuse() which is a more flexible version 
    of 'tidyr' unite() function. 
Pstat,2017-02-25,Pstat: Assessing Pst Statistics,Calculating Pst values to assess differentiation among populations from a set of quantitative traits is the primary purpose of such a package. The bootstrap method provides confidence intervals and distribution histograms of Pst. Variations of Pst in function of the parameter c/h^2 are studied as well. Finally, the package proposes different transformations especially to eliminate any variation resulting from allometric growth (calculation of residuals from linear regressions, Reist standardizations or Aitchison transformation).
RJSplot,2017-05-19,RJSplot: Interactive Graphs with R,Creates interactive graphs with 'R'. It joins the data analysis power of R and the visualization libraries of JavaScript in one package.
slowraker,2017-09-08,slowraker: A Slow Version of the Rapid Automatic Keyword Extraction (RAKE)
Algorithm,A mostly pure-R implementation of the RAKE algorithm (Rose, S., Engel, D., Cramer, N. and Cowley, W. (2010) <doi:10.1002/9780470689646.ch1>), which can be used to extract keywords from documents without any training data.
infraFDTD.assist,2016-11-20,infraFDTD.assist: IO Help for infraFDTD Model,Facilitates the generation of input files for infraFDTD and processes snapshot output. infraFDTD is a finite-difference model written by Keehoon Kim for simulating infrasound that considers topography and a 1-D atmosphere (see Kim et al., 2015 <doi:10.1002/2015GL064466>).
MBHdesign,2016-11-20,MBHdesign: Spatial Designs for Ecological and Environmental Surveys,Provides spatially balanced designs from a set of (contiguous) potential sampling locations in a study region. Accommodates , without detrimental effects on spatial balance, sites that the researcher wishes to include in the survey for reasons other than the current randomisation (legacy sites).
phylocanvas,2017-02-03,phylocanvas: Interactive Phylogenetic Trees Using the 'Phylocanvas'
JavaScript Library,Create and customize interactive phylogenetic trees using the 'phylocanvas' JavaScript library and the 'htmlwidgets' package. These trees can be used directly from the R console, from 'RStudio', in Shiny apps, and in R Markdown documents.  See <http://phylocanvas.org/>  for more information on the 'phylocanvas' library.
rsurfer,2017-05-03,rsurfer: Manipulating 'Freesurfer' Generated Data,The software suite, 'Freesurfer', is a open-source software suite involving the segmentation of brain MRIs (see <http://freesurfer.net/> for more information). This package provides functionality to import the data generated by 'Freesurfer'; functions to easily manipulate the data; and provides brain specific normalisation commonly used when studying structural brain MRIs. This package has been designed using an installation of and data generated from 'Freesurfer' version 5.3.
coppeCosenzaR,2017-05-20,coppeCosenzaR: COPPE-Cosenza Fuzzy Hierarchy Model,The program implements the COPPE-Cosenza Fuzzy Hierarchy Model. 
    The model was based on the evaluation of local alternatives, representing 
    regional potentialities, so as to fulfill demands of economic projects. 
    After defining demand profiles in terms of their technological coefficients, 
    the degree of importance of factors is defined so as to represent  
    the productive activity. The method can detect a surplus of supply without 
    the restriction of the distance of classical algebra, defining a hierarchy 
    of location alternatives. In COPPE-Cosenza Model, the distance between 
    factors is measured in terms of the difference between grades of memberships
    of the same factors belonging to two or more  sets under comparison. The 
    required factors are classified under the following linguistic variables: 
    Critical (CR); Conditioning (C); Little Conditioning (LC); and Irrelevant 
    (I). And the alternatives can assume the following linguistic variables: 
    Excellent (Ex), Good (G), Regular (R), Weak (W), Empty (Em), Zero (Z) and 
    Inexistent (In). The model also provides flexibility, allowing different 
    aggregation rules to be performed and defined by the Decision Maker. Such 
    feature is considered in this package, allowing the user to define other 
    aggregation matrices, since it considers the same linguistic variables 
    mentioned. 
vfcp,2017-05-15,vfcp: Computation of v Values for U and Copula C(U, v),Computation the value of one of two uniformly 
    distributed marginals if the copula probability value is known
    and the value of the second marginal is also known.
    Computation and plotting corresponding cumulative
    distribution function or survival function.
    The numerical definition of a common area limited by lines
    of the cumulative distribution function and survival function.
    Approximate quantification of the probability of this area.
    In addition to 'amh', the copula dimension may be larger than 2.
countyfloods,2017-04-01,countyfloods: Quantify United States County-Level Flood Measurements,Quantifies United States flood impacts at the county level using
    United States Geological Service (USGS) River Discharge data for the USGS
    API. This package builds on R packages from the USGS, with the goal of
    creating county-level time series of flood status that can be more easily
    joined with county-level impact measurements, including health outcomes.
    This work was supported in part by grants from the National Institute of
    Environmental Health Sciences (R00ES022631), the Colorado Water Center,
    and the National Science Foundation, Integrative Graduate Education and
    Research Traineeship (IGERT) Grant No. DGE-0966346 "I-WATER: Integrated
    Water, Atmosphere, Ecosystems Education and Research Program" at
    Colorado State University.
FinAna,2016-11-09,FinAna: Financial Analysis and Regression Diagnostic Analysis,Functions for financial analysis and financial modeling, 
             including batch graphs generation, beta calculation, 
             descriptive statistics, annuity calculation, bond pricing 
             and financial data download.
kaphom,2017-08-11,kaphom: Test the Homogeneity of Kappa Statistics,Tests the homogeneity of intraclass kappa statistics obtained from independent studies or a stratified study with binary results. It is desired to compare the kappa statistics obtained in multi-center studies or in a single stratified study to give a common or summary kappa using all available information. If the homogeneity test of these kappa statistics is not rejected, then it is possible to make inferences over a single kappa statistic that summarizes all the studies. Jun-mo Nam (2003) <doi:10.1111/j.0006-341X.2003.00118.x> Jun-mo Nam (2005) <doi:10.1002/sim.2321>Mousumi Banerjee, Michelle Capozzoli, Laura McSweeney,Debajyoti Sinha (1999) <doi:10.2307/3315487> Allan Donner, Michael Eliasziw, Neil Klar (1996) <doi:10.2307/2533154>.
meanr,2017-06-07,meanr: Sentiment Analysis Scorer,Sentiment analysis is a popular technique in text mining.  Roughly
    speaking, the technique is an attempt to determine the overall emotional
    attitude of a piece of text (i.e., positive or negative).  We provide a new
    implementation of a common method for computing sentiment, whereby words are
    scored as positive or negative according to a "dictionary", and then an
    sum of those scores for the document is produced.  We use the 'Hu' and 'Liu'
    sentiment dictionary for determining sentiment.  The scoring function is
    'vectorized' by document, and scores for multiple documents are computed in
    parallel via 'OpenMP'.
routr,2017-08-22,routr: A Simple Router for HTTP and WebSocket Requests,In order to make sure that web request ends up in the correct 
    handler function a router is often used. 'routr' is a package implementing a
    simple but powerful routing functionality for R based servers. It is a fully
    functional 'fiery' plugin, but can also be used with other 'httpuv' based
    servers.
GerminaR,2016-12-24,GerminaR: Germination Indexes for Seed Germination Variables for
Ecophysiological Studies,Different types of seed indexes, rates and visualization techniques
    are used to provide a robust approach for germination data analysis. The package
    aims to make available germination seed indexes and graphical functions to
    analyze germination seed data.
WWR,2017-02-12,WWR: Weighted Win Loss Statistics and their Variances,Calculate the (weighted) win loss statistics including the win ratio, win difference and win product 
 and their variances, with which the p-values are also calculated. The variance estimation is based on 
 Luo et al. (2015) <doi:10.1111/biom.12225> and Luo et al. (2017) <doi:10.1002/sim.7284>. This package also calculates general win loss statistics with 
 user-specified win loss function with variance estimation based on 
 Bebu and Lachin (2016) <doi:10.1093/biostatistics/kxv032>.
 This version corrected an error when outputting confidence interval for win difference.
cbar,2017-06-23,cbar: Contextual Bayesian Anomaly Detection in R,Detect contextual anomalies in time-series data with Bayesian data
  analysis. It focuses on determining a normal range of target value, and
  provides simple-to-use functions to abstract the outcome.
MOEADr,2017-03-16,MOEADr: Component-Wise MOEA/D Implementation,Modular implementation of Multiobjective Evolutionary Algorithms 
              based on Decomposition (MOEA/D) [Zhang and Li (2007), 
              <doi:10.1109/TEVC.2007.892759>] for quick assembling and 
              testing of new algorithmic components, as well as easy 
              replication of published MOEA/D proposals.
MoLE,2017-07-03,MoLE: Modeling Language Evolution,Model for simulating language evolution in terms of cultural evolution (Smith & Kirby (2008) <doi:10.1098/rstb.2008.0145>; Deacon 1997). The focus is on the emergence of argument-marking systems (Dowty (1991) <doi:10.1353/lan.1991.0021>, Van Valin 1999, Dryer 2002, Lestrade 2015a), i.e. noun marking (Aristar (1997) <doi:10.1075/sl.21.2.04ari>, Lestrade (2010) <doi:10.7282/T3ZG6R4S>), person indexing (Ariel 1999, Dahl (2000) <doi:10.1075/fol.7.1.03dah>, Bhat 2004), and word order (Dryer 2013), but extensions are foreseen. Agents start out with a protolanguage (a language without grammar; Bickerton (1981) <doi:10.17169/langsci.b91.109>, Jackendoff 2002, Arbib (2015) <doi:10.1002/9781118346136.ch27>) and interact through language games (Steels 1997). Over time, grammatical constructions emerge that may or may not become obligatory (for which the tolerance principle is assumed; Yang 2016). Throughout the simulation, uniformitarianism of principles is assumed (Hopper (1987) <doi:10.3765/bls.v13i0.1834>, Givon (1995) <doi:10.1075/z.74>, Croft (2000), Saffran (2001) <doi:10.1111/1467-8721.01243>, Heine & Kuteva 2007), in which maximal psychological validity is aimed at (Grice (1975) <doi:10.1057/9780230005853_5>, Levelt 1989, Gaerdenfors 2000) and language representation is usage based (Tomasello 2003, Bybee 2010). In Lestrade (2015b) <doi:10.15496/publikation-8640>, Lestrade (2015c) <doi:10.1075/avt.32.08les>, and Lestrade (2016) <doi:10.17617/2.2248195>), which reported on the results of preliminary versions, this package was announced as WDWTW (for who does what to whom), but for reasons of pronunciation and generalization the title was changed.
nspmix,2017-04-26,nspmix: Nonparametric and Semiparametric Mixture Estimation,Contains functions for maximum likelihood estimation of
	     nonparametric and semiparametric mixture models. 
optimization,2016-12-04,optimization: Flexible Optimization of Complex Loss Functions with State and
Parameter Space Constraints,Flexible optimizer with numerous input specifications for detailed parameterisation. Designed for complex loss functions with state and parameter space constraints. Visualization tools for validation and analysis of the convergence are included.
EfficientMaxEigenpair,2016-12-07,EfficientMaxEigenpair: Efficient Initials for Computing the Maximal Eigenpair,An implementation for using efficient initials to compute the
    maximal eigenpair in R. It provides three algorithms to find the efficient
    initials under two cases: the tridiagonal matrix case and the general matrix
    case. Besides, it also provides two algorithms for the next to the maximal eigenpair under
    these two cases.
MHCtools,2017-09-29,MHCtools: Analysis of MHC Data in Non-Model Species,Ten tools for analysis of major histocompatibility complex (MHC) data in non-
    model species. The functions are tailored for amplicon data sets that have been 
    filtered using the 'dada2' method (for more information visit 
    <https://benjjneb.github.io/dada2>), but even other data sets can be analysed, 
    if the data tables are formatted according to the description in each function.
    The ReplMatch() function matches replicates in data sets in order to evaluate 
    genotyping success.
    The GetReplTable() and GetReplStats() functions perform such an evaluation.
    The HpltFind() function infers putative haplotypes from families in the data 
    set. 
    The GetHpltTable() and GetHpltStats() functions evaluate the accuracy of 
    the haplotype inference.
    The PapaDiv() function compares parent pairs in the data set and calculate their 
    joint MHC diversity, taking into account sequence variants that occur in both 
    parents.
    The MeanPdist() function calculates the mean p-distance from pairwise 
    comparisons sequences in each sample in a data set. The function includes the 
    option to specify which codons to compare.
    The CreateFas() function creates a fasta file with all the sequences in the data 
    set.
    The CreateSamplesFas() function creates a fasta file for each sample in the data 
    set.
WaveLetLongMemory,2016-12-12,WaveLetLongMemory: Estimating Long Memory Parameter using Wavelet,Estimation of the long memory parameter using wavelets. Other estimation techniques like 
             GPH (Geweke and Porter-Hudak,1983, <doi:10.1111/j.1467-9892.1983.tb00371.x>) 
             and Semiparametric methods(Robinson, P. M.,1995, <doi:10.1214/aos/1176324317>) also have included.
zFactor,2017-06-28,zFactor: Calculate the Compressibility Factor 'z' for Hydrocarbon Gases,Computational algorithms to solve equations and find the
    compressibility factor 'z' of hydrocarbon gases. Correlations available: 
    Hall-Yarborough, Dranchuk-AbuKassem, Dranchuk-Purvis-Robinson, Beggs-Brill, 
    Papp, Shell and an Artificial Neural Network correlation (Ann10) by Kamyab 
    et al. The package uses the original Standing-Katz chart for statistical 
    comparison and plotting. Applicable to sweet hydrocarbon gases for now.
debugme,2016-11-01,debugme: Debug R Packages,Specify debug messages as special string constants, and
    control debugging of packages via environment variables.
docuSignr,2017-04-14,docuSignr: Connect to 'DocuSign' API,Connect to the 'DocuSign' Rest API <https://www.docusign.com/p/RESTAPIGuide/RESTAPIGuide.htm>, 
  which supports embedded signing, and sending of documents. 
groupdata2,2017-01-28,groupdata2: Creating Groups from Data,Subsetting methods for balanced cross-validation, time series windowing,
    and general grouping and splitting of data.
oii,2016-10-02,oii: Crosstab and Statistical Tests for OII MSc Stats Course,Provides simple crosstab output with optional statistics (e.g., Goodman-Kruskal Gamma, Somers' d, and Kendall's tau-b) as well as two-way and one-way tables. The package is used within the statistics component of the Masters of Science (MSc) in Social Science of the Internet at the Oxford Internet Institute (OII), University of Oxford, but the functions should be useful for general data analysis and especially for analysis of categorical and ordinal data.
ROI.plugin.msbinlp,2017-05-18,ROI.plugin.msbinlp: 'Multi-Solution' Binary Linear Problem Plug-in for the 'R'
Optimization Interface,Enhances the 'R' Optimization Infrastructure ('ROI') package
             with the possibility to obtain multiple solutions for linear 
             problems with binary variables. The main function is copied 
             (with small modifications) from the relations package.
ROI.plugin.optimx,2017-05-18,ROI.plugin.optimx: 'optimx' Plug-in for the 'R' Optimization Infrastructure,Enhances the R Optimization Infrastructure ('ROI') package
        with the 'optimx' package.
liteq,2017-01-27,liteq: Lightweight Portable Message Queue Using 'SQLite',Temporary and permanent message queues for R. Built on top of
    'SQLite' databases. 'SQLite' provides locking, and makes it possible
    to detect crashed consumers. Crashed jobs can be automatically marked
    as "failed", or put in the queue again, potentially a limited number of times.
EasyMx,2017-05-02,EasyMx: Easy Model-Builder Functions for 'OpenMx',Utilities for building certain kinds of common matrices and models in 
    the extended structural equation modeling package, 'OpenMx'.
htm2txt,2017-09-04,htm2txt: Convert Html into Text,Convert a html document to simple plain texts by removing all html tags.  This package utilizes regular expressions to strip off html tags. It also offers gettxt() and browse() function, which enables you to get or browse texts at a certain web page.
mafs,2016-11-19,mafs: Multiple Automatic Forecast Selection,Fits several forecast models available from the forecast package
    and selects the best one according to an error metric. Its main function
    is select_forecast().
monoreg,2017-06-29,monoreg: Bayesian Monotonic Regression Using a Marked Point Process
Construction,An extended version of the nonparametric Bayesian monotonic regression procedure described in Saarela & Arjas (2011) <doi:10.1111/j.1467-9469.2010.00716.x>, allowing for multiple additive monotonic components in the linear predictor, and time-to-event outcomes through case-base sampling. The extension and its applications, including estimation of absolute risks, are described in Saarela & Arjas (2015) <doi:10.1111/sjos.12125>.
LZeroSpikeInference,2017-05-18,LZeroSpikeInference: Exact Spike Train Inference via L0 Optimization,An implementation of algorithms described in Jewell and Witten (2017) <arXiv:1703.08644>. 
geomedb,2017-05-03,geomedb: Fetch 'GeOMe-db' FIMS Data,The Genomic Observatory Metadatabase (GeOMe Database) is an open access repository for
    geographic and ecological metadata associated with sequenced samples. This package is used to retrieve
    GeOMe data for analysis. See <http://www.geome-db.org> for more information regarding GeOMe.
sicegar,2017-03-19,sicegar: Analysis of Single-Cell Viral Growth Curves,Aims to quantify time intensity data by using sigmoidal and double sigmoidal curves. It fits straight lines, sigmoidal, and double sigmoidal curves on to time vs intensity data. Then all the fits are used to make decision on which model (sigmoidal, double sigmoidal, no signal or ambiguous) best describes the data. No signal means the intensity does not reach a high enough point or does not change at all over time. Sigmoidal means intensity starts from a small number than climbs to a maximum. Double sigmoidal means intensity starts from a small number, climbs to a maximum then starts to decay. After the decision between those four options, the algorithm gives the sigmoidal (or double sigmoidal) associated parameter values that quantifies the time intensity curve. The origin of the package name came from "SIngle CEll Growth Analysis in R".
vennplot,2017-04-09,vennplot: Venn Diagrams in 2D and 3D,Calculate and plot Venn diagrams in 2D and 3D.
GSMX,2016-10-03,GSMX: Multivariate Genomic Selection,Estimating trait heritability and handling overfitting. This package includes a collection of functions for (1) estimating genetic variance-covariances and calculate trait heritability; and (2) handling overfitting by calculating the variance components and the heritability through cross validation.
rucrdtw,2016-11-07,rucrdtw: R Bindings for the UCR Suite,R bindings for functions from the UCR Suite by Rakthanmanon et al. (2012) <doi:10.1145/2339530.2339576>, which enables ultrafast subsequence
      search for a best match under Dynamic Time Warping and Euclidean Distance.
curstatCI,2017-07-25,curstatCI: Confidence Intervals for the Current Status Model,Computes the maximum likelihood estimator, the smoothed maximum likelihood
    estimator and pointwise bootstrap confidence intervals for the distribution 
    function under current status data. 
    Groeneboom and Hendrickx (2017) <doi:10.1214/17-EJS1345>.
icmm,2017-07-27,icmm: Empirical Bayes Variable Selection via ICM/M Algorithm,Carries out empirical Bayes variable selection via ICM/M algorithm. The basic problem is to fit high-dimensional regression which most coefficients are assumed to be zero. This package allows incorporating the Ising prior to capture structure of predictors in the modeling process. The current version of this package can handle the normal, binary logistic, and Cox's regression (Pungpapong et. al. (2015) <doi:10.1214/15-EJS1034>, Pungpapong et. al. (2017) <arXiv:1707.08298>).
iDINGO,2017-08-22,iDINGO: Integrative Differential Network Analysis in Genomics,Fits covariate dependent partial correlation matrices for integrative models to identify differential networks between two groups. The method is described in Ha et. al., (2015) <doi:10.1093/bioinformatics/btv406>.
HybridFS,2017-09-25,HybridFS: A Hybrid Filter-Wrapper Feature Selection Method,A hybrid method of feature selection which combines both filter and wrapper methods. The first level involves feature reduction based on some of the important filter methods while the second level involves feature subset selection as in a wrapper method. Comparative analysis with the existing feature selection packages shows this package results in higher classification accuracy, reduced processing time and improved data handling capacity.
brea,2016-10-06,brea: Bayesian Recurrent Event Analysis,A function to produce MCMC samples for posterior inference in semiparametric Bayesian discrete time competing risks recurrent events models.
colf,2016-12-03,colf: Constrained Optimization on Linear Function,Performs least squares constrained optimization on a linear objective function. It contains
    a number of algorithms to choose from and offers a formula syntax similar to lm().
RcppBlaze,2017-02-20,RcppBlaze: 'Rcpp' Integration for the 'Blaze' High-Performance C++ Math
Library,'Blaze' is an open-source, high-performance C++ math library
    for dense and sparse arithmetic. With its state-of-the-art Smart Expression
    Template implementation 'Blaze' combines the elegance and ease of use of a
    domain-specific language with 'HPC'-grade performance, making it one of the most
    intuitive and fastest C++ math libraries available. The 'Blaze' library offers:
    - high performance through the integration of 'BLAS' libraries and manually
    tuned 'HPC' math kernels - vectorization by 'SSE', 'SSE2', 'SSE3', 'SSSE3', 'SSE4', 
    'AVX', 'AVX2', 'AVX-512', 'FMA', and 'SVML' - parallel execution by 'OpenMP', C++11 
    threads and 'Boost' threads ('Boost' threads are disabled in 'RcppBlaze') - the 
    intuitive and easy to use API of a domain specific language - unified arithmetic 
    with dense and sparse vectors and matrices - thoroughly tested matrix and vector 
    arithmetic - completely portable, high quality C++ source code. The 'RcppBlaze' 
    package includes the header files from the 'Blaze' library with disabling some 
    functionalities related to link to the thread and system libraries which make 
    'RcppBlaze' be a header-only library. Therefore, users do not need to install 
    'Blaze' and the dependency 'Boost'. 'Blaze' is licensed under the New (Revised) 
    BSD license, while 'RcppBlaze' (the 'Rcpp' bindings/bridge to 'Blaze') is licensed 
    under the GNU GPL version 2 or later, as is the rest of 'Rcpp'. Note that since 
    'Blaze' has committed to 'C++14' commit to 'C++14' which does not used by most R users
    from version 3.0, we will use the version 2.6 of 'Blaze' which is 'C++98' compatible 
    to support the most compilers and system.
Replicate,2017-09-30,Replicate: Statistical Metrics for Multisite Replication Studies,For a multisite replication project, computes metrics and confidence intervals representing: (1) the probability that the original study would observe an estimated effect size as extreme or more extreme than it actually did, if in fact the original study is statistically consistent with the replications; (2) the probability of a true effect of scientifically meaningful size in the same direction as the estimate the original study; and (3) the probability of a true effect of meaningful size in the direction opposite the original study's estimate. Additionally computes older metrics used in replication projects (namely expected agreement in "statistical significance" between an original study and replication studies as well as prediction intervals for the replication estimates). See Mathur and VanderWeele (2017; <https://osf.io/apnjk/>) for details. 
BMhyb,2017-09-11,BMhyb: Hybrid Trait Evolution under Brownian Motion,Analyzes the phenotypic evolution of species
    of hybrid origin on a phylogenetic network. This package can detect the hybrid
    vigor effect, a burst of variation at formation, and the relative portion of
    heritability from its parents. Parameters are estimated by maximum likelihood.
    Users need to enter a comparative data set, a phylogeny, and information on gene
    flow leading to hybrids. See Jhwueng and O'Meara (2017) 
    <doi:10.1101/023986>.
D3partitionR,2016-10-01,D3partitionR: Interactive Charts of Nested and Hierarchical Data with 'D3.js',Builds interactive 'd3.js' hierarchical visualisation easily. D3partitionR makes it easy to build and customize sunburst, circle treemap, treemap, partition chart, ...
editData,2017-09-24,editData: 'RStudio' Addin for Editing a 'data.frame',An 'RStudio' addin for editing a 'data.frame' or a 'tibble'. You can delete, add or update a 'data.frame'
    without coding. You can get resultant data as a 'data.frame'. In the package, modularized 'shiny' app codes are provided. 
    These modules are intended for reuse across applications.
BaTFLED3D,2017-02-12,BaTFLED3D: Bayesian Tensor Factorization Linked to External Data,BaTFLED is a machine learning algorithm designed to make predictions and determine interactions in data that varies along three independent modes. For example BaTFLED was developed to predict the growth of cell lines when treated with drugs at different doses. The first mode corresponds to cell lines and incorporates predictors such as cell line genomics and growth conditions. The second mode corresponds to drugs and incorporates predictors indicating known targets and structural features. The third mode corresponds to dose and there are no dose-specific predictors (although the algorithm is capable of including predictors for the third mode if present). See 'BaTFLED3D_vignette.rmd' for a simulated example.
BrownDog,2017-06-28,BrownDog: Brown Dog R Interface,An R interface for the Brown Dog which allows researchers to leverage Brown Dog Services 
    that provides modules to identify the conversion options for a file, to convert file to appropriate
    format, or to extract data from a file. See <http://browndog.ncsa.illinois.edu/> for more information.  
DWLasso,2017-08-25,DWLasso: Degree Weighted Lasso,Infers networks with hubs using degree weighted Lasso method.
DataEntry,2017-03-14,DataEntry: Make it Easier to Enter Questionnaire Data,This is a GUI application for defining
  attributes and setting valid values of variables, and then,
  entering questionnaire data in a data.frame.
proustr,2017-06-07,proustr: Tools for Natural Language Processing in French,Tools for Natural Language Processing in French and texts from Marcel Proust's collection 
  "A La Recherche Du Temps Perdu". The novels contained in this collection are 
  "Du cote de chez Swann ", "A l'ombre des jeunes filles en fleurs","Le Cote de Guermantes", 
  "Sodome et Gomorrhe I et II", "La Prisonniere", "Albertine disparue", and "Le Temps retrouve".
confinterpret,2017-03-15,confinterpret: Descriptive Interpretations of Confidence Intervals,Produces descriptive interpretations of confidence intervals.
    Includes (extensible) support for various test types, specified as sets
    of interpretations dependent on where the lower and upper confidence limits
    sit. Provides plotting functions for graphical display of interpretations.
additiveDEA,2017-08-02,additiveDEA: Additive Data Envelopment Analysis Models,Provides functions for calculating efficiency with two types of additive Data Envelopment Analysis models: (i) Generalized Efficiency Measures: unweighted additive model (Cooper et al., 2007 <doi:10.1007/978-0-387-45283-8>), Range Adjusted Measure (Cooper et al., 1999, <doi:10.1023/A:1007701304281>), Bounded Adjusted Measure (Cooper et al., 2011 <doi:10.1007/s11123-010-0190-2>), Measure of Inefficiency Proportions (Cooper et al., 1999 <doi:10.1023/A:1007701304281>), and the Lovell-Pastor Measure (Lovell and Pastor, 1995 <doi:10.1016/0167-6377(95)00044-5>); and (ii) the Slacks-Based Measure (Tone, 2001 <doi:10.1016/S0377-2217(99)00407-5>). The functions provide several options: (i) constant and variable returns to scale; (ii) fixed (non-controllable) inputs and/or outputs; (iii) bounding the slacks so that unrealistically large slack values are avoided; and (iv) calculating the efficiency of specific Decision-Making Units (DMUs), rather than of the whole sample. Package additiveDEA also provides a function for reducing computation time when datasets are large.
TSCS,2017-06-06,TSCS: Time Series Cointegrated System,A set of functions to implement Time Series Cointegrated System (TSCS)
    spatial interpolation and relevant data visualization.
msaR,2016-12-06,msaR: Multiple Sequence Alignment for R Shiny,Visualises multiple sequence alignments dynamically within the
    Shiny web application framework.
basictabler,2017-09-30,basictabler: Construct Rich Tables for Output to 'HTML'/'Excel',Easily create tables from data 
    frames/matrices.  Create/manipulate tables 
    row-by-row, column-by-column or cell-by-cell.  
    Use common formatting/styling to output 
    rich tables as 'HTML', 'HTML widgets' or to 
    'Excel'. 
msu,2017-09-30,msu: Multivariate Symmetric Uncertainty and Other Measurements,Estimators for multivariate symmetrical uncertainty based
    on the work of Gustavo Sosa et al. (2016) <arXiv:1709.08730>,
    total correlation, information gain and symmetrical uncertainty of
    categorical variables.
SimTimeVar,2017-09-30,SimTimeVar: Simulate Longitudinal Dataset with Time-Varying Correlated
Covariates,Flexibly simulates a dataset with time-varying covariates with user-specified exchangeable correlation structures across and within clusters. Covariates can be normal or binary and can be static within a cluster or time-varying. Time-varying normal variables can optionally have linear trajectories within each cluster. See ?make_one_dataset for the main wrapper function. See Montez-Rath et al. <arXiv:1709.10074> for methodological details. 
statsDK,2017-09-05,statsDK: A Wrapper for the API of Statistics Denmark,Makes it possible through simple functions and commands to get and
    organize official danish statistics within a wide range of subjects. Visit
    the <http://statbank.dk/> and <http://api.statbank.dk/console> for further
    exploration of Statistics Denmark data.
apercu,2017-04-26,apercu: Quick Look at your Data,The goal is to print an "aperçu", a short view of a vector, a
    matrix, a data.frame, a list or an array. By default, it prints the first 5
    elements of each dimension. By default, the number of columns is equal to
    the number of lines. If you want to control the selection of the elements,
    you can pass a list, with each element being a vector giving the selection
    for each dimension.
CHMM,2017-04-19,CHMM: Coupled Hidden Markov Models,An exact and a variational inference for
    coupled Hidden Markov Models applied to the joint detection of copy number variations.
MFKnockoffs,2017-07-08,MFKnockoffs: Model-Free Knockoff Filter for Controlled Variable Selection,Model-free knockoffs are a general procedure for controlling the false
  discovery rate (FDR) when performing variable selection. For more information,
  see the website below and the accompanying paper: Candes et al., 
  "Panning for Gold: Model-free Knockoffs for High-dimensional Controlled Variable Selection", 
  2016, <arXiv:1610.02351>.
ArchaeoPhases,2017-02-07,ArchaeoPhases: Post-Processing of the Markov Chain Simulated by 'ChronoModel',
'Oxcal' or 'BCal',Provides a list of functions for the statistical analysis of archaeological dates and groups of dates. It is based on the post-processing of the Markov Chains whose stationary distribution is the posterior distribution of a series of dates. Such output can be simulated by different applications as for instance 'ChronoModel' (see <http://www.chronomodel.fr>), 'Oxcal' (see <https://c14.arch.ox.ac.uk/oxcal.html>) or 'BCal' (see <http://bcal.shef.ac.uk/>). The only requirement is to have a csv file containing a sample from the posterior distribution.
breakfast,2017-05-26,breakfast: Multiple Change-Point Detection and Segmentation,The breakfast package performs multiple change-point detection in data
    sequences, or sequence segmentation, using computationally efficient multiscale
    methods. This version of the package implements the "Tail-Greedy Unbalanced Haar",
    "Wild Binary Segmentation" and "Adaptive Wild Binary Segmentation" change-point
    detection and segmentation methodologies. To start with, see the function
    segment.mean.
glacierSMBM,2017-09-28,glacierSMBM: Glacier Surface Mass Balance Model,A fully distributed glacier surface mass balance model developed for the simulation of accumulation and ablation processes on debris-free as well as debris-covered glaciers.
isnullptr,2017-09-25,isnullptr: Check if an 'externalptr' is a Null Pointer,
    Check if an 'externalptr' is a null pointer.
    R does currently not have a native function for that purpose.
    This package contains a C function that returns TRUE in case of a null pointer.
pder,2017-09-28,pder: Panel Data Econometrics with R,Data sets for the Panel Data Econometrics with R book.
pifpaf,2017-05-31,pifpaf: Potential Impact Fraction and Population Attributable Fraction
for Cross-Sectional Data,Uses a generalized method to estimate the Potential Impact Fraction (PIF) and the Population Attributable Fraction (PAF) from cross-sectional data. It creates point-estimates, confidence intervals, and estimates of variance. In addition it generates plots for conducting sensitivity analysis. The estimation method corresponds to  Zepeda-Tello,  Camacho-García-Formentí, et al. 2017. 'Nonparametric Methods to Estimate the Potential Impact Fraction from Cross-sectional Data'. Unpublished manuscript. This package was developed under funding by Bloomberg Philanthropies.
ecoseries,2017-01-05,ecoseries: An R Interface to Brazilian Central Bank and Sidra APIs and the
IPEA Data,Creates an R interface to the Bacen <http://api.bcb.gov.br/> and Sidra <http://api.sidra.ibge.gov.br> APIs and IPEA data <http://www.ipeadata.gov.br/Default.aspx>.
EventStudy,2017-05-20,EventStudy: Event Study Analysis,Perform Event Studies from through our <http://EventStudyTools.com> Application Programming Interface, parse the results, visualize it, and / or use the results in further analysis.
importar,2017-09-19,importar: Enables Importing/Loading of Packages or Functions While
Creating an Alias for Them,Enables 'Python'-like importing/loading of packages or functions
    with aliasing to prevent namespace conflicts.
kfda,2017-09-27,kfda: Kernel Fisher Discriminant Analysis,Kernel Fisher Discriminant Analysis (KFDA) is performed using Kernel Principal Component Analysis (KPCA) and Fisher Discriminant Analysis (FDA).
    There are some similar packages. First, 'lfda' is a package that performs Local Fisher Discriminant Analysis (LFDA) and performs other functions.
    In particular, 'lfda' seems to be impossible to test because it needs the label information of the data in the function argument. Also, the 'ks' package has a limited dimension, which makes it difficult to analyze properly.
    This package is a simple and practical package for KFDA based on the paper of Yang, J., Jin, Z., Yang, J. Y., Zhang, D., and Frangi, A. F. (2004) <doi:10.1016/j.patcog.2003.10.015>.
LFDREmpiricalBayes,2017-09-27,LFDREmpiricalBayes: Estimating Local False Discovery Rates Using Empirical Bayes
Methods,New empirical Bayes methods aiming at analyzing the association of single nucleotide polymorphisms (SNPs) to some particular disease are implemented in this package. The package uses local false discovery rate (LFDR) estimates of SNPs within a sample population defined as a  "reference class" and discovers if SNPs are associated with the corresponding disease. Although SNPs are used throughout this document, other biological data such as protein data and other gene data can be used. Karimnezhad, Ali and Bickel, D. R. (2016) <http://hdl.handle.net/10393/34889>.
tinyProject,2017-09-27,tinyProject: A Lightweight Template for Data Analysis Projects,Creates useful files and folders for data
  analysis  projects and provides functions to manage data,
  scripts and output files. Also provides a project
  template for 'Rstudio'.
BNPMIXcluster,2016-12-03,BNPMIXcluster: Bayesian Nonparametric Model for Clustering with Mixed Scale
Variables,Bayesian nonparametric approach for clustering that is capable to combine different types of variables (continuous, ordinal and nominal) and also accommodates for different sampling probabilities in a complex survey design. The model is based on a location mixture model with a Poisson-Dirichlet process prior on the location parameters of the associated latent variables. The package performs the clustering model described in Carmona, C., Nieto-Barajas, L. E., Canale, A. (2016) <arXiv:1612.00083>.
coinmarketcapr,2017-09-26,coinmarketcapr: Get Cryptocurrencies Market Cap Prices from Coin Market Cap,To extract and monitor price and market cap of 'Crypto currencies' from 'Coin Market Cap' <https://coinmarketcap.com/api/>. 
d3plus,2017-09-25,d3plus: Seamless 'D3Plus' Integration,Provides functions that offer seamless 'D3Plus' integration. The examples provided here are taken from the official 'D3Plus' website <http://d3plus.org>.
econullnetr,2017-09-25,econullnetr: Null Model Analysis for Ecological Networks,Tools for using null models to analyse ecological
    networks (e.g. food webs, flower-visitation networks, seed-dispersal
    networks) and detect resource preferences or non-random interactions among
    network nodes. Tools are provided to run null models, test for and plot
    preferences, plot and analyse bipartite networks, and export null model
    results in a form compatible with other network analysis packages. The 
    underlying null model was developed by Agusti et al. (2003) 
    <doi:10.1046/j.1365-294X.2003.02014.x> and the full application to 
    ecological networks by Vaughan et al. (2017) econullnetr: an R package 
    using null models to analyse the structure of ecological networks and 
    identify resource selection. Methods in Ecology & Evolution, in press.
prioritylasso,2017-03-16,prioritylasso: Analyzing Multiple Omics Data with an Offset Approach,Fits successive Lasso models for several blocks of (omics) data with different priorities and takes the predicted values as an offset for the next block.
parlitools,2017-05-03,parlitools: Tools for Analysing UK Politics,Provides various tools for analysing UK political data, including creating political cartograms and retrieving data.
leabRa,2017-09-22,leabRa: The Artificial Neural Networks Algorithm Leabra,The algorithm Leabra (local error driven and associative
    biologically realistic algorithm) allows for the construction of artificial
    neural networks that are biologically realistic and balance supervised and
    unsupervised learning within a single framework. This package is based on
    the 'MATLAB' version by Sergio Verduzco-Flores, which in turn was based on
    the description of the algorithm by Randall O'Reilly (1996)
    <ftp://grey.colorado.edu/pub/oreilly/thesis/oreilly_thesis.all.pdf>. For
    more general (not 'R' specific) information on the algorithm Leabra see
    <https://grey.colorado.edu/emergent/index.php/Leabra>.
mosaicModel,2017-09-22,mosaicModel: An Interface to Statistical Modeling Independent of Model
Architecture,Provides functions for evaluating, displaying, and interpreting statistical models. The goal is to abstract the operations on models from the particular architecture of the model. For instance, calculating effect sizes rather than looking at coefficients. The package includes interfaces to both regression and classification architectures, including lm(), glm(), rlm() in 'MASS', random forests and recursive partitioning, k-nearest neighbors, linear and quadratic discriminant analysis, and models produced by the 'caret' package's train(). It's straightforward to add in other other model architectures.
MRFA,2017-07-14,MRFA: Fitting and Predicting Large-Scale Nonlinear Regression Problems
using Multi-Resolution Functional ANOVA (MRFA) Approach,Performs the MRFA approach proposed by Sung et al. (2017+) <arXiv:1709.07064> to fit
    and predict nonlinear regression problems, particularly for large-scale and
    high-dimensional problems. The application includes deterministic or stochastic
    computer experiments, spatial datasets, and so on.
OBMbpkg,2017-09-22,OBMbpkg: Estimate the Population Size for the Mb Capture-Recapture Model,Applies an objective Bayesian method to the Mb capture-recapture model to estimate the population size N.  The Mb model is a class of capture-recapture methods used to account for variations in capture probability due to animal behavior.  Under the Mb formulation,  the initial capture of an animal may effect the probability of subsequent captures due to their becoming "trap happy" or "trap shy."
RcmdrPlugin.sutteForecastR,2017-09-22,RcmdrPlugin.sutteForecastR: 'Rcmdr' Plugin for Alpha-Sutte Indicator 'sutteForecastR',The 'sutteForecastR' is a package of Alpha-Sutte indicator. To make the 'sutteForecastR' user friendly, so we develop an 'Rcmdr' plug-in based on the Alpha-Sutte indicator function.
regexSelect,2017-09-22,regexSelect: Regular Expressions in 'shiny' Select Lists,'shiny' extension that adds regular expression filtering capabilities to 
  the choice vector of the select list.
USCF,2017-09-22,USCF: Elo Rating of a USCF Member,Given a U.S. Chess Federation ID number, the elo() function will return the classical Elo rating of that player.
    The function retrieves the information from the USCF website, making it easier for tournament directors at large tournaments to quickly retrieve the ratings of participants.
brazilmaps,2017-09-21,brazilmaps: Brazilian Maps from Different Geographic Levels,Obtain Brazilian map spatial objects of varying
    region types (e.g. cities, states, microregions, mesoregions).
    Convenience functions for plotting choropleths and working with
    the geographic codes are also provided.
magicLamp,2017-09-21,magicLamp: 'WeMo Switch' Smart Plug Utilities,Set of utility functions to interact with 'WeMo Switch', a smart 
    plug that can be remotely controlled via wifi. The provided functions make 
    it possible to turn one or more 'WeMo Switch' plugs on and off in a 
    scriptable fashion. More information about 'WeMo Switch' can be found at 
    <http://www.belkin.com/us/p/P-F7C027/>. 
QLearning,2017-09-21,QLearning: Reinforcement Learning using the Q Learning Algorithm,Implements Q-Learning, a model-free form of reinforcement
        learning, described in work by Strehl, Li, Wiewiora, Langford &
        Littman (2006) <doi:10.1145/1143844.1143955>.
rstansim,2017-09-21,rstansim: Simulation Studies with Stan,Provides a set of functions to facilitate and ease the
    running of simulation studies of Bayesian models using 'stan'. 
    Provides functionality to simulate data, fit models, and manage
    simulation results.
softermax,2017-09-21,softermax: Read Exported Data from 'SoftMax Pro',Read microtiter plate data and templates exported from Molecular
    Devices 'SoftMax Pro' software <https://www.moleculardevices.com/systems/microplate-readers/softmax-pro-7-software>.
    Data exported by 'SoftMax Pro' version 5.4 and greater are supported.
cptec,2017-09-20,cptec: An Interface to the 'CPTEC/INPE' API,Allows to retrieve data from the
    'CPTEC/INPE' weather forecast API. 'CPTEC' stands for 'Centro de Previsão
    de Tempo e Estudos Climáticos' and 'INPE' for 'Instituto Nacional de
    Pesquisas Espaciais'. 'CPTEC' is the most advanced numerical weather and
    climate forecasting center in Latin America, with high-precision short
    and medium-term weather forecasting since the beginning of 1995. See
    <http://www.cptec.inpe.br/> for more information.
ensemblepp,2017-09-20,ensemblepp: Ensemble Postprocessing Data Sets,Data sets for the chapter "Ensemble Postprocessing with R" of the book Stephane Vannitsem, Daniel S. Wilks, and Jakob W. Messner (2017) "Statistical Postprocessing of Ensemble Forecasts", Elsevier, to appear. These data sets contain temperature and precipitation ensemble weather forecasts and corresponding observations at Innsbruck/Austria. Additionally, a demo with the full code of the book chapter is provided.
FDRSeg,2017-09-07,FDRSeg: FDR-Control in Multiscale Change-Point Segmentation,Estimate step functions via multiscale inference with controlled false discovery rate (FDR). For details see H. Li, A. Munk and H. Sieling (2016) <doi:10.1214/16-EJS1131>. 
ROI.plugin.clp,2017-04-12,ROI.plugin.clp: 'Clp (Coin-or linear programming)' Plugin for the 'R'
Optimization Interface,Enhances the R Optimization Infrastructure (ROI) package by registering
	     the COIN-OR Clp open-source solver from the COIN-OR suite <https://projects.coin-or.org/>.
	     It allows for solving linear programming with continuous objective variables 
	     keeping sparse constraints definition.
binaryGP,2017-09-19,binaryGP: Fit and Predict a Gaussian Process Model with (Time-Series)
Binary Response,Allows the estimation and prediction for binary Gaussian process model. The mean function can be assumed to have time-series structure. The estimation methods for the unknown parameters are based on penalized quasi-likelihood/penalized quasi-partial likelihood and restricted maximum likelihood. The predicted probability and its confidence interval are computed by Metropolis-Hastings algorithm. More details can be seen in Sung et al (2017) <arXiv:1705.02511>.
BMT,2017-09-19,BMT: The BMT Distribution,Density, distribution, quantile function, random number generation for the BMT (Bezier-Montenegro-Torres) distribution. Torres-Jimenez C.J. and Montenegro-Diaz A.M. (2017) <arXiv:1709.05534>. Moments, descriptive measures and parameter conversion for different parameterizations of the BMT distribution. Fit of the BMT distribution to non-censored data by maximum likelihood, moment matching, quantile matching, maximum goodness-of-fit, also known as minimum distance, maximum product of spacing, also called maximum spacing, and minimum quantile distance, which can also be called maximum quantile goodness-of-fit. Fit of univariate distributions for non-censored data using maximum product of spacing estimation and minimum quantile distance estimation is also included.
curvecomp,2017-09-19,curvecomp: Multiple Curve Comparisons Using Parametric Bootstrap,Performs multiple comparison procedures on curve observations among different treatment groups. The methods are applicable in a variety of situations (such as independent groups with equal or unequal sample sizes, or repeated measures) by using parametric bootstrap. References to these procedures can be found at Konietschke, Gel, and Brunner (2014) <doi:10.1090/conm/622/12431> and Westfall (2011) <doi:10.1080/10543406.2011.607751>.
envDocument,2017-03-11,envDocument: Document the R Working Environment,Prints out information about the R working environment
    (system, R version,loaded and attached packages and versions) from a single
    function "env_doc()".  Optionally adds information on git repository,
    tags, commits and remotes (if available).
EQUIVNONINF,2017-09-19,EQUIVNONINF: Testing for Equivalence and Noninferiority,Making available in R the complete set of programs accompanying S. Wellek's (2010) monograph
             ”Testing Statistical Hypotheses of Equivalence and Noninferiority. Second Edition”
             (Chapman&Hall/CRC). 
fusionclust,2017-09-19,fusionclust: Clustering and Feature Screening using L1 Fusion Penalty,Provides the Big Merge Tracker and COSCI algorithms for convex clustering and 
    feature screening using L1 fusion penalty. See Radchenko, P. and Mukherjee, G. (2017) <doi:10.1111/rssb.12226> and 
    T.Banerjee et al. (2017) <doi:10.1016/j.jmva.2017.08.001> for more details.
gma,2017-09-19,gma: Granger Mediation Analysis,Performs Granger mediation analysis (GMA) for time series. This package includes a single level GMA model and a two-level GMA model, for time series with hierarchically nested structure. The single level GMA model for the time series of a single participant performs the causal mediation analysis which integrates the structural equation modeling and the Granger causality frameworks. A vector autoregressive model of order p is employed to account for the spatiotemporal dependencies in the data. Meanwhile, the model introduces the unmeasured confounding effect through a nonzero correlation parameter. Under the two-level model, by leveraging the variabilities across participants, the parameters are identifiable and consistently estimated based on a full conditional likelihood or a two-stage method. See Zhao, Y., & Luo, X. (2017), Granger Mediation Analysis of Multiple Time Series with an Application to fMRI, <arXiv:1709.05328> for details.
IGP,2017-09-19,IGP: Interchangeable Gaussian Process Models,Creates a Gaussian process model using the specified package. 
    Makes it easy to try different packages in same code, only the
    package argument needs to be changed.
    It is essentially a wrapper for the other Gaussian process
    software packages.
kpeaks,2017-09-19,kpeaks: Determination of K Using Peak Counts of Features for Clustering,The input argument k which is the number of clusters is needed to start all of the partitioning clustering algorithms. In unsupervised learning applications, an optimal value of this argument is widely determined by using the internal validity indexes. Since these indexes suggest a k value which is computed on the clustering results after several runs of a clustering algorithm they are computationally expensive. On the contrary, 'kpeaks' enables to estimate k before running any clustering algorithm. It is based on a simple novel technique using the descriptive statistics of peak counts of the features in a data set.
SiER,2017-09-19,SiER: Signal Extraction Approach for Sparse Multivariate Response
Regression,Methods for regression with high-dimensional predictors and  univariate or maltivariate response variables. It considers the decomposition of the coefficient matrix that leads to the best approximation to the signal part in the response given any rank, and estimates the decomposition by solving a penalized generalized eigenvalue problem followed by a least squares procedure. Ruiyan Luo and Xin Qi (2017) <doi:10.1016/j.jmva.2016.09.005>.
sure,2017-08-21,sure: Surrogate Residuals for Ordinal and General Regression Models,An implementation of the surrogate approach to residuals and 
  diagnostics for ordinal and general regression models; for details, see Liu 
  and Zhang (2017) <doi:10.1080/01621459.2017.1292915>. These residuals can be 
  used to construct standard residual plots for model diagnostics (e.g., 
  residual-vs-fitted value plots, residual-vs-covariate plots, Q-Q plots, etc.). 
  The package also provides an 'autoplot' function for producing standard 
  diagnostic plots using 'ggplot2' graphics. The package currently supports 
  cumulative link models from packages 'MASS', 'ordinal', 'rms', and 'VGAM'. 
  Support for binary regression models using the standard 'glm' function is also 
  available.
BNSL,2017-03-08,BNSL: Bayesian Network Structure Learning,From a given data frame, this package learns its Bayesian network structure based on a selected score.
leafSTAR,2017-09-18,leafSTAR: Silhouette to Area Ratio of Tilted Surfaces,Implementation of trigonometric functions to calculate the exposure of flat, tilted surfaces, such as leaves and slopes, to direct solar radiation. It implements the equations in A.G. Escribano-Rocafort, A. Ventre-Lespiaucq, C. Granado-Yela, et al. (2014) <doi:10.1111/2041-210X.12141> in a few user-friendly R functions. All functions handle data obtained with 'Ahmes' 1.0 for Android, as well as more traditional data sources (compass, protractor, inclinometer). The main function (star()) calculates the potential exposure of flat, tilted surfaces to direct solar radiation (silhouette to area ratio, STAR). It is equivalent to the ratio of the leaf projected area to total leaf area, but instead of using area data it uses spatial position angles, such as pitch, roll and course, and information on the geographical coordinates, hour, and date. The package includes additional functions to recalculate STAR with custom settings of location and time, to calculate the tilt angle of a surface, and the minimum angle between two non-orthogonal planes.
mcMST,2017-07-11,mcMST: A Toolbox for the Multi-Criteria Minimum Spanning Tree Problem,Algorithms to approximate the Pareto-front of multi-criteria minimum spanning tree problems. Additionally, a modular toolbox for the generation of multi-objective benchmark graph problems is included.
tsgui,2017-09-18,tsgui: Gui for Simulating Time Series,This gui shows realisations of times series, currently ARMA and GARCH processes. It might be helpful for teaching and studying.
cytominer,2017-09-17,cytominer: Methods for Image-Based Cell Profiling,Typical morphological profiling datasets have millions of cells
    and hundreds of features per cell. When working with this data, you must
    clean the data, normalize the features to make them comparable across
    experiments, transform the features, select features based on their
    quality, and aggregate the single-cell data, if needed. 'cytominer' makes
    these steps fast and easy. Methods used in practice in the field are
    discussed in Caicedo (2017) <doi:10.1038/nmeth.4397>. An overview of the
    field is presented in Caicedo (2016) <doi:10.1016/j.copbio.2016.04.003>.
randnet,2017-09-17,randnet: Random Network Model Selection and Parameter Tuning,Model selection and parameter tuning procedures for a class of random network models. The model selection can be done by a general cross-validation framework called ECV from Li et. al. (2016) <arXiv:1612.04717> . Several other model-based and task-specific methods are also included, such as NCV from Chen and Lei (2016) <arXiv:1411.1715>, likelihood ratio method from Wang and Bickel (2015) <arXiv:1502.02069>, spectral methods from Le and Levina (2015) <arXiv:1507.00827>. Many network analysis methods are also implemented, such as the regularized spectral clustering (Amini et. al. 2013 <doi:10.1214/13-AOS1138>) and its degree corrected version and graphon neighborhood smoothing (Zhang et. al. 2015 <arXiv:1509.08588>).
rbtt,2017-09-17,rbtt: Alternative Bootstrap-Based t-Test Aiming to Reduce Type-I Error
for Non-Negative, Zero-Inflated Data,Tu & Zhou (1999) <doi:10.1002/(SICI)1097-0258(19991030)18:20%3C2749::AID-SIM195%3E3.0.CO;2-C> showed that comparing the means of populations whose data-generating distributions are non-negative with excess zero observations is a problem of great importance in the analysis of medical cost data. In the same study, Tu & Zhou discuss that it can be difficult to control type-I error rates of general-purpose statistical tests for comparing the means of these particular data sets. This package allows users to perform a modified bootstrap-based t-test that aims to better control type-I error rates in these situations.
SampleSize4ClinicalTrials,2017-09-17,SampleSize4ClinicalTrials: Sample Size Calculation for Mean and Proportion Comparisons in
Phase 3 Clinical Trials,The design of phase 3 clinical trials can be classified into 4 types: (1) Testing for equality;(2) Superiority trial;(3) Non-inferiority trial; and (4) Equivalence trial according to the goals. Given that none of the available packages combines these designs in a single package, this package has made it possible for researchers to calculate sample size when comparing means or proportions in phase 3 clinical trials with different designs. The ssc function can calculate the sample size with pre-specified type 1 error rate,statistical power and effect size according to the hypothesis testing framework. Furthermore, effect size is comprised of true treatment difference and non-inferiority or equivalence margins which can be set in ssc function. (Reference: Yin, G. (2012). Clinical Trial Design: Bayesian and Frequentist Adaptive Methods. John Wiley & Sons.) 
DES,2017-09-16,DES: Discrete Event Simulation,Discrete event simulation (DES) involves modeling of systems
   having discrete, i.e. abrupt, state changes. For instance, when a job
   arrives to a queue, the queue length abruptly increases by 1.  This
   package is an R implementation of the event-oriented approach to DES;
   see the tutorial in Matloff (2008) 
   <http://heather.cs.ucdavis.edu/~matloff/156/PLN/DESimIntro.pdf>.
googleComputeEngineR,2016-11-19,googleComputeEngineR: R Interface with Google Compute Engine,Interact with the 'Google Compute Engine' API in R. Lets you create, 
  start and stop instances in the 'Google Cloud'.  Support for preconfigured instances, 
  with templates for common R needs. 
MsdeParEst,2017-09-16,MsdeParEst: Parametric Estimation in Mixed-Effects Stochastic Differential
Equations,Parametric estimation in stochastic differential equations with random effects in the drift, or in the diffusion or both. Approximate maximum likelihood methods are used. M. Delattre, V. Genon-Catalot and A. Samson (2012) <doi:10.1111/j.1467-9469.2012.00813.x> M. Delattre, V. Genon-Catalot and A. Samson (2015) <doi:10.1051/ps/2015006> M. Delattre, V. Genon-Catalot and A. Samson (2016) <doi:10.1016/j.jspi.2015.12.003>.
wildcard,2017-05-21,wildcard: Templates for Data Frames,Generate data frames from templates.
AurieLSHGaussian,2017-09-13,AurieLSHGaussian: Creates a Neighbourhood Using Locality Sensitive Hashing for
Gaussian Projections,Uses locality sensitive hashing and creates a neighbourhood graph for a data set and calculates the adjusted rank index value for the same. It uses Gaussian random planes to decide the nature of a given point. Datar, Mayur, Nicole Immorlica, Piotr Indyk, and Vahab S. Mirrokni(2004) <doi:10.1145/997817.997857>.
CATTexact,2017-09-15,CATTexact: Computation of the p-Value for the Exact Conditional
Cochran-Armitage Trend Test,Provides functions for computing the one-sided p-values of the Cochran-Armitage trend test
  statistic for the asymptotic and the exact conditional test. The computation of the p-value for the exact test
  is performed using an algorithm following an idea by Mehta, et al. (1992) <doi:10.2307/1390598>.
gradientPickerD3,2017-09-15,gradientPickerD3: Interactive Color Gradient Picker Using 'htmlwidgets' and the
Modified JS Script 'jquery-gradient-picker',Widget for an interactive selection and modification of a color gradient. 'gradientPickerD3' allows addition, removement and replacement of color ticks. List of numeric values will automatically translate in their corresponding tick position within the numeric range. App returns a data.frame containing tick values, colors and the positions in percent (0.0 to 1.0) for each color tick in the gradient. The original JS 'jquery-gradient-picker' was implemented by Matt Crinklaw-Vogt (nick: tantaman) <https://github.com/tantaman/>. Widget and JS modifications were done by CD. Peikert.
linemap,2017-09-15,linemap: Line Maps,Create maps made of lines. The package contains two functions: linemap() and getgrid(). linemap() displays a map made of lines using a data frame of gridded data. getgrid() transforms a set of polygons (sf objects) into a suitable data frame for linemap().
MFT,2017-09-15,MFT: The Multiple Filter Test for Change Point Detection,Provides statistical tests and algorithms for the detection of change points in time series and point processes - particularly for changes in the mean in time series and for changes in the rate and in the variance in point processes. References - Michael Messer, Marietta Kirchner, Julia Schiemann, Jochen Roeper, Ralph Neininger and Gaby Schneider (2014) <doi:10.1214/14-AOAS782>, Stefan Albert, Michael Messer, Julia Schiemann, Jochen Roeper, Gaby Schneider (2017) <doi:10.1111/jtsa.12254>, Michael Messer, Kaue M. Costa, Jochen Roeper and Gaby Schneider (2017) <doi:10.1007/s10827-016-0635-3>.
veccompare,2017-09-15,veccompare: Perform Set Operations on Vectors, Automatically Generating All
n-Wise Comparisons, and Create Markdown Output,Automates set operations (i.e., comparisons of overlap) between multiple vectors.
    It also contains a function for automating reporting in 'RMarkdown', by generating markdown output for easy analysis, as well as an 'RMarkdown' template for use with 'RStudio'.
CausalImpact,2017-04-10,CausalImpact: Inferring Causal Effects using Bayesian Structural Time-Series
Models,Implements a Bayesian approach to causal impact estimation in time
  series, as described in Brodersen et al. (2015) <doi:10.1214/14-AOAS788>.
  See the package documentation on GitHub
  <https://google.github.io/CausalImpact/> to get started.
causalMGM,2017-08-30,causalMGM: Causal Learning of Mixed Graphical Models,Allows users to learn undirected and directed (causal) graphs over mixed data types (i.e., continuous and discrete variables). To learn a directed graph over mixed data, it first calculates the undirected graph (Sedgewick et al, 2016) and then it uses local search strategies to prune-and-orient this graph (Sedgewick et al, 2017). AJ Sedgewick, I Shi, RM Donovan, PV Benos (2016) <doi:10.1186/s12859-016-1039-0>. AJ Sedgewick, JD Ramsey, P Spirtes, C Glymour, PV Benos (2017) <arXiv:1704.02621>.
glassdoor,2017-09-14,glassdoor: Interface to 'Glassdoor' API,Interacts with the 'Glassdoor' API
    <https://www.glassdoor.com/developer/index.htm>. Allows the user to
    search job statistics, employer statistics, and job progression,
    where 'Glassdoor' provides a breakdown of other jobs a person did
    after their current one.
ADPF,2017-09-13,ADPF: Use Least Squares Polynomial Regression and Statistical Testing
to Improve Savitzky-Golay,This function takes a vector or matrix of data and smooths
    the data with an improved Savitzky Golay transform. The Savitzky-Golay
    method for data smoothing and differentiation calculates convolution
    weights using Gram polynomials that exactly reproduce the results of
    least-squares polynomial regression. Use of the Savitzky-Golay
    method requires specification of both filter length and
    polynomial degree to calculate convolution weights. For maximum
    smoothing of statistical noise in data, polynomials with
    low degrees are desirable, while a high polynomial degree
    is necessary for accurate reproduction of peaks in the data.
    Extension of the least-squares regression formalism with
    statistical testing of additional terms of polynomial degree
    to a heuristically chosen minimum for each data window leads
    to an adaptive-degree polynomial filter (ADPF). Based on noise
    reduction for data that consist of pure noise and on signal
    reproduction for data that is purely signal, ADPF performed
    nearly as well as the optimally chosen fixed-degree
    Savitzky-Golay filter and outperformed sub-optimally chosen
    Savitzky-Golay filters. For synthetic data consisting of noise
    and signal, ADPF outperformed both optimally chosen and
    sub-optimally chosen fixed-degree Savitzky-Golay filters. See Barak, P. (1995) <doi:10.1021/ac00113a006> for more information.
auto.pca,2017-09-12,auto.pca: Automatic Variable Reduction Using Principal Component Analysis,PCA done by eigenvalue decomposition of a data correlation matrix, here it automatically determines the number of factors by eigenvalue greater than 1 and it gives the uncorrelated variables based on the rotated component scores, Such that in each principal component variable which has the high variance are selected. It will be useful for non-statisticians in selection of variables. For more information, see the <http://www.ijcem.org/papers032013/ijcem_032013_06.pdf> web page.
DCD,2017-09-12,DCD: Differential Community Detection in Paired Biological Networks,A differential community detection (DCD) based approach to effectively locate differential sub-networks in paired scale-free biological networks, e.g. case vs control - Raghvendra Mall et al (2017) <doi:10.1145/3107411.3107418>.
medmod,2017-09-12,medmod: Simple Mediation and Moderation Analysis,This toolbox allows you to do simple mediation and moderation 
    analysis. It is also available as a module for 'jamovi' 
    (see <https://www.jamovi.org> for more information). 'Medmod' is based 
    on the 'lavaan' package by Yves Rosseel. You can find an in depth tutorial 
    on the 'lavaan' model syntax used for this package on 
    <http://lavaan.ugent.be/tutorial/index.html>.
PredPsych,2017-02-15,PredPsych: Predictive Approaches in Psychology,
    Recent years have seen an increased interest in novel methods
    for analyzing quantitative data from experimental psychology. Currently, however, they lack an
    established and accessible software framework. Many existing implementations provide no guidelines,
    consisting of small code snippets, or sets of packages. In addition, the use of existing packages
    often requires advanced programming experience. 'PredPsych' is a user-friendly toolbox based on
    machine learning predictive algorithms. It comprises of multiple functionalities for multivariate
    analyses of quantitative behavioral data based on machine learning models.
unifDAG,2017-09-12,unifDAG: Uniform Sampling of Directed Acyclic Graphs,Uniform sampling of Directed Acyclic Graphs (DAG) using exact
 enumeration by relating each DAG to a sequence of outpoints (nodes with no
 incoming edges) and then to a composition of integers as suggested by
 Kuipers, J. and Moffa, G. (2015) <doi:10.1007/s11222-013-9428-y>.
GauPro,2016-10-12,GauPro: Gaussian Process Fitting,Fits a Gaussian process model to data. Gaussian processes
 are commonly used in computer experiments to fit an interpolating model.
 The model is stored as an 'R6' object and can be easily updated with new 
 data. There are options to run in parallel (not for Windows), and 'Rcpp'
 has been used to speed up calculations. Other R packages that perform
 similar calculations include 'laGP', 'DiceKriging', 'GPfit', and 'mlegp'.
nos,2017-05-31,nos: Compute Node Overlap and Segregation in Ecological Networks,Calculate NOS (node overlap and segregation) and
    the associated metrics described in Strona and Veech (2015)
    <doi:10.1111/2041-210X.12395> and Strona et al. (2017, In Press).
    The functions provided in the package enable assessment of
    structural patterns ranging from complete node segregation to perfect
    nestedness in a variety of network types. In addition, they provide a
    measure of network modularity.  
opendotaR,2017-09-11,opendotaR: Interface for OpenDota API,Enables the usage of the OpenDota API from <https://www.opendota.com/>, get game lists, and download JSON's of parsed replays from
    the OpenDota API. Also has functionality to execute own code to extract the specific parts of the JSON file.
sutteForecastR,2017-09-11,sutteForecastR: Forecasting Data using Alpha-Sutte Indicator,The alpha-Sutte indicator (alpha-Sutte) was originally from developed of Sutte indicator. Sutte indicator can using to predict the movement of stocks. As the development of science, then Sutte indicator developed to predict not only the movement of stocks but also can forecast data on financial, insurance, and others time series data. Ahmar, A.S. (2017) <doi:10.17605/osf.io/rknsv>.
yuimaGUI,2016-12-03,yuimaGUI: A Graphical User Interface for the 'yuima' Package,Provides a graphical user interface for the 'yuima' package.
MTSYS,2017-08-02,MTSYS: Methods in Mahalanobis-Taguchi (MT) System,Mahalanobis-Taguchi (MT) system is a collection of multivariate
    analysis methods developed for the field of quality engineering. MT system
    consists of two families depending on their purpose. One is a family of
    Mahalanobis-Taguchi (MT) methods (in the broad sense) for diagnosis (see
    Woodall, W. H., Koudelik, R., Tsui, K. L., Kim, S. B., Stoumbos, Z. G., and
    Carvounis, C. P. (2003) <doi:10.1198/004017002188618626>) and the other is a
    family of Taguchi (T) methods for forecasting (see Kawada, H., and Nagata, Y.
    (2015) <doi:10.17929/tqs.1.12>). The MT package contains three basic methods
    for the family of MT methods and one basic method for the family of T
    methods. The MT method (in the narrow sense), the Mahalanobis-Taguchi
    Adjoint (MTA) methods, and the Recognition-Taguchi (RT) method are for the
    MT method and the two-sided Taguchi (T1) method is for the family of T
    methods. In addition, the Ta and Tb methods, which are the improved versions
    of the T1 method, are included.
CARS,2017-08-02,CARS: Covariate Assisted Ranking and Screening for Large-Scale
Two-Sample Inference,It implements the CARS procedure, which is a two-sample multiple testing procedure that utilizes an additional auxiliary variable to capture the sparsity information, hence improving power. The CARS procedure is shown to be asymptotically valid and optimal for FDR control. For more information, please see the website <http://www-bcf.usc.edu/~wenguans/Papers/CARS.html> and the accompanying paper.
fecR,2016-11-03,fecR: Fishing Effort Calculator in R,Calculates fishing effort following the DG MARE Ad-Hoc Workshops on Transversal Variables in Zagreb (2015) and Nicosia (2016).
GeoMongo,2017-08-07,GeoMongo: Geospatial Queries Using 'PyMongo',Utilizes methods of the 'PyMongo' 'Python' library to initialize, insert and query 'GeoJson' data (see <https://api.mongodb.com/python/current/#> for more information on 'PyMongo'). Furthermore, it allows the user to validate 'GeoJson' objects and to use the console for 'MongoDB' (bulk) commands. The 'reticulate' package provides the 'R' interface to 'Python' modules, classes and functions.
RTaxometrics,2017-05-30,RTaxometrics: Taxometric Analysis,We provide functions to perform taxometric analyses. This package contains 44 functions, but only 5 should be called directly by users. CheckData() should be run prior to any taxometric analysis to ensure that the data are appropriate for taxometric analysis. RunTaxometrics() performs taxometric analyses for a sample of data. RunCCFIProfile() performs a series of taxometric analyses to generate a CCFI profile. CreateData() generates a sample of categorical or dimensional data. ClassifyCases() assigns cases to groups using the base-rate classification method.
distrr,2017-09-08,distrr: Estimate and Manage Empirical Distributions,Tools to estimate and manage empirical distributions,
    which should work with survey data. One of the main features is the 
    possibility to create data cubes of estimated statistics, that include
    all the combinations of the variables of interest (see for example functions
    dcc5() and dcc6()).
repurrrsive,2017-09-08,repurrrsive: Examples of Recursive Lists and Nested or Split Data Frames,Recursive lists in the form of R objects, 'JSON', and 'XML', for use in
    teaching and examples. Examples include color palettes, Game of Thrones
    characters, 'GitHub' users and repositories, and entities from the Star Wars
    universe. Data from the 'gapminder' package is also included, as a simple data
    frame and in nested and split forms.
SMM,2017-07-22,SMM: Simulation and Estimation of Multi-State Discrete-Time
Semi-Markov and Markov Models,Performs parametric and non-parametric estimation and simulation for multi-state discrete-time semi-Markov processes. 
	For the parametric estimation, several discrete distributions are considered for the sojourn times: Uniform, Geometric, Poisson, Discrete Weibull and Negative Binomial. The non-parametric estimation concerns the sojourn time distributions, where no assumptions are done on the shape of distributions. 
	Moreover, the estimation can be done on the basis of one or several sample paths, with or without censoring at the beginning or/and at the end of the sample paths. The implemented methods are described in Barbu, V.S., Limnios, N. (2008) <doi:10.1007/978-0-387-73173-5>, Barbu, V.S., Limnios, N. (2008) <doi:10.1080/10485250701261913> and 
	Trevezas, S., Limnios, N. (2011) <doi:10.1080/10485252.2011.555543>. 
	Estimation and simulation of discrete-time k-th order Markov chains are also considered.
AWR,2017-02-11,AWR: 'AWS' Java 'SDK' for R,Installs the compiled Java modules of the Amazon Web Services ('AWS') 'SDK' to be used in downstream R packages interacting with 'AWS'. See <https://aws.amazon.com/sdk-for-java> for more information on the 'AWS' 'SDK' for Java.
Bios2cor,2017-08-24,Bios2cor: From Biological Sequences and Simulations to Correlation
Analysis,Utilities for computation and analysis of correlation/co-variation in multiple sequence alignments and in side chain motions during molecular dynamics simulations. Features include the computation of correlation/co-variation scores using a variety of scoring functions between either sequence positions in alignments or side chain dihedral angles in molecular dynamics simulations and to analyze the correlation/co-variation matrix through a variety of tools including network representation and principal components analysis.  In addition, several utility functions are based on the R graphical environment to provide friendly tools for help in data interpretation. Examples of sequence co-variation analysis and utility tools are provided in: Pele J, Moreau M, Abdi H, Rodien P, Castel H, Chabbert M. (2014) <doi:10.1002/prot.24570>. This work was supported by the French National Research Agency (Grant number: ANR-11-BSV2-026).
cprr,2017-09-07,cprr: Functions for Working with Danish CPR Numbers,Calculate date of birth, age, and gender, and generate anonymous
    sequence numbers from CPR numbers.
    <https://en.wikipedia.org/wiki/Personal_identification_number_(Denmark)>.
mapReasy,2017-09-07,mapReasy: Producing Administrative Boundary Map with Additional Features
Embedded,Produce administrative boundary map, visualize and compare different factors on map, tracking latitude and longitude, bubble plot. The package provides some handy functions to produce different administrative maps easily. Functions to obtain colorful visualization of different regions of interest and sub-divisional administrative map at different levels are included. This csn be used to increase feasibility of mapping disease pattern across different regions (disease mapping) with appropriate colors having intensity coherent with magnitude of prevalence. In many surveys, information on location of sample are collected. Sometimes it is of interest to quick look at the spreadness of the collected sample, check if any observation falls outside of the survey area and identify them. The package provides unique function  to perform these tasks easily. Besides, some additional features have been added to make ad-lib comparison of different factors across the region through these maps. Visual presentation of two different variables on a particular map using two way bubble plot is also provided. Simple bar chart and pie chart can be produced on map to compare several factors.This package will be helpful to researchers-both statistician and non-statistician, to create geographic location wise plotting of different indicators. These types of maps are used in different research areas such public health, economics, environment, journalism etc. It provides functions that will also be helpful to users to create map using two indicators at a time (for example, shade on a map will give the information of one indicator variable, bar/pie/bubble chart will give the information on another indicator). Users only need to select the indicator's value and country wise region specific shapefile and run the functions to find their graphs quickly.The distinguishable features of the functions in this package are they are easy to understand to new R users who are searching some ad-lib functions to produce administrative map with different features and easy to use for those who are unfamiliar with file format of spatial data or geographic location data. Functions in this package adopt, compile and implement functions from some well-known packages on handling spatial data to make an user friendly functionality. So users do not need any additional knowledge about spatial statistics or geographic location data. All the examples presented in this package use shapefile of country Bangladesh downloaded from <http://www.gadm.org>. Users are requested to visit <http://www.gadm.org>, then select Download, then choose country and shapefile from country and File format dropdown menu. After downloading the shapefile of any particular country as compressed file, unzip the file and keep them in a known directory or working directory. Shapefiles of respective countries will be required to produce corresponding country maps. Use shapefile of corresponding country to produce all types of maps available in this package.      
modelwordcloud,2017-09-07,modelwordcloud: Model Word Clouds,Makes a word cloud of text, sized by the frequency of the word, and colored either by user-specified colors or colored by the strength of the coefficient of that text derived from a regression model.
multilaterals,2017-09-07,multilaterals: Transitive Index Numbers for Cross-Sections and Panel Data,Computing transitive (and non-transitive) index numbers (Coelli et al., 2005 <doi:10.1007/b136381>) for cross-sections and panel data. For the calculation of transitive indexes, the EKS (Coelli et al., 2005 <doi:10.1007/b136381>; Rao et al., 2002 <doi:10.1007/978-1-4615-0851-9_4>) and Minimum spanning tree (Hill, 2004 <doi:10.1257/0002828043052178>) methods are implemented. Traditional fixed-base and chained indexes, and their growth rates, can also be derived using the Paasche, Laspeyres, Fisher and Tornqvist formulas. 
PakPMICS2014Ch,2017-09-07,PakPMICS2014Ch: Multiple Indicator Cluster Survey (MICS) 2014 Child
Questionnaire Data for Punjab, Pakistan,Provides data set and functions for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Child questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).
PakPMICS2014HH,2017-09-07,PakPMICS2014HH: Multiple Indicator Cluster Survey (MICS) 2014 Household
Questionnaire Data for Punjab, Pakistan,Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Household questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).
PakPMICS2014HL,2017-09-07,PakPMICS2014HL: Multiple Indicator Cluster Survey (MICS) 2014 Household Listing
Questionnaire Data for Punjab, Pakistan,Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Household Listing questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).
PakPMICS2014Wm,2017-09-07,PakPMICS2014Wm: Multiple Indicator Cluster Survey (MICS) 2014 Women
Questionnaire Data for Punjab, Pakistan,Provides data set and function for exploration of Multiple Indicator Cluster Survey (MICS) 2014 Women (age 15-49 years) questionnaire data for Punjab, Pakistan (<http://www.mics.unicef.org/surveys>).
unjoin,2017-09-07,unjoin: Separate a Data Frame by Normalization,Separate a data frame in two based on key columns. The function unjoin() provides
   an inside-out version of a nested data frame. This is used to identify duplication and normalize it
   (in the database sense) by linking two tables with the redundancy removed. This is a basic 
   requirement for detecting topology within spatial structures that has motivated the need
   for this package as a building block for workflows within more applied projects. 
csabounds,2017-09-06,csabounds: Bounds on Distributional Treatment Effect Parameters,The joint distribution of potential outcomes is not typically identified under standard identifying assumptions such as selection on observables or even when individuals are randomly assigned to being treated. This package contains methods for obtaining tight bounds on distributional treatment effect parameters when panel data is available and under a Copula Stability Assumption as in Callaway (2017) <https://ssrn.com/abstract=3028251>.
FactorsR,2017-02-17,FactorsR: Identification of the Factors Affecting Species Richness,It identifies the factors significantly related to species richness, and their relative contribution, using multiple regressions and support vector machine models. It uses an output file of 'ModestR' (<http://www.ipez.es/ModestR>) with data of richness of the species and environmental variables in a cell size defined by the user. The residuals of the support vector machine model are shown on a map. Negative residuals may be potential areas with undiscovered and/or unregistered species, or areas with decreased species richness due to the negative effect of anthropogenic factors.
madrat,2017-05-29,madrat: May All Data be Reproducible and Transparent (MADRaT) *,Provides a framework which should improve reproducibility and transparency in data processing. It provides functionality such as automatic meta data creation and management, rudimentary quality management, data caching, work-flow management and data aggregation.
    * The title is a wish not a promise. By no means we expect this package to deliver everything what is needed to achieve full reproducibility and transparency, but we believe that it supports efforts in this direction.
Ohit,2017-09-06,Ohit: OGA+HDIC+Trim and High-Dimensional Linear Regression Models,Ing and Lai (2011) <doi:10.5705/ss.2010.081> proposed a high-dimensional model selection procedure that comprises three steps: orthogonal greedy algorithm (OGA), high-dimensional information criterion (HDIC), and Trim. The first two steps, OGA and HDIC, are used to sequentially select input variables and determine stopping rules, respectively. The third step, Trim, is used to delete irrelevant variables remaining in the second step. This package aims at fitting a high-dimensional linear regression model via OGA+HDIC+Trim.
TNC,2017-09-06,TNC: Temporal Network Centrality (TNC) Measures,Node centrality measures for temporal networks. Available measures are temporal degree centrality, temporal closeness centrality and temporal betweenness centrality defined by Kim and Anderson (2012) <doi:10.1103/PhysRevE.85.026107>. Applying the REN algorithm by Hanke and Foraita (2017) <doi:10.1186/s12859-017-1677-x> when calculating the centrality measures keeps the computational running time linear in the number of graph snapshots. Further, all methods can run in parallel up to the number of nodes in the network.
UdderQuarterInfectionData,2017-09-06,UdderQuarterInfectionData: Udder Quarter Infection Data,The udder quarter infection data set contains infection times of individual cow udder quarters with Corynebacterium bovis (Laevens et al. 1997 <doi:10.3168/jds.S0022-0302(97)76295-7>). Obviously, the four udder quarters are clustered within a cow, and udder quarters are sampled only approximately monthly, generating interval-censored data. The data set contains both covariates that change within a cow (e.g., front and rear udder quarters) and covariates that change between cows (e.g., parity [the number of previous calvings]). The correlation between udder infection times within a cow also is of interest, because this is a measure of the infectivity of the agent causing the disease. Various models have been applied to address the problem of interdependence for right-censored event times. These models, as applied to this data set, can be found back in the publications found in the reference list.
FuzzyNumbers.Ext.2,2017-03-18,FuzzyNumbers.Ext.2: Apply Two Fuzzy Numbers on a Monotone Function,One can easily draw the membership function of f(x,y) by package 'FuzzyNumbers.Ext.2' in which f(.,.) is supposed monotone and x and y are two fuzzy numbers. This work is possible using function f2apply() which is an extension of function fapply() from Package 'FuzzyNumbers' for two-variable monotone functions. Moreover, this package has the ability of computing the core, support and alpha-cuts of the fuzzy-valued final result.
graphql,2016-10-04,graphql: A GraphQL Query Parser,Bindings to the 'libgraphqlparser' C++ library. Currently parses
    GraphQL and exports the AST in JSON format.
RcextTools,2017-06-06,RcextTools: Analytical Procedures in Support of Brazilian Public Sector
External Auditing,Set of analytical procedures based on advanced data analysis in support of Brazil's public sector external control activity.
VDSPCalibration,2017-09-05,VDSPCalibration: Statistical Methods for Designing and Analyzing a Calibration
Study,Provides statistical methods for the design and analysis of a calibration study, which aims for calibrating measurements using two different methods. The package includes sample size calculation, sample selection,  regression analysis with error-in measurements and change-point regression. The method is described in Tian, Durazo-Arvizu, Myers, et al. (2014) <doi:10.1002/sim.6235>.
billboard,2017-09-04,billboard: Contains Data of Billboard Hot 100 Songs,Contains data sets regarding songs on the Billboard Hot 100 list
    from 1960 to 2016. The data sets include the ranks for the given year,
    musical features of a lot of the songs and lyrics for several of the songs
    as well.
BosonSampling,2017-09-04,BosonSampling: Classical Boson Sampling,Classical Boson Sampling using the algorithm of
 Clifford and Clifford (2017) <arXiv:1706.01260>. Also provides functions for
 generating random unitary matrices, evaluation of matrix permanents (both
 real and complex) and evaluation of complex permanent minors.
cbanalysis,2017-04-13,cbanalysis: Coffee Break Descriptive Analysis,A set of functions that helps you to generate descriptive statistics based on the variable types.
dplyrAssist,2017-09-04,dplyrAssist: RStudio Addin for Teaching and Learning Data Manipulation Using
'dplyr',An RStudio addin for teaching and learning data manipulation using the 'dplyr' package.
    You can learn each steps of data manipulation by clicking your mouse without coding.
    You can get resultant data (as a 'tibble') and the code for data manipulation.
freqdom.fda,2017-09-04,freqdom.fda: Functional Time Series: Dynamic Functional Principal Components,Implementations of functional dynamic principle components analysis. Related graphic tools and frequency domain methods.
  These methods directly use multivariate dynamic principal components implementation,
  following the guidelines from Hormann, Kidzinski and Hallin (2016), Dynamic Functional Principal Component <doi:10.1111/rssb.12076>.
re2r,2017-09-04,re2r: RE2 Regular Expression,RE2 <https://github.com/google/re2> is a primarily deterministic finite automaton based regular expression engine from Google that is very fast
    at matching large amounts of text. 
RGeode,2017-09-04,RGeode: Geometric Density Estimation,Provides the hybrid Bayesian method Geometric Density Estimation. On the one hand, it scales the dimension of our data, on the other it performs inference. The method is fully described in the paper "Scalable Geometric Density Estimation" by Y. Wang, A. Canale, D. Dunson (2016) <http://proceedings.mlr.press/v51/wang16e.pdf>.                   
threshr,2017-09-04,threshr: Threshold Selection and Uncertainty for Extreme Value Analysis,Provides functions for the selection of thresholds for use in 
    extreme value models, based mainly on the methodology in 
    Northrop, Attalides and Jonathan (2017) <doi:10.1111/rssc.12159>.
    It also performs predictive inferences about future extreme values, 
    based either on a single threshold or on a weighted average of inferences 
    from multiple thresholds, using the 'revdbayes' package 
    <https://cran.r-project.org/package=revdbayes>.   
    At the moment only the case where the data can be treated as 
    independent identically distributed observations is considered.
    See the 'threshr' website for more information, documentation and examples.
alphavantager,2017-09-03,alphavantager: Lightweight R Interface to the Alpha Vantage API,
    Alpha Vantage has free historical financial information. 
    All you need to do is get a free API key at <https://www.alphavantage.co>.
    Then you can use the R interface to retrieve free equity information.
    Refer to the Alpha Vantage website for more information.
doubcens,2017-09-03,doubcens: Survivor Function Estimation for Doubly Interval-Censored
Failure Time Data,Contains the discrete nonparametric survivor function estimation algorithm of De Gruttola and Lagakos for doubly interval-censored failure time data and the discrete nonparametric survivor function estimation algorithm of Sun for doubly interval-censored left-truncated failure time data [Victor De Gruttola  & Stephen W. Lagakos (1989) <doi:10.2307/2532030>] [Jianguo Sun (1995) <doi:10.2307/2533008>].  
pcdpca,2016-11-27,pcdpca: Dynamic Principal Components for Periodically Correlated
Functional Time Series,Method extends multivariate and functional dynamic principal components
    to periodically correlated multivariate time series. This package allows you to
    compute true dynamic principal components in the presence of periodicity. 
    We follow implementation guidelines as described in Kidzinski, Kokoszka and
    Jouzdani (2017), in Principal component analysis of periodically correlated
    functional time series <arXiv:1612.00040>.
ShinyImage,2017-09-03,ShinyImage: Image Manipulation, with an Emphasis on Journaling,Standard imaging operations, e.g. crop and contrast
  adjustment, but with ability to go back and forth through sequence of
  changes, with records being persistent.  Optional Shiny interface.
  Useful to help with the research reproducibility problem, and as a
  teaching tool.
AlphaVantageClient,2017-09-02,AlphaVantageClient: Wrapper for Alpha Vantage API,Download data from the Alpha Vantage API (<https://www.alphavantage.co/>).
    Alpha Vantage is a RESTful API which provides various financial data, 
    including stock prices and technical indicators. 
    There is documentation for the underlying API available 
    here: <https://www.alphavantage.co/documentation/>. To get access to this API,
    the user needs to first claim an API key: <https://www.alphavantage.co/support/>.
BinarybalancedCut,2017-09-02,BinarybalancedCut: Threshold Cut Point of Probability for a Binary Classifier Model,Allows to view the optimal probability cut-off point at which the Sensitivity and Specificity meets and its a best way to minimize both Type-1 and Type-2 error for a binary Classifier in determining the Probability threshold.
afpt,2017-09-01,afpt: Tools for Modelling of Animal Flight Performance,Allows estimation and modelling of flight costs in animal (vertebrate) flight,
    implementing the aerodynamic power model described in Klein Heerenbrink et al.
    (2015) <doi:10.1098/rspa.2014.0952>. Taking inspiration from the program
    'Flight', developed by Colin Pennycuick (Pennycuick (2008) "Modelling the flying
    bird". Amsterdam: Elsevier. ISBN 0-19-857721-4), flight performance is estimated
    based on basic morphological measurements such as body mass, wingspan and wing
    area. 'afpt' can be used to make predictions on how animals should adjust their
    flight behaviour and wingbeat kinematics to varying flight conditions.
cr17,2017-09-01,cr17: Testing Differences Between Competing Risks Models and Their
Visualisations,Tool for analyzing competing risks models. The main point of interest is testing differences between groups (as described in R.J Gray (1988) <doi:10.1214/aos/1176350951> and J.P. Fine, R.J Gray (1999) <doi:10.2307/2670170>) and visualizations of survival and cumulative incidence curves. 
DelayedEffect.Design,2017-09-01,DelayedEffect.Design: Sample Size and Power Calculations using the APPLE and SEPPLE
Methods,Provides sample size and power calculations when the treatment time-lag effect is present and the lag duration is homogeneous across the individual subject. The methods used are described in Xu, Z., Zhen, B., Park, Y., & Zhu, B. (2017) <doi:10.1002/sim.7157>.
EcoIndR,2017-03-13,EcoIndR: Ecological Indicators,Calculates several indices, such as of diversity, fluctuation, etc., and they are used to estimate ecological indicators.
Inflation,2017-09-01,Inflation: Core Inflation,Provides access to core inflation functions. Four different core inflation 
 functions are provided. The well known trimmed means, exclusion and double weighing methods, 
 alongside the new Triple Filter method introduced in Ferreira et al. (2016) <https://goo.gl/UYLhcj>.
jaod,2017-09-01,jaod: Directory of Open Access Journals Client,Client for the Directory of Open Access Journals ('DOAJ')
    (<https://doaj.org/>). 'API' documentation at
    <https://doaj.org/api/v1/docs>. Methods included for working with
    all 'DOAJ' 'API' routes: fetch article information by identifier,
    search for articles, fetch journal information by identifier,
    and search for journals.
rDotNet,2017-08-30,rDotNet: Low-Level Interface to the '.NET' Virtual Machine Along the
Lines of the R C/Call API,Low-level interface to '.NET' virtual machine along the lines of the R C .call interface.  Can create '.NET' object, call methods, get or set properties, call static functions, etc.
ari,2017-08-31,ari: Automated R Instructor,Create videos from 'R Markdown' documents, or images and audio
    files. These images can come from image files or HTML slides, and the audio
    files can be provided by the user or computer voice narration can be created
    using 'Amazon Polly'. The purpose of this package is to allow users to create
    accessible, translatable, and reproducible lecture videos. See
    <https://aws.amazon.com/polly/> for more information.
cdparcoord,2017-08-31,cdparcoord: Top Frequency-Based Parallel Coordinates,Parallel coordinate plotting with resolutions for large data sets
 and missing values.
npphen,2017-08-31,npphen: Vegetation Phenological Cycle and Anomaly Detection using Remote
Sensing Data,Calculates phenological cycle and anomalies using a non-parametric
    approach applied to time series of vegetation indices derived from remote sensing data 
    or field measurements. The package implements basic and high-level functions for 
    manipulating vector data (numerical series) and raster data (satellite derived products).
    Processing of very large raster files is supported.
wktmo,2017-05-31,wktmo: Converting Weekly Data to Monthly Data,Converts weekly data to monthly data.
     Users can use three types of week formats: ISO week, epidemiology week (epi week) and calendar date. 
cenGAM,2017-08-30,cenGAM: Censored Regression with Smooth Terms,Implementation of Tobit type I and type II families for censored regression using the 'mgcv' package, based on methods detailed in Woods (2016) <doi:10.1080/01621459.2016.1180986>.
deltar,2017-08-30,deltar: Calculation of Delta R Values,Computes the regional correction factor of 14C age offset in marine-derived samples (Delta R). This is possible with the recently established "marine13" calibration curve and the 'BchronCalibrate' function from the 'Bchron' package. The algorithm of Delta R computation includes four steps: measure radiocarbon age of a marine sample; identify its true age; compute its modeled radiocarbon age corresponding to the true age; and finally calculate the difference between its measured and modeled radiocarbon ages. This package has functions that compute Delta R with three methods: by using marine samples with known collection dates (before 1950s), usually molluscan shells from museum collections, (function dr_shell()); by measuring other radioactive isotopes, mainly uranium-thorium (230Th/234U), ratio (dr_pair() function and the "pair" method in the dr_df() function); and finally by using a pair of coeval samples, one being marine and the other terrestrial (dr_pair() function and the "pair" method for the dr_df() function as well). Usually such samples originate from archaeological sites where the context, in which paired samples were found, is taken as a guarantee of their synchronicity.  
 References: 
 Oeschger H, Siegenthaler U, Schotterer U, Gugelmann A (1975) <doi:10.3402/tellusa.v27i2.9900>
 Reimer PJ, Bard E, Bayliss A, Beck JW, Blackwell PG, Bronk Ramsey C, Buck CE, Cheng H, Edwards RL, Friedrich M, Grootes PM, Guilderson TP, Haflidason H, Hajdas I, Hatté C, Heaton TJ, Hoffmann DL, Hogg AG, Hughen KA, Kaiser KF, Kromer B, Manning SW, Niu M, Reimer RW, Richards DA, Scott EM, Southon JR, Staff RA, Turney CSM, van der Plicht J (2013) <doi:10.2458/azu_js_rc.55.16947>
 Soulet G (2015) <doi:10.1016/j.quageo.2015.05.023>
 Stuiver M, Braziunas TF (1993) <doi:10.1017/S0033822200013874> .
seedCCA,2017-08-30,seedCCA: Seeded Canonical Correlation Analysis,Functions for dimension reduction through the seeded canonical correlation analysis are provided. A classical canonical correlation analysis (CCA) is one of useful statistical methods in multivariate data analysis, but it is limited in use due to the matrix inversion for large p small n data. To overcome this, a seeded CCA has been proposed in Im, Gang and Yoo (2015) <doi:10.1002/cem.2691>. The seeded CCA is a two-step procedure. The sets of variables are initially reduced by successively projecting cov(X,Y) or cov(Y,X) onto cov(X) and cov(Y), respectively, without loss of information on canonical correlation analysis, following Cook, Li and Chiaromonte (2007) <doi:10.1093/biomet/asm038> and Lee and Yoo (2014) <doi:10.1111/anzs.12057>. Then, the canonical correlation is finalized with the initially-reduced two sets of variables.
ebmc,2017-08-29,ebmc: Ensemble-Based Methods for Class Imbalance Problem,Four ensemble-based methods (SMOTEBoost, RUSBoost, UnderBagging, and SMOTEBagging) for class imbalance problem are implemented for binary classification. Such methods adopt ensemble methods and data re-sampling techniques to improve model performance in presence of class imbalance problem. One special feature offers the possibility to choose multiple supervised learning algorithms to build weak learners within ensemble models. References: Nitesh V. Chawla, Aleksandar Lazarevic, Lawrence O. Hall, and Kevin W. Bowyer (2003) <doi:10.1007/978-3-540-39804-2_12>, Chris Seiffert, Taghi M. Khoshgoftaar, Jason Van Hulse, and Amri Napolitano (2010) <doi:10.1109/TSMCA.2009.2029559>, R. Barandela, J. S. Sanchez, R. M. Valdovinos (2003) <doi:10.1007/s10044-003-0192-z>, Shuo Wang and Xin Yao (2009) <doi:10.1109/CIDM.2009.4938667>, Yoav Freund and Robert E. Schapire (1997) <doi:10.1006/jcss.1997.1504>.
FPV,2017-08-29,FPV: Testing Hypotheses via Fuzzy P-Value in Fuzzy Environment,The main goal of this package is drawing the membership function of the fuzzy p-value which is defined as a fuzzy set on the unit interval for three following problems: (1) testing crisp hypotheses based on fuzzy data, see Filzmoser and Viertl (2004) <doi:10.1007/s001840300269>, (2) testing fuzzy hypotheses based on crisp data, see Parchami et al. (2010) <doi:10.1007/s00362-008-0133-4>, and (3) testing fuzzy hypotheses based on fuzzy data, see Parchami et al. (2012) <doi:10.1007/s00362-010-0353-2>. In all cases, the fuzziness of data or / and the fuzziness of the boundary of null fuzzy hypothesis transported via the p-value function and causes to produce the fuzzy p-value. If the p-value is fuzzy, it is more appropriate to consider a fuzzy significance level for the problem. Therefore, the comparison of the fuzzy p-value and the fuzzy significance level is evaluated by a fuzzy ranking method in this package.
LowWAFOMSobol,2017-07-13,LowWAFOMSobol: Low WAFOM Sobol Sequence,Implementation of Low Walsh Figure of Merit (WAFOM) sequence
        based on Sobol sequence.
mcompanion,2017-08-29,mcompanion: Objects and Methods for Multi-Companion Matrices,
    Provides a class for multi-companion matrices with methods for
    arithmetic and factorization.  A method for generation of
    multi-companion matrices with prespecified spectral properties is
    provided, as well as some utilities for periodically correlated and
    multivariate time series models. See Boshnakov (2002)
    <doi:10.1016/j.laa.2007.02.010> and Boshnakov & Iqelan (2009)
    <doi:10.1111/j.1467-9892.2009.00617.x>.
MTE,2017-08-29,MTE: Maximum Tangent Likelihood and Other Robust Estimation for
High-Dimensional Regression,Provides several robust estimators for linear regression and variable selection. They are Maximum tangent likelihood estimator (Qin, et al. (2017) <arXiv:1708.05439>), least absolute deviance estimator, and Huber loss. The penalized version of each of these estimator incorporates L1 penalty function, i.e., LASSO and Adaptive Lasso. They are able to produce consistent estimates for both fixed and high-dimensional settings.
nomogramEx,2016-11-30,nomogramEx: Extract Equations from a Nomogram,
  A nomogram can not be easily applied,
    because it is difficult to calculate the points or even the survival probability.
  The package, including a function of nomogramEx(),
    is to extract the polynomial equations to calculate the points of each variable,
    and the survival probability corresponding to the total points.
PeriodicTable,2017-01-05,PeriodicTable: Periodic Table of the Elements,Provides a dataset containing properties for chemical elements.
    Helper functions are also provided to access some atomic properties.
sensitivitymult,2017-05-16,sensitivitymult: Sensitivity Analysis for Observational Studies with Multiple
Outcomes,Sensitivity analysis for multiple outcomes in observational studies.  For instance, all linear combinations of several outcomes may be explored using Scheffe projections in the comparison() function; see Rosenbaum (2016, Annals of Applied Statistics) <doi:10.1214/16-AOAS942>.  Alternatively, attention may focus on a few principal components in the principal() function.  The package includes parallel methods for individual outcomes, including tests in the senm() function and confidence intervals in the senmCI() function.
caffsim,2017-08-14,caffsim: Simulation of Plasma Caffeine Concentrations by Using Population
Pharmacokinetic Model,Simulate plasma caffeine concentrations using population pharmacokinetic model described in Lee, Kim, Perera, McLachlan and Bae (2015) <doi:10.1007/s00431-015-2581-x>.
ccmm,2017-08-28,ccmm: Compositional Mediation Model,Estimate the direct and indirect (mediation) effects of treatment on the outcome when intermediate variables (mediators) are compositional and high-dimensional. Sohn, M.B. and Li, H. (2017). Compositional Mediation Analysis for Microbiome Studies. (AOAS: In revision).
dmutate,2017-01-25,dmutate: Mutate Data Frames with Random Variates,Work within the 'dplyr' workflow to add random variates to your data frame. 
  Variates can be added at any level of an existing column.  Also, bounds can be specified 
  for simulated variates. 
PSIMEX,2017-07-25,PSIMEX: SIMEX Algorithm on Pedigree Structures,Generalization of the SIMEX algorithm from Cook & Stefanski (1994) <doi:10.2307/2290994> for the calculation of inbreeding depression or heritability on pedigree structures affected by missing or misassigned paternities. It simulates errors and tracks the behavior of the estimate as a function of the error proportion. It extrapolates back a true value corresponding to the null error rate. 
SpatialEpiApp,2017-02-27,SpatialEpiApp: A Shiny Web Application for the Analysis of Spatial and
Spatio-Temporal Disease Data,Runs a Shiny web application that allows to visualize spatial and spatio-temporal disease data, estimate disease risk and detect clusters. The application allows to fit Bayesian disease models to obtain risk estimates and their uncertainty by using the 'R-INLA' package, <http://www.r-inla.org>, and to detect clusters by using the scan statistics implemented in 'SaTScan', <https://www.satscan.org>. The application allows user interaction and creates interactive visualizations such as maps supporting padding and zooming and tables that allow for filtering. It also enables the generation of reports containing the analyses performed.
LowWAFOMNX,2017-07-11,LowWAFOMNX: Low WAFOM Niederreiter-Xing Sequence,Implementation of Low Walsh Figure of Merit (WAFOM) sequence
        based on Niederreiter-Xing sequence <doi:10.1007/978-3-642-56046-0_30>.
prcr,2017-02-17,prcr: Person-Centered Analysis,Provides an easy-to-use yet adaptable set of tools to conduct person-center analysis using a two-step clustering procedure. As described in Bergman and El-Khouri (1999) <doi:10.1002/(SICI)1521-4036(199910)41:6%3C753::AID-BIMJ753%3E3.0.CO;2-K>, hierarchical clustering is performed to determine the initial partition for the subsequent k-means clustering procedure.
accSDA,2017-08-24,accSDA: Accelerated Sparse Discriminant Analysis,Implementation of sparse linear discriminant analysis, which is a supervised
    classification method for multiple classes. Various novel optimization approaches to
    this problem are implemented including alternating direction method of multipliers (ADMM),
    proximal gradient (PG) and accelerated proximal gradient (APG) (See Atkins et al. <arXiv:1705.07194>).
    Functions for performing cross validation are also supplied along with basic prediction
    and plotting functions.
    Sparse zero variance discriminant analysis (SZVD) is also included in the package
    (See Ames and Hong, <arXiv:1401.5492>). See the github wiki for a more extended description.
Ecohydmod,2017-08-24,Ecohydmod: Ecohydrological Modelling,Simulates the soil water balance (soil moisture, evapotranspiration, leakage and runoff), rainfall series by using the marked Poisson process and the vegetation growth through the normalized difference vegetation index (NDVI). Please see Souza et al. (2016) <doi:10.1002/hyp.10953>.
mExplorer,2017-08-24,mExplorer: Identifying Master Gene Regulators from Gene Expression and
DNA-Binding Data,The method 'm:Explorer' associates a given list of target genes (e.g. those involved in a biological process) to gene regulators such as transcription factors. Transcription factors that bind DNA near significantly many target genes or correlate with target genes in transcriptional (microarray or RNAseq data) are selected. Selection of candidate master regulators is carried out using multinomial regression models, likelihood ratio tests and multiple testing correction. Reference: m:Explorer: multinomial regression models reveal positive and negative regulators of longevity in yeast quiescence. Juri Reimand, Anu Aun, Jaak Vilo, Juan M Vaquerizas, Juhan Sedman and Nicholas M Luscombe. Genome Biology (2012) 13:R55 <doi:10.1186/gb-2012-13-6-r55>.
multdyn,2017-03-23,multdyn: Multiregression Dynamic Models,Multiregression Dynamic Models for directed dynamic functional brain network analysis.
noncomplyR,2017-08-24,noncomplyR: Bayesian Analysis of Randomized Experiments with Non-Compliance,Functions for Bayesian analysis of data from randomized experiments with non-compliance. The functions are based on the models described in Imbens and Rubin (1997) <doi:10.1214/aos/1034276631>. Currently only two types of outcome models are supported: binary outcomes and normally distributed outcomes. Models can be fit with and without the exclusion restriction and/or the strong access monotonicity assumption. Models are fit using the data augmentation algorithm as described in Tanner and Wong (1987) <doi:10.2307/2289457>.
Strategy,2016-12-09,Strategy: Generic Framework to Analyze Trading Strategies,Users can build and test customized quantitative trading strategies. Some quantitative trading strategies are already implemented, e.g. various moving-average filters with trend following approaches.
    The implemented class called "Strategy" allows users to access several methods to analyze performance figures, plots and backtest the strategies.
    Furthermore, custom strategies can be added, a generic template is available. The custom strategies require a certain input and output so they can be called from the Strategy-constructor.
ActiveDriver,2017-08-23,ActiveDriver: Finding Cancer Driver Proteins with Enriched Mutations in
Post-Translational Modification Sites,A mutation analysis tool that discovers cancer driver genes with frequent mutations in protein signalling sites such as post-translational modifications (phosphorylation, ubiquitination, etc). The Poisson generalised linear regression model identifies genes where cancer mutations in signalling sites are more frequent than expected from the sequence of the entire gene. Integration of mutations with signalling information helps find new driver genes and propose candidate mechanisms to known drivers. Reference: Systematic analysis of somatic mutations in phosphorylation signaling predicts novel cancer drivers. Juri Reimand and Gary D Bader. Molecular Systems Biology (2013) 9:637 <doi:10.1038/msb.2012.68>.
genepop,2017-06-14,genepop: Population Genetic Data Analysis Using Genepop,Makes the Genepop software available in R. This software implements a mixture of traditional population genetic methods and some more focused developments: it computes exact tests for Hardy-Weinberg equilibrium, for population differentiation and for genotypic disequilibrium among pairs of loci; it computes estimates of F-statistics, null allele frequencies, allele size-based statistics for microsatellites, etc.; and it performs analyses of isolation by distance from pairwise comparisons of individuals or population samples. 
kntnr,2016-11-17,kntnr: R Client for 'kintone' API,Retrieve data from 'kintone' (<https://www.kintone.com/>) via its API.
    'kintone' is an enterprise application platform.
macc,2016-11-03,macc: Mediation Analysis of Causality under Confounding,Performs causal mediation analysis under confounding or correlated errors. This package includes a single level mediation model, a two-level mediation model, and a three-level mediation model for data with hierarchical structures. Under the two/three-level mediation model, the correlation parameter is identifiable and is estimated based on a hierarchical-likelihood, a marginal-likelihood or a two-stage method. See Zhao, Y., & Luo, X. (2014), Estimating Mediation Effects under Correlated Errors with an Application to fMRI, <arXiv:1410.7217> for details.
ConfigParser,2017-08-22,ConfigParser: Package to Parse an INI File, Including Variable Interpolation,Enhances the 'ini' package by adding the ability to interpolate variables.
	     The INI configuration file is read into an R6 ConfigParser object (loosely inspired by Pythons ConfigParser module)
	     and the keys can be read, where '%(....)s' instances are interpolated by other included options or outside variables.
esreg,2017-08-17,esreg: Joint Quantile and Expected Shortfall Regression,
    Simultaneous modeling of the quantile and the expected shortfall of a response variable given 
    a set of covariates, see Dimitriadis and Bayer (2017) <arXiv:1704.02213>.
R2DGC,2017-08-22,R2DGC: Multiple Peak Alignment for 2D Gas Chromatography Mass
Spectrometry Metabolomics Analysis,Provides functions for aligning 2D gas chromatography mass spectrometry derived metabolite peaks obtained from primary processing and generates an alignment table that
        allows for a comparison of common peaks across samples and metabolite identification. Publication describing the package in detail is available at the following citation: Ryne C. Ramaker, Emily Gordon, Sara J. Cooper (2017) <doi:10.1101/179168>.
simpleCache,2017-08-21,simpleCache: Simply Caching R Objects,Provides intuitive functions for caching R objects, encouraging
    reproducible, restartable, and distributed R analysis. The user selects a
    location to store caches, and then provides  nothing more than a cache name
    and instructions (R code) for how to produce the R object. Also
    provides some advanced options like environment assignments, recreating or
    reloading caches, and cluster compute bindings (using the 'batchtools'
    package) making it flexible enough for use in large-scale data analysis
    projects.
SLICER,2017-08-22,SLICER: Selective Locally Linear Inference of Cellular Expression
Relationships,Provides an implementation of SLICER, an algorithm for inferring cellular trajectories from single cell RNA sequencing data. See Welch, JD, Hartemink AJ, Prins JF (2016) <doi:10.1186/s13059-016-0975-3>.
STARTdesign,2017-08-22,STARTdesign: Single to Double Arm Transition Design for Phase II Clinical
Trials,The package is used for calibrating the design parameters for single-to-double arm transition design proposed by Shi and Yin (2017). The calibration is performed via numerical enumeration to find the optimal design that satisfies the constraints on the type I and II error rates.
Wrapped,2017-02-05,Wrapped: Computes Pdf, Cdf, Quantile, Random Numbers and Provides
Estimation for any Univariate Wrapped Distributions,Computes the pdf, cdf, quantile, random numbers  for any wrapped G distributions.  Computes maximum likelihood estimates of the parameters, standard errors, 95 percent confidence intervals, value of Cramer-von Misses statistic, value of Anderson Darling statistic, value of Kolmogorov Smirnov test statistic and its $p$-value, value of Akaike Information Criterion, value of Consistent Akaike Information Criterion, value of Bayesian Information Criterion, value of Hannan-Quinn information criterion, minimum value of the negative log-likelihood function and convergence status when the wrapped distribution is fitted  to some data.
InfoTrad,2016-12-23,InfoTrad: Calculates the Probability of Informed Trading (PIN),Estimates the probability of informed trading (PIN) initially introduced by Easley et. al. (1996) <doi:10.1111/j.1540-6261.1996.tb04074.x> . Contribution of the package is that it uses likelihood factorizations of Easley et. al. (2010) <doi:10.1017/S0022109010000074> (EHO factorization) and Lin and Ke (2011) <doi:10.1016/j.finmar.2011.03.001> (LK factorization). Moreover, the package uses different estimation algorithms. Specifically, the grid-search algorithm proposed by Yan and Zhang (2012) <doi:10.1016/j.jbankfin.2011.08.003> , hierarchical agglomerative clustering approach proposed by Gan et. al. (2015) <doi:10.1080/14697688.2015.1023336> and later extended by Ersan and Alici (2016) <doi:10.1016/j.intfin.2016.04.001> .
ircor,2017-08-21,ircor: Correlation Coefficients for Information Retrieval,Provides implementation of various correlation coefficients of common use in
  Information Retrieval. In particular, it includes Kendall (1970, isbn:0852641990) tau coefficient
  as well as tau_a and tau_b for the treatment of ties. It also includes Yilmaz et al. (2008)
  <doi:10.1145/1390334.1390435> tauAP correlation coefficient, and versions tauAP_a and tauAP_b
  developed by Urbano and Marrero (2017) <doi:10.1145/3121050.3121106> to cope with ties.
GRCdata,2017-08-20,GRCdata: Parameter Inference and Optimal Designs for Grouped and/or
Right-Censored Count Data,We implement two main functions.
    The first function uses a given grouped and/or
    right-censored grouping scheme and empirical data to infer parameters,
    and implements chi-square goodness-of-fit tests.
    The second function searches for the global optimal grouping
    scheme of grouped and/or right-censored count responses in surveys.
happybiRthday,2017-08-20,happybiRthday: Calculate Upcoming Birthday Dates of Github Repos,Software creation is a pretty big deal!  A repository's initial commit date can be thought of as its birthday.  Next time, drop in and wish a developer (any Github username) a happy birthday of their repo(s).  Or maybe just toast to the upcoming anniversary of your own software!  The software life cycle is too short not to celebrate!
ccRemover,2017-05-18,ccRemover: Removes the Cell-Cycle Effect from Single-Cell RNA-Sequencing
Data,Implements a method for identifying and removing
				the cell-cycle effect from scRNA-Seq data. The description of the 
				method is in Barron M. and Li J. (2016) <doi:10.1038/srep33892>. Identifying and removing 
				the cell-cycle effect from single-cell RNA-Sequencing data. Submitted. 
				Different from previous methods, ccRemover implements a mechanism that
				formally tests whether a component is cell-cycle related or not, and thus
				while it often thoroughly removes the cell-cycle effect, it preserves
				other features/signals of interest in the data.
sasMap,2017-08-18,sasMap: Static 'SAS' Code Analysis,A static code analysis tool for 'SAS' scripts. It is designed to load, count, extract, remove, and summarise components of 'SAS' code.
CompDist,2017-08-17,CompDist: Multisection Composite Distributions,Computes density function, cumulative distribution function, quantile function and random numbers for a multisection composite distribution specified by the user.  Also fits the user specified distribution to a given data set.  More details of the package can be found in the following paper submitted to the R journal Wiegand M and Nadarajah S (2017)  CompDist: Multisection composite distributions.
forwards,2017-08-17,forwards: Data from Surveys Conducted by Forwards,Anonymized data from surveys conducted by Forwards <http://forwards.github.io/>, the R Foundation task force on women and other under-represented groups. Currently, a single data set of responses to a survey of attendees at useR! 2016 <http://user2016.org/>, the R user conference held at Stanford University, Stanford, California, USA, June 27 - June 30 2016.
gamCopula,2017-01-14,gamCopula: Generalized Additive Models for Bivariate Conditional Dependence
Structures and Vine Copulas,Implementation of various inference and simulation tools to
    apply generalized additive models to bivariate dependence structures and
    non-simplified vine copulas.
AssayCorrector,2016-12-29,AssayCorrector: Detection and Correction of Spatial Bias in HTS Screens,Allows to correct bias in high-throughput screening (HTS) assays. It (1) Detects plate-specific spatial bias by identifying rows and columns of all plates of the assay affected by this bias (following the results of the Mann-Whitney U test) as well as assay-specific spatial bias by identifying well locations (i.e., well positions scanned across all plates of a given assay) affected by this bias (also following the results of the Mann-Whitney U test); (2) Allows one to correct plate-specific spatial bias using either of the three additive or either of the three multiplicative PMP (Partial Mean Polish) methods (the most appropriate spatial bias model can be either specified by the user or determined by the program following the results of the Kolmogorov-Smirnov, Anderson-Darling or Cramer-von-Mises two-sample test) to correct the assay measurements as well as to correct assay-specific spatial bias by carrying out robust Z-scores within each plate of the assay and then traditional Z-scores across well locations.
atlantistools,2017-05-10,atlantistools: Process and Visualise Output from Atlantis Models,Atlantis is an end-to-end marine ecosystem modelling framework. It was originally developed in Australia by E.A. Fulton, A.D.M. Smith and D.C. Smith (2007) and has since been adopted in many marine ecosystems around the world (<http://atlantis.cmar.csiro.au>). The output of an Atlantis simulation is stored in various file formats like .netcdf and .txt and different output structures are used for the output variables like e.g. productivity or biomass. This package is used to convert the different output types to a unified format according to the "tidy-data" approach by H. Wickham (2014) <doi:10.18637/jss.v059.i10>. Additionally, ecological metrics like for example spatial overlap of predator and prey or consumption can be calculated and visualised with this package. Due to the unified data structure it is very easy to share model output with each other and perform model comparisons.
IceCast,2017-06-23,IceCast: Apply Statistical Post-Processing to Improve Sea Ice Predictions,Tools for modeling and correcting biases in sea ice predictions obtained from dynamical models. This package depends on the 'ncdf4' and 'rgeos' R packages. These packages respectively require installing externally from R Unidata's 'NetCDF' library and Geometry Engine - Open Source ('GEOS'). (See the 'rgeos' and 'ncdf4' packages for details.) References, Bivand and Rundel (2017) <https://CRAN.R-project.org/package=rgeos>, Open Source Geospatial Foundation (2017) <https://trac.osgeo.org/geos>, Pierce (2017) <https://CRAN.R-project.org/package=ncdf4>, Unidata (2017) <https://www.unidata.ucar.edu/software/netcdf/>.
ggquiver,2017-08-15,ggquiver: Quiver Plots for 'ggplot2',An extension of 'ggplot2' to provide quiver plots to visualise vector fields. 
    This functionality is implemented using a geom to produce a new graphical layer, which
    allows aesthetic options. This layer can be overlaid on a map to improve visualisation
    of mapped data.
GrpString,2017-01-06,GrpString: Patterns and Statistical Differences Between Two Groups of
Strings,Methods include converting series of event names to strings, finding common patterns
    in a group of strings, discovering featured patterns when comparing two groups of strings as well
    as the number and starting position of each pattern in each string, obtaining transition matrix, 
    computing transition entropy, statistically comparing the difference between two groups of strings,
    and clustering string groups. Event names can be any action names or labels such as events in log
    files or areas of interest (AOIs) in eye tracking research.
LBSPR,2016-12-13,LBSPR: Length-Based Spawning Potential Ratio,Simulate expected equilibrium length composition, yield-per-recruit, and
    the spawning potential ratio (SPR) using the length-based SPR (LBSPR) model. Fit the LBSPR
    model to length data to estimate  selectivity, relative apical fishing mortality, and
    the spawning potential ratio for data-limited fisheries.
    See Hordyk et al (2016) <doi:10.1139/cjfas-2015-0422> for more information about the
    LBSPR assessment method.
PeakSegDP,2017-06-21,PeakSegDP: Dynamic Programming Algorithm for Peak Detection in ChIP-Seq
Data,A quadratic time dynamic programming algorithm
 can be used to compute an approximate solution to the problem of
 finding the most likely changepoints
 with respect to the Poisson likelihood, subject
 to a constraint on the number of segments, and the changes which must
 alternate: up, down, up, down, etc. For more info read
 <http://proceedings.mlr.press/v37/hocking15.html>
 "PeakSeg: constrained optimal segmentation and supervised penalty learning
 for peak detection in count data" by TD Hocking et al,
 proceedings of ICML2015.
samon,2017-08-15,samon: Sensitivity Analysis for Missing Data,In a clinical trial with repeated measures designs, outcomes are often taken from subjects at fixed time-points.  The focus of the trial may be to compare the mean outcome in two or more groups at some pre-specified time after enrollment. In the presence of missing data auxiliary assumptions are necessary to perform such comparisons.  One commonly employed assumption is the missing at random assumption (MAR).   The 'samon' package allows the user to perform a (parameterized) sensitivity analysis of this assumption.  In particular it can be used to examine the sensitivity of tests in the difference in outcomes to violations of the MAR assumption.  The sensitivity analysis can be performed under two scenarios, a) where the data exhibit a monotone missing data pattern (see the samon() function), and, b) where in addition to a monotone missing data pattern the data exhibit intermittent missing values (see the samonIM() function).
SorptionAnalysis,2017-08-15,SorptionAnalysis: Static Adsorption Experiment Plotting and Analysis,Provides tools to efficiently analyze and visualize laboratory data from aqueous static adsorption experiments. The package provides functions to plot Langmuir, Freundlich, and Temkin isotherms and functions to determine the statistical conformity of data points to the Langmuir, Freundlich, and Temkin adsorption models through statistical characterization of the isothermic least squares regressions lines. Scientific Reference: Dada, A.O, Olalekan, A., Olatunya, A. (2012) <doi:10.9790/5736-0313845>.
CIplot,2017-08-14,CIplot: Functions to Plot Confidence Interval,Plot confidence interval from the objects of statistical tests such as
  t.test(), var.test(), cor.test(), prop.test() and fisher.test() ('htest' class),
  Tukey test [TukeyHSD()], Dunnett test [glht() in 'multcomp' package],
  logistic regression [glm()], and Tukey or Games-Howell test [posthocTGH() in
  'userfriendlyscience' package].
  Users are able to set the styles of lines and points.
  This package contains the function to calculate odds ratios and their confidence
  intervals from the result of logistic regression.
ConfoundedMeta,2017-06-02,ConfoundedMeta: Sensitivity Analyses for Unmeasured Confounding in Meta-Analyses,Conducts sensitivity analyses for unmeasured confounding in
    random-effects meta-analysis per Mathur & VanderWeele (in preparation).
    Given output from a random-effects meta-analysis with a relative risk
    outcome, computes point estimates and inference for: (1) the proportion
    of studies with true causal effect sizes more extreme than a specified threshold
    of scientific significance; and (2) the minimum bias factor and confounding
    strength required to reduce to less than a specified threshold the proportion
    of studies with true effect sizes of scientifically significant size.
    Creates plots and tables for visualizing these metrics across a range of bias values.
    Provides tools to easily scrape study-level data from a published forest plot or 
    summary table to obtain the needed estimates when these are not reported.  
fastJT,2017-01-27,fastJT: Efficient Jonckheere-Terpstra Test Statistics for Robust Machine
Learning and Genome-Wide Association Studies,This 'Rcpp'-based package implements highly efficient functions for the calculation of the Jonckheere-Terpstra statistic. It can be used for a variety of applications, including feature selection in machine learning problems, or to conduct genome-wide association studies (GWAS) with multiple quantitative phenotypes. The code leverages 'OpenMP' directives for multi-core computing to reduce overall processing time. 
lmmen,2017-08-14,lmmen: Linear Mixed Model Elastic Net,Fits (Gaussian) linear mixed-effects models
        for high-dimensional data (n<<p) using the linear mixed model elastic-net penalty.
tsiR,2017-02-17,tsiR: An Implementation of the TSIR Model,An implementation of the time-series Susceptible-Infected-Recovered (TSIR) model using a number of different
    fitting options for infectious disease time series data. The method implemented here is described by Finkenstadt and Grenfell (2000) <doi:10.1111/1467-9876.00187>.
rdpla,2016-10-14,rdpla: Client for the Digital Public Library of America ('DPLA'),Interact with the Digital Public Library of America
    <https://dp.la> ('DPLA') 'REST' 'API'
    <https://dp.la/info/developers/codex/> from R, including search
    and more.
dataMeta,2017-04-24,dataMeta: Create and Append a Data Dictionary for an R Dataset,Designed to create a basic data dictionary and append to the original dataset's attributes list. The package makes use of a tidy dataset and creates a data frame that will serve as a linker that will aid in building the dictionary. The dictionary is then appended to the list of the original dataset's attributes. The user will have the option of entering variable and item descriptions by writing code or use alternate functions that will prompt the user to add these.
IAbin,2017-08-11,IAbin: Plotting N-T Plane for Decision on Performing an Interim
Analysis,In randomized-controlled trials, interim analyses are often planned for possible early 
   trial termination to claim superiority or futility of a new therapy. Blinded data also have 
   information about the potential treatment difference between the groups. We developed a blinded 
   data monitoring tool that enables investigators to predict whether they observe such an unblinded 
   interim analysis results that supports early termination of the trial. Investigators may skip 
   some of the planned interim analyses if an early termination is unlikely. 
   This tool will provide reference information about N: Sample size at interim analysis, and T: Total 
   number of responders at interim analysis for decision on performing an interim analysis.
rasterList,2017-08-11,rasterList: A Raster Where Cells are Generic Objects,A S4 class has been created such that complex operations can be
    executed on each cells of a raster map. The raster of objects contains the
    traditional raster map with the addition of a list of generic objects: one
    object for each raster cells. It allows to write few lines of R code for complex
    map algebra. Two environmental applications about frequency analysis of raster
    map of precipitation and creation of a raster map of soil water retention curves
    have been presented.
rcv,2017-06-14,rcv: Ranked Choice Voting,A collection of ranked choice voting data and functions to 
    manipulate, run elections with, and visualize this data and others. 
    It can bring in raw data, transform it into a ballot you can read, 
    and return election results for an RCV contest.
valaddin,2017-03-24,valaddin: Functional Input Validation,A set of basic tools to transform functions into functions with
    input validation checks, in a manner suitable for both programmatic and
    interactive use.
vanddraabe,2017-08-11,vanddraabe: Identification and Statistical Analysis of Conserved Waters in
Proteins,Identify and analyze conserved waters within crystallographic 
  protein structures and molecular dynamics simulation trajectories. Statistical 
  parameters for each water cluster, informative graphs, and a PyMOL session 
  file to visually explore the conserved waters and protein are returned. 
  Hydrophilicity is the propensity of waters to congregate near specific protein 
  atoms and is related to conserved waters. An informatics derived set of 
  hydrophilicity values are provided based on a large, high-quality X-ray 
  protein structure dataset.
vocaldia,2017-04-11,vocaldia: Create and Manipulate Vocalisation Diagrams,Create adjacency matrices of vocalisation graphs from
  dataframes containing sequences of speech and silence intervals,
  transforming these matrices into Markov diagrams, and generating
  datasets for classification of these diagrams by 'flattening' them
  and adding global properties (functionals) etc.  Vocalisation
  diagrams date back to early work in psychiatry (Jaffe and Feldstein,
  1970) and social psychology (Dabbs and Ruback, 1987) but have only
  recently been employed as a data representation method for machine
  learning tasks including meeting segmentation (Luz, 2012)
  <doi:10.1145/2328967.2328970> and classification (Luz,
  2013) <doi:10.1145/2522848.2533788>.
GEint,2016-10-01,GEint: Misspecified Models for Gene-Environment Interaction,First major functionality is to compute the bias in misspecified linear gene-environment interaction models. The most 
	generalized function for this objective is GE_bias().  However GE_bias() requires specification of many
	higher order moments of covariates in the model.  If users are unsure about how to calculate/estimate
	these higher order moments, it may be easier to use GE_bias_normal_squaredmis().  This function places
	many more assumptions on the covariates (most notably that they are all jointly generated from a multivariate
	normal distribution) and is thus able to automatically calculate many of the higher order moments automatically,
	necessitating only that the user specify some covariances.  There are also functions to solve for the bias 
	through simulation and non-linear equation solvers, these can be used to check your work. Second major functionality
	is to implement the Bootstrap Inference with Correct Sandwich (BICS) testing procedure, which we have found to provide better finite-sample
	performance than other inference procedures for testing GxE interaction.  More details on these functions 
	are available in Sun, Carroll, Christiani, and Lin, "Testing for Gene-Environment Interaction Under Exposure Misspecification"
	(In Revision).
IPMRF,2017-05-05,IPMRF: Intervention in Prediction Measure (IPM) for Random Forests,Computes IPM for assessing variable importance for random forests. See details at I. Epifanio (2017) <doi:10.1186/s12859-017-1650-8>. 
poker,2017-08-09,poker: Play Texas Hold Em Poker,Type testRoundOfPoker() to demonstrate the game of Texas Hold ‘Em poker.  Rotate the dealer button, deal cards, rank each hand, compare ranks, break ties (if necessary), determine the winner, output a textual summary, and output a graphical user interface.
PsyControl,2017-08-09,PsyControl: CUSUM Person Fit Statistics,Person fit statistics based on Quality Control measures are provided for questionnaires and tests given a specified IRT model. Statistics based on Cumulative Sum (CUSUM) charts are provided. Options are given for banks with polytomous and dichotomous data.
kangar00,2017-04-27,kangar00: Kernel Approaches for Nonlinear Genetic Association Regression,Methods to extract information on pathways, genes and SNPs from
    online databases. It provides functions for data preparation and evaluation
    of genetic influence on a binary outcome using the logistic kernel machine
    test (LKMT). Three different kernel functions are offered to analyze genotype
    information in this variance component test: A linear kernel, a size-adjusted
    kernel and a network based kernel.
OHPL,2017-07-17,OHPL: Ordered Homogeneity Pursuit Lasso for Group Variable Selection,Ordered homogeneity pursuit lasso (OHPL)
    algorithm for group variable selection proposed in Lin et al. (2017)
    <doi:10.1016/j.chemolab.2017.07.004>. The OHPL method exploits the
    homogeneity structure in high-dimensional data and enjoys the
    grouping effect to select groups of important variables
    automatically. This feature makes it particularly useful for
    high-dimensional datasets with strongly correlated variables,
    such as spectroscopic data.
blink,2017-08-07,blink: Record Linkage for Empirically Motivated Priors,An implementation of the model in Steorts (2015) <doi:10.1214/15-BA965SI>, which performs Bayesian entity resolution for categorical and text data, for any distance function defined by the user. In addition, the precision and recall are in the package to allow one to compare to any other comparable method such as logistic regression, Bayesian additive regression trees (BART), or random forests. The experiments are reproducible and illustrated using a simple vignette. 
default,2017-08-07,default: Change the Default Arguments in R Functions,A simple syntax to change the default values for function
  arguments, whether they are in packages or defined locally.
multiCA,2016-10-06,multiCA: Multinomial Cochran-Armitage Trend Test,Implements a generalization of the Cochran-Armitage trend test to
    multinomial data. In addition to an overall test, multiple testing adjusted
    p-values for trend in individual outcomes and power calculation is
    available.
permGS,2017-01-24,permGS: Permutational Group Sequential Test for Time-to-Event Data,Permutational group-sequential tests for time-to-event data based on the log-rank test statistic. Supports exact permutation test when the censoring distributions are equal in the treatment and the control group and approximate imputation-permutation methods when the censoring distributions are different. 
statesRcontiguous,2017-08-07,statesRcontiguous: Shapefiles for the Contiguous United States of America,Data package containing shapefiles for the US that may easily be restricted to only
    the contiguous US. Shapefiles are provided for; states, congressional districts and counties.
    All shapefiles have the resolution of 1:20,000,000 and are from the US Census Bureau -
    <https://www.census.gov/geo/maps-data/data/tiger-cart-boundary.html>. State/County/District 
    information has been combined from multiple disjoint Census shapefile products in this package, 
    see the 'shapefile_details' tibble for details. Please note, this package is explicitly designed to 
    fit all shapefiles within one CRAN-hosted package. You will want to use the 'tigris' package 
    for programmatic access to the US Census' shapefile products.
restfulr,2017-03-07,restfulr: R Interface to RESTful Web Services,Models a RESTful service as if it were a nested R list.
ggversa,2017-08-05,ggversa: Graficas Versatiles Con 'ggplot2',A collection of datasets for the upcoming book "Graficas versatiles con ggplot: Analisis visuales de datos", by Raymond L. Tremblay and Julian Hernandez-Serano. 
italy,2017-08-05,italy: The Italian Survey on Household and Wealth, 2008 and 2010,Provides two record linkage data sets on the Italian Survey on Household and Wealth, 2008 and 2010, a sample survey conducted by the Bank of Italy every two years. The 2010 survey covered 13,702 individuals, while the 2008 survey covered 13,734 individuals. The following categorical variables are included in this data set: year of birth, working status, employment status, branch of activity, town size, geographical area of birth, sex, whether or not Italian national, and highest educational level obtained. Unique identifiers are available to assess the accuracy of one’s method. Please see Steorts (2015) <doi:10.1214/15-BA965SI> to find more details about the data set. 
equaltestMI,2017-08-04,equaltestMI: Examine Measurement Invariance via Equivalence Testing and
Projection Method,Functions for examining measurement invariance via equivalence testing along with adjusted RMSEA(root mean square error of approximation; Steiger & Lind, 1980) cutoff values. In particular, a projection-based method is implemented to test the equality of latent factor means across groups without assuming the equality of intercepts.
GFA,2016-10-11,GFA: Group Factor Analysis,Factor analysis implementation for multiple data sources, i.e., for groups of variables. The whole data analysis pipeline is provided, including functions and recommendations for data normalization and model definition, as well as missing value prediction and model visualization. The model group factor analysis (GFA) is inferred with Gibbs sampling, and it has been presented originally by Virtanen et al. (2012), and extended in Klami et al. (2015) <doi:10.1109/TNNLS.2014.2376974> and Bunte et al. (2016) <doi:10.1093/bioinformatics/btw207>; for details, see the citation info.
metaBMA,2017-07-26,metaBMA: Bayesian Model Averaging for Random and Fixed Effects
Meta-Analysis,Computes the posterior model probabilities for four meta-analysis models 
    (null model vs. alternative model assuming either fixed- or random-effects, respectively).
    These posterior probabilities are used to estimate the overall mean effect size 
    as the weighted average of the mean effect size estimates of the random- and 
    fixed-effect model as proposed by Gronau, Van Erp, Heck, Cesario, Jonas, & 
    Wagenmakers (2017, <doi:10.1080/23743603.2017.1326760>). The user can define 
    a wide range of noninformative or informative priors for the mean effect size 
    and the heterogeneity coefficient. Funding for this research was provided by 
    the Berkeley Initiative for Transparency in the Social Sciences, a program of 
    the Center for Effective Global Action (CEGA), with support from the Laura and 
    John Arnold Foundation.
RcppXPtrUtils,2017-08-04,RcppXPtrUtils: XPtr Add-Ons for 'Rcpp',Provides the means to compile user-supplied C++ functions with 
  'Rcpp' and retrieve an 'XPtr' that can be passed to other C++ components.
soilcarbon,2017-05-03,soilcarbon: Tools to Analyze Soil Carbon Database Created by Powell Center
Working Group,A tool for importing, visualizing, and analyzing the soil carbon database created by the Powell Center working group.
SpatialAcc,2017-05-22,SpatialAcc: Spatial Accessibility Measures,Provides a set of spatial accessibility measures from a set of locations 
             (demand) to another set of locations (supply). It aims, among others, 
             to support research on spatial accessibility to health care facilities. 
             Includes the locations and some characteristics of major public hospitals in Greece.
banR,2017-08-03,banR: R Client for the BAN API,A client for the "Base Adresses Nationale" (BAN) API, which allows to (batch)
    geocode and reverse-geocode French addresses. For more information about the BAN and its API, please see <https://adresse.data.gouv.fr/api>. 
cranlike,2017-04-27,cranlike: Tools for 'CRAN'-Like Repositories,A set of functions to manage 'CRAN'-like repositories
    efficiently.
echogram,2017-02-08,echogram: Echogram Visualisation and Analysis,Easily import multi-frequency acoustic data stored in 'HAC' files (see <http://biblio.uqar.ca/archives/30005500.pdf> for more information on the format), and produce echogram visualisations with predefined or customized color palettes. It is also possible to merge consecutive echograms; mask or delete unwanted echogram areas; model and subtract background noise; and more important, develop, test and interpret different combinations of frequencies in order to perform acoustic filtering of the echogram's data. 
EMAtools,2017-05-15,EMAtools: Data Management Tools for Real-Time Monitoring/Ecological
Momentary Assessment Data,Do data management functions common in real-time monitoring (also called: ecological momentary assessment, experience sampling, micro-longitudinal) data, including creating power curves for multilevel data, centering on participant means and merging event-level data into momentary data sets where you need the events to correspond to the nearest data point in the momentary data. This is VERY early release software, and more features will be added over time. 
ggsignif,2017-04-05,ggsignif: Significance Brackets for 'ggplot2',Enrich your 'ggplots' with group-wise comparisons.
  This package provides an easy way to indicate if two groups are significantly different.
  Commonly this is shown by a bracket on top connecting the groups of interest which itself is annotated with the level of significance (NS, *, **, ***).
  The package provides a single layer (geom_signif()) that takes the groups for comparison and the test (t.test(), wilcox.text() etc.) as arguments and adds the annotation
  to the plot.
lmmpar,2017-08-03,lmmpar: Parallel Linear Mixed Model,Embarrassingly Parallel Linear Mixed Model calculations spread across local cores which repeat until convergence.
multistate,2017-08-03,multistate: Fitting Multistate Models,Medical researchers are often interested in investigating the relationship between explicative variables and multiple times-to-event. Time-inhomogeneous Markov models consist of modelling the probabilities of transitions according to the chronological times (times since the baseline of the study). Semi-Markov (SM) models consist of modelling the probabilities of transitions according to the times spent in states. In this package, we propose functions implementing such 3-state and 4-state multivariable and multistate models. The user can introduce multiple covariates to estimate conditional (subject-specific) effects. We also propose to adjust for possible confounding factors by using the Inverse Probability Weighting (IPW). When a state is patient death, the user can consider to take into account the mortality of the general population (relative survival approach). Finally, in the particular situation of one initial transient state and two competing and absorbing states, this package allows for estimating mixture models.
rddensity,2017-03-16,rddensity: Manipulation Testing Based on Density Discontinuity,Density discontinuity test (a.k.a. manipulation test) is commonly employed in regression discontinuity designs and other treatment effect settings to detect whether there is evidence suggesting perfect self-selection (manipulation) around a cutoff where a treatment/policy assignment changes. This package provides tools for conducting the aforementioned statistical test: rddensity() to construct local polynomial based density discontinuity test given a prespecified cutoff, rdbwdensity() to perform bandwidth selection, and rdplotdensity() to construct density plot near the cutoff.
svenssonm,2017-08-03,svenssonm: Svensson's Method,Obtain parameters of Svensson's Method, including percentage agreement, 
    systematic change and individual change. Also, the contingency table can be generated. 
    Svensson's Method is a rank-invariant nonparametric method for the analysis of ordered scales 
    which measures the level of change both from systematic and individual aspects. For the details, 
    please refer to Svensson E. Analysis of systematic and random differences between paired ordinal 
    categorical data [dissertation]. Stockholm: Almqvist & Wiksell International; 1993.
ambhasGW,2017-07-15,ambhasGW: Ground Water Modelling,Implements distributed transient groundwater modelling. The model
    is based on the groundwater flow equation solved numerically using the 
    finite difference explicit scheme.
GreedyEPL,2017-08-02,GreedyEPL: Greedy Expected Posterior Loss,Summarises a collection of partitions into a single optimal partition. The objective function is the expected posterior loss, and the minimisation is performed through a greedy algorithm described in Rastelli, R. and Friel, N. (2016) "Optimal Bayesian estimators for latent variable cluster models" <arXiv:1607.02325>.
IrishDirectorates,2016-11-18,IrishDirectorates: Irish Companies' Boards from 2003 to 2013,This data package contains the boards' compositions of companies quoted in the Irish Stock Exchange at the end of each year from 2003 to 2013. The data have been first analysed in Friel, N., Rastelli, R., Wyse, J. and Raftery, A.E. (2016) <doi:10.1073/pnas.1606295113>.
MixtureRegLTIC,2017-08-01,MixtureRegLTIC: Mixture Regression Models for Left-Truncated and
Interval-Censored Data,Fit mixture regression models with nonsusceptibility/cure for left-truncated and interval-censored (LTIC) data (see Chen et al. (2013) <doi:10.1002/sim.5845>). This package also provides the nonparametric maximum likelihood estimator (NPMLE) for the survival/event curves with LTIC data.
rtimicropem,2017-08-02,rtimicropem: Supports the Analysis of RTI MicroPEM Output Files,Supports the input and reproducible analysis of RTI MicroPEM output files.
subgroup.discovery,2017-07-20,subgroup.discovery: Subgroup Discovery and Bump Hunting,Developed to assist in discovering interesting subgroups in high-dimensional data. The PRIM implementation is based on the 1998 paper "Bump hunting in high-dimensional data" by Jerome H. Friedman and Nicholas I. Fisher. <doi:10.1023/A:1008894516817> PRIM involves finding a set of "rules" which combined imply unusually large (or small) values of some other target variable. Specifically one tries to find a set of sub regions in which the target variable is substantially larger than overall mean. The objective of bump hunting in general is to find regions in the input (attribute/feature) space with relatively high (low) values for the target variable. The regions are described by simple rules of the type if: condition-1 and ... and condition-n then: estimated target value. Given the data (or a subset of the data), the goal is to produce a box B within which the target mean is as large as possible. There are many problems where finding such regions is of considerable practical interest.  Often these are problems where a decision maker can in a sense choose or select the values of the input variables so as to optimize the value of the target variable. In bump hunting it is customary to follow a so-called covering strategy. This means that the same box construction (rule induction) algorithm is applied sequentially to subsets of the data.
tbl2xts,2017-06-23,tbl2xts: Convert Tibbles or Data Frames to Xts Easily,Facilitate the movement between data frames to 'xts'. Particularly
    useful when moving from 'tidyverse' to the widely used 'xts' package, which is
    the input format of choice to various other packages. It also allows the user 
    to use a 'spread_by' argument for a character column 'xts' conversion.
ThermIndex,2017-07-25,ThermIndex: Calculate Thermal Indexes,Calculates several thermal comfort indexes using temperature, wind speed and relative humidity values, calculating indexes such as Humidex, windchill, Discomfort Index and others.
dejaVu,2017-08-01,dejaVu: Multiple Imputation for Recurrent Events,Performs reference based multiple imputation of recurrent event data
    based on a negative binomial regression model, as described
    by Keene et al (2014) <doi:10.1002/pst.1624>.
DoEstRare,2017-08-01,DoEstRare: Rare Variant Association Test Based on Position Density
Estimation,Rare variant association test integrating variant position information. It aims to identify the presence of clusters of disease-risk variants in specific gene regions. For more details, please read the publication from Persyn et al. (2017)  <doi:10.1371/journal.pone.0179364>.
fasjem,2017-04-21,fasjem: A Fast and Scalable Joint Estimator for Learning Multiple
Related Sparse Gaussian Graphical Models,This is an R implementation of "A Fast and Scalable Joint Estimator for Learning Multiple Related Sparse Gaussian Graphical Models" (FASJEM). The FASJEM algorithm can be used to estimate multiple related precision matrices. For instance, it can identify context-specific gene networks from multi-context gene expression datasets. By performing data-driven network inference from high-dimensional and heterogonous data sets, this tool  can help users effectively translate aggregated data into knowledge that take the form of graphs among entities. Please run demo(fasjem) to learn the basic functions provided by this package. For more details, please see <http://proceedings.mlr.press/v54/wang17e/wang17e.pdf>.
glmnetUtils,2017-02-05,glmnetUtils: Utilities for 'Glmnet',Provides a formula interface for the 'glmnet' package for
    elasticnet regression, a method for cross-validating the alpha parameter,
    and other quality-of-life tools.
kpmt,2017-08-01,kpmt: Known Population Median Test,Functions that implement the known population median test.
structree,2016-12-13,structree: Tree-Structured Clustering,Tree-structured modelling of categorical predictors or measurement
    units.
nonlinearICP,2017-07-31,nonlinearICP: Invariant Causal Prediction for Nonlinear Models,Performs 'nonlinear Invariant Causal Prediction' to estimate the 
    causal parents of a given target variable from data collected in
    different experimental or environmental conditions, extending
    'Invariant Causal Prediction' from Peters, Buehlmann and Meinshausen (2016), 
    <arXiv:1501.01332>, to nonlinear settings. For more details, see C. Heinze-Deml, 
    J. Peters and N. Meinshausen: 'Invariant Causal Prediction for Nonlinear Models', 
    <arXiv:1706.08576>.
fChange,2017-07-29,fChange: Change Point Analysis in Functional Data,Change point estimation and detection methods for functional data are implemented using dimension reduction via functional principal component analysis and a fully-functional (norm-based) method. Detecting and dating structural breaks for both dependent and independent functional samples is illustrated along with some basic functional data generating processes. 
rclipboard,2017-07-29,rclipboard: Shiny/R Wrapper for 'clipboard.js',Leverages the functionality of 'clipboard.js', a JavaScript library
    for HMTL5-based copy to clipboard from web pages (see <https://clipboardjs.com>
    for more information), and provides a reactive copy-to-clipboard UI button 
    component, called 'rclipButton', for 'shiny' R applications.
RkMetrics,2017-07-28,RkMetrics: Hybrid Mortality Estimation,Hybrid Mortality Modelling (HMM) provides a framework in which mortality around "the accident hump" and at very old ages can be modelled under a single model. The graphics' codes necessary for visualization of the models' output are included here. Specifically, the graphics are based on the assumption that, the mortality rates can be expressed as a function of the area under the curve between the crude mortality rates plots and the tangential transform of the force of mortality.
CDVineCopulaConditional,2017-03-02,CDVineCopulaConditional: Sampling from Conditional C- and D-Vine Copulas,Provides tools for sampling from a conditional copula density decomposed via 
     Pair-Copula Constructions as C- or D- vine. Here, the vines which can be used for such a 
     sampling are those which sample as first the conditioning variables (when following the 
     sampling algorithms shown in Aas et al. (2009) <doi:10.1016/j.insmatheco.2007.02.001>). 
     The used sampling algorithm is presented and discussed in Bevacqua et al. (2017) 
     <doi:10.5194/hess-2016-652>, and it is a modified version of that from Aas et al. (2009) 
     <doi:10.1016/j.insmatheco.2007.02.001>. A function is available to select the best vine 
     (based on information criteria) among those which allow for such a conditional sampling. 
     The package includes a function to compare scatterplot matrices and pair-dependencies of 
     two multivariate datasets.
mmtsne,2017-07-28,mmtsne: Multiple Maps t-SNE,An implementation of multiple maps t-distributed stochastic
    neighbor embedding (t-SNE). Multiple maps t-SNE is a method for
    projecting high-dimensional data into several low-dimensional maps such that
    non-metric space properties are better preserved than they would be by a single
    map. Multiple maps t-SNE with only one map is equivalent to standard t-SNE.
    When projecting onto more than one map, multiple maps t-SNE estimates a set
    of latent weights that allow each point to contribute to one or more maps
    depending on similarity relationships in the original data. This
    implementation is a port of the original 'Matlab' library by Laurens van der
    Maaten. 
    See Van der Maaten and Hinton (2012) <doi:10.1007/s10994-011-5273-4>.
    This material is based upon work supported by the United States Air Force 
    and Defense Advanced Research Project Agency (DARPA) under Contract No. 
    FA8750-17-C-0020.
    Any opinions, findings and conclusions or recommendations expressed in this
    material are those of the author(s) and do not necessarily reflect the views 
    of the United States Air Force and Defense Advanced Research Projects Agency.
    Distribution Statement A: Approved for Public Release; Distribution Unlimited.
lsplsGlm,2017-07-27,lsplsGlm: Classification using LS-PLS for Logistic Regression,Fit logistic regression models using LS-PLS approaches 
	to analyse both clinical and genomic data. (C. Bazzoli and 
	S. Lambert-Lacroix. (2017) Classification using LS-PLS with 
	logistic regression based on both clinical and gene expression
	variables <https://hal.archives-ouvertes.fr/hal-01405101>).
mosaicCalc,2017-07-27,mosaicCalc: Function-Based Numerical and Symbolic Differentiation and
Antidifferentiation,Part of the Project MOSAIC (<http://mosaic-web.org/>)
    suite that provides utility functions for doing calculus 
    (differentiation and integration) in R. The main differentiation and 
    antidifferentiation operators are described using formulas and return functions 
    rather than numerical values. Numerical values can be obtained by evaluating
    these functions.
optiSolve,2017-07-27,optiSolve: Linear, Quadratic, and Rational Optimization,Solver for linear, quadratic, and rational programs with linear, quadratic, and rational constraints. A unified interface to different R packages is provided. Optimization problems are transformed into equivalent formulations and solved by the respective package. For example, quadratic programming problems with linear, quadratic and rational constraints can be solved by augmented Lagrangian minimization using package 'alabama', or by sequential quadratic programming using solver 'slsqp'.  Alternatively, they can be reformulated as optimization problems with second order cone constraints and solved with package 'cccp', or transformed into semidefinite programming problems and solved using solver 'csdp'.
iRF,2017-07-26,iRF: iterative Random Forests,Iteratively grows feature weighted random forests and finds high-order feature interactions in a stable fashion.
maxTPR,2017-07-26,maxTPR: Maximizing the TPR for a Specified FPR,Estimates a linear combination of predictors by maximizing a smooth approximation to the estimated true positive rate (TPR; sensitivity) while constraining a smooth approximation to the estimated false positive rate (FPR; 1-specificity) at a user-specified level.
unrepx,2017-07-26,unrepx: Analysis and Graphics for Unreplicated Experiments,Provides half-normal plots, reference plots, and Pareto plots
    of effects from an unreplicated experiment, along with various 
    pseudo-standard-error measures, simulated reference distributions, 
    and other tools. Many of these methods are described in 
    Daniel C. (1959) <doi:10.1080/00401706.1959.10489866> and/or
    Lenth R.V. (1989) <doi:10.1080/00401706.1989.10488595>, but some new
    approaches are added and integrated in one package.
bayeslongitudinal,2017-07-25,bayeslongitudinal: Adjust Longitudinal Regression Models Using Bayesian Methodology,Adjusts longitudinal regression models using Bayesian methodology 
            for covariance structures of composite symmetry (SC), 
            autoregressive ones of order 1 AR (1) and 
            autoregressive moving average of order (1,1) ARMA (1,1).
concaveman,2017-07-25,concaveman: A Very Fast 2D Concave Hull Algorithm,The concaveman function ports the 'concaveman' (<https://github.com/mapbox/concaveman>) library from 'mapbox'. It computes the concave polygon(s) for one or several set of points.
ggseqlogo,2017-06-13,ggseqlogo: A 'ggplot2' Extension for Drawing Publication-Ready Sequence
Logos,The extensive range of functions provided by this package makes it possible to draw highly versatile sequence logos. Features include, but not limited to, modifying colour schemes and fonts used to draw the logo, generating multiple logo plots, and aiding the visualisation with annotations. Sequence logos can easily be combined with other plots 'ggplot2' plots.
MRTSampleSize,2017-07-25,MRTSampleSize: A Sample Size Calculator for Micro-Randomized Trials,Provide a sample size calculator for micro-randomized
    trials (MRTs) based on methodology developed in Sample Size Calculations for
    Micro-randomized Trials in mHealth by Liao et al. (2016) <doi:10.1002/sim.6847>.
PowerNormal,2017-06-04,PowerNormal: Power Normal Distribution,Miscellaneous functions for a descriptive analysis and initial Bayesian and classical 
             inference for the power parameter of the the Power Normal (PN) distribution. This 
             miscellaneous will be extend for more distributions into the power family and the 
             three-parameter model.
seqICP,2017-06-27,seqICP: Sequential Invariant Causal Prediction,Contains an implementation of invariant causal prediction for sequential data. The main function in the package is 'seqICP', which performs linear sequential invariant causal prediction and has guaranteed type I error control. For non-linear dependencies the package also contains a non-linear method 'seqICPnl', which allows to input any regression procedure and performs tests based on a permutation approach that is only approximately correct. In order to test whether an individual set S is invariant the package contains the subroutines 'seqICP.s' and 'seqICPnl.s' corresponding to the respective main methods.
sidrar,2017-04-23,sidrar: An Interface to IBGE's SIDRA API,Allows the user to connect with IBGE's (Instituto Brasileiro de 
    Geografia e Estatistica, see <http://www.ibge.gov.br/> for more information)
    SIDRA API in a flexible way. SIDRA is the acronym to "Sistema IBGE de 
    Recuperacao Automatica" and is the system where IBGE turns available 
    aggregate data from their researches.
GGEBiplots,2017-07-24,GGEBiplots: GGE Biplots with 'ggplot2',Genotype plus genotype-by-environment (GGE) biplots rendered using 'ggplot2'. Provides a command line interface to all of the functionality contained within 'GGEBiplotGUI'.
pcensmix,2017-07-24,pcensmix: Model Fitting to Progressively Censored Mixture Data,Functions for generating progressively Type-II censored data in
    a mixture structure and fitting models using a constrained EM algorithm. It can also
    create a progressive Type-II censored version of a given real dataset to be considered for
    model fitting. 
c2c,2017-07-23,c2c: Compare Two Classifications or Clustering Solutions of Varying
Structure,Compare two classifications or clustering solutions that may or may
    not have the same number of classes, and that might have hard or soft
    (fuzzy, probabilistic) membership. Calculate various metrics to assess how
    the clusters compare to each other. The calculations are simple, but provide
    a handy tool for users unfamiliar with matrix multiplication. This package
    is not geared towards traditional accuracy assessment for classification/
    mapping applications - the motivating use case is for comparing a
    probabilistic clustering solution to a set of reference or existing class
    labels that could have any number of classes (that is, without having to
    degrade the probabilistic clustering to hard classes).
geoGAM,2016-10-29,geoGAM: Select Sparse Geoadditive Models for Spatial Prediction,A model building procedure to build parsimonious geoadditive model from a large number of covariates. Continuous, binary and ordered categorical responses are supported. The model building is based on component wise gradient boosting with linear effects, smoothing splines and a smooth spatial surface to model spatial autocorrelation. The resulting covariate set after gradient boosting is further reduced through backward elimination and aggregation of factor levels. The package provides a model based bootstrap method to simulate prediction intervals for point predictions. A test data set of a soil mapping case study in Berne (Switzerland) is provided. 
dsmodels,2016-11-11,dsmodels: A Language to Facilitate Simulation and Visualization of
Two-Dimensional Dynamical Systems,An expressive language to facilitate simulation and visualization
    of two-dimensional dynamical systems. The basic elements of the language are
    a model wrapping around a function(x,y) which outputs a list(x
    = xprime, y = yprime), and a range. The language supports three
    types of visual objects: visualizations, features, and backgrounds. Visualizations, including dots and arrows,
    depict the behavior of the dynamical system over the entire range.
    Features display
    user-defined curves and points, and their images under the system.
    Backgrounds define and color regions of interest, such as basins of attraction.
    The language
    can also approximate attractors and their basins through simulation.
prisonbrief,2017-07-22,prisonbrief: Downloads and Parses World Prison Brief Data,Download, parses and tidies information from the World Prison Brief project <http://www.prisonstudies.org/>. 
vcov,2017-07-22,vcov: Variance-Covariance Matrices and Standard Errors,Methods for faster extraction (about 5x faster in a few test cases) of variance-covariance matrices and standard errors from models. Methods in the 'stats' package tend to rely on the summary method, which may waste time computing other summary statistics which are summarily ignored.
spNNGP,2017-07-16,spNNGP: Spatial Regression Models for Large Datasets using Nearest
Neighbor Gaussian Processes,Fits Gaussian univariate Bayesian spatial regression models for large datasets using Nearest Neighbor Gaussian Processes (NNGP) detailed in Datta, Banerjee, Finley, and Gelfand (2016) <doi:10.1080/01621459.2015.1044091> and Finley, Datta, Cook, Morton, Andersen, and Banerjee (2017) <arXiv:1702.00434v2>.
DCA,2017-04-11,DCA: Dynamic Correlation Analysis for High Dimensional Data,Finding dominant latent signals that regulate dynamic correlation between many pairs of variables.
BayesianGLasso,2017-07-19,BayesianGLasso: Bayesian Graphical Lasso,Implements a data-augmented block Gibbs sampler for simulating the posterior distribution of concentration matrices for specifying the topology and parameterization of a Gaussian Graphical Model (GGM). This sampler was originally proposed in Wang (2012) <doi:10.1214/12-BA729>.
FastSF,2017-07-06,FastSF: Fast Structural Filtering,An implementation of the fast structural filtering with L0 penalty. It includes an adaptive polynomial estimator by minimizing the least squares error with constraints on the number of breaks in their (k + 1)-st discrete derivative, for a chosen integer k >= 0. It also includes generalized structure sparsity constraint, i.e., graph trend filtering. This package is implemented via the primal dual active set algorithm, which formulates estimates and residuals as primal and dual variables, and utilizes efficient active set selection strategies based on the properties of the primal and dual variables.
harmonicmeanp,2017-07-19,harmonicmeanp: Harmonic Mean p-Values and Model Averaging by Mean Maximum
Likelihood,The harmonic mean p-value (HMP) test simply and instantly combines p-values and corrects for multiple testing while controlling the family-wise error rate in a way that is more powerful than common alternatives including Bonferroni and Simes procedures, more stringent than controlling the false discovery rate, and is robust to positive correlations between tests and unequal weights. It is a multi-level test in the sense that a superset of one or more significant tests is almost certain to be significant and conversely when the superset is non-significant, the constituent tests are almost certain to be non-significant. It is based on MAMML (model averaging by mean maximum likelihood), a frequentist analogue to Bayesian model averaging, and is theoretically grounded in generalized central limit theorem.
ivregEX,2017-07-19,ivregEX: Create Independent Evidence in IV Analyses and Do Sensitivity
Analysis in Regression and IV Analysis,Allows you to create an evidence factor (EX analysis) in an 
	instrumental variables regression model. Additionally, performs Sensitivity 
	analysis for OLS analysis, 2SLS analysis and EX analysis with interpretable 
	plotting and printing features.
liquidSVM,2017-02-24,liquidSVM: A Fast and Versatile SVM Package,Support vector machines (SVMs) and related kernel-based learning
    algorithms are a well-known class of machine learning algorithms, for
    non-parametric classification and regression.
    liquidSVM is an implementation of SVMs whose key features are:
    fully integrated hyper-parameter selection,
    extreme speed on both small and large data sets,
    full flexibility for experts, and
    inclusion of a variety of different learning scenarios:
    multi-class classification, ROC, and Neyman-Pearson learning, and
    least-squares, quantile, and expectile regression.
OBRE,2017-07-19,OBRE: Optimal B-Robust Estimator Tools,An implementation for computing Optimal B-Robust Estimators (OBRE) of two
    parameters distributions. The procedure is composed by some equations
    that are evaluated alternatively until the solution is reached. Some tools
    for analyzing the estimates are included. The most relevant is OBRE
    covariance matrix computation using a closed formula.
scifigure,2017-07-19,scifigure: Visualize Reproducibility and Replicability in a Comparison of
Scientific Studies,Users may specify what fundamental qualities of a new study have 
             or have not changed in an attempt to reproduce or replicate an original study. A comparison of 
			 the differences is visualized. Visualization approach follows Patil, Peng, and Leek (2016) <doi:10.1101/066803>.
diffpriv,2017-07-18,diffpriv: Easy Differential Privacy,An implementation of major general-purpose mechanisms for privatizing
    statistics, models, and machine learners, within the framework of differential
    privacy of Dwork et al. (2006) <doi:10.1007/11681878_14>. Example mechanisms
    include the Laplace mechanism for releasing numeric aggregates, and the 
    exponential mechanism for releasing set elements. A sensitivity sampler 
    (Rubinstein & Alda, 2017) <arXiv:1706.02562> permits sampling target 
    non-private function sensitivity; combined with the generic mechanisms, it 
    permits turn-key privatization of arbitrary programs.
social,2017-07-18,social: Social Autocorrelation,A set of functions to quantify and visualise 
    social autocorrelation.
brlrmr,2017-05-24,brlrmr: Bias Reduction with Missing Binary Response,Provides two main functions, il() and fil(). The il() function implements the EM algorithm developed by Ibrahim and Lipsitz (1996) <doi:10.2307/2533068> to estimate the parameters of a logistic regression model with the missing response when the missing data mechanism is nonignorable. The fil() function implements the algorithm proposed by Maity et. al. (2017+) <https://github.com/arnabkrmaity/brlrmr> to reduce the bias produced by the method of Ibrahim and Lipsitz (1996) <doi:10.2307/2533068>.
Census2016,2017-07-17,Census2016: Data from the Australian Census 2016,Contains selected variables from the time series profiles for statistical areas level 2 from the 2006, 2011, and 2016 censuses of population and housing, Australia. Also provides methods for viewing the questions asked for convenience during analysis.
cnbdistr,2017-07-17,cnbdistr: Conditional Negative Binomial Distribution,Provided R functions for working with the Conditional Negative Binomial distribution.
ercv,2017-07-17,ercv: Fitting Tails by the Empirical Residual Coefficient of Variation,Provides a methodology simple and trustworthy for the analysis of extreme values and multiple threshold tests for a generalized Pareto distribution, together
    with an automatic threshold selection algorithm. See del Castillo, J, Daoudi, J and Lockhart, R (2014) <doi:10.1111/sjos.12037>.
flexsurvcure,2017-05-14,flexsurvcure: Flexible Parametric Cure Models,Flexible parametric mixture and non-mixture cure models for time-to-event data.
fragilityindex,2016-10-06,fragilityindex: Fragility Index,Implements and extends the fragility index calculation for
    dichotomous results as described in Walsh, Srinathan, McAuley,
    Mrkobrada, Levine, Ribic, Molnar, Dattani, Burke, Guyatt,
    Thabane, Walter, Pogue, and Devereaux (2014)
    <doi:10.1016/j.jclinepi.2013.10.019>.
LCox,2017-07-17,LCox: A Tool for Selecting Genes Related to Survival Outcomes using
Longitudinal Gene Expression Data,Longitudinal genomics data and survival outcome are common in biomedical studies. It is of great interest to select genes related to the survival outcome. LCox is a computationally efficient tool for selecting genes related to the survival outcome using the longitudinal genomics data. LCox is powerful to detect different forms of dependence between the longitudinal biomarkers and the survival outcome. 
sergeant,2017-07-17,sergeant: Tools to Transform and Query Data with 'Apache' 'Drill','Apache Drill' is a low-latency distributed query engine designed to enable 
    data exploration and 'analytics' on both relational and non-relational 'datastores', 
    scaling to petabytes of data. Methods are provided that enable working with 'Apache' 
    'Drill' instances via the 'REST' 'API', 'JDBC' interface (optional), 'DBI' 'methods'
    and using 'dplyr'/'dbplyr' idioms.
gh,2017-07-16,gh: 'GitHub' 'API',Minimal client to access the 'GitHub' 'API'.
llogistic,2017-07-16,llogistic: The L-Logistic Distribution,Density, distribution function, quantile function and random generation for the L-Logistic distribution with parameters m and b. The parameter m is the median of the distribution.
senstrat,2017-07-16,senstrat: Sensitivity Analysis for Stratified Observational Studies,Sensitivity analysis in unmatched observational studies, with or without strata.  The main functions are sen2sample() and senstrat().  See Rosenbaum, P. R. and Krieger, A. M. (1990), JASA, 85, 493-498, <doi:10.1080/01621459.1990.10476226> and Gastwirth, Krieger and Rosenbaum (2000), JRSS-B, 62, 545–555 <doi:10.1111/1467-9868.00249> .
centiserve,2017-07-15,centiserve: Find Graph Centrality Indices,Calculates centrality indices additional to the 'igraph' package centrality functions.
docker,2017-07-13,docker: Wraps Docker Python SDK,Allows accessing 'Docker' 'SDK' from 'R' via the 'Docker' 'Python' 'SDK' using the 'reticulate' package.
  This is a very thin wrapper that tries to do very little and get out of the way.
  The user is expected to know how to use the 'reticulate' package to access 'Python' modules, and how the 'Docker' 'Python' 'SDK' works.
DrImpute,2017-07-15,DrImpute: Imputing Dropout Events in Single-Cell RNA-Sequencing Data,R codes for imputing dropout events. Many statistical methods in cell type identification, visualization and lineage reconstruction do not account for dropout events ('PCAreduce', 'SC3', 'PCA', 't-SNE', 'Monocle', 'TSCAN', etc). 'DrImpute' can improve the performance of such software by imputing dropout events.
randomForestExplainer,2017-07-15,randomForestExplainer: Explaining and Visualizing Random Forests in Terms of Variable
Importance,A set of tools to help explain which variables are most important in a random forests. Various variable importance measures are calculated and visualized in different settings in order to get an idea on how their importance changes depending on our criteria (Hemant Ishwaran and Udaya B. Kogalur and Eiran Z. Gorodeski and Andy J. Minn and Michael S. Lauer (2010) <doi:10.1198/jasa.2009.tm08622>, Leo Breiman (2001) <doi:10.1023/A:1010933404324>).
spongecake,2016-11-25,spongecake: Transform a Movie into a Synthetic Picture,Transform a Movie into a Synthetic Picture. A frame every 10 seconds is summarized into one colour, then every generated colors are stacked together.
tetraclasse,2017-07-15,tetraclasse: Satisfaction Analysis using Tetraclasse Model and Llosa Matrix,The satisfaction Analysis using the tetraclasse model from Sylvie Llosa. Llosa (1997) <http://www.jstor.org/stable/40592578>.
TSF,2017-07-15,TSF: Two Stage Forecasting (TSF) for Long Memory Time Series in
Presence of Structural Break,Forecasting of long memory time series in presence of structural break by using TSF algorithm by Papailias and Dias (2015) <doi:10.1016/j.ijforecast.2015.01.006>. 
credsubs,2017-07-14,credsubs: Credible Subsets,Functions for constructing simultaneous credible bands and identifying subsets via the "credible subsets" (also called "credible subgroups") method.
geotoolsR,2017-07-14,geotoolsR: Tools to Improve the Use of Geostatistic,The basic idea of this package is provides some tools to help the researcher to work with geostatistics. Initially, we present a collection of functions that allow the researchers to deal with spatial data using bootstrap procedure.There are five methods available and two ways to display them: bootstrap confidence interval - provides a two-sided bootstrap confidence interval; bootstrap plot - a graphic with the original variogram and each of the B bootstrap variograms.
interfr,2017-07-13,interfr: Interference Color Charts for Polarized Light Microscopy,Computes interference color tables and plots customized Michel-Levy or Raith-Sorensen charts. Automatic interpretation of polarized-light microscopy images is still under development and will come soon.
noaastormevents,2017-07-13,noaastormevents: Explore NOAA Storm Events Database,Allows users to explore and plot data from the
    National Oceanic and Atmospheric Administration (NOAA) 
    Storm Events database through R for United States counties. 
    Functionality includes matching storm event listings by time and 
    location to hurricane best tracks data. This work was 
    supported by grants from the Colorado Water Center, the National Institute 
    of Environmental Health Sciences (R00ES022631) and the National Science 
    Foundation (1331399). 
facebook.S4,2017-07-12,facebook.S4: Access to Facebook API V2 via a Set of S4 Classes,Provides an interface to the Facebook API and builds collections of elements that reflects the graph architecture of Facebook.
  See <https://developers.facebook.com/docs/graph-api> for more information.
interim,2017-06-08,interim: Scheduling Interim Analyses in Clinical Trials,Allows the simulation of both the recruitment and treatment phase of a clinical trial. Based on these simulations, the timing of interim analyses can be assessed.
integIRTy,2017-07-11,integIRTy: Integrating Multiple Modalities of High Throughput Assays Using
Item Response Theory,Provides a systematic framework for
 integrating multiple modalities of assays profiled on the same set of
 samples. The goal is to identify genes that are altered in cancer
 either marginally or consistently across different assays. The
 heterogeneity among different platforms and different samples are
 automatically adjusted so that the overall alteration magnitude can
 be accurately inferred. See Tong and Coombes (2012) 
 <doi:10.1093/bioinformatics/bts561>. 
NameNeedle,2017-07-11,NameNeedle: Using Needleman-Wunsch to Match Sample Names,The Needleman-Wunsch global alignment algorithm can be
  used to find approximate matches between sample names in different
  data sets. See Wang et al. (2010) <doi:10.4137/CIN.S5613>.
roots,2017-07-11,roots: Reconstructing Ordered Ontogenic Trajectories,A set of tools to reconstruct ordered ontogenic trajectories from
    single cell RNAseq data.
AutoDeskR,2016-11-12,AutoDeskR: An Interface to the 'AutoDesk' 'API' Platform,An interface to the 'AutoDesk' 'API' Platform including the Authentication 
    'API' for obtaining authentication to the 'AutoDesk' Forge Platform, Data Management 
    'API' for managing data across the platform's cloud services, Design Automation 'API'
    for performing automated tasks on design files in the cloud, Model
    Derivative 'API' for translating design files into different formats, sending
    them to the viewer app, and extracting design data, and Viewer for rendering
    2D and 3D models (see <https://developer.autodesk.com> for more information).
dGAselID,2016-11-20,dGAselID: Genetic Algorithm with Incomplete Dominance for Feature
Selection,Feature selection from high dimensional data using a diploid
    genetic algorithm with Incomplete Dominance for genotype to phenotype mapping
    and Random Assortment of chromosomes approach to recombination.
FUNLDA,2017-07-07,FUNLDA: Genomic Latent Dirichlet Allocation,A tool for fitting latent Dirichlet allocation models to genomic annotation data. 
netcom,2017-07-08,netcom: Dynamic Network Alignment,Functions to take two networks stored as matrices and return a node-level injection between them (bijection if the input networks are of the same size). The alignment is made by comparing diffusion kernels originating from each node in one network to those originating from each node in the other network. This creates a cost matrix where rows are nodes from one network and columns are nodes from the other network. Optimal node pairings are then found using the Hungarian algorithm.
oompaData,2017-07-10,oompaData: Data to Illustrate OOMPA Algorithms,This is a data-only package to provide example data for
  other packages that are part of the "Object-Oriented Microrray and
  Proteomics Analysis" suite of packages. These are described in more
  detail at the package URL.
PoloniexR,2017-07-10,PoloniexR: Interface to the Poloniex Cryptocurrency Trading API,Provides a user-friendly R wrapper on top of the Poloniex (Cryptocurrency Trading) REST API (see <https://poloniex.com/support/api/> for more information).
    Results are converted into R data structures and are returned to the users in an intuitive manner.
    The package provides the users with two separate S4 classes:
    - 'PoloniexPublicAPI': Consists of wrapper methods on top of the Poloniex Public REST API.
    - 'PoloniexTradingAPI': Consists of wrapper methods on top of the Poloniex Trading REST API.
SFS,2017-06-20,SFS: Similarity-First Search Seriation Algorithm,An implementation of the Similarity-First Search algorithm (SFS), a combinatorial algorithm which can be used to solve the seriation problem and to recognize some structured weighted graphs. The SFS algorithm represents a generalization to weighted graphs of the graph search algorithm Lexicographic Breadth-First Search (Lex-BFS), a variant of Breadth-First Search. The SFS algorithm reduces to Lex-BFS when applied to binary matrices (or, equivalently, unweighted graphs). Hence this library can be also considered for Lex-BFS applications such as recognition of graph classes like chordal or unit interval graphs. In fact, the SFS seriation algorithm implemented in this package is a multisweep algorithm, which consists in repeating a finite number of SFS iterations (at most \eqn{n} sweeps for a matrix of size \eqn{n}). If the data matrix has a Robinsonian structure, then the ranking returned by the multistep SFS algorithm is a Robinson ordering of the input matrix. Otherwise the algorithm can be used as a heuristic to return a ranking partially satisfying the Robinson property. 
decomposedPSF,2017-07-09,decomposedPSF: Time Series Prediction with PSF and Decomposition Methods (EMD
and EEMD),Predict future values with hybrid combinations of Pattern Sequence based
        Forecasting (PSF), Autoregressive Integrated Moving Average (ARIMA), Empirical Mode
        Decomposition (EMD) and Ensemble Empirical Mode Decomposition (EEMD) methods based
        hybrid methods.
fcm,2017-05-25,fcm: Inference of Fuzzy Cognitive Maps (FCMs),Provides a selection of 3 different inference rules (including additionally the clamped types of the referred inference rules) and 4 threshold functions in order to obtain the inference of the FCM (Fuzzy Cognitive Map). Moreover, the 'fcm' package returns a data frame of the concepts' values of each state after the inference procedure. Fuzzy cognitive maps were introduced by Kosko (1986) <doi:10.1002/int.4550010405> providing ideal causal cognition tools for modeling and simulating dynamic systems.
lpdensity,2017-04-11,lpdensity: Local Polynomial Density Estimation and Inference,Without imposing stringent distributional assumptions or shape restrictions, nonparametric density estimation has been popular in economics and other social sciences for counterfactual analysis, program evaluation, and policy recommendations. This package implements a novel density estimator based on local polynomial regression, documented in Cattaneo, Jansson and Ma (2017a): lpdensity() to construct local polynomial based density (and derivatives) estimator; lpbwdensity() to perform data-driven bandwidth selection; and lpdensity.plot() for density plot with robust confidence interval.
mthapower,2017-07-09,mthapower: Sample Size and Post-Hoc Power of Association Studies Involving
Mitochondrial DNA Haplogroups,Calculate Sample Size and Post-Hoc Power of
    Association Studies Involving Mitochondrial DNA Haplogroups.
    Based on formulae by Samuels et al. AJHG, 2006. 78(4):713-720. <doi:10.1086/502682>.
postlightmercury,2017-06-26,postlightmercury: Parses Web Pages using Postlight Mercury,This is a wrapper for the Mercury Parser API. The Mercury Parser is 
    a single API endpoint that takes a URL and gives you back the content reliably 
    and easily. 
    With just one API request, Mercury takes any web article and returns 
    only the relevant content — headline, author, body text, relevant images and 
    more — free from any clutter. It’s reliable, easy-to-use and free.
    See the webpage here: <https://mercury.postlight.com/>.
fcuk,2017-07-07,fcuk: The Ultimate Helper for Clumsy Fingers,Automatically suggests a correction when a typo occurs.
ggplotgui,2017-07-08,ggplotgui: Create Ggplots via a Graphical User Interface,Easily explore data by creating ggplots through a (shiny-)GUI. R-code to recreate graph provided.   
l1kdeconv,2017-04-18,l1kdeconv: Deconvolution for LINCS L1000 Data,LINCS L1000 is a high-throughput technology that allows the gene expression measurement in a large number of assays. However, to fit the measurements of ~1000 genes in the ~500 color channels of LINCS L1000, every two landmark genes are designed to share a single channel. Thus, a deconvolution step is required to infer the expression values of each gene. Any errors in this step can be propagated adversely to the downstream analyses. We present a LINCS L1000 data peak calling R package l1kdeconv based on a new outlier detection method and an aggregate Gaussian mixture model. Upon the remove of outliers and the borrowing information among similar samples, l1kdeconv shows more stable and better performance than methods commonly used in LINCS L1000 data deconvolution.
mixlink,2016-12-23,mixlink: Mixture Link Regression,The Mixture Link model <arXiv:1612.03302> is a proposed extension to generalized linear models, where the outcome distribution is a finite mixture of J > 1 densities. This package supports Mixture Link computations for Poisson and Binomial outcomes. This includes the distribution functions, numerical maximum likelihood estimation, Bayesian analysis, and quantile residuals to assess model fit.
waccR,2017-07-08,waccR: Cost of Capital by Sector Data,
    Downloads and tidies Aswath Damodaran's Cost of Capital Data.
BNPMediation,2017-07-07,BNPMediation: Bayesian Nonparametric Method for Mediation,Provides the Bayesian nonparametric inference for the causal effects of mediation. The function bnpmediation()
      gives the posterior means and credible intervals of the effects of mediation on the data. Full details: Kim, C., Daniels, M. J., Marcus, B. H. and Roy, J. A. (2017) <doi:10.1111/biom.12575>.
SobolSequence,2017-07-07,SobolSequence: Sobol Sequences with Better Two-Dimensional Projections,R implementation of S. Joe and F. Y. Kuo(2008)
        <doi:10.1137/070709359>.
        The implementation is based on the data file new-joe-kuo-6.21201
        <http://web.maths.unsw.edu.au/~fkuo/sobol/>.
textile,2017-07-07,textile: Textile Images,Contains real images of the same textile material 
    with/without local defects, which were used in 
    Bui and Apley (2017) <doi:10.1080/00401706.2017.1302362>.
Autoplotprotein,2017-07-06,Autoplotprotein: Development of Visualization Tools for Protein Sequence,The image of the amino acid transform on the protein level is drawn, and the automatic routing of the functional elements such as the domain and the mutation site is completed.
correlbinom,2017-07-06,correlbinom: Correlated Binomial Probabilities,Calculates the probabilities of k successes given n trials of a binomial random variable with non-negative correlation across trials. The function takes as inputs the scalar values the level of correlation or association between trials, the success probability, the number of trials, an optional input specifying the number of bits of precision used in the calculation, and an optional input specifying whether the calculation approach to be used is from Witt (2014) <doi:10.1080/03610926.2012.725148> or from Kuk (2004) <doi:10.1046/j.1467-9876.2003.05369.x>. The output is a (trials+1)-dimensional vector containing the likelihoods of 0, 1, ..., trials successes.
ggChernoff,2017-07-06,ggChernoff: Chernoff Faces for 'ggplot2',Provides a Chernoff face geom for 'ggplot2'. Maps multivariate data
    to human-like faces.
mandelbrot,2017-07-06,mandelbrot: Generates Views on the Mandelbrot Set,Estimates membership for the Mandelbrot set.
Robocoap,2017-07-06,Robocoap: Generation of Dynamic Coappearance Matrices Within Texts,Generation of dynamic coappearance matrices for elements
             within a text along with utilities to aid in the generation
	     of Gephi dynamic networks.
assocInd,2017-07-05,assocInd: Implements New and Existing Association Indices for Constructing
Animal Social Networks,Implements several new association indices that can control for various types of errors. Also includes existing association indices and functions for simulating the effects of different rates of error on estimates of association strength between individuals using each method.
awspack,2017-07-01,awspack: Amazon Web Services Bundle Package,A bundle of all of 'cloudyr' project <http://cloudyr.github.io/> packages for Amazon Web Services ('AWS') <https://aws.amazon.com/>. It depends upon all of the 'cloudyr' project's 'AWS' packages. It is mainly useful for installing the entire suite of packages; more likely than not you will only want to load individual packages one at a time.
catSurv,2017-06-15,catSurv: Computerized Adaptive Testing for Survey Research,Provides methods of computerized adaptive testing for survey researchers. Includes functionality for data fit with the classic item response methods including the latent trait model, Birnbaum's three parameter model, the graded response, and the generalized partial credit model.  Additionally, includes several ability parameter estimation and item selection routines.  During item selection, all calculations are done in compiled C++ code.
coxphSGD,2017-07-05,coxphSGD: Stochastic Gradient Descent log-Likelihood Estimation in Cox
Proportional Hazards Model,Estimate coefficients of Cox proportional hazards model using stochastic gradient descent algorithm for batch data.
midas,2017-07-05,midas: Turn HTML 'Shiny',Contains functions for converting existing HTML/JavaScript
   source into equivalent 'shiny' functions. Bootstraps the process of making
   new 'shiny' functions by allowing us to turn HTML snippets directly into 
   R functions.
numGen,2017-05-21,numGen: Number Series Generator,A number series generator that creates number series items based on cognitive models.
SuperGauss,2017-07-05,SuperGauss: Superfast Likelihood Inference for Stationary Gaussian Time
Series,Likelihood evaluations for stationary Gaussian time series are typically obtained via the Durbin-Levinson algorithm, which scales as O(n^2) in the number of time series observations.  This package provides a "superfast" O(n log^2 n) algorithm written in C++, crossing over with Durbin-Levinson around n = 300.  Efficient implementations of the score and Hessian functions are also provided, leading to superfast versions of inference algorithms such as Newton-Raphson and Hamiltonian Monte Carlo.  The C++ code provides a Toeplitz matrix class packaged as a header-only library, to simplify low-level usage in other packages and outside of R.
aws.cloudtrail,2017-07-04,aws.cloudtrail: AWS CloudTrail Client Package,A simple client package for the Amazon Web Services ('AWS') 'CloudTrail'
    'API' <https://aws.amazon.com/cloudtrail/>.
aws.sns,2016-12-08,aws.sns: AWS SNS Client Package,A simple client package for the Amazon Web Services ('AWS') Simple
    Notification Service ('SNS') 'API' <https://aws.amazon.com/sns/>.
aws.sqs,2016-12-09,aws.sqs: AWS SQS Client Package,A simple client package for the Amazon Web Services ('AWS') Simple
    Queue Service ('SQS') <https://aws.amazon.com/sqs/> 'API'.
cepR,2017-07-04,cepR: Busca CEPs Brasileiros,
    Retorna detalhes de dados de CEPs brasileiros, bairros, logradouros e tal. (Returns info of Brazilian postal codes, city names, addresses and so on.)
SSM,2017-07-04,SSM: Fit and Analyze Smooth Supersaturated Models,Creates an S4 class "SSM" and defines functions for fitting smooth
    supersaturated models, a polynomial model with spline-like behaviour.
    Functions are defined for the computation of Sobol indices for sensitivity
    analysis and plotting the main effects using FANOVA methods. It also
    implements the estimation of the SSM metamodel error using a GP model with
    a variety of defined correlation functions.
wql,2017-07-04,wql: Exploring Water Quality Monitoring Data,Functions to assist in the processing and
    exploration of data from environmental monitoring programs.
    The package name stands for "water quality" and reflects the
    original focus on time series data for physical and chemical
    properties of water, as well as the biota. Intended for
    programs that sample approximately monthly, quarterly or
    annually at discrete stations, a feature of many legacy data
    sets. Most of the functions should be useful for analysis of
    similar-frequency time series regardless of the subject
    matter.
aurelius,2017-07-03,aurelius: Generates PFA Documents from R Code and Optionally Runs Them,Provides tools for converting R objects and syntax into the Portable 
    Format for Analytics (PFA). Allows for testing validity and runtime behavior 
    of PFA documents through rPython and Titus, a more complete implementation of 
    PFA for Python. The Portable Format for Analytics is a specification for 
    event-based processors that perform predictive or analytic calculations and is aimed 
    at helping smooth the transition from statistical model development to large-scale 
    and/or online production. See <http://dmg.org/pfa> for more information.
ecolottery,2017-07-03,ecolottery: Coalescent-Based Simulation of Ecological Communities,Coalescent-Based Simulation of Ecological Communities as proposed
    by Munoz et al. (2017) <doi:10.13140/RG.2.2.31737.26728>. The package includes
    a tool for estimating parameters of community assembly by using Approximate 
    Bayesian Computation.
mnis,2016-12-29,mnis: Easy Downloading Capabilities for the Members' Name Information
Service,An API package for the Members' Name Information Service operated by the UK parliament. Documentation for the API itself can be found here: <http://data.parliament.uk/membersdataplatform/default.aspx>.
autoBagging,2017-07-02,autoBagging: Learning to Rank Bagging Workflows with Metalearning,A framework for automated machine learning. Concretely, the focus is on the optimisation of bagging workflows. A bagging workflows is composed by three phases: (i) generation: which and how many predictive models to learn; (ii) pruning: after learning a set of models, the worst ones are cut off from the ensemble; and (iii) integration: how the models are combined for predicting a new observation. autoBagging optimises these processes by combining metalearning and a learning to rank approach to learn from metadata. It automatically ranks 63 bagging workflows by exploiting past performance and dataset characterization. A complete description of the method can be found in: Pinto, F., Cerqueira, V., Soares, C., Mendes-Moreira, J. (2017): "autoBagging: Learning to Rank Bagging Workflows with Metalearning" arXiv preprint arXiv:1706.09367.
aws.lambda,2017-07-02,aws.lambda: AWS Lambda Client Package,A simple client package for the Amazon Web Services ('AWS') Lambda 'API' <https://aws.amazon.com/lambda/>.
geoSpectral,2017-03-24,geoSpectral: Classes and Methods for Working with Spectral Data with
Space-Time Attributes,Provides S4 classes and data import, preprocessing, graphing, 
    manipulation and export methods for geo-Spectral datasets (datasets with space/time/spectral 
    dimensions). These type of data are frequently collected within earth observation projects 
    (remote sensing, spectroscopy, bio-optical oceanography, mining, agricultural, atmospheric, 
    environmental or similar branch of science).
hurdlr,2017-07-02,hurdlr: Zero-Inflated and Hurdle Modelling Using Bayesian Inference,When considering count data, it is often the case that many more zero counts than would be expected of some given distribution are observed. It is well established that data such as this can be reliably modelled using zero-inflated or hurdle distributions, both of which may be applied using the functions in this package. Bayesian analysis methods are used to best model problematic count data that cannot be fit to any typical distribution. The package functions are flexible and versatile, and can be applied to varying count distributions, parameter estimation with or without explanatory variable information, and are able to allow for multiple hurdles as it is also not uncommon that count data have an abundance of large-number observations which would be considered outliers of the typical distribution. In lieu of throwing out data or misspecifying the typical distribution, these extreme observations can be applied to a second, extreme distribution. With the given functions of this package, such a two-hurdle model may be easily specified in order to best manage data that is both zero-inflated and over-dispersed.
kgschart,2017-05-13,kgschart: KGS Rank Graph Parser,Restore underlining numeric data from rating history graph of 
    KGS (an online platform of the game of go, <http://www.gokgs.com/>). 
    A shiny application is also provided.
quickregression,2017-07-02,quickregression: Quick Linear Regression,Helps to perform linear regression analysis by reducing manual effort. Reduces the independent variables based on specified p-value and Variance Inflation Factor (VIF) level.
rsoi,2017-04-04,rsoi: El Nino/Southern Oscillation (ENSO) and Related Climate Indices,Downloads Southern Oscillation Index, Oceanic Nino Index and North Pacific Gyre Oscillation data. Data sources are described in the README file.
aws.iam,2017-07-01,aws.iam: AWS IAM Client Package,A simple client for the Amazon Web Services ('AWS') Identity
    and Access Management ('IAM') 'API' <https://aws.amazon.com/iam/>.
fence,2017-07-01,fence: Using Fence Methods for Model Selection,This method is a new class of model selection strategies, 
    for mixed model selection, which includes linear and generalized linear 
    mixed models. The idea involves a procedure to isolate a subgroup of what 
    are known as correct models (of which the optimal model is a member). This is 
    accomplished by constructing a statistical fence, or barrier, to carefully 
    eliminate incorrect models. Once the fence is constructed, the optimal model is 
    selected from among those within the fence according to a criterion which can 
    be made flexible.
    References: 
    1. Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. 
    The Annals of Statistics, 36(4): 1669-1692.  
    <doi:10.1214/07-AOS517> <https://projecteuclid.org/euclid.aos/1216237296>.
    2. Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. 
    Statistics and Probability Letters, 79, 625-629.  
    <doi:10.1016/j.spl.2008.10.014> <https://www.researchgate.net/publication/23991417_A_simplified_adaptive_fence_procedure>
    3. Jiang J., Nguyen T., Rao J.S. (2010), Fence Method for Nonparametric Small Area Estimation. 
    Survey Methodology, 36(1), 3-11.  
    <http://publications.gc.ca/collections/collection_2010/statcan/12-001-X/12-001-x2010001-eng.pdf>.
    4. Jiming Jiang, Thuan Nguyen and J. Sunil Rao (2011), Invisible fence methods and the identification of differentially expressed gene sets. 
    Statistics and Its Interface, Volume 4, 403-415.
    <http://www.intlpress.com/site/pub/files/_fulltext/journals/sii/2011/0004/0003/SII-2011-0004-0003-a014.pdf>.
    5. Thuan Nguyen & Jiming Jiang (2012), Restricted fence method for covariate selection in longitudinal data analysis. 
    Biostatistics, 13(2), 303-314.  
    <doi:10.1093/biostatistics/kxr046> <https://academic.oup.com/biostatistics/article/13/2/303/263903/Restricted-fence-method-for-covariate-selection-in>.
    6. Thuan Nguyen, Jie Peng, Jiming Jiang (2014), Fence Methods for Backcross Experiments.  
    Statistical Computation and Simulation, 84(3), 644-662.  
    <doi:10.1080/00949655.2012.721885> <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3891925/>.
    7. Jiang, J. (2014), The fence methods, in Advances in Statistics, Hindawi Publishing Corp., Cairo.  
    <doi:10.1155/2014/830821>.
    8. Jiming Jiang and Thuan Nguyen (2015), The Fence Methods, World Scientific, Singapore.  
    <https://www.abebooks.com/9789814596060/Fence-Methods-Jiming-Jiang-981459606X/plp>.
hbdct,2017-06-29,hbdct: Hierarchical Bayesian Design for Clinical Trials,Implements our hierarchical Bayesian design for randomized clinical trials.
MicroMacroMultilevel,2017-07-01,MicroMacroMultilevel: Micro-Macro Multilevel Modeling,Most multilevel methodologies can only model macro-micro
    multilevel situations in an unbiased way, wherein group-level predictors
    (e.g., city temperature) are used to predict an individual-level
    outcome variable (e.g., citizen personality). In contrast,
    this R package enables researchers to model micro-macro situations, wherein
    individual-level (micro) predictors (and other group-level predictors) are
    used to predict a group-level (macro) outcome variable in an unbiased way.
SkyWatchr,2016-12-04,SkyWatchr: Search and Download Satellite Imagery using the SkyWatch API,Query and download satellite imagery and climate/atmospheric datasets using the SkyWatch API. 
     Search datasets by wavelength (band), cloud cover, resolution, location, date, etc.
     Get the query results as data frame and as HTML. To learn more about the SkyWatch API, see <https://github.com/skywatchspaceapps/api>.
BiBitR,2016-11-30,BiBitR: R Wrapper for Java Implementation of BiBit,A simple R wrapper for the Java BiBit algorithm from "A
    biclustering algorithm for extracting bit-patterns from binary datasets"
    from Domingo et al. (2011) <doi:10.1093/bioinformatics/btr464>. An simple adaption for the BiBit algorithm which allows noise in the biclusters is also introduced as well as a function to guide the algorithm towards given (sub)patterns. Further, a workflow to derive noisy biclusters from discoverd larger column patterns is included as well.
hhh4contacts,2017-06-30,hhh4contacts: Age-Structured Spatio-Temporal Models for Infectious Disease
Counts,Meyer and Held (2017) <doi:10.1093/biostatistics/kxw051> present an
    age-structured spatio-temporal model for infectious disease counts. The
    approach is illustrated in a case study on norovirus gastroenteritis in
    Berlin, 2011-2015, by age group, city district and week, using additional
    contact data from the POLYMOD survey. This package contains the data and
    code to reproduce the results from the paper, see 'demo("hhh4contacts")'.
scpm,2017-06-28,scpm: An R Package for Spatial Smoothing,Group of functions for spatial smoothing using cubic splines and variogram maximum likelihood estimation. Also allow the inclusion of linear parametric terms and change-points for segmented smoothing splines models.
StratifiedRF,2017-06-21,StratifiedRF: Builds Trees by Sampling Variables in Groups,Random Forest-like tree ensemble that works with groups of predictor variables. When building a tree, a number of variables is taken randomly from each group separately, thus ensuring that it considers variables from each group for the splits. Useful when rows contain information about different things (e.g. user information and product information) and it's not sensible to make a prediction with information from only one group of variables, or when there are far more variables from one group than the other and it's desired to have groups appear evenly on trees.
    Trees are grown using the C5.0 algorithm rather than the usual CART algorithm. Supports parallelization (multithreaded), missing values in predictors, and categorical variables (without doing One-Hot encoding in the processing). Can also be used to create a regular (non-stratified) Random Forest-like model, but made up of C5.0 trees and with some additional control options.
    As it's built with C5.0 trees, it works only for classification (not for regression).
BradleyTerryScalable,2017-06-29,BradleyTerryScalable: Fits the Bradley-Terry Model to Potentially Large and Sparse
Networks of Comparison Data,Facilities are provided for fitting the simple, unstructured Bradley-Terry model to networks of binary comparisons. The implemented methods are designed to scale well to large, potentially sparse, networks. A fairly high degree of scalability is achieved through the use of EM and MM algorithms, which are relatively undemanding in terms of memory usage (relative to some other commonly used methods such as iterative weighted least squares, for example). Both maximum likelihood and Bayesian MAP estimation methods are implemented. The package provides various standard methods for a newly defined 'btfit' model class, such as the extraction and summarisation of model parameters and the simulation of new datasets from a fitted model. Tools are also provided for reshaping data into the newly defined "btdata" class, and for analysing the comparison network, prior to fitting the Bradley-Terry model. This package complements, rather than replaces, the existing 'BradleyTerry2' package. (BradleyTerry2 has rather different aims, which are mainly the specification and fitting of "structured" Bradley-Terry models in which the strength parameters depend on covariates.)
gsloid,2017-06-29,gsloid: Global Sea Level and Oxygen Isotope Data,Contains published data sets for global benthic d18O data for 
    0-5.3 Myr <doi:10.1029/2004PA001071> and global sea levels based 
    on marine sediment core data for 0-800 ka <doi:10.5194/cp-12-1-2016>.
kazaam,2017-06-29,kazaam: Tools for Tall Distributed Matrices,Many data science problems reduce to operations on very tall,
    skinny matrices.  However, sometimes these matrices can be so tall that they
    are difficult to work with, or do not even fit into main memory.  One
    strategy to deal with such objects is to distribute their rows across
    several processors.  To this end, we offer an 'S4' class for tall, skinny,
    distributed matrices, called the 'shaq'.  We also provide many useful
    numerical methods and statistics operations for operating on these
    distributed objects.  The naming is a bit "tongue-in-cheek", with the class
    a play on the fact that 'Shaquille' 'ONeal' ('Shaq') is very tall, and he
    starred in the film 'Kazaam'.
My.stepwise,2017-06-29,My.stepwise: Stepwise Variable Selection Procedures for Regression Analysis,The stepwise variable selection procedure (with iterations
 between the 'forward' and 'backward' steps) can be used to obtain
 the best candidate final regression model in regression analysis.
 All the relevant covariates are put on the 'variable list' to be
 selected. The significance levels for entry (SLE) and for stay
 (SLS) are usually set to 0.15 (or larger) for being conservative.
 Then, with the aid of substantive knowledge, the best candidate
 final regression model is identified manually by dropping the
 covariates with p value > 0.05 one at a time until all regression
 coefficients are significantly different from 0 at the chosen alpha
 level of 0.05.
pinnacle.data,2017-06-29,pinnacle.data: Market Odds Data from Pinnacle,Market odds from from Pinnacle, an online sports betting bookmaker (see <https://www.pinnacle.com> for more information). Included are datasets for the Major League Baseball (MLB) 2016 season and the USA election 2016. These datasets can be used to build models and compare statistical information with the information from prediction markets.The Major League Baseball (MLB) 2016 dataset can be used for sabermetrics analysis and also can be used in conjunction with other popular Major League Baseball (MLB) datasets such as Retrosheets or the Lahman package by merging by GameID.
assertable,2017-01-14,assertable: Verbose Assertions for Tabular Data (Data.frames and
Data.tables),Simple, flexible, assertions on data.frame or data.table objects with verbose output for vetting. While other assertion packages apply towards more general use-cases, assertable is tailored towards tabular data. It includes functions to check variable names and values, whether the dataset contains all combinations of a given set of unique identifiers, and whether it is a certain length. In addition, assertable includes utility functions to check the existence of target files and to efficiently import multiple tabular data files into one data.table.
ExpRep,2017-06-28,ExpRep: Experiment Repetitions,Allows to calculate the probabilities  of occurrences of an event in a 
 great number of repetitions of Bernoulli experiment, through the application of  
 the local and the integral theorem of De Moivre Laplace, and the theorem of Poisson. 
 Gives the possibility to show the results graphically and analytically, and to compare
 the results obtained by the application of the above  theorems with those calculated by
 the direct application of the Binomial formula. Is basically useful for educational
 purposes. 
ForecastFramework,2017-06-28,ForecastFramework: A Basis for Modular Model Creation,Create modular models.  Quickly prototype models whose input includes (multiple) time series data.  Create pieces of model use cases separately, and swap out particular models as desired. Create modeling competitions, data processing pipelines, and re-useable models.
goldi,2016-10-17,goldi: Gene Ontology Label Discernment and Identification,A tool for identifying multiple word key terms in free text with application to Gene Ontology labels.
ppcc,2017-06-28,ppcc: Probability Plot Correlation Coefficient Test,Calculates the Probability Plot Correlation Coefficient (PPCC) 
             between a continuous variable X and a specified distribution. The corresponding 
	     composite hypothesis test can be done to test whether the sample 
	     X is element of either the Normal, log-Normal, Exponential,
	     Uniform, Cauchy, Logistic, Generalized Logistic, Gumbel (GEVI), Weibull,
	     Generalized Extreme Value, Pearson III (Gamma 2), Mielke's Kappa, Rayleigh
	     or Generalized Logistic Distribution. The PPCC test is performed with
	     a fast Monte-Carlo simulation.
SFtools,2017-06-28,SFtools: Space Filling Based Tools for Data Mining,Contains space filling based tools for
    machine learning and data mining. Some functions offer
    several computational techniques and deal with the out of
    memory for large big data by using the ff package.
sparsio,2017-06-28,sparsio: I/O Operations with Sparse Matrices,Fast 'SVMlight' reader and writer. 
    'SVMlight' is most commonly used format for storing 
    sparse matrices (possibly with some target variable) on disk.
    For additional information about 'SVMlight' format see <http://svmlight.joachims.org/>.
FSTpackage,2017-06-27,FSTpackage: Unified Sequence-Based Association Tests Allowing for Multiple
Functional Annotation Scores,Functions for sequencing studies allowing for multiple functional annotation scores. Score type tests and an efficient perturbation method are used for individual gene/large gene-set/genome wide analysis. Only summary statistics are needed.
gmediation,2017-05-11,gmediation: Mediation Analysis for Multiple and Multi-Stage Mediators,Current version of this R package conducts mediation path analysis for multiple mediators in two stages.
NCSampling,2017-06-27,NCSampling: Nearest Centroid (NC) Sampling,Provides functionality for performing Nearest Centroid (NC) Sampling. The NC sampling procedure was developed for forestry applications and selects plots for ground measurement so as to maximize the efficiency of imputation estimates. It uses multiple auxiliary variables and multivariate clustering to search for an optimal sample. Further details are given in Melville G. & Stone C. (2016) <doi:10.1080/00049158.2016.1218265>. 
Opportunistic,2017-05-10,Opportunistic: Routing Distribution, Broadcasts, Transmissions and Receptions
in an Opportunistic Network,Computes the routing distribution, the expectation of the number of broadcasts, transmissions and receptions considering an Opportunistic transport model. It provides theoretical results and also estimated values based on Monte Carlo simulations.
otrimle,2016-10-05,otrimle: Robust Model-Based Clustering,Performs robust cluster analysis allowing for outliers and noise that cannot be fitted by any cluster. The data are modelled by a mixture of Gaussian distributions and a noise component, which is an improper uniform  distribution covering the whole Euclidean space. Parameters are estimated by  (pseudo) maximum likelihood. This is fitted by a EM-type algorithm. See Coretto and Hennig (2016) <doi:10.1080/01621459.2015.1100996>, and Coretto and Hennig (2017) <arXiv:1309.6895>.
BayesTwin,2017-06-26,BayesTwin: Bayesian Analysis of Item-Level Twin Data,Bayesian analysis of item-level hierarchical twin data using an integrated item response theory model. Analyses are based on Schwabe & van den Berg (2014) <doi:10.1007/s10519-014-9649-7>, Molenaar & Dolan (2014) <doi:10.1007/s10519-014-9647-9>, Schwabe, Jonker & van den Berg (2016) <doi:10.1007/s10519-015-9768-9> and Schwabe, Boomsma & van den Berg (2016) <doi:10.1016/j.lindif.2017.01.018>.
CRANsearcher,2017-06-26,CRANsearcher: RStudio Addin for Searching Packages in CRAN Database Based on
Keywords,One of the strengths of R is its vast package ecosystem. Indeed, R packages extend from visualization to Bayesian inference and from spatial analyses to pharmacokinetics (<https://cran.r-project.org/web/views/>). There is probably not an area of quantitative research that isn't represented by at least one R package. At the time of this writing, there are more than 10,000 active CRAN packages. Because of this massive ecosystem, it is important to have tools to search and learn about packages related to your personal R needs. For this reason, we developed an RStudio addin capable of searching available CRAN packages directly within RStudio.
intRvals,2017-06-26,intRvals: Analysis of Time-Ordered Event Data with Missed Observations,Calculates event rates and compares means and variances of groups of interval data corrected for missed arrival observations.
plater,2016-10-06,plater: Read, Tidy, and Display Data from Microtiter Plates,Tools for interacting with data from experiments done in microtiter
    plates. Easily read in plate-shaped data and convert it to tidy format, 
    combine plate-shaped data with tidy data, and view tidy data in plate shape.  
pltesim,2017-02-23,pltesim: Simulate Probabilistic Long-Term Effects in Models with Temporal
Dependence,Calculates and depicts probabilistic long-term effects
    in binary models with temporal dependence variables. The package performs
    two tasks. First, it calculates the change in the probability of the event
    occurring given a change in a theoretical variable. Second, it calculates
    the rolling difference in the future probability of the event for two
    scenarios: one where the event occurred at a given time and one where the
    event does not occur. The package is consistent with the recent movement to
    depict meaningful and easy-to-interpret quantities of interest with the
    requisite measures of uncertainty. It is the first to make it easy for
    researchers to interpret short- and long-term effects of explanatory
    variables in binary autoregressive models, which can have important
    implications for the correct interpretation of these models.
rattle.data,2017-06-26,rattle.data: Rattle Datasets,Contains the datasets used as default examples
  by the rattle package. The datasets themselves can be used
  independently of the rattle package to illustrate analytics,
  data mining, and data science tasks.
twfy,2017-06-26,twfy: Drive the API for TheyWorkForYou,An R wrapper around the API of TheyWorkForYou, a parliamentary 
    monitoring site that scrapes and repackages Hansard (the UK's parliamentary 
    record) and augments it with information from the Register of Members' 
    Interests, election results, and voting records to provide a unified 
    source of information about UK legislators and their activities. See 
    <http://www.theyworkforyou.com> for details.
net.security,2017-04-01,net.security: Security Standards Data Sets,Provides functions for security standards data management. It comes with data frames of 1000 observations for each security standard and updates are possible from official sources to build updated data sets.
tidygenomics,2017-06-25,tidygenomics: Tidy Verbs for Dealing with Genomic Data Frames,Handle genomic data within data frames just as you would with 'GRanges'.
    This packages provides method to deal with genomic intervals the "tidy-way" which makes
    it simpler to integrate in the the general data munging process. The API is inspired by the
    popular 'bedtools' and the genome_join() method from the 'fuzzyjoin' package.
DZEXPM,2017-06-24,DZEXPM: Estimation and Prediction of Skewed Spatial Processes,A collection of functions designed to estimate and predict skewed spatial processes, and a real data set.
MultiSkew,2017-06-12,MultiSkew: Measures, Tests and Removes Multivariate Skewness,Computes the third multivariate cumulant of either the raw, centered or standardized data. Computes the main measures of multivariate skewness, together with their bootstrap distributions. Finally, computes the least skewed linear projections of the data.
BCgee,2017-06-23,BCgee: Bias-Corrected Estimates for Generalized Linear Models for
Dependent Data,Provides bias-corrected estimates for the regression coefficients of a marginal model estimated with generalized estimating equations. Details about the bias formula used are in Lunardon, N., Scharfstein, D. (2017) <doi:10.1002/sim.7366>.
corset,2017-03-24,corset: Arbitrary Bounding of Series and Time Series Objects,Set of methods to constrain numerical series and time series within
             arbitrary boundaries.
JumpTest,2017-06-22,JumpTest: Financial Jump Detection,A fast simulation on stochastic volatility model, with jump tests, p-values pooling, and FDR adjustments.
m2r,2017-06-23,m2r: Macaulay2 in R,Persistent interface to Macaulay2 (<http://www.math.uiuc.edu/Macaulay2/>)
	and front-end tools facilitating its use in the R ecosystem.
mljar,2017-06-01,mljar: R API for MLJAR,Provides an R API wrapper for 'mljar.com', a web service allowing for on-line training for machine learning models (see <https://mljar.com> for more information).
nlsrk,2017-06-23,nlsrk: Runge-Kutta Solver for Function nls(),Performs univariate or multivariate computation of a single ODE or of a set of ODE (ordinary differential equations).
SCAT,2017-06-23,SCAT: Summary based Conditional Association Test,Conditional association test based on summary data from genome-wide association study (GWAS) adjusting for heterogeneity in SNP coverage.
MOQA,2017-06-22,MOQA: Basic Quality Data Assurance for Epidemiological Research,With the provision of several tools and templates the MOSAIC project (DFG-Grant Number HO 1937/2-1) supports the implementation of a central data management in epidemiological research projects. The 'MOQA' package enables epidemiologists with none or low experience in R to generate basic data quality reports for a wide range of application scenarios. See <https://mosaic-greifswald.de/> for more information. Please read and cite the corresponding open access publication (using the former package-name) in METHODS OF INFORMATION IN MEDICINE by M. Bialke, H. Rau, T. Schwaneberg, R. Walk, T. Bahls and W. Hoffmann (2017) <doi:10.3414/ME16-01-0123>. <https://methods.schattauer.de/en/contents/most-recent-articles/issue/2483/issue/special/manuscript/27573/show.html>.
rMouse,2017-06-22,rMouse: Automate Mouse Clicks and Send Keyboard Input,Provides wrapper functions to the Java Robot class to automate user input, like mouse movements, clicks and keyboard input.
rrcov3way,2017-06-22,rrcov3way: Robust Methods for Multiway Data Analysis, Applicable also for
Compositional Data,Provides methods for multiway data analysis by means of Parafac
    and Tucker 3 models. Robust versions (Engelen and Hubert (2011) <doi:10.1016/j.aca.2011.04.043>) and versions
    for compositional data are also provided (Gallo (2015) <doi:10.1080/03610926.2013.798664>, Di Palma et al. (in press)).
swapClass,2017-06-20,swapClass: A Null Model Adapted to Abundance Class Data in Ecology,A null model randomizing semi-quantitative multi-classes (or ordinal) data by swapping sub-matrices while both the row and the column marginal sums are held constant.
ftDK,2017-06-21,ftDK: A Wrapper for the API of the Danish Parliament,A wrapper for the API of the Danish Parliament. It makes it 
    possible to get data from the API easily into a data frame. Learn more at 
    <http://www.ft.dk/dokumenter/aabne_data>.
anchoredDistr,2017-06-15,anchoredDistr: Post-Processing for the Method of Anchored Distributions,Supplements the 'MAD#' software (see <http://mad.codeplex.com/>, 
    or Osorio-Murillo, et al. (2015) <doi:10.1016/j.envsoft.2015.01.002>) that
    implements the Method of Anchored Distributions for inferring geostatistical
    parameters (see Rubin, et al. (2010) <doi:10.1029/2009WR008799>). Reads 'MAD#' 
    result databases, performs dimension reduction on inversion data, calculates
    likelihoods and posteriors, and tests for convergence. Also generates plots 
    to summarize results.
mssqlR,2017-06-20,mssqlR: MSSQL Querying using R,Can be used to query data from data from Microsoft SQL Server (MSSQL, see <http://www.microsoft.com/sqlserver/> for more information). Based on the concepts of Entity Framework, the package allows querying data from MSSQL Database.
POMaSPU,2017-06-20,POMaSPU: Adaptive Association Tests for Multiple Phenotypes using
Proportional Odds Model (POM-aSPU),POM-aSPU test evaluates an association between an ordinal response and multiple phenotypes, for details see Kim and Pan (2017) <doi:10.1002/gepi.22033>.
rematch2,2017-06-20,rematch2: Tidy Output from Regular Expression Matching,Wrappers on 'regexpr' and 'gregexpr' to return the match
    results in tidy data frames.
RLeafAngle,2017-06-20,RLeafAngle: Estimates, Plots and Evaluates Leaf Angle Distribution
Functions, Calculates Extinction Coefficients,Leaf angle distribution is described by a number of functions
    (e.g. ellipsoidal, Beta and rotated ellipsoidal). The parameters of leaf angle
    distributions functions are estimated through different empirical relationship.
    This package includes estimations of parameters of different leaf angle
    distribution function, plots and evaluates leaf angle distribution functions,
    calculates extinction coefficients given leaf angle distribution.
    Reference: Wang(2007)<doi:10.1016/j.agrformet.2006.12.003>. 
taxizedb,2017-05-04,taxizedb: Tools for Working with 'Taxonomic' Databases,Tools for working with 'taxonomic' databases, including
    utilities for downloading databases, loading them into various
    'SQL' databases, cleaning up files, and providing a 'SQL' connection
    that can be used to do 'SQL' queries directly or used in 'dplyr'.
ukbabynames,2017-06-20,ukbabynames: UK Baby Names Data,Full listing of UK baby names occurring more than three times per year between 1996 and 2015, and rankings of baby name popularity by decade from 1904 to 1994.
clinPK,2017-06-19,clinPK: Clinical Pharmacokinetics Toolkit,Calculates equations commonly used in clinical pharmacokinetics and clinical pharmacology, such as equations for dose individualization, compartmental pharmacokinetics, drug exposure, anthropomorphic calculations, clinical chemistry, and conversion of common clinical parameters. Where possible and relevant, it provides multiple published and peer-reviewed equations within the respective R function.
namedCapture,2017-06-19,namedCapture: Named Capture Regular Expressions,User-friendly wrappers for 
 named capture regular expressions.
PeakError,2017-06-19,PeakError: Compute the Annotation Error of Peak Calls,Chromatin immunoprecipitation DNA sequencing results in genomic
    tracks that show enriched regions or peaks where proteins are bound.
    This package implements fast C code that computes the true and false
    positives with respect to a database of annotated regions.
sfadv,2017-06-19,sfadv: Advanced Methods for Stochastic Frontier Analysis,
 Stochastic frontier analysis with advanced methods.
 In particular, it applies the approach proposed by Latruffe et al. (2017) 
 <doi:10.1093/ajae/aaw077> to estimate a stochastic frontier with technical 
 inefficiency effects when one input is endogenous.
forecastSNSTS,2016-11-12,forecastSNSTS: Forecasting for Stationary and Non-Stationary Time Series,Methods to compute linear h-step ahead prediction coefficients based
    on localised and iterated Yule-Walker estimates and empirical mean squared
    and absolute prediction errors for the resulting predictors. Also, functions
    to compute autocovariances for AR(p) processes, to simulate tvARMA(p,q) time
    series, and to verify an assumption from Kley et al. (2017),
    Preprint <http://personal.lse.ac.uk/kley/forecastSNSTS.pdf>.
processmonitR,2017-06-18,processmonitR: Building Process Monitoring Dashboards,Functions for constructing dashboards for business process monitoring. Building on the event log objects class from package 'bupaR'. Allows the use to assemble custom shiny dashboards based on process data.
ECFsup,2017-06-17,ECFsup: Equal Covariance Functions Testing by L2-Norm and Sup-Norm,Testing the equality of several covariance functions of functional data. Four different methods are implemented: L2-norm with W-S naive, L2-norm with W-S bias-reduced, L2-norm (Zhang 2013) <ISBN:9781439862735>, and sup-norm with resampling (Guo et al. 2017) <arXiv:1609.04232>.
secret,2017-06-17,secret: Share Sensitive Information in R Packages,Allow sharing sensitive information, for example passwords,
    'API' keys, etc., in R packages, using public key cryptography.
CityWaterBalance,2017-06-16,CityWaterBalance: Track Flows of Water Through an Urban System,Retrieves data and estimates unmeasured flows of water through the 
  urban network. Any city may be modeled with preassembled data, but data for 
  US cities can be gathered via web services using this package and dependencies 
  'geoknife' and 'dataRetrieval'. 
phenopix,2017-06-15,phenopix: Process Digital Images of a Vegetation Cover,A collection of functions to process digital images, depict greenness index trajectories and extract relevant phenological stages. 
baseballDBR,2017-06-15,baseballDBR: Sabermetrics and Advanced Baseball Statistics,A tool for gathering and analyzing data from the Baseball Databank <http://www.baseball-databank.org/>, which includes player performance statistics from major league baseball in the United States beginning in the year 1871.
dataverse,2017-06-15,dataverse: Client for Dataverse 4 Repositories,Provides access to Dataverse version 4 APIs <https://dataverse.org/>, 
    enabling data search, retrieval, and deposit. For Dataverse versions <= 4.0, 
    use the deprecated 'dvn' package <https://cran.r-project.org/package=dvn>.
GeoRange,2017-06-15,GeoRange: Calculating Geographic Range from Occurrence Data,Calculates and analyzes six measures of geographic range from a set of longitudinal and latitudinal occurrence data. Measures included are minimum convex hull area, minimum spanning tree distance, longitudinal range, latitudinal range, maximum pairwise great circle distance, and number of X by X degree cells occupied.
mccr,2017-06-12,mccr: The Matthews Correlation Coefficient,The Matthews correlation coefficient (MCC) score is calculated (Matthews BW  (1975) <doi:10.1016/0005-2795(75)90109-9>).
pleiades,2016-12-20,pleiades: Interface to the 'Pleiades' 'Archeological' Database,Provides a set of functions for interacting with the
    'Pleiades' (<https://pleiades.stoa.org/>) 'API', including 
    getting status data, places data, and creating a 'GeoJSON' 
    based map on 'GitHub' 'gists'.
zooaRchGUI,2017-05-11,zooaRchGUI: Interactive Analytical Tools for Zooarchaeological Data,The analysis and inference of faunal remains recovered from
    archaeological sites concerns the field of zooarchaeology. The zooaRchGUI package
    provides a graphical user interface to analytical tools found in the R statistical environment
    to make inferences on zooarchaeological data. Functions in this package allow users to interactively
    read, manipulate, visualize, and analyze zooarchaeological data.
nscprepr,2017-06-13,nscprepr: Prepares and Writes Files to Submit to the National Student
Clearinghouse,Prepares and writes files to submit to the National Student Clearinghouse's 
  StudentTracker service <http://www.studentclearinghouse.org/colleges/studenttracker/>.
ZIBseq,2017-04-24,ZIBseq: Differential Abundance Analysis for Metagenomic Data via
Zero-Inflated Beta Regression,Detects abundance differences across clinical conditions. Besides, it takes the sparse nature of metagenomic data into account and handles compositional data efficiently.
d3Tree,2017-04-02,d3Tree: Create Interactive Collapsible Trees with the JavaScript 'D3'
Library,Create and customize interactive collapsible 'D3' trees using the 'D3'
    JavaScript library and the 'htmlwidgets' package. These trees can be used
    directly from the R console, from 'RStudio', in Shiny apps and R Markdown documents.
    When in Shiny the tree layout is observed by the server and can be used as a reactive filter
    of structured data.
argon2,2017-06-12,argon2: Secure Password Hashing,Utilities for secure password hashing via the argon2 algorithm.
    It is a relatively new hashing algorithm and is believed to be very secure.
    The 'argon2' implementation included in the package is the reference
    implementation.  The package also includes some utilities that should be
    useful for digest authentication, including a wrapper of 'blake2b'.  For
    similar R packages, see sodium and 'bcrypt'.  See
    <https://en.wikipedia.org/wiki/Argon2> or
    <https://eprint.iacr.org/2015/430.pdf> for more information.
patternator,2017-06-12,patternator: Feature Extraction from Female Brown Anole Lizard Dorsal
Patterns,Provides a set of functions to efficiently recognize and clean the continuous dorsal pattern of a female brown anole lizard (Anolis sagrei) traced from 'ImageJ', an open platform for scientific image analysis (see <https://imagej.net> for more information), and extract common features such as the pattern sinuosity indices, coefficient of variation, and max-min width.
SanFranBeachWater,2017-06-12,SanFranBeachWater: Downloads and Tidies the San Francisco Public Utilities
Commission Beach Water Quality Monitoring Program Data,
    Downloads and tidies the San Francisco Public Utilities Commission Beach Water Quality Monitoring Program data. Data sets can be downloaded per beach, or the raw data can be downloaded. See <https://sfwater.org/cfapps/lims/beachmain1.cfm>.
standardize,2017-04-04,standardize: Tools for Standardizing Variables for Regression in R,Tools which allow regression variables to be placed on similar
    scales, offering computational benefits as well as easing interpretation of
    regression output.
featurizer,2017-06-11,featurizer: Some Helper Functions that Help Create Features from Data,A collection of functions that would help one to build features based on external data. Very useful for Data Scientists in data to day work. Many functions create features using parallel computation. Since the nitty gritty of parallel computation is hidden under the hood, the user need not worry about creating clusters and shutting them down.
orderstats,2017-06-11,orderstats: Efficiently Generates Random Order Statistic Variables,All the methods in this package generate a vector of uniform order statistics using a beta distribution and use an inverse cumulative distribution function for some distribution to give a vector of random order statistic variables for some distribution. This is much more efficient than using a loop since it is directly sampling from the order statistic distribution.
colorpatch,2017-06-10,colorpatch: Optimized Rendering of Fold Changes and Confidence Values,Shows color patches for encoding fold changes (e.g. log ratios) together with confidence values 
    within a single diagram. This is especially useful for rendering gene expression data as well as
    other types of differential experiments. In addition to different rendering methods (ggplot extensions)
    functionality for perceptually optimizing color palettes are provided.
    Furthermore the package provides extension methods of the colorspace color-class in order to
    simplify the work with palettes (a.o. length, as.list, and append are supported).
soptdmaeA,2017-06-10,soptdmaeA: Sequential Optimal Designs for Two-Colour cDNA Microarray
Experiments,Computes sequential A-, MV-, D- and E-optimal or near-optimal block and row-column designs for two-colour cDNA microarray experiments using the linear fixed effects and mixed effects models where the interest is in a comparison of all possible elementary treatment contrasts. The package also provides an optional method of using the graphical user interface (GUI) R package 'tcltk' to ensure that it is user friendly.
frequencies,2017-06-08,frequencies: Create Frequency Tables with Counts and Rates,Provides functions to create frequency tables which display both counts
    and rates.
getmstatistic,2017-06-06,getmstatistic: Quantifying Systematic Heterogeneity in Meta-Analysis,Quantifying systematic heterogeneity in meta-analysis using R.
    The M statistic aggregates heterogeneity information across multiple
    variants to, identify systematic heterogeneity patterns and their direction
    of effect in meta-analysis. It's primary use is to identify outlier studies,
    which either show "null" effects or consistently show stronger or weaker
    genetic effects than average across, the panel of variants examined in a
    GWAS meta-analysis. In contrast to conventional heterogeneity metrics
    (Q-statistic, I-squared and tau-squared) which measure random heterogeneity
    at individual variants, M measures systematic (non-random)
    heterogeneity across multiple independently associated variants. Systematic
    heterogeneity can arise in a meta-analysis due to differences in the study
    characteristics of participating studies. Some of the differences may
    include: ancestry, allele frequencies, phenotype definition, age-of-disease
    onset, family-history, gender, linkage disequilibrium and quality control
    thresholds. See <https://magosil86.github.io/getmstatistic/> for statistical
    statistical theory, documentation and examples.
mixEMM,2017-06-08,mixEMM: A Mixed-Effects Model for Analyzing Cluster-Level Non-Ignorable
Missing Data,Contains functions for estimating a mixed-effects model for
             clustered data (or batch-processed data) with cluster-level (or batch-
             level) missing values in the outcome, i.e., the outcomes of some 
             clusters are either all observed or missing altogether. The model is 
             developed for analyzing incomplete data from labeling-based quantitative 
             proteomics experiments but is not limited to this type of data. 
             We used an expectation conditional maximization (ECM) algorithm for model 
             estimation. The cluster-level missingness may depend on the average 
             value of the outcome in the cluster (missing not at random).
Risk,2017-06-08,Risk: Computes 26 Financial Risk Measures for Any Continuous
Distribution,Computes 26 financial risk measures for any continuous distribution.  The 26 financial risk measures  include value at risk, expected shortfall due to Artzner et al. (1999) <doi:10.1007/s10957-011-9968-2>, tail conditional median due to Kou et al. (2013) <doi:10.1287/moor.1120.0577>, expectiles due to Newey and Powell (1987) <doi:10.2307/1911031>, beyond value at risk due to Longin (2001) <doi:10.3905/jod.2001.319161>, expected proportional shortfall due to Belzunce et al. (2012) <doi:10.1016/j.insmatheco.2012.05.003>, elementary risk measure due to Ahmadi-Javid (2012) <doi:10.1007/s10957-011-9968-2>, omega due to Shadwick and Keating (2002), sortino ratio due to Rollinger and Hoffman (2013), kappa  due to Kaplan and Knowles  (2004), Wang (1998)'s <doi:10.1080/10920277.1998.10595708> risk measures, Stone (1973)'s <doi:10.2307/2978638> risk measures, Luce (1980)'s <doi:10.1007/BF00135033> risk measures, Sarin (1987)'s <doi:10.1007/BF00126387> risk measures, Bronshtein and Kurelenkova (2009)'s risk measures.
xsp,2017-06-08,xsp: The Chi-Square Periodogram,The circadian period of a time series data is predicted and the statistical significance of the periodicity are calculated using the chi-square periodogram.
gqlr,2017-06-07,gqlr: 'GraphQL' Server in R,Server implementation of 'GraphQL' <http://facebook.github.io/graphql/>,
    a query language created by Facebook for describing data requirements on complex application
    data models.  Visit <http://graphql.org> to learn more about 'GraphQL'.
iNOTE,2017-06-07,iNOTE: Integrative Network Omnibus Total Effect Test,Integrated joint analysis of multiple platform genomic data across biological gene sets or pathways using powerful variance-component based testing procedures.
BAYESDEF,2017-06-06,BAYESDEF: Bayesian Analysis of DSD,Definitive Screening Designs are a class of experimental designs that under factor sparsity have the potential to estimate linear, quadratic and interaction effects with little experimental effort. BAYESDEF is a package that performs a five step strategy to analyze this kind of experiments that makes use of tools coming from the Bayesian approach. It also includes the least absolute shrinkage and selection operator (lasso) as a check (Aguirre VM. (2016) <doi:10.1002/asmb.2160>).
bdlp,2017-06-06,bdlp: Transparent and Reproducible Artificial Data Generation,The main function generateDataset() processes a user-supplied .R file that 
  contains metadata parameters in order to generate actual data. The metadata parameters 
  have to be structured in the form of metadata objects, the format of which is 
  outlined in the package vignette. This approach allows to generate artificial data 
  in a transparent and reproducible manner.
covfefe,2017-06-06,covfefe: Covfefy Any Word, Sentence or Speech,Converts any word, sentence or speech into Trump's infamous
  "covfefe" format. Reference: <https://www.nytimes.com/2017/05/31/us/politics/covfefe-trump-twitter.html>.
  Inspiration thanks to: <https://codegolf.stackexchange.com/questions/123685/covfefify-a-string>.
gamlssbssn,2017-06-06,gamlssbssn: Bimodal Skew Symmetric Normal Distribution,Density, distribution function, quantile function and random generation for the bimodal skew symmetric normal distribution of Hassan and El-Bassiouni (2016) <doi:10.1080/03610926.2014.882950>.
gghalfnorm,2016-12-31,gghalfnorm: Create a Half Normal Plot Using 'ggplot2',Reproduce the halfnorm() function found in the 'faraway' package 
    using the 'ggplot2' API.
HDCI,2017-06-06,HDCI: High Dimensional Confidence Interval Based on Lasso and
Bootstrap,Fits regression models on high dimensional data to estimate coefficients and use bootstrap method to obtain confidence intervals. Choices for regression models are Lasso, Lasso+OLS, Lasso partial ridge, Lasso+OLS partial ridge. 
iadf,2017-06-06,iadf: Analysis of Intra Annual Density Fluctuations,Calculate false ring proportions from data frames of intra annual 
  density fluctuations.
piton,2017-05-28,piton: Parsing Expression Grammars in Rcpp,A wrapper around the 'Parsing Expression Grammar Template Library', a C++11 library for generating
    Parsing Expression Grammars, that makes it accessible within Rcpp. With this, developers can implement
    their own grammars and easily expose them in R packages.
pwrAB,2017-06-06,pwrAB: Power Analysis for AB Testing,Power analysis for AB testing. The calculations are based on the Welch's unequal variances t-test,
  which is generally preferred over the Student's t-test when sample sizes and variances of the two groups are
  unequal, which is frequently the case in AB testing. In such situations, the Student's t-test will give 
  biased results due to using the pooled standard deviation, unlike the Welch's t-test.
rpst,2017-06-06,rpst: Recursive Partitioning Survival Trees,An implementation of Recursive Partitioning Survival Trees via a node-splitting rule that builds decision tree models that reflected within-node and within-treatment responses. The algorithm aims to find the maximal difference in survival time among different treatments.
themetagenomics,2017-06-06,themetagenomics: Exploring Thematic Structure and Predicted Functionality of 16s
rRNA Amplicon Data,A means to explore the structure of 16S rRNA surveys using a Structural 
  Topic Model coupled with functional prediction. The user provides an abundance 
  table, sample metadata, and taxonomy information, and themetagenomics infers 
  associations between topics and sample features, as well as topics and predicted 
  functional content. Functional prediction can be accomplished via Tax4Fun (for 
  Silva references) and PICRUSt (for GreenGeenes references).
zstdr,2017-06-02,zstdr: R Bindings to the 'Zstandard' Compression Library,Provides R bindings to the 'Zstandard' compression library.
    'Zstandard' is a real-time compression algorithm, providing high compression ratios.
    It offers a very wide range of compression / speed trade-off, while being backed by a very fast decoder.
    See <http://facebook.github.io/zstd/> for more information.
capn,2017-06-05,capn: Capital Asset Pricing for Nature,Implements approximation methods for natural capital asset prices suggested by Fenichel and Abbott (2014) <doi:10.1086/676034> in Journal of the Associations of Environmental and Resource Economists (JAERE), Fenichel et al. (2016) <doi:10.1073/pnas.1513779113> in Proceedings of the National Academy of Sciences (PNAS), and Yun et al. (2017) in PNAS (accepted), and their extensions: creating Chebyshev polynomial nodes and grids, calculating basis of Chebyshev polynomials, approximation and their simulations for: V-approximation (single and multiple stocks, PNAS), P-approximation (single stock, PNAS), and Pdot-approximation (single stock, JAERE). Development of this package was generously supported by the Knobloch Family Foundation.
imaginator,2017-06-05,imaginator: Simulate General Insurance Policies and Losses,Simulate general insurance policies, losses and loss emergence. The package contemplates 
  deterministic and stochastic policy retention and growth scenarios. Retention and growth rates are percentages relative
  to the expiring portfolio. Claims are simulated for each policy. This is accomplished either be assuming a frequency
  distribution per development lag or by generating random wait times until claim emergence and settlement. Loss simulation 
  uses standard loss distributions for claim amounts.
ck37r,2017-06-03,ck37r: Chris Kennedy's R Toolkit,Toolkit for statistical, machine learning, and targeted learning
  analyses. Functionality includes loading & auto-installing packages,
  standardizing datasets, creating missingness indicators, imputing missing
  values, creating multicore or multinode clusters, automatic SLURM integration,
  enhancing SuperLearner and TMLE with automatic parallelization, and many other
  SuperLearner analysis & plotting enhancements.
eesim,2017-06-03,eesim: Simulate and Evaluate Time Series for Environmental Epidemiology,Provides functions to create simulated time series of environmental
    exposures (e.g., temperature, air pollution) and health outcomes for use in
    power analysis and simulation studies in environmental epidemiology. This
    package also provides functions to evaluate the results of simulation studies
    based on these simulated time series. This work was supported by a grant
    from the National Institute of Environmental Health Sciences (R00ES022631) and
    a fellowship from the Colorado State University Programs for Research and
    Scholarly Excellence.
glmertree,2017-06-03,glmertree: Generalized Linear Mixed Model Trees,Recursive partitioning based on (generalized) linear mixed models
    (GLMMs) combining lmer()/glmer() from lme4 and lmtree()/glmtree() from partykit.
KRMM,2017-06-03,KRMM: Kernel Ridge Mixed Model,Solves kernel ridge regression, within the the mixed model framework, for the linear, polynomial, Gaussian, Laplacian and ANOVA kernels. The model components (i.e. fixed and random effects) and variance parameters are estimated using the expectation-maximization (EM) algorithm. All the estimated components and parameters, e.g. BLUP of dual variables and BLUP of random predictor effects for the linear kernel (also known as RR-BLUP), are available. The kernel ridge mixed model (KRMM) is described in Jacquin L, Cao T-V and Ahmadi N (2016) A Unified and Comprehensible View of Parametric and Kernel Methods for Genomic Prediction with Application to Rice. Front. Genet. 7:145. <doi:10.3389/fgene.2016.00145>.
NB.MClust,2017-05-03,NB.MClust: Negative Binomial Model-Based Clustering,Model-based clustering of high-dimensional non-negative
             data that follow Generalized Negative Binomial distribution. All functions 
             in this package applies to either continuous or integer data. Correlation
            between variables are allowed, while samples are assumed to be independent.
hypersampleplan,2017-06-02,hypersampleplan: Attribute Sampling Plan with Exact Hypergeometric Probabilities
using Chebyshev Polynomials,Implements an algorithm for efficient and exact calculation of hypergeometric 
    and binomial probabilities using Chebyshev polynomials, while other algorithm use an 
    approximation when N is large. A useful applications is also considered in this package 
    for the construction of attribute sampling plans which is an important field of statistical
    quality control. The quantile, and the confidence limit for the attribute sampling plan are
    also implemented in this package. The hypergeometric distribution can be represented in 
    terms of Chebyshev polynomials. This representation is particularly useful in the calculation
    of exact values of hypergeometric variables. 
logOfGamma,2017-06-02,logOfGamma: Natural Logarithms of the Gamma Function for Large Values,Uses approximations to compute the natural logarithm of the Gamma
    function for large values.
webglobe,2017-06-02,webglobe: 3D Interactive Globes,Displays geospatial data on an interactive 3D globe in the web browser.
kerasR,2017-03-20,kerasR: R Interface to the Keras Deep Learning Library,Provides a consistent interface to the 'Keras' Deep Learning Library
  directly from within R. 'Keras' provides specifications for describing dense
  neural networks, convolution neural networks (CNN) and recurrent neural networks
  (RNN) running on top of either 'TensorFlow' or 'Theano'. Type conversions between
  Python and R are automatically handled correctly, even when the default
  choices would otherwise lead to errors. Includes complete R documentation
  and many working examples.
QPBoot,2017-06-01,QPBoot: Model Validation using Quantile Spectral Analysis and Parametric
Bootstrap,Provides functionality for model validation by computing a
    parametric bootstrap and comparing the Quantile Spectral Densities.
baitmet,2017-01-14,baitmet: Library Driven Compound Profiling in Gas Chromatography - Mass
Spectrometry Data,Automated quantification of metabolites by targeting mass spectral/retention time libraries into full scan-acquired gas chromatography - mass spectrometry (GC-MS) chromatograms. Baitmet outputs a table with compounds name, spectral matching score, retention index error, and compounds area in each sample. Baitmet can automatically determine the compounds retention indexes with or without co-injection of internal standards with samples.
difconet,2017-05-31,difconet: Differential Coexpressed Networks,Estimation of DIFferential COexpressed NETworks using diverse and user metrics.
			 This package is basically used for three functions related to the estimation
			 of differential coexpression. 
			 First, to estimate differential coexpression where
			 the coexpression is estimated, by default, by Spearman correlation. For this,
			 a metric to compare two correlation distributions is needed. The package includes
			 6 metrics. Some of them needs a threshold. A new metric can also be specified as
			 a user function with specific parameters (see difconet.run). The significance is
			 be estimated by permutations.
			 Second, to generate datasets with controlled differential correlation data. This 
			 is done by either adding noise, or adding specific correlation structure.
			 Third, to show the results of differential correlation analyses. Please see
			 <http://bioinformatica.mty.itesm.mx/difconet> for further information.
ElastH,2017-05-28,ElastH: Replicar metodologia de SPE/MF para calculo de elasticidade de
receita,O pacote desponibiliza funções para estimar modelos de componentes 
  não observados e determinar intervenções automaticamente. Com especial
  atenção para a replicação dos modelos utilizados na metodologia de calculo
  do resultado estrutural da SPE/MF.
  The package provides simple ways to estimates general unobserved components models
  and automatically detects intervenctions. It is specially useful to
  replicate Brazilian Ministry of Finance methodology to estimate income-output gap
  elasticities.
ids,2016-11-04,ids: Generate Random Identifiers,Generate random or human readable and pronounceable identifiers.
ImaginR,2017-05-31,ImaginR: Delimit and Characterize Color Phenotype of the Pearl Oyster,The pearl oyster, Pinctada margaritifera (Linnaeus, 1758), represents the second economic resource of French Polynesia. It is one of the only bivalves expressing a large varied range of inner shell color, & by correlation, of pearl color. This phenotypic variability is partly under genetic control, but also under environmental influence. With ImaginR, it's now possible to delimit the color phenotype of the pearl oyster's inner shell and to characterize their color variations (by the HSV color code system) with pictures.
logistic4p,2017-05-31,logistic4p: Logistic Regression with Misclassification in Dependent
Variables,Error in a binary dependent variable, also known as misclassification, has not drawn much attention in psychology. Ignoring misclassification in logistic regression can result in misleading parameter estimates and statistical inference. This package conducts logistic regression analysis with misspecification in outcome variables. 
pencopulaCond,2017-05-31,pencopulaCond: Estimating Non-Simplified Vine Copulas Using Penalized Splines,Estimating Non-Simplified Vine Copulas Using Penalized Splines.
mdpeer,2016-11-25,mdpeer: Graph-Constrained Regression with Enhanced Regularization
Parameters Selection,Provides graph-constrained regression methods in which
    regularization parameters are selected automatically via estimation of
    equivalent Linear Mixed Model formulation. 'riPEER' (ridgified Partially
    Empirical Eigenvectors for Regression) method employs a penalty term being
    a linear combination of graph-originated and ridge-originated penalty terms,
    whose two regularization parameters are ML estimators from corresponding
    Linear Mixed Model solution; a graph-originated penalty term allows imposing
    similarity between coefficients based on graph information given whereas
    additional ridge-originated penalty term facilitates parameters estimation:
    it reduces computational issues arising from singularity in a graph-originated
    penalty matrix and yields plausible results in situations when graph information
    is not informative. 'riPEERc' (ridgified Partially Empirical Eigenvectors
    for Regression with constant) method utilizes addition of a diagonal matrix
    multiplied by a predefined (small) scalar to handle the non-invertibility of
    a graph Laplacian matrix. 'vrPEER' (variable reducted PEER) method performs
    variable-reduction procedure to handle the non-invertibility of a graph
    Laplacian matrix.
DDM,2017-05-29,DDM: Death Registration Coverage Estimation,A set of three two-census methods to the estimate the degree of death registration coverage for a population. Implemented methods include the Generalized Growth Balance method (GGB), the Synthetic Extinct Generation method (SEG), and a hybrid of the two, GGB-SEG. Each method offers automatic estimation, but users may also specify exact parameters or use a graphical interface to guess parameters in the traditional way if desired.
dfCompare,2017-05-29,dfCompare: Compare Two Dataframes and Return Adds, Changes, and Deletes,Compares two dataframes with a common key
            and returns the delta records. The package will return
            three dataframes that contain the added, changed,
            and deleted records.
phrasemachine,2016-10-24,phrasemachine: Simple Phrase Extraction,Simple noun phrase extraction using part-of-speech information.
    Takes a collection of un-processed documents as input and returns a set of noun
    phrases associated with those documents.
here,2017-05-28,here: A Simpler Way to Find Your Files,Constructs paths to your project's files.
    The 'here()' function uses a reasonable heuristics to find your project's
    files, based on the current working directory at the time when the package
    is loaded. Use it as a drop-in replacement for 'file.path()', it will always
    locate the files relative to your project root.
SmartSVA,2016-11-13,SmartSVA: Fast and Robust Surrogate Variable Analysis,Introduces a fast and efficient Surrogate Variable Analysis algorithm that captures variation of unknown sources (batch effects) for high-dimensional data sets. The algorithm is built on the 'irwsva.build' function of the 'sva' package and proposes a revision on it that achieves an order of magnitude faster running time while trading no accuracy loss in return.
didrooRFM,2017-05-27,didrooRFM: Compute Recency Frequency Monetary Scores for your Customer Data,This hosts the findRFM function which generates RFM scores on a 1-5 point scale for
             customer transaction data. The function consumes a data frame with Transaction Number,
             Customer ID, Date of Purchase (in date format) and Amount of Purchase as the attributes.
             The function returns a data frame with RFM data for the sales information.
polypoly,2017-05-27,polypoly: Helper Functions for Orthogonal Polynomials,Tools for reshaping, plotting, and manipulating matrices of orthogonal polynomials.
SeerMapper,2017-05-27,SeerMapper: A Quick Way to Map U.S. Rates and Data of U. S. States,
Counties, Census Tracts, or Seer Registries using 2000 and 2010
U. S. Census Boundaries,Provides an easy way to map seer registry area rate data on a U. S, map.  
   The U. S. data may be mapped at the state, U. S. NCI Seer Register, state/county 
   or census tract level. The function can categorize the data into "n" quantiles, where "n" is 3 to 11 or
   the caller can specify a cut point list for the categorizes.  
   The caller can also provide the data and the comparison operation to request
   hatching over any areas.  The default operation and value are > 0.05 (p-values).
   The location id provided in the data determines the geographic level of the mapping.
   If states, state/counties or census tracts are being mapped, the location ids 
   used must be the U.S. FIPS codes for states (2 digits), state/counties (5 digits)
   or state/county/census tracts (11 digits). If the location id references the U.S. Seer Registry 
   areas, the Seer Registry area identifier used to link the data to the geographical 
   areas, then the location id is the Seer Registry name or abbreviation.
   Additional parameters are used to provide control over the drawing of the boundaries
   at the data's boundary level and higher levels.
   The package uses modified boundary data from the 2000 and 2010 U. S. Census to reduce the 
   storage requirements and improve drawing speed.  
   The 'SeerMapper' package contains the U. S. Census 2000 and 2010 boundary data
   for the regional, state, Seer Registry, and county levels.  Six supplement packages 
   contain the census tract boundary data (see manual for more details.)
stratvns,2017-05-27,stratvns: Optimal Stratification in Stratified Sampling Optimization
Algorithm,An Optimization Algorithm Applied
  to stratification Problem.
  It is aims to delimit the population strata
  and defining the allocation of sample,considering
  the following objective: minimize the sample size given
  a fixed precision level. Exhaustive enumeration method
  is applied in small problems, while in problems with greater
  complexity the algorithm is based on metaheuristic Variable
  Neighborhood Decomposition Search with Path Relink.
CharFun,2017-05-26,CharFun: Numerical Computation Cumulative Distribution Function and
Probability Density Function from Characteristic Function,The Characteristic Functions Toolbox (CharFun) consists of a set of algorithms for evaluating selected characteristic functions and algorithms for numerical inversion of the (combined and/or compound) characteristic functions, used to evaluate the probability density function (PDF) and the cumulative distribution function (CDF).
stratbr,2017-05-11,stratbr: Optimal Stratification in Stratified Sampling,An Optimization Algorithm Applied to
    Stratification Problem.This function aims
    at constructing optimal strata with an optimization algorithm
    based on a global optimisation technique called Biased
    Random Key Genetic Algorithms.
tictactoe,2016-12-28,tictactoe: Tic-Tac-Toe Game,
  Implements tic-tac-toe game to play on console, either with human or AI players.
  Various levels of AI players are trained through the Q-learning algorithm.
apng,2017-05-25,apng: Convert Png Files into Animated Png,Convert several png files into an animated png file.
  This package exports only a single function ‘apng’. Call the
  apng function with a vector of file names (which should be
  png files) to convert them to a single animated png file.
rdoxygen,2017-05-25,rdoxygen: Create Doxygen Documentation for Source Code,Create doxygen documentation for source code in R packages. 
  Includes a RStudio Addin, that allows to trigger the doxygenize process.
timelineR,2017-05-25,timelineR: Visualization for Time Series Data,Helps to visualize multi-variate time-series having numeric and factor variables.
    You can use the package for visual analysis of data by plotting the data for each variable in the desired order and study
    interaction between a factor and a numeric variable by creating overlapping plots.
TriadSim,2017-05-13,TriadSim: Simulating Triad Genomewide Genotypes,Simulate genotypes for case-parent triads, case-control, and quantitative trait samples with realistic linkage diequilibrium structure and allele frequency distribution. For studies of epistasis one can simulate models that involve specific SNPs at specific sets of loci, which we will refer to as "pathways". TriadSim generates genotype data by resampling triad genotypes from existing data. The details of the method is described in the manuscript under preparation "Simulating Autosomal Genotypes with Realistic Linkage Disequilibrium and a Spiked in Genetic Effect" Shi, M., Umbach, D.M., Wise A.S., Weinberg, C.R. 	
lans2r,2017-05-24,lans2r: Work with Look at NanoSIMS Data in R,R interface for working with nanometer scale secondary ion mass 
    spectrometry (NanoSIMS) data exported from Look at NanoSIMS. 
wally,2017-05-17,wally: The Wally Calibration Plot for Risk Prediction Models,A prediction model is calibrated if, roughly, for any percentage x we can expect that x subjects out of 100 experience the event among all subjects that have a predicted risk of x%. A calibration plot provides a simple, yet useful, way of assessing the calibration assumption. The Wally plot consists of a sequence of usual calibration plots. Among the plots contained within the sequence, one is the actual calibration plot which has been obtained from the data and the others are obtained from similar simulated data under the calibration assumption. It provides the investigator with a direct visual understanding of the shape and sampling variability that are common under the calibration assumption. The original calibration plot from the data is included randomly among the simulated calibration plots, similarly to a police lineup. If the original calibration plot is not easily identified then the calibration assumption is not contradicted by the data. The method handles the common situations in which the data contain censored observations and occurrences of competing events.
RHPCBenchmark,2017-05-23,RHPCBenchmark: Benchmarks for High-Performance Computing Environments,Microbenchmarks for determining the run time
  performance of aspects of the R programming environment and packages
  relevant to high-performance computation.  The benchmarks are divided into
  three categories: dense matrix linear algebra kernels, sparse matrix linear
  algebra kernels, and machine learning functionality.
RNAstructureModuleMiner,2017-05-23,RNAstructureModuleMiner: RNA Secondary Structure Comparison and Module Mining,Functions in this program is designed for RNA secondary structure plotting, comparison and module mining. Given a RNA secondary structure, you can obtain stem regions, hairpin loops, internal loops, bulge loops and multibranch loops of this RNA structure using this program. They are the basic modules of RNA secondary structure. For each module you get, you can use this program to label the RNA structure with a specific color. You can also use this program to compare two RNA secondary structures to get a score that represents similarity.
ROI.models.miplib,2017-05-23,ROI.models.miplib: R Optimization Infrastructure: 'MIPLIB' 2010 Benchmark Instances,The mixed integer programming library 'MIPLIB' (see <http://miplib.zib.de/>) 
	is commonly used to compare the performance of mixed integer optimization solvers.
	This package provides functions to access 'MIPLIB' from the 
	'R' Optimization Infrastructure ('ROI'). More information about 'MIPLIB'
	can be found in the paper by Koch et al. available at
	<http://mpc.zib.de/index.php/MPC/article/viewFile/56/28>.
	The 'README.md' file illustrates how to use this package.
rpatrec,2017-04-20,rpatrec: Recognising Visual Charting Patterns in Time Series Data,Generating visual charting patterns and noise,
    smoothing to find a signal in noisy time series and enabling
    users to apply their findings to real life data.
xLLiM,2016-12-05,xLLiM: High Dimensional Locally-Linear Mapping,Provides a tool for non linear mapping (non linear regression) using a mixture of regression model and an inverse regression strategy. The methods include the GLLiM model (see Deleforge et al (2015) <doi:10.1007/s11222-014-9461-5>) based on Gaussian mixtures and a robust version of GLLiM, named SLLiM (see Perthame et al (2016) <https://hal.archives-ouvertes.fr/hal-01347455>) based on a mixture of Generalized Student distributions. The methods also include BLLiM (see Devijver et al (2017) <https://arxiv.org/abs/1701.07899>) which is an extension of GLLiM with a sparse block diagonal structure for large covariance matrices (particularly interesting for transcriptomic data).
Rd2md,2017-05-22,Rd2md: Markdown Reference Manuals,The native R functionalities only allow PDF exports of reference manuals. This shall be extended by converting the package documentation files into markdown files and combining them into a markdown version of the package reference manual.
sotu,2017-05-22,sotu: United States Presidential State of the Union Addresses,The President of the United States is constitutionally obligated to provide
  a report known as the 'State of the Union'. The report summarizes the current challenges
  facing the country and the president's upcoming legislative agenda. While historically
  the State of the Union was often a written document, in recent decades it has always
  taken the form of an oral address to a joint session of the United States Congress.
  This package provides the raw text from every such address with the intention of
  being used for meaningful examples of text analysis in R. The corpus is well suited
  to the task as it is historically important, includes material intended to be read
  and material intended to be spoken, and it falls in the public domain. As the corpus
  spans over two centuries it is also a good test of how well various methods hold up
  to the idiosyncrasies of historical texts. Associated data about each address, such
  as the year, president, party, and format, are also included.
NPMOD,2017-05-21,NPMOD: Non Parametric Module,Non-Parametric Module (NPMOD) is a graphical interface dedicated to the testing of non-parametric data for educational purposes.
AHMbook,2017-04-20,AHMbook: Functions and Data for the Book 'Applied Hierarchical Modeling
in Ecology',Provides functions and data sets to accompany the book 'Applied Hierarchical Modeling in Ecology: Analysis of distribution, abundance and species richness in R and BUGS' by Marc Kery and Andy Royle. The first volume appeared early in 2016 (ISBN: 978-0-12-801378-6, <https://www.mbr-pwrc.usgs.gov/pubanalysis/keryroylebook>); the second volume is in  preparation and additional functions will be added to this package.
CATT,2017-02-22,CATT: The Cochran-Armitage Trend Test,This function conducts the Cochran-Armitage trend test to a 2 by k contingency table. It will report the test statistic (Z) and p-value.A linear trend in the frequencies will be calculated, because the weights (0,1,2) will be used by default. 
checkarg,2017-05-19,checkarg: Check the Basic Validity of a (Function) Argument,Utility functions that allow checking the basic validity of a function argument or any other value, 
             including generating an error and assigning a default in a single line of code. The main purpose of
             the package is to provide simple and easily readable argument checking to improve code robustness. 
kdevine,2017-01-14,kdevine: Multivariate Kernel Density Estimation with Vine Copulas,Implements the vine copula based kernel density estimator of
    Nagler and Czado (2016) <doi:10.1016/j.jmva.2016.07.003>. The estimator does
    not suffer from the curse of dimensionality and is therefore well suited for
    high-dimensional applications.
numKM,2017-05-19,numKM: Create a Kaplan-Meier Plot with Numbers at Risk,To add the table of numbers at risk below the Kaplan-Meier plot.
poisbinom,2017-05-16,poisbinom: A Faster Implementation of the Poisson-Binomial Distribution,Provides the probability, distribution, and quantile functions and random number generator for the Poisson-Binomial distribution.  This package relies on FFTW to implement the discrete Fourier transform, so that it is much faster than the existing implementation of the same algorithm in R.
printr,2017-05-19,printr: Automatically Print R Objects to Appropriate Formats According
to the 'knitr' Output Format,Extends the S3 generic function knit_print() in 'knitr'
    to automatically print some objects using an appropriate format such as
    Markdown or LaTeX. For example, data frames are automatically printed as
    tables, and the help() pages can also be rendered in 'knitr' documents.
GUIgems,2017-05-18,GUIgems: Graphical User Interface for Generalized Multistate Simulation
Model,A graphical user interface for the R package Gems.  
    Apart from the functionality of Gems package in the Graphical User interface, GUIgems
    allows adding states to a defined model, merging states for the analysis and plotting 
    progression paths between states based on the simulated cohort.
    There is also a module in the GUIgems which allows to compare costs and QALYs between different cohorts.
easyNCDF,2017-04-08,easyNCDF: Tools to Easily Read/Write NetCDF Files into/from
Multidimensional R Arrays,Set of wrappers for the 'ncdf4' package to simplify and extend its reading/writing capabilities into/from multidimensional R arrays.
zeligverse,2017-05-05,zeligverse: Easily Install and Load Stable Zelig Packages,Provides an easy way to load stable Core Zelig and ancillary Zelig
    packages.
ExcessMass,2017-05-16,ExcessMass: Excess Mass Calculation and Plots,Implementation of a function which calculates the empirical excess mass 
	for given \eqn{\lambda} and given maximal number of modes (excessm()). Offering 
	powerful plot features to visualize empirical excess mass (exmplot()). This 
	includes the possibility of drawing several plots (with different maximal 
	number of modes / cut off values) in a single graph.
PROscorer,2017-05-16,PROscorer: Functions to Score Commonly-Used Patient-Reported Outcome (PRO)
Measures and Other Psychometric Instruments,An extensible repository of accurate, up-to-date functions to score 
    commonly used patient-reported outcome (PRO), quality of life (QOL), and 
    other psychometric and psychological measures.  'PROscorer', together with 
    the 'PROscorerTools' package, is a system to facilitate the incorporation of 
    PRO measures into research studies and clinical settings in a scientifically 
    rigorous and reproducible manner.  These packages and their vignettes are 
    intended to help establish and promote "best practices" to improve the 
    planning, scoring, and reporting of PRO-like measures in research.  
    The 'PROscorer' "Instrument Descriptions" vignette contains descriptions of 
    each instrument scored by 'PROscorer', complete with references.  These 
    instrument descriptions are suitable for inclusion in formal study protocol 
    documents, grant proposals, and manuscript Method sections.  Each 
    'PROscorer' function is composed of helper functions from the 
    'PROscorerTools' package, and users are encouraged to contribute new 
    functions to 'PROscorer'.  More scoring functions are currently in 
    development and will be added in future updates.
rif,2017-03-16,rif: Client for 'Neuroscience' Information Framework 'APIs',Client for 'Neuroscience' Information Framework ('NIF') 'APIs'
    (<https://neuinfo.org/>; <https://neuinfo.org/about/webservices>).
    Package includes functions for each 'API' route, and gives back data
    in tidy data.frame format.
PairwiseD,2017-05-04,PairwiseD: Pairing Up Units and Vectors in Panel Data Setting,Pairing observations according to a chosen formula and facilitates bilateral analysis of the panel data. Paring is possible for observations, as well as for vectors of observations ordered with respect to time.
PROscorerTools,2017-05-15,PROscorerTools: Tools to Score Patient-Reported Outcome (PRO) and Other
Psychometric Measures,Provides a reliable and flexible toolbox to score 
    patient-reported outcome (PRO), Quality of Life (QOL), and other 
    psychometric measures. The guiding philosophy is that scoring errors can 
    be eliminated by using a limited number of well-tested, well-behaved 
    functions to score PRO-like measures. The workhorse of the package is 
    the 'scoreScale' function, which can be used to score most single-scale 
    measures. It can reverse code items that need to be reversed before 
    scoring and pro-rate scores for missing item data. Currently, three 
    different types of scores can be output: summed item scores, mean item 
    scores, and scores scaled to range from 0 to 100. The 'PROscorerTools' 
    functions can be used to write new functions that score more complex 
    measures. In fact, 'PROscorerTools' functions are the building blocks of 
    the scoring functions in the 'PROscorer' package (which is a repository 
    of functions that score specific commonly-used instruments). Users are 
    encouraged to use 'PROscorerTools' to write scoring functions for their 
    favorite PRO-like instruments, and to submit these functions for 
    inclusion in 'PROscorer' (a tutorial vignette will be added soon). The 
    long-term vision for the 'PROscorerTools' and 'PROscorer' packages is to 
    provide an easy-to-use system to facilitate the incorporation of PRO 
    measures into research studies in a scientifically rigorous and 
    reproducible manner. These packages and their vignettes are intended to 
    help establish and promote "best practices" for scoring and describing 
    PRO-like measures in research. 
slim,2016-11-07,slim: Singular Linear Models for Longitudinal Data,Fits singular linear models to longitudinal data. Singular linear
    models are useful when the number, or timing, of longitudinal observations
    may be informative about the observations themselves. They are described
    in Farewell (2010) <doi:10.1093/biomet/asp068>, and are extensions of the
    linear increments model <doi:10.1111/j.1467-9876.2007.00590.x> to general
    longitudinal data.   
gomms,2017-05-14,gomms: GLM-Based Ordination Method,A zero-inflated quasi-Poisson factor model to display similarity between samples visually in a low (2 or 3) dimensional space.
GEEmediate,2016-11-18,GEEmediate: Mediation Analysis for Generalized Linear Models Using the
Difference Method,Causal mediation analysis for a single exposure/treatment and a
    single mediator, both allowed to be either continuous or binary. The package
    implements the difference method and provide point and interval estimates as
    well as testing for the natural direct and indirect effects and the mediation
    proportion.
learnrbook,2017-05-13,learnrbook: Datasets for Aphalo's "Learn R" Book,Datasets used in the book "Learn R ...as you learnt your mother
    tongue" by Pedro J. Aphalo (2017) <https://leanpub.com/learnr>.
mbgraphic,2017-05-13,mbgraphic: Measure Based Graphic Selection,Measure based exploratory data analysis. Some of the functions call interactive apps programmed with the package shiny to provide flexible selection options.
diffMeshGP,2017-05-12,diffMeshGP: Multi-Fidelity Computer Experiments Using the Tuo-Wu-Yu Model,This R function implements the nonstationary Kriging model proposed by Tuo, Wu and Yu (2014) <doi:10.1080/00401706.2013.842935> for analyzing multi-fidelity computer outputs. This function computes the maximum likelihood estimates for the model parameters as well as the predictive means and variances of the exact solution (i.e., the conceptually highest fidelity).
EpistemicGameTheory,2017-05-10,EpistemicGameTheory: Constructing an Epistemic Model for the Games with Two Players,Constructing an epistemic model such that, for every player i and for every choice c(i) which is optimal, there is one type that expresses common belief in rationality.
fastTextR,2017-05-12,fastTextR: An Interface to the 'fastText' Library,An interface to the 'fastText' library
	<https://github.com/facebookresearch/fastText>. The package
	can be used for text classification and to learn word vectors.
	The install folder contains the 'PATENTS' file.
	An example how to use 'fastTextR' can be found in the 'README' file.
iGSEA,2017-05-12,iGSEA: Integrative Gene Set Enrichment Analysis Approaches,To integrate multiple GSEA studies, we propose a hybrid strategy,
    iGSEA-AT, for choosing random effects (RE) versus fixed effect (FE) models,
    with an attempt to achieve the potential maximum statistical efficiency as 
    well as stability in performance in various practical situations. In addition
    to iGSEA-AT, this package also provides options to perform integrative GSEA
    with testing based on a FE model (iGSEA-FE) and testing based on a RE model
    (iGSEA-RE). The approaches account for different set sizes when testing a
    database of gene sets. The function is easy to use, and the three approaches
    can be applied to both binary and continuous phenotypes. 
jocre,2016-10-05,jocre: Joint Confidence Regions,Computing and plotting joint confidence regions and intervals. Regions include classical ellipsoids, minimum-volume or minimum-length regions, and an empirical Bayes region. Intervals include the TOST procedure with ordinary or expanded intervals and a fixed-sequence procedure. Such regions and intervals are useful e.g., for the assessment of multi-parameter (bio-)equivalence. Joint confidence regions for the mean and variance of a normal distribution are available as well.
lifelogr,2017-05-12,lifelogr: Life Logging,Provides a framework for combining self-data (exercise, sleep, etc.) from multiple sources (fitbit, Apple Health), creating visualizations, and experimenting on onself.
shinycssloaders,2017-05-10,shinycssloaders: Add CSS Loading Animations to 'shiny' Outputs,Create a lightweight Shiny wrapper for the css-loaders created by Luke Hass <https://github.com/lukehaas/css-loaders>. Wrapping a Shiny output will automatically show a loader when the output is (re)calculating.
sinib,2017-05-12,sinib: Sum of Independent Non-Identical Binomial Random Variables,Density, distribution function, quantile function 
	and random generation for the sum of independent non-identical
	binomial distribution with parameters \code{size} and \code{prob}.
usedist,2017-05-12,usedist: Distance Matrix Utilities,Functions to re-arrange, extract, and work with distances.
iECAT,2017-05-11,iECAT: Integrating External Controls into Association Test,Functions for single-variant and region-based tests with external control samples. These methods use external study samples as control samples with adjusting for possible batch effects. 
lhmixr,2017-05-11,lhmixr: Fit Sex-Specific Life History Models with Missing
Classifications,Fits sex-specific life-history models for fish and other taxa where some of the individuals have unknown sex.
pawls,2017-05-11,pawls: Penalized Adaptive Weighted Least Squares Regression,Efficient algorithms for fitting weighted least squares regression with \eqn{L_{1}}{L1} regularization on both the
 coefficients and weight vectors, which is able to perform simultaneous variable selection 
 and outliers detection efficiently.
WebGestaltR,2017-02-26,WebGestaltR: The R Version of WebGestalt,The web version WebGestalt <http://www.webgestalt.org> supports 12 organisms, 324 gene identifiers and 150,937 function categories. Users can upload the data and functional categories with their own gene identifiers. In addition to the Over-Representation Analysis, WebGestalt also supports Gene Set Enrichment Analysis. The user-friendly output interface allow interactive and efficient exploration of enrichment results. The WebGestaltR package not only supports all above functions but also can be integrated into other pipeline or simultaneous analyze multiple gene lists.
lindia,2017-05-10,lindia: Automated Linear Regression Diagnostic,Provides a set of streamlined functions that allow
    easy generation of linear regression diagnostic plots necessarily 
    for checking linear model assumptions.
    This package is meant for easy scheming of linear 
    regression diagnostics, while preserving merits of 
    "The Grammar of Graphics" as implemented in 'ggplot2'.
    See the 'ggplot2' website for more information regarding the
    specific capability of graphics.
lsasim,2017-02-23,lsasim: Functions to Facilitate the Simulation of Large Scale Assessment
Data,Provides functions to simulate data from large-scale educational 
  assessments, including background questionnaire data and cognitive item 
  responses that adhere to a multiple-matrix sampled design.
outbreaks,2016-10-31,outbreaks: A Collection of Disease Outbreak Data,Empirical or simulated disease outbreak data, provided either as
    RData or as text files.
qrsvm,2017-05-10,qrsvm: SVM Quantile Regression with the Pinball Loss,Quantile Regression (QR) using Support Vector Machines under the Pinball-Loss. Estimation is based on "Nonparametric Quantile Regression" by I. Takeuchi,  Q.V.Le , T. Sears, A.J.Smola (2004). Implementation relies on 'quadprog' package, package 'kernlab' Kernelfunctions and package 'Matrix' nearPD to find next Positive definite Kernelmatrix. Package estimates quantiles individually but an Implementation of non crossing constraints coming soon. Function multqrsvm() now supports parallel backend for faster fitting. 
AcuityView,2017-05-09,AcuityView: A Package for Displaying Visual Scenes as They May Appear to an
Animal with Lower Acuity,This code provides a simple method for representing a visual scene as it may be seen by an animal with less acute vision. When using (or for more information), please cite the original publication.
plotprotein,2017-05-09,plotprotein: Development of Visualization Tools for Protein Sequence,The image of the amino acid transform on the protein level is drawn, and the automatic routing of the functional elements such as the domain and the mutation site is completed.
IndianTaxCalc,2017-02-28,IndianTaxCalc: Indian Income Tax Calculator,Calculate Indian Income Tax liability for Financial years of Individual resident aged below 60 years,Senior Citizen,Super Senior Citizen, Firm, Local Authority, Any Non Resident Individual / Hindu Undivided Family / Association of Persons /Body of Individuals / Artificial Judicial Person, Co-operative Society.
RPEXE.RPEXT,2017-05-08,RPEXE.RPEXT: Reduced Piecewise Exponential Estimate/Test Software,This reduced piecewise exponential survival software implements the likelihood ratio test and backward elimination procedure in Han, Schell, and Kim (2012 <doi:10.1080/19466315.2012.698945>, 2014 <doi:10.1002/sim.5915>), and Han et al. (2016 <doi:10.1111/biom.12590>). Inputs to the program can be either times when events/censoring occur or the vectors of total time on test and the number of events. Outputs of the programs are times and the corresponding p-values in the backward elimination. Details about the model and implementation are given in Han et al. 2014. This program can run in R version 3.2.2 and above.
PROreg,2017-05-06,PROreg: Patient Reported Outcomes Regression Analysis,Offers a variety of tools, such as specific plots and regression model approaches, for analyzing different patient reported questionnaires. Specially, mixed-effects models based on the beta-binomial distribution are implemented to deal with binomial data with over-dispersion (see Najera-Zuloaga J., Lee D.-J. and Arostegui I. (2017) <doi:10.1177/0962280217690413>).
pwr2,2017-05-06,pwr2: Power and Sample Size Analysis for One-way and Two-way ANOVA
Models,User friendly functions for power and sample size analysis at one-way and two-way ANOVA settings take either effect size or delta and sigma as arguments. They are designed for both one-way and two-way ANOVA settings. In addition, a function for plotting power curves is available for power comparison, which can be easily visualized by statisticians and clinical researchers.
cowbell,2017-05-05,cowbell: Performs Segmented Linear Regression on Two Independent
Variables,Implements a specific form of segmented linear regression
    with two independent variables. The visualization of that function looks 
    like a quarter segment of a cowbell giving the package its name. 
    The package has been specifically constructed for the case where minimum 
    and maximum value of the dependent and two independent variables 
    are known a prior, which is usually the case
    when those values are derived from Likert scales.
crunchy,2017-05-05,crunchy: Shiny Apps on Crunch,To facilitate building custom dashboards on the Crunch data
    platform <http://crunch.io/>, the 'crunchy' package provides tools for
    working with 'shiny'. These tools include utilities to manage authentication
    and authorization automatically and custom stylesheets to help match the
    look and feel of the Crunch web application.
ContourFunctions,2017-05-04,ContourFunctions: Create Contour Plots from Data or a Function,Provides functions for making contour plots.
  The contour plot can be created from grid data, a function,
  or a data set. If non-grid data is given, then a Gaussian
  process is fit to the data and used to create the contour plot.
DataGraph,2017-05-03,DataGraph: Export Data from R so DataGraph can Read it,Functions to save either '.dtable' or '.dtbin' files that can be read by DataGraph, a graphing and analysis application for macOS. Can save a data frame, collection of data frames and sequences of data frames and individual vectors. For more information see <https://www.visualdatatools.com/DataGraph/Help/DataFiles/R/index.html>.
idar,2017-05-04,idar: Individual Diversity-Area Relationships,Computes and tests individual (species, phylogenetic and functional) diversity-area relationships, i.e., how species-, phylogenetic- and functional-diversity varies with spatial scale around the individuals of some species in a community. See applications of these methods in Wiegand et al. (2007) <doi:10.1073/pnas.0705621104> or Chacon-Labella et al. (2016) <doi:10.1007/s00442-016-3547-z>.
seasonalview,2016-12-14,seasonalview: Graphical User Interface for Seasonal Adjustment,A graphical user interface to the 'seasonal' package and
  'X-13ARIMA-SEATS', the U.S. Census Bureau's seasonal adjustment software. 
  Unifies the code base of <http://www.seasonal.website> and the GUI in the
  'seasonal' package.
kmcudaR,2017-05-03,kmcudaR: 'Yinyang' K-Means and K-NN using NVIDIA CUDA,K-means implementation is based on "Yinyang K-Means: A Drop-In Replacement of 
	the Classic K-Means with Consistent Speedup". While it introduces some overhead and many 
	conditional clauses which are bad for CUDA, it still shows 1.6-2x speedup against the Lloyd 
	algorithm. K-nearest neighbors employ the same triangle inequality idea and require 
	precalculated centroids and cluster assignments, similar to the flattened ball tree.
m2b,2017-05-03,m2b: Movement to Behaviour Inference using Random Forest,Prediction of behaviour from movement 
	characteristics using observation and random forest for the analyses of movement
	data in ecology.
	From movement information (speed, bearing...) the model predicts the
	observed behaviour (movement, foraging...) using random forest. The
	model can then extrapolate behavioural information to movement data
	without direct observation of behaviours.
	The specificity of this method relies on the derivation of multiple predictor variables from the
	movement data over a range of temporal windows. This procedure allows to capture
	as much information as possible on the changes and variations of movement and
	ensures the use of the random forest algorithm to its best capacity. The method
	is very generic, applicable to any set of data providing movement data together with
	observation of behaviour.
qrmix,2017-05-03,qrmix: Quantile Regression Mixture Models,Implements the robust algorithm for fitting finite mixture models based on quantile regression proposed by Emir et al., 2017 (unpublished).
discord,2017-05-02,discord: Functions for Discordant Kinship Modeling,Functions for discordant kinship modeling (and other sibling-based quasi-experimental designs). Currently, the package contains data restructuring functions; functions for generating genetically- and environmentally-informed data for kin pairs.
dsrTest,2017-04-24,dsrTest: Tests and Confidence Intervals on Directly Standardized Rates
for Several Methods,Perform a test of a simple null hypothesis about a 
    directly standardized rate and obtain the matching confidence 
    interval using a choice of methods.
KSEAapp,2017-05-02,KSEAapp: Kinase-Substrate Enrichment Analysis,Infers relative kinase activity from phosphoproteomics data
    using the method described by Casado et al. (2013) <doi:10.1126/scisignal.2003573>.
mut,2017-05-02,mut: Pairwise Likelihood Ratios,Main function LR2 calculates likelihood ratio for non-inbred relationships accounting for mutation, silent alleles and theta correction. Egeland, Pinto and Amorim (2017) <doi:10.1016/j.fsigen.2017.04.018>. 
ncdump,2017-05-02,ncdump: Extract Metadata from 'NetCDF' Files as Data Frames,Tools for handling 'NetCDF' metadata in data frames. The metadata is provided
    as relations in tabular form, to avoid having to scan printed header output or to navigate 
    nested lists of raw metadata. 
onehot,2017-05-02,onehot: Fast Onehot Encoding for Data.frames,Quickly create numeric matrices for machine learning algorithms
    that require them. It converts factor columns into onehot vectors.
angstroms,2017-05-01,angstroms: Tools for 'ROMS' the Regional Ocean Modeling System,Helper functions for working with Regional Ocean Modeling System 'ROMS' output. See
    <https://www.myroms.org/> for more information about 'ROMS'. 
EML,2016-12-20,EML: Read and Write Ecological Metadata Language Files,Parse and serialize Ecological Metadata Language ('EML', see
    <https://en.wikipedia.org/wiki/Ecological_Metadata_Language> for
    more information) files into S4 objects.
MHTmult,2017-05-01,MHTmult: Multiple Hypotheses Testing for Multiple Families/Groups
Structure,A Comprehensive tool for almost all existing multiple testing
    methods for multiple families. The package summarizes the existing methods for multiple families multiple testing procedures (MTPs) such as double FDR, group Benjamini-Hochberg (GBH) procedure and average FDR controlling procedure. The package also provides some novel multiple testing procedures using selective inference idea.
MetaboList,2016-12-29,MetaboList: Annotation of Metabolites from Liquid Chromatography-Mass
Spectrometry Data,Automatic metabolite annotation from Liquid Chromatography-Mass Spectrometry (LC-MS and LC-MS/MS) data from .mzXML files, providing an inclusion list of metabolites/fragments (Only the ion mass). The function returns the identification and quantification of the peaks presented in the sample, as well as the non-identified metabolites/fragments.
pafdR,2017-04-30,pafdR: Book Companion for Processing and Analyzing Financial Data with
R,Provides access to material from the book "Processing and Analyzing Financial Data with R" by Marcelo Perlin (2017) available at <https://sites.google.com/view/pafdr/home>.
SPADAR,2017-04-30,SPADAR: Spherical Projections of Astronomical Data,Provides easy to use functions to create all-sky grid plots of widely used astronomical coordinate systems (equatorial, ecliptic, galactic) and scatter plots of data on any of these systems including on-the-fly system conversion. It supports any type of spherical projection to the plane defined by the 'mapproj' package.
ChocoLattes,2017-04-29,ChocoLattes: Processing Data from Lattes CV Files,Processes data from Lattes CV 
    (<http://lattes.cnpq.br/>) XML files. Extract, condition, and plot 
    lists of journal and conference papers, book chapters, books, 
    and more.
dataseries,2017-02-17,dataseries: Switzerland's Data Series in One Place,Download and import time series from <http://www.dataseries.org>, a comprehensive and up-to-date collection of open data from Switzerland.
mockr,2017-04-29,mockr: Mocking in R,Provides a means to mock a package function, i.e., temporarily substitute it for testing. Designed as a drop-in replacement for 'testthat::with_mock()', which may break in R 3.4.0 and later.
casebase,2017-04-28,casebase: Fitting Flexible Smooth-in-Time Hazards and Risk Functions via
Logistic and Multinomial Regression,Implements the case-base sampling approach of Hanley and Miettinen (2009) <doi:10.2202/1557-4679.1125>, 
    Saarela and Arjas (2015) <doi:10.1111/sjos.12125>, and Saarela (2015) <doi:10.1007/s10985-015-9352-x>, for fitting flexible hazard 
    regression models to survival data with single event type or multiple competing causes via logistic and multinomial regression. 
    From the fitted hazard function, cumulative incidence, risk functions of time, treatment and profile 
    can be derived. This approach accommodates any log-linear hazard function of prognostic time, treatment, 
    and covariates, and readily allows for non-proportionality. We also provide a plot method for visualizing 
    incidence density via population time plots.
gsrsb,2017-04-28,gsrsb: Group Sequential Refined Secondary Boundary,A gate-keeping procedure to test a primary and a secondary endpoint in a group sequential design with multiple interim looks. Computations related to group sequential primary and secondary boundaries. Refined secondary boundaries are calculated for a gate-keeping test on a primary and a secondary endpoint in a group sequential design with multiple interim looks. The choices include both the standard boundaries and the boundaries using error spending functions. Version 1.0.0 was released on April 12, 2017. See Tamhane et al. (2017+) "A gatekeeping procedure to test a primary and a secondary endpoint in a group sequential design with multiple interim looks", Biometrics, to appear.
WikidataQueryServiceR,2017-01-17,WikidataQueryServiceR: API Client Library for 'Wikidata Query Service',An API client for the 'Wikidata Query Service'
    <https://query.wikidata.org/>.
aSPC,2017-04-27,aSPC: An Adaptive Sum of Powered Correlation Test (aSPC) for Global
Association Between Two Random Vectors,The aSPC test is designed to test global association between two groups of variables potentially with moderate to high dimension (e.g. in hundreds). The aSPC is particularly useful when the association signals between two groups of variables are sparse. 
mstherm,2017-04-27,mstherm: Analyze MS/MS Protein Melting Data,Software to aid in modeling and analyzing mass-spectrometry-based
    proteome melting data. Quantitative data is imported and normalized and
    thermal behavior is modeled at the protein level. Methods exist for
    normalization, modeling, visualization, and export of results. For a
    general introduction to MS-based thermal profiling, see Savitski et al.
    (2014) <doi:10.1126/science.1255784>.
bulletr,2017-04-26,bulletr: Algorithms for Matching Bullet Lands,Analyze bullet lands using nonparametric methods. We provide a
    reading routine for x3p files (see <http://www.openfmc.org> for more
    information) and a host of analysis functions designed to assess the
    probability that two bullets were fired from the same gun barrel.
coxphMIC,2017-04-26,coxphMIC: Sparse Estimation of Cox Proportional Hazards Models via
Approximated Information Criterion,Sparse estimation for Cox PH models is done via
    Minimum approximated Information Criterion (MIC) by Su, Wijayasinghe, 
    Fan, and Zhang (2016) <doi:10.1111/biom.12484>. MIC mimics the best 
    subset selection using a penalized likelihood approach yet with no need 
    of a tuning parameter. The problem is further reformulated with a 
    re-parameterization step so that it reduces to one unconstrained non-convex
    yet smooth programming problem, which can be solved efficiently. Furthermore,
    the re-parameterization tactic yields an additional advantage in terms of
    circumventing post-selection inference.
md.log,2017-04-26,md.log: Produces Markdown Log File with a Built-in Function Call,Produces clean and neat Markdown log file
    and also provide an argument to include the function call inside the Markdown log.
censCov,2017-04-25,censCov: Linear Regression with a Randomly Censored Covariate,Implementations of threshold regression approaches for linear
	     regression models with a covariate subject to random censoring,
	     including deletion threshold regression and completion threshold regression.
	     Reverse survival regression, which flip the role of response variable and the
	     covariate, is also considered.
RandMeta,2017-04-25,RandMeta: Efficient Numerical Algorithm for Exact Inference in Meta
Analysis,A novel numerical algorithm that provides functionality for estimating the exact 95% confidence interval of the location parameter in the random effects model, and is much faster than the naive method. Works best when the number of studies is between 6-20.
zip,2017-04-25,zip: Cross-Platform 'zip' Compression,Cross-Platform 'zip' Compression Library. A replacement
    for the 'zip' function, that does not require any additional
    external tools on any platform.
ajv,2017-04-24,ajv: Another JSON Schema Validator,A thin wrapper around the 'ajv' JSON validation package for
    JavaScript. See <http://epoberezkin.github.io/ajv/> for details.
BarBorGradient,2017-04-24,BarBorGradient: Function Minimum Approximator,Tool to find where a function has its lowest value(minimum). The
    functions can be any dimensions. Recommended use is with eps=10^-10, but can be
    run with 10^-20, although this depends on the function. Two more methods are in
    this package, simple gradient method (Gradmod) and Powell method (Powell). These
    are not recommended for use, their purpose are purely for comparison.
ider,2017-04-24,ider: Various Methods for Estimating Intrinsic Dimension,An implementation of various methods for estimating intrinsic
    dimension of vector-valued dataset or distance matrix. Most methods implemented
    are based on different notion of fractal dimension such as the capacity
    dimension, the box-counting dimension, and the information dimension.
nonpar,2017-02-21,nonpar: A Collection of Nonparametric Hypothesis Tests,Contains the following 5 nonparametric hypothesis tests:
    The Sign Test,
    The 2 Sample Median Test,
    Miller's Jackknife Procedure,
    Cochran's Q Test, &
    The Stuart-Maxwell Test.
ring,2017-04-24,ring: Circular / Ring Buffers,Circular / ring buffers in R and C.  There are a couple
    of different buffers here with different implementations that
    represent different trade-offs.
selectapref,2017-04-24,selectapref: Analysis of Field and Laboratory Foraging,Provides indices such as Manly's alpha, foraging ratio, and Ivlev's selectivity to allow for analysis of dietary selectivity and preference. Can accommodate multiple experimental designs such as constant prey number of prey depletion.
startR,2017-04-22,startR: Automatically Retrieve Multidimensional Distributed Data Sets,Tool to automatically fetch, transform and arrange subsets of multidimensional data sets (collections of files) stored in local and/or remote file systems or servers, using multicore capabilities where possible. The tool provides an interface to perceive a collection of data sets as a single large multidimensional data array, and enables the user to request for automatic retrieval, processing and arrangement of subsets of the large array. Wrapper functions to add support for custom file formats can be plugged in/out, making the tool suitable for any research field where large multidimensional data sets are involved.
chemmodlab,2017-04-21,chemmodlab: A Cheminformatics Modeling Laboratory for Fitting and Assessing
Machine Learning Models,Contains a set of methods for fitting models and methods for
    validating the resulting models. The statistical methodologies comprise
    a comprehensive collection of approaches whose validity and utility have
    been accepted by experts in the Cheminformatics field. As promising new
    methodologies emerge from the statistical and data-mining communities, they
    will be incorporated into the laboratory. These methods are aimed at discovering
    quantitative structure-activity relationships (QSARs). However, the user can
    directly input their own choices of descriptors and responses, so the capability
    for comparing models is effectively unlimited.
CrossScreening,2017-03-09,CrossScreening: Cross-Screening in Observational Studies that Test Many
Hypotheses,Cross-screening is a new method that uses both random halves of the sample to screen and test many hypotheses. It generally improves statistical power in observational studies when many hypotheses are tested simultaneously. References: 1. Qingyuan Zhao, Dylan S Small, and Paul R Rosenbaum. Cross-screening in observational studies that test many hypotheses. <arXiv:1703.02078>. 2. Qingyuan Zhao. On sensitivity value of pair-matched observational studies. <arXiv:1702.03442>.
KENDL,2017-03-21,KENDL: Kernel-Smoothed Nonparametric Methods for Environmental Exposure
Data Subject to Detection Limits,Calculate the kernel-smoothed nonparametric estimator for the exposure distribution in presence of detection limits. 
RpeakChrom,2016-12-14,RpeakChrom: Tools for Chromatographic Column Characterization and Modelling
Chromatographic Peak,The quantitative measurement and detection of molecules in HPLC should be carried out by an accurate description of chromatographic peaks. In this package non-linear fitting using a modified Gaussian model with a parabolic variance (PVMG) has been implemented to obtain the retention time and height at the peak maximum. This package also includes the traditional Van Deemter approach and two alternatives approaches to characterize chromatographic column.
SADISA,2017-04-21,SADISA: Species Abundance Distributions with Independent-Species
Assumption,Computes the probability of a set of species abundances of a single or multiple samples of individuals under a mainland-island model. One must specify the mainland (metacommunity) model and the island (local) community model. It assumes that species fluctuate independently. See Haegeman, B. & R.S. Etienne (2017). A general sampling formula for community structure data. Methods in Ecology & Evolution. In press.
simMP,2017-04-21,simMP: Simulate Somatic Mutations in Cancer Genomes from Mutational
Processes,Simulates somatic single base substitutions carried in cancer genomes. By only providing a human reference genome, substitutions that result from mutational processes operative in every cancer genome can be generated.
statGraph,2017-04-21,statGraph: Statistical Methods for Graphs,Contains statistical methods to analyze graphs, such as
    graph parameter estimation, model selection based on the GIC
    (Graph Information Criterion), statistical tests to
    discriminate two or more populations of graphs (ANOGVA
    -Analysis of Graph Variability), correlation between graphs,
    and clustering of graphs.
unix,2017-04-03,unix: Unix System Utilities,Bindings to system utilities found in most Unix systems such as
    POSIX functions which are not part of the Standard C Library.
PortfolioOptim,2017-04-20,PortfolioOptim: Small/Large Sample Portfolio Optimization,Two functions for financial portfolio optimization by linear programming are provided. One function implements Benders decomposition algorithm and can be used for very large data sets. The other, applicable for moderate sample sizes, finds optimal portfolio which has the smallest distance to a given benchmark portfolio.
PCADSC,2017-04-19,PCADSC: Tools for Principal Component Analysis-Based Data Structure
Comparisons,A suite of non-parametric, visual tools for assessing differences in data structures
    for two datasets that contain different observations of the same variables. These tools are all 
    based on Principal Component Analysis (PCA) and thus effectively address differences in the structures
    of the covariance matrices of the two datasets. The PCASDC tools consist of easy-to-use, 
    intuitive plots that each focus on different aspects of the PCA decompositions. The cumulative eigenvalue
    (CE) plot describes differences in the variance components (eigenvalues) of the deconstructed covariance matrices. The
    angle plot presents the information loss when moving from the PCA decomposition of one dataset to the 
    PCA decomposition of the other. The chroma plot describes the loading patterns of the two datasets, thereby
    presenting the relative weighting and importance of the variables from the original dataset. 
yarrr,2016-10-08,yarrr: A Companion to the e-Book "YaRrr!: The Pirate's Guide to R",Contains a mixture of functions and data sets referred to in the introductory e-book "YaRrr!: The Pirate's Guide to R". The latest version of the e-book is available for free at <https://www.thepiratesguidetor.com>.
icosa,2017-04-18,icosa: Global Triangular and Penta-Hexagonal Grids Based on Tessellated
Icosahedra,Employs triangular tessellation to refine icosahedra
    defined in 3d space. The procedures can be set to provide a grid with a
    custom resolution. Both the primary triangular and their inverted penta-
    hexagonal grids are available for implementation. Additional functions
    are provided to position points (latitude-longitude data) on the grids,
    to allow 2D and 3D plotting, use raster data and shapefiles.
TSGSIS,2017-04-18,TSGSIS: Two Stage-Grouped Sure Independence Screening,To provide a high dimensional grouped variable selection approach for detection of whole-genome SNP effects and SNP-SNP interactions, as described in Fang et al. (2017, under review).
uqr,2016-10-30,uqr: Unconditional Quantile Regression,Estimation and Inference for Unconditional Quantile Regression for cross-sectional and panel data (see Firpo et al. (2009) <doi:10.3982/ECTA6822>).
WLreg,2017-04-18,WLreg: Regression Analysis Based on Win Loss Endpoints,Use various regression models for the analysis of win loss endpoints 
             adjusting for non-binary and multivariate covariates.
mro,2017-04-16,mro: Multiple Correlation,Computes multiple correlation coefficient when the data matrix is given and tests its significance.
complexity,2017-01-21,complexity: Calculate the Proportion of Permutations in Line with an
Informative Hypothesis,Allows for the easy computation of complexity: the proportion of the parameter space in line with the hypothesis by chance. The package comes with a Shiny application in which the calculations can be conducted as well. 
bayesCL,2017-04-14,bayesCL: Bayesian Inference on a GPU using OpenCL,Bayesian Inference on a GPU. The package currently supports sampling from PolyaGamma, Multinomial logit and Bayesian lasso.
SeerMapper2010East,2017-04-14,SeerMapper2010East: Supplemental U. S. 2010 Census Tract Boundaries for 23 Eastern
States without Registries for 'SeerMapper',Provides supplemental 2010 census tract boundary package for 23 states
   without Seer Registries that are east of the Mississippi river 
   for use with the 'SeerMapper' package.  
   The data contained in this 
   package is derived from U. S. Census data and is in public domain. 
SeerMapper2010West,2017-04-14,SeerMapper2010West: Supplemental U.S. 2010 Census Tract Boundaries for 14 Western
States without Seer Registries for 'SeerMapper',Provides supplemental 2010 census tract boundaries for the 14 states
   without Seer Registries that are west of the Mississippi river 
   for use with the 'SeerMapper' package.
   The data contained in this 
   package is derived from U. S. 2010 Census data and is in public domain.
StatPerMeCo,2017-04-14,StatPerMeCo: Statistical Performance Measures to Evaluate Covariance Matrix
Estimates,Statistical performance measures used in the econometric literature to evaluate conditional covariance/correlation matrix estimates (MSE, MAE, Euclidean distance, Frobenius distance, Stein distance, asymmetric loss function, eigenvalue loss function and the loss function defined in Eq. (4.6) of Engle et al. (2016) <doi:10.2139/ssrn.2814555>). Additionally, compute Eq. (3.1) and (4.2) of Li et al. (2016) <doi:10.1080/07350015.2015.1092975> to compare the factor loading matrix. The statistical performance measures implemented have been previously used in, for instance, Laurent et al. (2012) <doi:10.1002/jae.1248>,  Amendola et al. (2015) <doi:10.1002/for.2322> and  Becker et al. (2015) <doi:10.1016/j.ijforecast.2013.11.007>.
thankr,2017-04-14,thankr: Find Out Who Maintains the Packages you Use,Find out who maintains the packages you use in
             your current session or in your package library and
             maybe say 'thank you'.
fpest,2017-04-13,fpest: Estimating Finite Population Total,Given the values of sampled units and selection probabilities 
             the desraj function  in the package computes the estimated value of the total
             as well as estimated variance.
nopaco,2017-01-13,nopaco: Non-Parametric Concordance Coefficient,A non-parametric test for multi-observer concordance and
    differences between concordances in (un)balanced data.
R2ucare,2017-04-13,R2ucare: Goodness-of-Fit Tests for Capture-Recapture Models,Performs goodness-of-fit tests for capture-recapture models. Also contains several functions to process capture-recapture data.
SeerMapper2010Regs,2017-04-13,SeerMapper2010Regs: Supplemental U. S. 2010 Census Tract Boundaries for 15 States
with Seer Registries for 'SeerMapper',Provides  supplemental 2010 census tract boundaries of the 15 states 
   containing Seer Registries for use with the 'SeerMapper' package.
   The data contained in this 
   package is derived from U. S. 2010 Census data and is in public domain. 
spec,2017-03-10,spec: A Data Specification Format and Interface,Creates a data specification that describes the columns of a 
 table (data.frame). Provides methods to read, write, and update the 
 specification. Checks whether a table matches its specification. See
 specification.data.frame(),read.spec(), write.spec(), as.csv.spec(),
 respecify.character(), and %matches%.data.frame().
Tnseq,2017-02-09,Tnseq: Identification of Conditionally Essential Genes in Transposon
Sequencing Studies,Identification of conditionally essential genes using high-throughput sequencing data from transposon mutant libraries.
tubern,2017-04-13,tubern: R Client for the YouTube Analytics and Reporting API,Get statistics and reports from YouTube. To learn more about
    the YouTube Analytics and Reporting API, see <https://developers.google.com/youtube/reporting/>.
wrangle,2017-02-20,wrangle: A Systematic Data Wrangling Idiom,Supports systematic scrutiny, modification, and integration of
    data. The function status() counts rows that have missing values in 
    grouping columns (returned by na() ), have non-unique combinations of 
    grouping columns (returned by dup() ), and that are not locally sorted
    (returned by unsorted() ). Functions enumerate() and itemize() give 
    sorted unique combinations of columns, with or without occurrence counts,
    respectively. Function ignore() drops columns in x that are present in y,
    and informative() drops columns in x that are entirely NA. Data that have
    defined unique combinations of grouping values behave more predictably
    during merge operations.
marcher,2017-04-12,marcher: Migration and Range Change Estimation in R,A set of tools for likelihood-based estimation, model selection and testing of two- and three-range shift and migration models for animal movement data as described in Gurarie et al. (2017) <doi:10.1111/1365-2656.12674>.  Provided movement data (X, Y and Time), including irregularly sampled data, functions estimate the time, duration and location of one or two range shifts, as well as the ranging area and auto-correlation structure of the movment.  Tests assess, for example, whether the shift was "significant", and whether a two-shift migration was a true return migration.
optrcdmaeAT,2017-04-12,optrcdmaeAT: Optimal Row-Column Designs for Two-Colour cDNA Microarray
Experiments,Computes A-, MV-, D- and E-optimal or near-optimal row-column designs for two-colour cDNA microarray experiments using the linear fixed effects and mixed effects models where the interest is in a comparison of all pairwise treatment contrasts. The algorithms used in this package are based on the array exchange and treatment exchange algorithms adopted from Debusho, Gemechu and Haines (2016, unpublished) algorithms after adjusting for the row-column designs setup. The package also provides an optional method of using the graphical user interface (GUI) R package tcltk to ensure that it is user friendly.
SeerMapperEast,2017-04-12,SeerMapperEast: Supplemental U. S. 2000 Census Tract Boundaries for 23 Eastern
States without Seer Registries,Provides supplemental 2000 census tract boundaries for the 23 states
   without Seer Registries that are east of the Mississippi river 
   for use with the 'SeerMapper' package.  
   The data contained in this 
   package is derived from U. S. Census data and is in the public domain. 
SeerMapperWest,2017-04-12,SeerMapperWest: Supplemental U.S. 2000 Census Tract Boundaries for 14 Western
States without Seer Registries for 'SeerMapper',Provides supplemental 2000 census tract boundaries for the 14 states
   without Seer Registries that are west of the Mississippi river
   for use with the 'SeerMapper' package.  
   The data contained in this 
   package is derived from U. S. Census data and is in the public domain. 
fastqcr,2017-04-11,fastqcr: Quality Control of Sequencing Data,'FASTQC' is the most widely used tool for evaluating the quality of high throughput sequencing data.  
    It produces, for each sample, an html report and a compressed file containing the raw data. 
    If you have hundreds of samples, you are not going to open up each 'HTML' page. 
    You need some way of looking at these data in aggregate. 
    'fastqcr' Provides helper functions to easily parse, aggregate and analyze 
    'FastQC' reports for large numbers of samples. It provides a convenient solution for building 
    a 'Multi-QC' report, as well as, a 'one-sample' report with result interpretations.
GADAG,2017-04-11,GADAG: A Genetic Algorithm for Learning Directed Acyclic Graphs,Sparse large Directed Acyclic Graphs learning with a combination of a convex program and a tailored genetic algorithm (see Champion et al. (2017) <https://hal.archives-ouvertes.fr/hal-01172745v2/document>). 
GLIDE,2017-04-11,GLIDE: Global and Individual Tests for Direct Effects,Functions evaluate global and individual tests for direct effects in Mendelian randomization studies.
D3GB,2017-04-10,D3GB: Interactive Genome Browser with R,Creates interactive genome browser with 'R'. It joins the data analysis power of R and the visualization libraries of JavaScript in one package.
lspline,2017-04-10,lspline: Linear Splines with Convenient Parametrisations,Linear splines with convenient parametrisations such that 
  (1) coefficients are slopes of consecutive segments or (2) coefficients are 
  slope changes at consecutive knots. Knots can be set manually or at break points
  of equal-frequency or equal-width intervals covering the range of 'x'.
  The implementation follows Greene (2003), chapter 7.2.5.
SeerMapperRegs,2017-04-10,SeerMapperRegs: Supplemental U. S. 2000 Census Tract Boundary for 15 States with
Seer Registries for 'SeerMapper',Provides supplemental 2000 census tract boundaries for the 15 states
   containing Seer Registries for use with the 'SeerMapper' package.  
   The data contained in this 
   package is derived from U. S. Census data and is in the public domain. 
mRchmadness,2017-04-09,mRchmadness: Numerical Tools for Filling Out an NCAA Basketball Tournament
Bracket,Scrape season results, estimate win probabilities, and find a
  competitive bracket for your office pool. Additional utilities include:
  scraping population picks; simulating tournament results; and testing your
  bracket in simulation.
skeletor,2016-12-30,skeletor: An R Package Skeleton Generator,A tool for bootstrapping new packages with useful defaults,
    including a test suite outline that passes checks and helpers for running
    tests, checking test coverage, building vignettes, and more. Package
    skeletons it creates are set up for pushing your package to
    'GitHub' and using other hosted services for building and test automation.
duckduckr,2017-04-07,duckduckr: Simple Client for the DuckDuckGo Instant Answer API,Programmatic access to the DuckDuckGo Instant Answer API <https://api.duckduckgo.com/api>.
IMTest,2017-04-07,IMTest: Information Matrix Test for Generalized Partial Credit Models,Implementation of the information matrix test for generalized partial credit models.
MedDietCalc,2017-04-07,MedDietCalc: Multi Calculator to Compute Scores of Adherence to Mediterranean
Diet,Multi Calculator of different scores to measure adherence to Mediterranean Diet, to compute them in nutriepidemiological data. Additionally, a sample dataset of this kind of data is provided, and some other minor tools useful in epidemiological studies.
micEconIndex,2017-04-07,micEconIndex: Price and Quantity Indices,Tools for calculating Laspeyres, Paasche, and Fisher
  price and quantity indices.
secure,2017-03-24,secure: Sequential Co-Sparse Factor Regression,Sequential factor extraction via co-sparse unit-rank estimation (SeCURE).
sylcount,2017-04-07,sylcount: Syllable Counting and Readability Measurements,An English language syllable counter, plus readability score
    measure-er.  The package has been carefully optimized and should be very
    efficient, both in terms of run time performance and memory consumption.
    The main methods are 'vectorized' by document, and scores for multiple
    documents are computed in parallel via 'OpenMP'.
classifierplots,2017-01-12,classifierplots: Generates a Visualization of Classifier Performance as a Grid of
Diagnostic Plots,
  Generates a visualization of binary classifier performance as a grid of
  diagnostic plots with just one function call. Includes ROC curves,
  prediction density, accuracy, precision, recall and calibration plots, all using
  ggplot2 for easy modification.
  Debug your binary classifiers faster and easier!
CoFRA,2016-12-26,CoFRA: Complete Functional Regulation Analysis,Calculates complete functional regulation analysis and visualize
    the results in a single heatmap. The provided example data is for biological
    data but the methodology can be used for large data sets to compare quantitative
    entities that can be grouped. For example, a store might divide entities into
    cloth, food, car products etc and want to see how sales changes in the groups
    after some event. The theoretical background for the calculations are provided
    in New insights into functional regulation in MS-based drug profiling, Ana Sofia
    Carvalho, Henrik Molina & Rune Matthiesen, Scientific Reports <doi:10.1038/srep18826>.
eshrink,2017-04-06,eshrink: Shrinkage for Effect Estimation,Computes shrinkage estimators for regression problems. Selects
    penalty parameter by minimizing bias and variance in the effect estimate, where bias and variance are estimated from the posterior predictive distribution.
zfa,2017-04-06,zfa: Zoom-Focus Algorithm,Performs Zoom-Focus Algorithm (ZFA) to optimize testing regions for rare variant association tests in exome sequencing data.
HYRISK,2017-04-04,HYRISK: Hybrid Methods for Addressing Uncertainty in RISK Assessments,Methods for addressing uncertainty in risk assessments using hybrid representations of uncertainty (probability distributions, fuzzy numbers, intervals, probability distributions with imprecise parameters). The uncertainty propagation procedure combines random sampling using Monte Carlo method with fuzzy interval analysis of Baudrit et al. (2007) <doi:10.1109/TFUZZ.2006.876720>. The sensitivity analysis is based on the pinching method of Ferson and Tucker (2006) <doi:10.1016/j.ress.2005.11.052>.
TSMN,2017-04-04,TSMN: Truncated Scale Mixtures of Normal Distributions,Return the first four moments of the SMN distributions (Normal, Student-t, Pearson VII, Slash or Contaminated Normal).
afmToolkit,2017-04-03,afmToolkit: Functions for Atomic Force Microscope Force-Distance Curves
Analysis,Set of functions for analyzing Atomic Force Microscope (AFM) force-distance curves. It allows to obtain the contact and unbinding points, perform the baseline correction, estimate the Young's modulus, fit up to two exponential decay function to a stress-relaxation / creep experiment, obtain adhesion energies. These operations can be done either over a single F-d curve or over a set of F-d curves in batch  mode.
groupsubsetselection,2017-04-03,groupsubsetselection: Group Subset Selection,Group subset selection for linear regression models is provided in this package. Given response variable, and explanatory variables, which are organised in groups, group subset selection selects a small number of groups to explain response variable linearly using least squares.  
nlshelper,2017-04-03,nlshelper: Convenient Functions for Non-Linear Regression,A few utilities for summarizing, testing, and plotting non-linear
    regression models fit with nls(), nlsList() or nlme().
vesselr,2017-03-24,vesselr: Gradient and Vesselness Tools for Arrays and NIfTI Images,Simple functions for calculating the image gradient, image hessian, volume ratio filter, and Frangi vesselness filter of 3-dimensional volumes.
xbreed,2017-03-31,xbreed: Genomic Simulation of Purebred and Crossbred Populations,Simulation of purebred and crossbred genomic data as well as pedigree and phenotypes are possible by this package. 'xbreed' can be used for the simulation of populations with flexible genome structures and trait genetic architectures. It can also be used to evaluate breeding schemes and generate genetic data to test statistical tools. 
xyz,2016-11-05,xyz: The 'xyz' Algorithm for Fast Interaction Search in
High-Dimensional Data,High dimensional interaction search by brute force requires a
    quadratic computational cost in the number of variables. The xyz algorithm provably finds strong interactions in almost linear time.
    For details of the algorithm see: G. Thanei, N. Meinshausen and R. Shah (2016). The xyz algorithm for fast interaction search in high-dimensional data <https://arxiv.org/pdf/1610.05108v1.pdf>.
enrichR,2017-04-02,enrichR: Provides an R Interface to 'Enrichr',Provides an R interface to all 'Enrichr' databases, a web-based tool for analysing gene sets and returns any enrichment of common annotated biological functions. <http://amp.pharm.mssm.edu/Enrichr/>.
medicare,2016-10-10,medicare: Tools for Obtaining and Cleaning Medicare Public Use Files,Publicly available data from Medicare frequently requires extensive
    initial effort to extract desired variables and merge them; this package
    formalizes the techniques I've found work best. More information on the 
    Medicare program, as well as guidance for the publicly available data this package 
    targets, can be found on CMS's website covering publicly available data. See <https://www.cms.gov/Research-Statistics-Data-and-Systems/Research-Statistics-Data-and-Systems.html>.
grapes,2017-04-01,grapes: Make Binary Operators,Turn arbitrary functions into binary operators.
InterfaceqPCR,2017-04-01,InterfaceqPCR: GUI to Analyse qPCR Results after PMA Treatment or not,Graphical User Interface allowing to determine the concentration in the sample in CFU per mL or in number of copies per mL provided to qPCR results after with or without PMA treatment. This package is simply to use because no knowledge in R commands is necessary. A graphic represents the standard curve, and a table containing the result for each sample is created.
SARP.moodle,2017-02-19,SARP.moodle: XML Output Functions for Easy Creation of Moodle Questions,Provides a set of basic functions for creating Moodle XML
 output files suited for importing questions in Moodle (a learning
 management system, see <https://moodle.org/> for more information).
tensorr,2017-04-01,tensorr: Sparse Tensors in R,Provides methods to manipulate and store sparse tensors. Tensors 
  are multidimensional generalizations of matrices (two dimensional) and 
  vectors (one dimensional).
aptg,2017-03-31,aptg: Automatic Phylogenetic Tree Generator,Generates phylogenetic trees and distance matrices from a list of species name or from a taxon down to whatever lower taxon. It can do so based on two reference super trees: mammals and angiosperms. 
focusedMDS,2017-03-22,focusedMDS: Focused, Interactive Multidimensional Scaling,Takes a distance matrix and plots it as an 
    interactive graph. One point is focused at the center of the graph,
    around which all other points are plotted in their exact distances as
    given in the distance matrix. All other non-focus points are plotted 
    as best as possible in relation to one another. Double click on any 
    point to choose a new focus point, and hover over points to see their
    ID labels. If color label categories are given, hover over colors in 
    the legend to highlight only those points and click on colors to 
    highlight multiple groups. For more information on the rationale 
    and mathematical background, as well as an interactive introduction,
    see <https://lea-urpa.github.io/focusedMDS.html>.
kscons,2017-03-31,kscons: A Bayesian Approach for Protein Residue Contact Prediction using
the Knob-Socket Model of Protein Tertiary Structure,Predicts a protein's residue contact map, based on the estimation of the corresponding knob-socket list. For more details, please refer to our paper:  Q. Li, D. B. Dahl, M. Vannucci, H. Joo, J. W. Tsai (2016), KScons: A Bayesian Approach for Protein Residue Contact Prediction using the Knob-socket Model of Protein Tertiary Structure, Bioinformatics, 32(24): 3774-3781 <doi:10.1093/bioinformatics/btw553>.
optim.functions,2017-03-30,optim.functions: Standard Benchmark Optimization Functions,A set of standard benchmark optimization functions for R and
    a common interface to sample them.
BLModel,2017-03-29,BLModel: Black-Litterman Posterior Distribution,Posterior distribution in the Black-Litterman model is computed from a prior distribution given in the form of a time series of asset returns and a continuous distribution of views provided by the user as an external function.
fam2r,2017-03-29,fam2r: From 'Familias' to R,Functionality provided for conditional simulation, likelihoods and plotting of pedigrees, mostly as a wrapper for 'paramlink'. Users typically start by exporting from the Windows version of 'Familias'.
metavcov,2017-02-20,metavcov: Variance-Covariance Matrix for Multivariate Meta-Analysis,Compute variance-covariance matrix for multivariate meta-analysis. Effect sizes include correlation (r), mean difference (MD), standardized mean difference (SMD), log odds ratio (logOR), log risk ratio (logRR), and risk difference (RD).
moezipfR,2016-12-09,moezipfR: Marshall-Olkin Extended Zipf,Statistical utilities for the analysis of data by means of the Marshall-Olkin Extended Zipf distribution are presented. The distribution is a two-parameter extension of the widely used Zipf model. By plotting the probabilities in log-log scale, this two-parameter extension allows a concave as well as a convex behavior of the function at the beginning of the distribution, maintaining the linearity, associated to the Zipf model, in the tail.
patternize,2017-03-29,patternize: Quantification of Color Pattern Variation,Quantification of variation in organismal color patterns as
    obtained from image data. Patternize defines homology between pattern positions
    across images either through fixed landmarks or image registration. Pattern
    identification is performed by categorizing the distribution of colors using RGB
    thresholds or image segmentation.
tilegramsR,2016-11-10,tilegramsR: R Spatial Data for Tilegrams,R spatial objects for Tilegrams.
  Tilegrams are tiled maps where the region size is proportional to
  the certain characteristics of the dataset.
tsqn,2017-03-29,tsqn: Applications of the Qn Estimator to Time Series (Univariate and
Multivariate),Time Series Qn is a package with applications of the Qn estimator of Rousseeuw and Croux (1993) <doi:10.1080/01621459.1993.10476408> to univariate and multivariate Time Series in time and frequency domains. More specifically, the robust estimation of autocorrelation or autocovariance matrix functions from Ma and Genton (2000, 2001) <doi:10.1111/1467-9892.00203>, <doi:10.1006/jmva.2000.1942> and Cotta (2017) <doi:10.13140/RG.2.2.14092.10883> are provided. The robust pseudo-periodogram of Molinares et. al. (2009) <doi:10.1016/j.jspi.2008.12.014> is also given. This packages also provides the M-estimator of the long-memory parameter d based on the robustification of the GPH estimator proposed by Reisen et al. (2017) <doi:10.1016/j.jspi.2017.02.008>. 
itan,2017-03-28,itan: Item Analysis for Multiple Choice Tests,Functions for analyzing multiple choice items. These analyses include the convertion of student response into binaty data (correct/incorrect), the computation of the number of corrected responses and grade for each subject, the calculation of item difficulty and discrimination, the computation of the frecuency and point-biserial correlation for each distractor and the graphical analysis of each item.
shinyHeatmaply,2017-03-28,shinyHeatmaply: Deploy 'heatmaply' using 'shiny',Access functionality of the 'heatmaply' package through 'Shiny UI'.
NetworkRiskMeasures,2017-01-10,NetworkRiskMeasures: Risk Measures for (Financial) Networks,Implements some risk measures for (financial) networks, such as DebtRank, Impact Susceptibility, Impact Diffusion and Impact Fluidity. 
slimrec,2017-03-25,slimrec: Sparse Linear Method to Predict Ratings and Top-N
Recommendations,Sparse Linear Method(SLIM) predicts ratings and top-n
    recommendations suited for sparse implicit positive feedback systems. SLIM
    is decomposed into multiple elasticnet optimization problems which are solved
    in parallel over multiple cores. The package is based on "SLIM: Sparse Linear
    Methods for Top-N Recommender Systems" by Xia Ning and George Karypis <doi:10.1109/ICDM.2011.134>.
TeachBayes,2017-01-14,TeachBayes: Teaching Bayesian Inference,Several functions for communicating Bayesian thinking including Bayes rule for deciding among spinners, visualizations for Bayesian inference for one proportion and for one mean, and comparison of two proportions using a discrete prior.
vortexRdata,2017-03-25,vortexRdata: Example Data for R Package 'vortexR',Contains selected data from two publications,
    Campbell et al. (2016) <doi:10.1080/14486563.2015.1028486>
    and Pacioni et al. (2017) <doi:10.1071/PC17002>.
    The data is provided both as raw outputs from the population viability
    analysis software Vortex and packaged as R objects.
    The R package 'vortexR' uses the raw data provided here to illustrate its
    functionality of parsing raw Vortex output into R objects.
docstring,2017-03-24,docstring: Provides Docstring Capabilities to R Functions,Provides the ability to display something analogous to
    Python's docstrings within R.  By allowing the user to document
    their functions as comments at the beginning of their function
    without requiring putting the function into a package we allow
    more users to easily provide documentation for their functions.
    The documentation can be viewed just like any other help files
    for functions provided by packages as well.
IPWsurvival,2017-03-24,IPWsurvival: Propensity Score Based Adjusted Survival Curves and
Corresponding Log-Rank Statistic,In observational studies, the presence of confounding factors is common and the comparison of different groups of subjects requires adjustment. In this package, we propose simple functions to estimate adjusted survival curves and log-rank test based on inverse probability weighting (IPW).
PCFAM,2017-03-24,PCFAM: Computation of Ancestry Scores with Mixed Families and Unrelated
Individuals,We provide several algorithms to compute the genotype ancestry scores (such as eigenvector projections) in the case where highly correlated individuals are involved.
affluenceIndex,2017-03-23,affluenceIndex: Affluence Indices,Computes the statistical indices of affluence (richness) and constructs bootstrap confidence intervals for these indices. Also computes the Wolfson polarization index.
summariser,2017-03-23,summariser: Easy Calculation and Visualisation of Confidence Intervals,Functions to speed up the exploratory analysis of simple
    datasets using 'dplyr' and 'ggplot2'. Functions are provided to do the 
    common tasks of calculating confidence intervals and visualising the 
    results. 
tsxtreme,2017-03-14,tsxtreme: Bayesian Modelling of Extremal Dependence in Time Series,Characterisation of the extremal dependence structure of time series, avoiding pre-processing and filtering as done typically with peaks-over-threshold methods. It uses the conditional approach of Heffernan and Tawn (2004) <doi:10.1111/j.1467-9868.2004.02050.x> which is very flexible in terms of extremal and asymptotic dependence structures, and Bayesian methods improve efficiency and allow for deriving measures of uncertainty. For example, the extremal index, related to the size of clusters in time, can be estimated and samples from its posterior distribution obtained.
CVR,2017-03-22,CVR: Canonical Variate Regression,Perform canonical variate regression (CVR) for two sets of covariates and a univariate
            response, with regularization and weight parameters tuned by cross validation.  
pathmapping,2017-03-20,pathmapping: Compute Deviation and Correspondence Between Spatial Paths,Functions to compute and display the area-based deviation between spatial paths and to compute a mapping based on minimizing area and distance-based cost.  For details, see: Mueller, S. T., Perelman, B. S., & Veinott, E. S. (2016) <doi:10.3758/s13428-015-0562-7>.
xlsimple,2017-03-22,xlsimple: 'XLConnect' Wrapper,Provides a simple wrapper for some 'XLConnect' functions. 'XLConnect' is
    a package that allows for reading, writing, and manipulating Microsoft Excel
    files. This package, 'xlsimple', adds some documentation and pre-defined formatting
    to the outputted Excel file. Individual sheets can include a description on the
    first row to remind user what is in the data set. Auto filters and freeze
    rows are turned on. A brief readme file is created that provides a summary
    listing of the created sheets and, where provided, the description.
FMC,2017-03-21,FMC: Factorial Experiments with Minimum Level Changes,Generate cost effective minimally changed run sequences 
              for symmetrical as well as asymmetrical factorial 
              designs.
gpg,2016-10-13,gpg: GNU Privacy Guard for R,Bindings to GnuPG for working with OpenGPG (RFC4880) cryptographic methods.
    Includes utilities for public key encryption, creating and verifying digital signatures,
    and managing your local keyring. Note that some functionality depends on the version of 
    GnuPG that is installed on the system. On Windows this package can be used together with
    'GPG4Win' which provides a GUI for managing keys and entering passphrases.
orgutils,2017-03-21,orgutils: Helper Functions for Org Files,Helper functions for Org files (<http://orgmode.org/>):
  a generic function 'toOrg' for transforming R objects into Org
  markup (most useful for data frames; there are also methods for
  Dates/POSIXt) and a function to read Org tables into data frames.
rnaturalearth,2017-03-21,rnaturalearth: World Map Data from Natural Earth,Facilitates mapping by making natural earth map data from <http://www.naturalearthdata.com/> more easily available to R users.
rolr,2017-03-21,rolr: Finding Optimal Three-Group Splits Based on a Survival Outcome,Provides fast procedures for exploring all pairs of
    cutpoints of a single covariate with respect to survival and determining
    optimal cutpoints using a hierarchical method and various ordered logrank tests.
stmgp,2017-03-21,stmgp: Rapid and Accurate Genetic Prediction Modeling for Genome-Wide
Association or Whole-Genome Sequencing Study Data,Rapidly build accurate genetic prediction models for genome-wide association or whole-genome sequencing study data by smooth-threshold multivariate genetic prediction (STMGP) method. Variable selection is performed using marginal association test p-values with an optimal p-value cutoff selected by Cp-type criterion. Quantitative and binary traits are modeled respectively via linear and logistic regression models. A function that works through PLINK software (Purcell et al. 2007 <doi:10.1086/519795>, Chang et al. 2015 <doi:10.1186/s13742-015-0047-8>) <https://www.cog-genomics.org/plink2> is provided. Covariates can be included in regression model.
EstimateGroupNetwork,2017-03-20,EstimateGroupNetwork: Perform the Joint Graphical Lasso and Selects Tuning Parameters,Can be used to simultaneously estimate networks (Gaussian Graphical Models) in data from different groups or classes via Joint Graphical Lasso. Tuning parameters are selected via information criteria (AIC / BIC / eBIC) or crossvalidation.
Rvoterdistance,2017-03-20,Rvoterdistance: Calculates the Distance Between Voter and Multiple Polling
Locations,Designed to calculate the distance between each voter in a voter file – given lat/long coordinates – and many potential (early) polling or vote by mail drop box locations, then return the minimum distance.
shinyShortcut,2017-03-19,shinyShortcut: Creates an Executable Shortcut for Shiny Applications,Provides function shinyShortcut() that, 
    when given the base directory of a shiny application, will produce an
    executable file that runs the shiny app directly in the user's
    default browser. Tested on both windows and unix machines. Inspired
    by and borrowing from 
    <http://www.mango-solutions.com/wp/2017/03/shiny-based-tablet-or-desktop-app/>.
OSCV,2017-03-18,OSCV: One-Sided Cross-Validation,Functions for implementing different versions of the OSCV method in the kernel regression and density estimation frameworks. The package mainly supports the following articles: (1) Savchuk, O.Y., Hart, J.D. (2017). Fully robust one-sided cross-validation for regression functions. Computational Statistics, <doi:10.1007/s00180-017-0713-7> and (2) Savchuk, O.Y. (2017). One-sided cross-validation for nonsmooth density functions, <arXiv:1703.05157>.
BASS,2016-12-16,BASS: Bayesian Adaptive Spline Surfaces,Bayesian fitting and sensitivity analysis methods for adaptive
    spline surfaces. Built to handle continuous and categorical inputs as well as
    functional or scalar output. An extension of the methodology in Denison, Mallick
    and Smith (1998) <doi:10.1023/A:1008824606259>.
BCSub,2016-10-29,BCSub: A Bayesian Semiparametric Factor Analysis Model for Subtype
Identification (Clustering),Gene expression profiles are commonly utilized to infer disease
             subtypes and many clustering methods can be adopted for this task.
             However, existing clustering methods may not perform well when
             genes are highly correlated and many uninformative genes are included
             for clustering. To deal with these challenges, we develop a novel
             clustering method in the Bayesian setting. This method, called BCSub,
             adopts an innovative semiparametric Bayesian factor analysis model
             to reduce the dimension of the data to a few factor scores for
             clustering. Specifically, the factor scores are assumed to follow
             the Dirichlet process mixture model in order to induce clustering.
CNull,2017-03-16,CNull: Fast Algorithms for Frequency-Preserving Null Models in Ecology,Efficient computations for null models that require shuffling columns on big matrix data.
             This package provides functions for faster computation of diversity measure statistics
             when independent random shuffling is applied to the columns of a given matrix. 
             Given a diversity measure f and a matrix M, the provided functions can generate random samples 
             (shuffled matrix rows of M), the mean and variance of f, and the p-values of this measure 
             for two different null models that involve independent random shuffling of the columns of M.
             The package supports computations of alpha and beta diversity measures.  
FlexDir,2017-03-16,FlexDir: Tools to Work with the Flexible Dirichlet Distribution,Provides tools to work with the Flexible Dirichlet
    distribution. The main features are an E-M algorithm for computing the maximum
    likelihood estimate of the parameter vector and a function based on conditional
    bootstrap to estimate its asymptotic variance-covariance matrix. It contains
    also functions to plot graphs, to generate random observations and to handle
    compositional data.
RankingProject,2017-03-16,RankingProject: The Ranking Project: Visualizations for Comparing Populations,Functions to generate plots and tables for comparing independently-
    sampled populations. Companion package to "A Primer on Visualizations
    for Comparing Populations, Including the Issue of Overlapping Confidence
    Intervals" by Wright, Klein, and Wieczorek (2017, in press).
rolypoly,2017-03-16,rolypoly: Identifying Trait-Relevant Functional Annotations,Using enrichment of genome-wide association summary statistics to
  identify trait-relevant cellular functional annotations.
gee4,2017-03-15,gee4: Generalised Estimating Equations (GEE/WGEE) using 'Armadillo'
and S4,Fit joint mean-covariance models for longitudinal data within the 
    framework of (weighted) generalised estimating equations (GEE/WGEE). The 
    models and their components are represented using S4 classes and methods. 
    The core computational algorithms are implemented using the 'Armadillo' C++ 
    library for numerical linear algebra and 'RcppArmadillo' glue.
gatepoints,2016-11-18,gatepoints: Easily Gate or Select Points on a Scatter Plot,Allows user to choose/gate a region on the plot and returns points
    within it.
outreg,2017-03-14,outreg: Regression Table for Publication,Create regression tables for publication.
    Currently supports 'lm', 'glm', 'survreg', and 'ivreg' outputs.
collpcm,2017-03-13,collpcm: Collapsed Latent Position Cluster Model for Social Networks,Markov chain Monte Carlo based inference routines for collapsed latent position cluster models or social networks, which includes searches over the model space (number of clusters in the latent position cluster model). The label switching algorithm used is that of Nobile and Fearnside (2007) <doi:10.1007/s11222-006-9014-7> which relies on the algorithm of Carpaneto and Toth (1980) <doi:10.1145/355873.355883>. 
radmixture,2017-03-13,radmixture: Calculate Population Stratification,Implementation of ADMIXTURE for individual ancestry inference in R. Specifically, ADMIXTURE is a software tool for maximum likelihood estimation of individual ancestries from multilocus SNP genotype datasets, see <https://www.genetics.ucla.edu/software/admixture/>. Users can use 'radmixture' to calculate ancestry components with different public datasets. It is very convenient and fast for personal genotype data. For more details, see <https://github.com/wegene-llc/radmixture/blob/master/README.md>.
cmpprocess,2017-03-11,cmpprocess: Flexible Modeling of Count Processes,A toolkit for flexible modeling of count processes where data (over- or under-) dispersion exists.
    Estimations can be obtained under two data constructs where one has:
    (1) data on number of events in an s-unit time interval, or (2) only wait-time data.
    This package is supplementary to the work set forth in Zhu et al. (2016) <doi:10.1080/00031305.2016.1234976>.
iNextPD,2017-03-11,iNextPD: Interpolation and Extrapolation for Phylogenetic Diversity,Interpolation and extrapolation for phylogenetic diversity.
rdataretriever,2017-03-11,rdataretriever: R Interface to the Data Retriever,Provides an R interface to the Data Retriever
    <http://data-retriever.org/> via the Data Retriever's
    command line interface. The Data Retriever automates the
    tasks of finding, downloading, and cleaning public datasets,
    and then stores them in a local database.
HoRM,2017-01-27,HoRM: Supplemental Functions and Datasets for "Handbook of Regression
Methods",Supplement for the book "Handbook of Regression Methods" by D. S. Young.  Some datasets used in the book are included and documented.  Wrapper functions are included that simplify the examples in the textbook, such as code for constructing a regressogram and expanding ANOVA tables to reflect the total sum of squares.
SigOptR,2017-03-10,SigOptR: R API Wrapper for SigOpt,Interfaces with the 'SigOpt' API. More info at <https://sigopt.com>.
CONS,2017-01-17,CONS: Consonance Analysis Module,Consonance Analysis is a useful numerical and graphical approach
    for evaluating the consistency of the measurements and the panel of people
    involved in sensory evaluation. It makes use of several uni and multivariate
    techniques either graphical or analytical. It shows the implementation of this
    procedure in a graphical interface.
iSDM,2017-03-09,iSDM: Invasive Species Distribution Modelling,Functions for predicting and mapping potential and realized distributions of invasive species within the invaded range.
SymTS,2017-03-09,SymTS: Symmetric Tempered Stable Distributions,Contains methods for simulation and for evaluating the pdf, cdf, and quantile functions for symmetric stable, symmetric classical tempered stable, and symmetric power tempered stable distributions. 
VertexSort,2017-03-04,VertexSort: Network Hierarchical Structure and Randomization,Permits to apply the 'Vertex Sort' algorithm (Jothi et al. (2009) <10.1038/msb.2009.52>) to a graph in order to elucidate its hierarchical structure. It also allows graphic visualization of the sorted graph by exporting the results to a cytoscape friendly format. Moreover, it offers five different algorithms of graph randomization: 1) Randomize a graph with preserving node degrees, 2) with preserving similar node degrees, 3) without preserving node degrees, 4) with preserving node in-degrees and 5) with preserving node out-degrees.
badger,2017-03-08,badger: Badge for R Package,Query information and generate badge for using in README
    and GitHub Pages.
BCellMA,2016-11-03,BCellMA: B Cell Receptor Somatic Hyper Mutation Analysis,Includes a set of functions to analyze for instance nucleotide frequencies as well as transition and  transversion. Can reconstruct germline sequences based on the international ImMunoGeneTics information system (IMGT/HighV-QUEST) outputs, calculate and plot the difference (%) of nucleotides at 6 positions around a mutation to identify and characterize hotspot motifs as well as calculate and plot average mutation frequencies of nucleotide mutations resulting in amino acid substitution.
NHLData,2017-03-08,NHLData: Scores for Every Season Since the Founding of the NHL in 1917,Each dataset contains scores for every game during a specific season of the NHL.
readOffice,2017-03-08,readOffice: Read Text Out of Modern Office Files,Reads in text from 'unstructured' modern Microsoft Office files (XML based files) such as Word and PowerPoint.
    This does not read in structured data (from Excel or Access) as there are many other great packages to that do so already.
cpr,2017-03-07,cpr: Control Polygon Reduction,Implementation of the Control Polygon Reduction and Control Net
    Reduction methods for finding parsimonious B-spline regression models.
otinference,2017-03-07,otinference: Inference for Optimal Transport,Sample from the limiting distributions of empirical Wasserstein
    distances under the null hypothesis and under the alternative. Perform a 
    two-sample test on multivariate data using these limiting distributions and 
    binning.
remindR,2017-03-07,remindR: Insert and Extract "Reminders" from Function Comments,Insert/extract text "reminders" into/from function source code 
    comments or as the "comment" attribute of any object.  
    The former can be handy in development as reminders of e.g. argument
    requirements, expected objects in the calling environment, required options
    settings, etc. The latter can be used to provide information of the object and 
    as simple manual "tooltips" for users, among other things.
edarf,2016-10-25,edarf: Exploratory Data Analysis using Random Forests,Functions useful for exploratory data analysis
    using random forests which can be used to compute multivariate partial
    dependence, observation, class, and variable-wise marginal and joint permutation
    importance as well as observation-specific measures of distance 
    (supervised or unsupervised). All of the aforementioned functions are
    accompanied by 'ggplot2' plotting functions.
funchir,2017-03-05,funchir: Convenience Functions by Michael Chirico,A set of functions, some subset of which I use in every .R file I write. Examples are table2(), which adds useful functionalities to base table (sorting, built-in proportion argument, etc.); lyx.xtable(), which converts xtable() output to a format more easily copy-pasted into LyX; pdf2(), which writes a plot to file while also displaying it in the RStudio plot window; and abbr_to_colClass(), which is a much more concise way of feeding many types to a colClass argument in a data reader.
gt4ireval,2017-03-06,gt4ireval: Generalizability Theory for Information Retrieval Evaluation,Provides tools to measure the reliability of an Information Retrieval test collection.
  It allows users to estimate reliability using Generalizability Theory and map those estimates onto
  well-known indicators such as Kendall tau correlation or sensitivity.
MLID,2017-02-23,MLID: Multilevel Index of Dissimilarity,Tools and functions to fit a multilevel index of dissimilarity.
twilio,2017-03-06,twilio: An Interface to the Twilio API for R,The Twilio web service provides an API for computer programs
    to interact with telephony. The included functions wrap the SMS and MMS 
    portions of Twilio's API, allowing users to send and receive text messages
    from R. See <https://www.twilio.com/docs/> for more information.
VarED,2017-03-05,VarED: Variance Estimation using Difference-Based Methods,Generating functions for both optimal and ordinary difference sequences, and the difference-based estimation functions.
CPsurv,2017-03-04,CPsurv: Nonparametric Change Point Estimation for Survival Data,Nonparametric change point estimation for survival data based on p-values of exact binomial tests.
SubgrpID,2017-02-28,SubgrpID: Patient Subgroup Identification for Clinical Drug Development,Function Wrapper contains four algorithms for developing threshold-based multivariate (prognostic/predictive) biomarker signatures via bootstrapping and aggregating of thresholds from trees, Monte-Carlo variations of the Adaptive Indexing method and Patient Rule Induction Method. Variable selection is automatically built-in to these algorithms. Final signatures are returned with interaction plots for predictive signatures. Cross-validation performance evaluation and testing dataset results are also output.
CensSpatial,2016-10-08,CensSpatial: Censored Spatial Models,Fits linear regression models for censored spatial data. Provides different estimation methods as the SAEM (Stochastic Approximation of Expectation Maximization) algorithm and seminaive that uses Kriging prediction to estimate the response at censored locations and predict new values at unknown locations. Also offers graphical tools for assessing the fitted model.
cghRA,2017-03-03,cghRA: Array CGH Data Analysis and Visualization,Provides functions to import data from Agilent CGH arrays and process them according to the cghRA workflow. Implements several algorithms such as WACA, STEPS and cnvScore and an interactive graphical interface.
Dpit,2017-03-03,Dpit: Distribution Pitting,Compares distributions with one another in terms of their fit to each sample in a dataset that contains multiple samples, as described in Joo, Aguinis, and Bradley (in press). Users can examine the fit of seven distributions per sample: pure power law, lognormal, exponential, power law with an exponential cutoff, normal, Poisson, and Weibull. Automation features allow the user to compare all distributions for all samples with a single command line, which creates a separate row containing results for each sample until the entire dataset has been analyzed.
cropdatape,2017-03-02,cropdatape: Open Data of Agricultural Production of Crops of Peru,Provides peruvian agricultural production data from the Agriculture Minestry of Peru (MINAGRI). The first version includes
             6 crops: rice, quinoa, potato, sweet potato, tomato and wheat; all of them across 24 departments. Initially,  in excel files which has been transformed
             and assembled using tidy data principles, i.e. each variable is in a column, each observation is a row and each value is in a cell.
             The variables variables are sowing and harvest area per crop, yield, production and price per plot, every one year, from 2004 to 2014.
fitplc,2016-10-19,fitplc: Fit Hydraulic Vulnerability Curves,Fits Weibull or sigmoidal models to percent loss conductivity (plc) curves as a function of plant water potential, computes confidence intervals of parameter estimates and predictions with bootstrap or parametric methods, and provides convenient plotting methods.
gaiah,2017-03-02,gaiah: Genetic and Isotopic Assignment Accounting for Habitat
Suitability,Tools for using genetic markers, stable isotope data, and habitat
    suitability data to calculate posterior probabilities of breeding origin of
    migrating birds.
WPKDE,2017-03-02,WPKDE: Weighted Piecewise Kernel Density Estimation,Weighted Piecewise Kernel Density Estimation for large data.
DiffNet,2017-02-28,DiffNet: Detection of Statistically Significant Changes in Complex
Biological Networks,Provides an implementation of statistically significant 
    differential sub-network analysis for paired biological networks.  
rcc,2017-02-28,rcc: Parametric Bootstrapping to Control Rank Conditional Coverage,Functions to implement the parametric and non-parametric bootstrap 
    confidence interval methods described in Morrison and Simon (2017) <arXiv:1702.06986>.
dirmcmc,2017-02-27,dirmcmc: Directional Metropolis Hastings Algorithm,Implementation of Directional Metropolis Hastings Algorithm for
    MCMC.
extdplyr,2017-02-23,extdplyr: Data Manipulation Extensions of 'Dplyr' and 'Tidyr',If 'dplyr' is a grammar for data manipulation, 'extdplyr' is like
    a short paragraph written in 'dplyr'. 'extdplyr' extends 'dplyr' and
    'tidyr' verbs to some common "routines" that manipulate data sets. It uses
    the same interface and preserves all the features from 'dplyr', has good 
    performance, and supports various data sources.
fontHind,2017-02-27,fontHind: Additional 'ggplot2' Themes Using 'Hind' Fonts,Provides 'ggplot2' themes based on the 'Hind' fonts.
  'Hind' is an open source 'typeface' supporting the 'Devanagari' and Latin scripts.
  Developed explicitly for use in User Interface design, the 'Hind' font family includes five styles.
  More information about the font can be found at <https://fonts.google.com/specimen/Hind>.
fontMPlus,2017-02-27,fontMPlus: Additional 'ggplot2' Themes Using 'M+' Fonts,Provides 'ggplot2' themes based on the 'M+' fonts.
  The 'M+' fonts are a font family under a free license. The font family provides
  multilingual glyphs. The fonts provide 'Kana', over 5,000 'Kanji', Basic Latin,
  Latin-1 Supplement, Latin Extended-A, and 'IPA' Extensions glyphs. Most of the Greek,
  Cyrillic, Vietnamese, and extended glyphs and symbols are included too.
  So the fonts are in conformity with ISO-8859-1, 2, 3, 4, 5, 7, 9, 10, 13, 14, 15, 16,
  Windows-1252, T1, and VISCII encoding.
  More information about the fonts can be found at <http://mplus-fonts.osdn.jp/about-en.html>.
gbts,2016-10-08,gbts: Hyperparameter Search for Gradient Boosted Trees,An implementation of hyperparameter optimization for Gradient
    Boosted Trees on binary classification and regression problems. The current
    version provides two optimization methods: Bayesian optimization and random
    search. Instead of giving the single best model, the final output is an 
    ensemble of Gradient Boosted Trees constructed via the method of ensemble 
    selection.
leafletCN,2016-12-30,leafletCN: An R Gallery for China and Other Geojson Choropleth Map in
Leaflet,An R gallery for China and other geojson choropleth map in leaflet. Contains the geojson data for provinces, cities in China.
misreport,2016-12-05,misreport: Statistical Analysis of Misreporting on Sensitive Survey
Questions,Enables investigation of the predictors of misreporting on sensitive survey questions through a multivariate list experiment regression method. The method permits researchers to model whether a survey respondent's answer to the sensitive item in a list experiment is different from his or her answer to an analogous direct question.
automagic,2017-02-26,automagic: Automagically Document and Install Packages Necessary to Run R
Code,Parse R code in a given directory for R packages and attempt to install them from CRAN or GitHub. Optionally use a dependencies file for tighter control over which package versions to install.
AWR.Kinesis,2017-02-26,AWR.Kinesis: Amazon 'Kinesis' Consumer Application for Stream Processing,Fetching data from Amazon 'Kinesis' Streams using the Java-based 'MultiLangDaemon' interacting with Amazon Web Services ('AWS') for easy stream processing from R. For more information on 'Kinesis', see <https://aws.amazon.com/kinesis>.
betacal,2017-02-25,betacal: Beta Calibration,Fit beta calibration models and obtain calibrated probabilities from
    them.
ccafs,2017-02-24,ccafs: Client for 'CCAFS' 'GCM' Data,Client for Climate Change, Agriculture, and Food Security ('CCAFS')
    General Circulation Models ('GCM') data. Data is stored in Amazon 'S3', from
    which we provide functions to fetch data.
europop,2017-01-17,europop: Historical Populations of European Cities, 1500-1800,This dataset contains population estimates of all European cities 
    with at least 10,000 inhabitants during the period 1500-1800. These data are
    adapted from Jan De Vries, "European Urbanization, 1500-1800" (1984).
som.nn,2017-02-09,som.nn: Topological k-NN Classifier Based on Self-Organising Maps,A topological version of k-NN: An abstract model is build
             as 2-dimensional self-organising map. Samples of unknown
             class are predicted by mapping them on the SOM and analysing
             class membership of neurons in the neighbourhood.
TAR,2017-02-24,TAR: Bayesian Modeling of Autoregressive Threshold Time Series Models,Identification and estimation of the autoregressive threshold models with Gaussian noise, as well as positive-valued time series. The package provides the identification of the number of regimes, the thresholds and the autoregressive orders, as well as the estimation of remain parameters. The package implements the methodology from the 2005 paper: Modeling Bivariate Threshold Autoregressive Processes in the Presence of Missing Data <doi:10.1081/STA-200054435>.
EnviroPRA,2017-02-23,EnviroPRA: Environmental Probabilistic Risk Assessment Tools,Methods to perform a Probabilistic Environmental Risk assessment from exposure to toxic substances - i.e. USEPA (1997) <https://www.epa.gov/risk/guiding-principles-monte-carlo-analysis> -.
InvasionCorrection,2017-02-23,InvasionCorrection: Invasion Correction,The correction is achieved under the assumption that non-migrating cells of the essay approximately form a quadratic flow profile due to frictional effects, compare law of Hagen-Poiseuille for flow in a tube. The script fits a conical plane to give xyz-coordinates of the cells. It outputs the number of migrated cells and the new corrected coordinates.
naptime,2016-11-13,naptime: A Flexible and Robust Sys.sleep() Replacement,Provides a near drop-in replacement for base::Sys.sleep() that allows more types of input
    to produce delays in the execution of code and can silence/prevent typical sources of error.
neighbr,2017-02-23,neighbr: Classification, Regression, Clustering with K Nearest Neighbors,Classification, regression, and clustering with k nearest neighbors
    algorithm. Implements several distance and similarity measures, covering
    continuous and logical features. Outputs ranked neighbors. Most features of
    this package are directly based on the PMML specification for KNN.
prefeR,2017-02-23,prefeR: R Package for Pairwise Preference Elicitation,Allows users to derive multi-objective weights from pairwise comparisons, which
    research shows is more repeatable, transparent, and intuitive other techniques. These weights
    can be rank existing alternatives or to define a multi-objective utility function for optimization.
robustarima,2017-02-23,robustarima: Robust ARIMA Modeling,Functions for fitting a linear regression model with ARIMA
  errors using a filtered tau-estimate.
BayesSpec,2017-02-22,BayesSpec: Bayesian Spectral Analysis Techniques,An implementation of methods for spectral analysis using the Bayesian framework. It includes functions for modelling spectrum as well as appropriate plotting and output estimates. There is segmentation capability with RJ MCMC (Reversible Jump Markov Chain Monte Carlo). The package takes these methods predominantly from the 2012 paper "AdaptSPEC: Adaptive Spectral Estimation for Nonstationary Time Series" <doi:10.1080/01621459.2012.716340>.
BCC1997,2017-02-22,BCC1997: Calculation of Option Prices Based on a Universal Solution,Calculates the prices of European options based on the universal solution provided by Bakshi, Cao and Chen (1997) <doi:10.1111/j.1540-6261.1997.tb02749.x>. This solution considers stochastic volatility, stochastic interest and random jumps. Please cite their work if this package is used. 
bsearchtools,2016-11-06,bsearchtools: Binary Search Tools,Exposes the binary search functions of the C++ standard library (std::lower_bound, std::upper_bound) plus other convenience functions, allowing faster lookups on sorted vectors.
DecorateR,2017-02-08,DecorateR: Fit and Deploy DECORATE Trees,DECORATE (Diverse Ensemble Creation by Oppositional Relabeling
    of Artificial Training Examples) builds an ensemble of J48 trees by recursively
    adding artificial samples of the training data ("Melville, P., & Mooney, R. J. (2005). Creating diversity in ensembles using artificial data. Information Fusion, 6(1), 99-111. <doi:10.1016/j.inffus.2004.04.001>").
lclGWAS,2016-11-15,lclGWAS: Efficient Estimation of Discrete-Time Multivariate Frailty Model
Using Exact Likelihood Function for Grouped Survival Data,The core of this 'Rcpp' based package is several functions to estimate the baseline hazard, frailty variance, and fixed effect parameter for a discrete-time shared frailty model with random effects. The functions are designed to analyze grouped time-to-event data accounting for family structure of related individuals (i.e., trios). The core functions include two processes: (1) evaluate the multivariable integration to compute the exact proportional hazards model based likelihood and (2) estimate the desired parameters using maximum likelihood estimation. The integration is evaluated by the 'Cuhre' algorithm from the 'Cuba' library (Hahn, T., Cuba-a library for multidimensional numerical integration, Comput. Phys. Commun. 168, 2005, 78-95 <doi:10.1016/j.cpc.2005.01.010>), and the source files of the 'Cuhre' function are included in this package. The maximization process is carried out using Brent's algorithm, with the 'C++' code file from John Burkardt and John Denker (Brent, R.,Algorithms for Minimization without Derivatives, Dover, 2002, ISBN 0-486-41998-3).
mle.tools,2017-02-21,mle.tools: Expected/Observed Fisher Information and Bias-Corrected Maximum
Likelihood Estimate(s),Calculates the expected/observed Fisher information and the bias-corrected maximum likelihood estimate(s) via Cox-Snell Methodology.
rnaturalearthdata,2017-02-21,rnaturalearthdata: World Vector Map Data from Natural Earth Used in 'rnaturalearth',Vector map data from <http://www.naturalearthdata.com/>. Access functions are provided in the accompanying package 'rnaturalearth'.
stdvectors,2017-02-21,stdvectors: C++ Standard Library Vectors in R,Allows the creation and manipulation of C++ std::vector's in R.
AWR.KMS,2017-02-20,AWR.KMS: A Simple Client to the 'AWS' Key Management Service,Encrypt plain text and 'decrypt' cipher text using encryption keys hosted at Amazon Web Services ('AWS') Key Management Service ('KMS'), on which see <https://aws.amazon.com/kms> for more information.
BayesFM,2016-11-03,BayesFM: Bayesian Inference for Factor Modeling,Collection of procedures to perform Bayesian analysis on a variety
    of factor models. Currently, it includes: Bayesian Exploratory Factor
    Analysis (befa), an approach to dedicated factor analysis with stochastic
    search on the structure of the factor loading matrix. The number of latent
    factors, as well as the allocation of the manifest variables to the factors,
    are not fixed a priori but determined during MCMC sampling.
    More approaches will be included in future releases of this package.
colorr,2017-02-20,colorr: Color Palettes for EPL, MLB, NBA, NHL, and NFL Teams,Color palettes for EPL, MLB, NBA, NHL, and NFL teams.
fileplyr,2017-02-03,fileplyr: Chunk Processing or Split-Apply-Combine on Delimited Files and
Distributed Dataframes,Perform chunk processing or split-apply-combine on data in a
    delimited file (example: CSV) and Distributed Dataframes (DDF) across multiple
    cores of a single machine with low memory footprint. These functions are a
    convenient wrapper over the versatile package 'datadr'.
gMOIP,2017-01-23,gMOIP: '2D plots of linear or integer programming models',Make 2D plots of the polyeder of a LP or IP problem, including
    integer points and iso profit curve. Can also make a plot of a bi-objective
    criterion space.
GSparO,2017-02-20,GSparO: Group Sparse Optimization,Approaches a group sparse solution of an underdetermined linear system. It implements the proximal gradient algorithm to solve a lower regularization model of group sparse learning. For details, please refer to the paper "Y. Hu, C. Li, K. Meng, J. Qin and X. Yang. Group sparse optimization via l_{p,q} regularization. Journal of Machine Learning Research, to appear, 2017".
upmfit,2017-02-19,upmfit: Unified Probability Model Fitting,Fitting a Unified Probability Model for household-community tuberculosis transmission dynamics.
educineq,2017-02-17,educineq: Compute and Decompose Inequality in Education,Easily compute education inequality measures and the distribution 
  of educational attainments for any group of countries, using the data set 
  developed in Jorda, V. and Alonso, JM. (2017) <doi:10.1016/j.worlddev.2016.10.005>. 
  The package offers the possibility to compute not only the Gini index, but 
  also generalized entropy measures for different values of the sensitivity 
  parameter. In particular, the package includes functions to compute the 
  mean log deviation, which is more sensitive to the bottom part of the 
  distribution; the Theil’s entropy measure, equally sensitive to all parts 
  of the distribution; and finally, the GE measure when the sensitivity 
  parameter is set equal to 2, which gives more weight to differences in 
  higher education. The decomposition of these measures in the components 
  between-country and within-country inequality is also provided. Two 
  graphical tools are also provided, to analyse the evolution of the
  distribution of educational attainments: The cumulative distribution 
  function and the Lorenz curve.
keyringr,2016-10-23,keyringr: Decrypt Passwords from Gnome Keyring, Windows Data Protection
API and macOS Keychain,Decrypts passwords stored in the Gnome Keyring, macOS Keychain and
    strings encrypted with the Windows Data Protection API.
marinespeed,2017-02-17,marinespeed: Benchmark Data Sets and Functions for Marine Species
Distribution Modelling,A collection of marine species benchmark data sets and functions
    for species distribution modelling (ecological niche modelling).
opusminer,2017-02-16,opusminer: OPUS Miner Algorithm for Filtered Top-k Association Discovery,Provides a simple R interface to the OPUS Miner algorithm (implemented in C++) for finding the top-k productive, non-redundant itemsets from transaction data.  The OPUS Miner algorithm uses the OPUS search algorithm to efficiently discover the key associations in transaction data, in the form of self-sufficient itemsets, using either leverage or lift.  See <http://i.giwebb.com/index.php/research/association-discovery/> for more information in relation to the OPUS Miner algorithm.
rope,2017-02-16,rope: Model Selection with FDR Control of Selected Variables,Selects one model with variable selection FDR controlled at a
    specified level. A q-value for each potential variable is also returned. The
    input, variable selection counts over many bootstraps for several levels of
    penalization, is modeled as coming from a beta-binomial mixture
    distribution.
spdownscale,2017-02-16,spdownscale: Spatial Downscaling Using Bias Correction Approach,Spatial downscaling of climate data (Global Circulation Models/Regional Climate Models) using quantile-quantile bias correction technique.
ubeR,2016-10-22,ubeR: Interface to the Uber API,The Uber API provides a programmatic way to interact with the Uber
    international online transportation network. This package enables access to
    the Uber API from within R. Specifically it is possible to: extract information
    about a user's account, find out about nearby Uber vehicles, get estimates for
    rides, book or cancel a ride. See <https://developer.uber.com/> for more
    information.
condir,2017-02-15,condir: Computation of P Values and Bayes Factors for Conditioning Data,Set of functions for the easy analyses of conditioning data.
velociraptr,2017-02-15,velociraptr: Fossil Analysis,Functions for downloading, reshaping, culling, cleaning, and analyzing fossil data from the Paleobiology Database <https://paleobiodb.org>.
warpMix,2017-02-15,warpMix: Mixed Effects Modeling with Warping for Functional Data Using
B-Spline,Mixed effects modeling with warping for functional data using B-
    spline. Warping coefficients are considered as random effects, and warping
    functions are general functions, parameters representing the projection onto B-
    spline basis of a part of the warping functions. Warped data are modelled by a
    linear mixed effect functional model, the noise is Gaussian and independent from
    the warping functions.
dgodata,2017-02-14,dgodata: Data for the 'dgo' Package,Provides data used by package 'dgo' in examples and vignettes.
eefAnalytics,2017-02-14,eefAnalytics: Analysing Education Trials,Provides tools for analysing education trials. Making different
    methods accessible in a single place is essential for sensitivity analysis
    of education trials, particularly the implication of the different methods in
    analysing simple randomised trials, cluster randomised trials and multisite
    trials.
paperplanes,2017-02-14,paperplanes: Distance Recordings from a Paper Plane Folding/Flying Experiment,This is a data only package, that provides distances from a paper plane experiment.
rapiclient,2017-02-14,rapiclient: Dynamic OpenAPI/Swagger Client,Access services specified in OpenAPI (formerly Swagger) format.
  It is not a code generator. Client is generated dynamically as a list of R 
  functions.
HRQoL,2017-02-12,HRQoL: Health Related Quality of Life Analysis,Offers tools and modelling approaches for binomial data with overdispersion, with particular interest in Health Related Quality of Life (HRQoL) questionnaires regression analysis.
maxnet,2016-11-16,maxnet: Fitting 'Maxent' Species Distribution Models with 'glmnet',Procedures to fit species distributions models from occurrence records and environmental variables, using 'glmnet' for model fitting. Model structure is the same as for the 'Maxent' Java package, version 3.4.0, with the same feature types and regularization options.  See the 'Maxent' website <http://biodiversityinformatics.amnh.org/open_source/maxent> for more details.
optbdmaeAT,2017-02-09,optbdmaeAT: Optimal Block Designs for Two-Colour cDNA Microarray Experiments,Computes A-, MV-, D- and E-optimal or near-optimal block designs for two-colour cDNA microarray experiments using the linear fixed effects and mixed effects models where the interest is in a comparison of all possible elementary treatment contrasts. The algorithms used in this package are based on the treatment exchange and array exchange algorithms of Debusho, Gemechu and Haines (2016, unpublished). The package also provides an optional method of using the graphical user interface (GUI) R package tcltk to ensure that it is user friendly.
BayesCombo,2017-02-08,BayesCombo: Bayesian Evidence Combination,Combine diverse evidence across multiple studies to test a high level scientific theory. The methods can also be used as an alternative to a standard meta-analysis.
FuzzyStatTra,2017-02-08,FuzzyStatTra: Statistical Methods for Trapezoidal Fuzzy Numbers,The aim of the package is to provide some basic functions
 for doing statistics with trapezoidal fuzzy numbers. In particular,
  the package contains several functions for simulating trapezoidal 
  fuzzy numbers, as well as for calculating some central tendency 
  measures (mean and two types of median), some scale measures 
  (variance, ADD, MDD, Sn, Qn, Tn and some M-estimators) and 
  one diversity index and one inequality index. Moreover, 
  functions for calculating the 1-norm distance, the mid/spr 
  distance and the (phi,theta)-wabl/ldev/rdev distance between 
  fuzzy numbers are included, and a function to calculate the 
  value phi-wabl given a sample of trapezoidal fuzzy numbers.
OCA,2017-02-08,OCA: Optimal Capital Allocations,Computes optimal capital allocations based on some standard principles such as Haircut, Overbeck type II and the Covariance Allocation Principle. It also provides some shortcuts for obtaining the Value at Risk and the Expectation Shortfall, using both the normal and the t-student distribution, see Urbina and Guillén (2014)<doi:10.1016/j.eswa.2014.05.017> and Urbina (2013)<http://hdl.handle.net/2099.1/19443>.
GPB,2017-02-07,GPB: Generalized Poisson Binomial Distribution,Functions that compute the distribution functions for the Generalized Poisson Binomial distribution, which provides the cdf, pmf, quantile function, and random number generation for the distribution.
cbird,2017-02-06,cbird: Clustering of Multivariate Binary Data with Dimension Reduction
via L1-Regularized Likelihood Maximization,The clustering of binary data with reducing the dimensionality (CLUSBIRD) proposed by Yamamoto and Hayashi (2015) <doi:10.1016/j.patcog.2015.05.026>.
mdftracks,2017-02-06,mdftracks: Read and Write 'MTrackJ Data Files','MTrackJ' is an 'ImageJ' plugin for motion tracking and analysis (see 
    <https://imagescience.org/meijering/software/mtrackj/>). This package reads 
    and writes 'MTrackJ Data Files' ('.mdf', see 
    <https://imagescience.org/meijering/software/mtrackj/format/>). It supports
    2D data and read/writes cluster, point, and channel information. If desired, 
    generates track identifiers that are unique over the clusters.
    See the project page for more information and examples.
QuantileGradeR,2017-02-05,QuantileGradeR: Quantile-Adjusted Restaurant Grading,Implementation of the food safety restaurant grading system adopted by Public Health - Seattle & King County (see Ashwood, Z.C., Elias, B., and Ho. D.E. "Improving the Reliability of Food Safety Disclosure: A Quantile Adjusted Restaurant Grading System for Seattle-King County" (working paper)). As reported in the accompanying paper, this package allows jurisdictions to easily implement refinements that address common challenges with unadjusted grading systems. First, in contrast to unadjusted grading, where the most recent single routine inspection is the primary determinant of a grade, grading inputs are allowed to be flexible. For instance, it is straightforward to base the grade on average inspection scores across multiple inspection cycles. Second, the package can identify quantile cutoffs by inputting substantively meaningful regulatory thresholds (e.g., the proportion of establishments receiving sufficient violation points to warrant a return visit). Third, the quantile adjustment equalizes the proportion of establishments in a flexible number of grading categories (e.g., A/B/C) across areas (e.g., ZIP codes, inspector areas) to account for inspector differences. Fourth, the package implements a refined quantile adjustment that addresses two limitations with the stats::quantile() function when applied to inspection score datasets with large numbers of score ties. The quantile adjustment algorithm iterates over quantiles until, over all restaurants in all areas, grading proportions are within a tolerance of desired global proportions. In addition the package allows a modified definition of "quantile" from "Nearest Rank". Instead of requiring that at least p[1]% of restaurants receive the top grade and at least (p[1]+p[2])% of restaurants receive the top or second best grade for quantiles p, the algorithm searches for cutoffs so that as close as possible p[1]% of restaurants receive the top grade, and as close as possible to p[2]% of restaurants receive the second top grade.
samplingDataCRT,2017-02-06,samplingDataCRT: Sampling Data Within Different Study Designs for Cluster
Randomized Trials,Package provides the possibility to sampling complete datasets 
  from a normal distribution to simulate cluster randomized trails for different study designs. 
SMLoutliers,2017-02-06,SMLoutliers: Outlier Detection Using Statistical and Machine Learning Methods,Local Correlation Integral (LOCI) method for outlier identification is implemented here. The LOCI method developed here is invented in Breunig, et al. (2000), see <doi:10.1145/342009.335388>.
mbrglm,2017-02-05,mbrglm: Median Bias Reduction in Binomial-Response GLMs,Fit generalized linear models with binomial responses using  a median modified score approach (Kenne Pagui et al., 2016, <https://arxiv.org/abs/1604.04768>) to median bias reduction. This method respects equivariance under reparameterizations for each parameter component and also solves the infinite estimates problem (data separation).
flippant,2016-12-21,flippant: Dithionite Scramblase Assay Analysis,The lipid scrambling activity of protein extracts and purified
    scramblases is often determined using a fluorescence-based assay involving
    many manual steps. flippant offers an integrated solution for the analysis
    and publication-grade graphical presentation of dithionite scramblase
    assays, as well as a platform for review, dissemination and extension of the
    strategies it employs. The package's name derives from a play on the fact
    that lipid scrambling is also sometimes referred to as 'flipping'.
superheat,2017-02-04,superheat: A Graphical Tool for Exploring Complex Datasets Using Heatmaps,A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types.
moveWindSpeed,2016-10-19,moveWindSpeed: Estimate Wind Speeds from Bird Trajectories,Estimating wind speed from trajectories of individually tracked birds using a maximum likelihood approach.
mpe,2017-02-02,mpe: Multiple Primary Endpoints,Functions for calculating sample size and power for clinical trials
    with multiple (co-)primary endpoints.
readHAC,2017-02-02,readHAC: Read Acoustic HAC Format,Read Acoustic HAC format.
SignifReg,2017-02-02,SignifReg: Significant Variable Selection in Linear Regression,Provide a significant variable selection procedure with different directions (forward, backward, stepwise) based on diverse criteria (Mallows' Cp, AIC, BIC, adjusted r-square, p-value). The algorithm selects a final model with only significant variables based on a correction choice of False Discovery Rate, Bonferroni, or no correction.
EnsCat,2017-01-18,EnsCat: Clustering of Categorical Data,An implementation of the clustering methods of categorical data
    discussed in Amiri, S., Clarke, B., and Clarke, J. (2015). Clustering categorical 
    data via ensembling dissimilarity matrices.  Preprint <arXiv:1506.07930>.
ShinyTester,2017-02-01,ShinyTester: Functions to Minimize Bonehead Moves While Working with 'shiny',It's my experience that working with 'shiny' is intuitive once you're
    into it, but can be quite daunting at first. Several common mistakes are fairly
    predictable, and therefore we can control for these. The functions in this
    package help match up the assets listed in the UI and the SERVER files, and
    Visualize the ad hoc structure of the 'shiny' App.
sonify,2017-02-01,sonify: Data Sonification - Turning Data into Sound,Sonification (or audification) is the process of representing data by sounds in the audible range. This package provides the R function sonify() that transforms univariate data, sampled at regular or irregular intervals, into a continuous sound with time-varying frequency. The ups and downs in frequency represent the ups and downs in the data. Sonify provides a substitute for R's plot function to simplify data analysis for the visually impaired.
ssmsn,2017-02-01,ssmsn: Scale-Shape Mixtures of Skew-Normal Distributions,It provides the density and random number generator for the Scale-Shape Mixtures of Skew-Normal Distributions proposed by Jamalizadeh and Lin (2016) <doi:10.1007/s00180-016-0691-1>.
iBST,2017-01-31,iBST: Improper Bagging Survival Tree,Fit a bagging survival tree on a mixture of population (susceptible and nonsusceptible)
             using either a pseudo R2 criterion or an adjusted Logrank criterion. The predictor is 
             evaluated using the Out Of Bag Integrated Brier Score (IBS) and several scores of importance
             are computed for variable selection. The thresholds values for variable selection are 
             computed using a nonparametric permutation test.
flood,2017-01-30,flood: Statistical Methods for the (Regional) Analysis of Flood
Frequency,Includes several statistical methods for the estimation of parameters and high quantiles of river flow distributions. The focus is on regional estimation based on homogeneity assumptions and computed from multivariate observations (multiple measurement stations).
	For details see Kinsvater et al. (2017) <arXiv:1701.06455>.
inspectr,2017-01-30,inspectr: Perform Basic Checks of Dataframes,Check one column or multiple columns of a dataframe
    using the preset basic checks or your own functions. Enables
    checks without knowledge of lapply() or sapply().
observer,2017-01-29,observer: Observe and Check your Data,Checks that a given dataset passes user-specified 
    rules. The main functions are observe_if() and inspect(). 
poio,2016-10-30,poio: Input/Output Functionality for "PO" and "POT" Message
Translation Files,Read and write PO and POT files, for package translations.
alphabetr,2017-01-28,alphabetr: Algorithms for High-Throughput Sequencing of Antigen-Specific T
Cells,Provides algorithms for frequency-based pairing of alpha-beta T
  cell receptors.
gbp,2017-01-28,gbp: A Bin Packing Problem Solver,Basic infrastructure and several algorithms for 1d-4d bin packing
    problem. This package provides a set of c-level classes and solvers for
    1d-4d bin packing problem, and an r-level solver for 4d bin packing problem,
    which is a wrapper over the c-level 4d bin packing problem solver.
    The 4d bin packing problem solver aims to solve bin packing problem, a.k.a
    container loading problem, with an additional constraint on weight.
    Given a set of rectangular-shaped items, and a set of rectangular-shaped bins
    with weight limit, the solver looks for an orthogonal packing solution
    such that minimizes the number of bins and maximize volume utilization.
    Each rectangular-shaped item i = 1, .. , n is characterized by length l_i,
    depth d_i, height h_i, and weight w_i, and each rectangular-shaped bin
    j = 1, .. , m is specified similarly by length l_j, depth d_j, height h_j,
    and weight limit w_j.
    The item can be rotated into any orthogonal direction, and no further
    restrictions implied.
hurricaneexposure,2017-01-28,hurricaneexposure: Explore and Map County-Level Hurricane Exposure in the United
States,Allows users to create time series of tropical storm
    exposure histories for chosen counties for a number of hazard metrics (wind, 
    rain, distance from the storm, etc.). This package interacts with data available 
    through the 'hurricaneexposuredata' package, which is available in a 'drat'
    repository. To access this data package, run 'install.packages("hurricaneexposuredata", 
    repos = "https://geanders.github.io/drat/", type = "source")'. The size of the 
    'hurricaneexposuredata' package is approximately 25 MB. This work was supported in 
    part by grants from the National Institute of Environmental Health Sciences 
    (R00ES022631), the National Science Foundation (1331399), and a NASA Applied 
    Sciences Program/Public Health Program Grant (NNX09AV81G).
tracer,2017-01-28,tracer: Slick Call Stacks,Better looking call stacks after an error.
LumReader,2017-01-27,LumReader: TL/OSL Reader Simulator,A series of functions to estimate the detection windows of a luminescence reader based on the filters and the photomultiplier (PMT) selected. These functions also allow to simulate a luminescence experiment based on the thermoluminesce (TL) or the optically stimulated luminescence (OSL) properties of a material.
sparsestep,2017-01-27,sparsestep: SparseStep Regression,Implements the SparseStep model for solving regression
    problems with a sparsity constraint on the parameters. The SparseStep 
    regression model was proposed in Van den Burg, Groenen, and Alfons (2017) 
    <https://arxiv.org/abs/1701.06967>. In the model, a regularization term is 
    added to the regression problem which approximates the counting norm of 
    the parameters.  By iteratively improving the approximation a sparse 
    solution to the regression problem can be obtained.  In this package both 
    the standard SparseStep algorithm is implemented as well as a path 
    algorithm which uses golden section search to determine solutions with 
    different values for the regularization parameter.
BayesPieceHazSelect,2017-01-26,BayesPieceHazSelect: Variable Selection in a Hierarchical Bayesian Model for a Hazard
Function,Fits a piecewise exponential hazard to survival data using a
    Hierarchical Bayesian model with an Intrinsic Conditional Autoregressive
    formulation for the spatial dependency in the hazard rates for each piece.
    This function uses Metropolis- Hastings-Green MCMC to allow the number of split
    points to vary and also uses Stochastic Search Variable Selection to determine
    what covariates drive the risk of the event. This function outputs trace plots
    depicting the number of split points in the hazard and the number of variables
    included in the hazard. The function saves all posterior quantities to the
    desired path.
eclust,2017-01-26,eclust: Environment Based Clustering for Interpretable Predictive Models
in High Dimensional Data,Companion package to the paper: An analytic approach for 
    interpretable predictive models in high dimensional data, in the presence of 
    interactions with exposures. Bhatnagar, Yang, Khundrakpam, Evans, Blanchette, Bouchard, Greenwood (2017) <doi:10.1101/102475>. 
    This package includes an algorithm for clustering high dimensional data that can be affected by an environmental factor. 
nparsurv,2017-01-26,nparsurv: Nonparametric Tests for Main Effects, Simple Effects and
Interaction Effect in a Factorial Design with Censored Data,Nonparametric Tests for Main Effects, Simple Effects and Interaction Effect with Censored Data and Two Factorial Influencing Variables.
mutSignatures,2017-01-24,mutSignatures: Decipher Mutational Signatures from Somatic Mutational Catalogs,Cancer cells accumulate DNA mutations as result of DNA damage and DNA repair processes. This computational framework is aimed at deciphering DNA mutational signatures operating in cancer. The input is a numeric matrix of DNA mutation counts detected in a panel of cancer samples. The framework performs Non-negative Matrix Factorization to extract the most likely signatures explaining the observed set of DNA mutations. The framework relies on parallelization and is optimized for use on multi-core systems. This framework is an R-based implementation of the original MATLAB WTSI framework by Alexandrov LB et al (2013) <doi:10.1016/j.celrep.2012.12.008>.
NORMA,2017-01-24,NORMA: Builds General Noise SVRs,Builds general noise SVR models using Naive Online R Minimization Algorithm, NORMA, an optimization method based on classical stochastic gradient descent suitable for computing SVR models in an online setting.
powerEQTL,2017-01-24,powerEQTL: Power and Sample Size Calculation for eQTL Analysis,Power and sample size calculation for eQTL analysis
             based on ANOVA or simple linear regression. It can also calculate power/sample size 
             for testing the association of a SNP to a continuous type phenotype.
rKIN,2017-01-24,rKIN: (Kernel) Isotope Niche Estimation,Applies methods used to estimate animal homerange, but
    instead of geospatial coordinates, we use isotopic coordinates. The estimation
    methods include: 1) 2-dimensional bivariate normal kernel utilization density
    estimator, 2) bivariate normal ellipse estimator, and 3) minimum convex polygon
    estimator, all applied to stable isotope data. Additionally, functions to
    determine niche area, polygon overlap between groups and levels (confidence
    contours) and plotting capabilities.
simpleSetup,2017-01-24,simpleSetup: Set Up R Source Code Files for Use on Multiple Machines,When working across multiple machines and, similarly for
    reproducible research, it can be time consuming to ensure that you have
    all of the needed packages installed and loaded and that the correct working
    directory is set. 'simpleSetup' provides simple functions for making these
    tasks more straightforward.
chi2x3way,2016-12-13,chi2x3way: Partitioning Chi-Squared and Tau Index for Three-Way Contingency
Tables,Provides two index partitions for three-way contingency tables:
   partition of the association measure chi-squared and of the predictability index tau 
   under several representative hypotheses about the expected frequencies (hypothesized probabilities). 
skm,2017-01-23,skm: Selective k-Means,Algorithms for solving selective k-means problem,
    which is defined as finding k rows in an m x n matrix such that 
    the sum of each column minimal is minimized. 
    In the scenario when m == n and each cell value in matrix is a 
    valid distance metric, this is equivalent to a k-means problem. 
    The selective k-means extends the k-means problem in the sense 
    that it is possible to have m != n, often the case m < n which 
    implies the search is limited within a small subset of rows. 
    Also, the selective k-means extends the k-means problem in the 
    sense that the instance in row set can be instance not seen in 
    the column set, e.g., select 2 from 3 internet service provider
    (row) for 5 houses (column) such that minimize the overall cost 
    (cell value) - overall cost is the sum of the column minimal of
    the selected 2 service provider.
ICV,2017-01-22,ICV: Indirect Cross-Validation (ICV) for Kernel Density Estimation,Functions for computing the global and local Gaussian density estimates based on the ICV bandwidth. See the article of Savchuk, O.Y., Hart, J.D., Sheather, S.J. (2010). Indirect cross-validation for density estimation. Journal of the American Statistical Association, 105(489), 415-423 <doi:10.1198/jasa.2010.tm08532>.
intrval,2016-12-06,intrval: Relational Operators for Intervals,Evaluating if values 
  of vectors are within different open/closed intervals
  ('x %[]% c(a, b)'), or if two closed
  intervals overlap ('c(a1, b1) %[]o[]% c(a2, b2)').
  Operators for negation and directional relations also implemented.
kpcalg,2017-01-22,kpcalg: Kernel PC Algorithm for Causal Structure Detection,Kernel PC (kPC) algorithm for causal structure learning and causal inference using graphical models. kPC is a version of PC algorithm that uses kernel based independence criteria in order to be able to deal with non-linear relationships and non-Gaussian noise.
mglR,2017-01-22,mglR: Master Gene List,Tools to download and organize large-scale, publicly available genomic studies on a candidate gene scale. Includes functions to integrate these data sources and compare features across candidate genes.
SOFIA,2017-01-22,SOFIA: Making Sophisticated and Aesthetical Figures in R,Software that leverages the capabilities of Circos by manipulating data, preparing configuration files, and running the Perl-native Circos directly from the R environment with minimal user intervention. Circos is a novel software that addresses the challenges in visualizing genetic data by creating circular ideograms composed of tracks of heatmaps, scatter plots, line plots, histograms, links between common markers, glyphs, text, and etc. Please see <http://www.circos.ca>. 
tea,2017-01-22,tea: Threshold Estimation Approaches,Different approaches for selecting the threshold in generalized Pareto distributions. Most of them are based on minimizing the AMSE-criterion or at least by reducing the bias of the assumed GPD-model. Others are heuristically motivated by searching for stable sample paths, i.e. a nearly constant region of the tail index estimator with respect to k, which is the number of data in the tail. The third class is motivated by graphical inspection. In addition to the very helpful eva package which includes many goodness of fit tests for the generalized Pareto distribution, the sequential testing procedure provided in Thompson et al. (2009) <doi:10.1016/j.coastaleng.2009.06.003> is also implemented here.
teda,2016-10-27,teda: An Implementation of the Typicality and Eccentricity Data
Analysis Framework,The typicality and eccentricity data analysis (TEDA) framework was
    put forward by Angelov (2013) <doi:10.14313/JAMRIS_2-2014/16>. It has been further developed into multiple
    different techniques since, and provides a non-parametric way of determining how
    similar an observation, from a process that is not purely random, is to other
    observations generated by the process. This package provides code to use the
    batch and recursive TEDA methods that have been published.
rcure,2017-01-21,rcure: Robust Cure Models for Survival Analysis,Implements robust cure models for survival analysis by incorporate
    a weakly informative prior in the logistic part of cure models. Estimates
    prognostic accuracy, i.e. AUC, k-index and c-index, with bootstrap confidence
    interval for cure models.
testforDEP,2017-01-07,testforDEP: Dependence Tests for Two Variables,Provides test statistics, p-value, and confidence intervals based on 9 hypothesis tests for dependence.
bytescircle,2016-11-16,bytescircle: Statistics About Bytes Contained in a File as a Circle Plot,Shows statistics about bytes contained in a file 
  as a circle graph of deviations from mean in sigma increments. 
  The function can be useful for statistically analyze the content of files 
  in a glimpse: text files are shown as a green centered crown, compressed 
  and encrypted files should be shown as equally distributed variations with 
  a very low CV (sigma/mean), and other types of files can be classified between 
  these two categories depending on their text vs binary content, which can be 
  useful to quickly determine how information is stored inside them (databases, 
  multimedia files, etc). 
caesar,2017-01-18,caesar: Encrypts and Decrypts Strings,Encrypts and decrypts strings using either the Caesar cipher or a
    pseudorandom number generation (using set.seed()) method.
cleanr,2016-12-21,cleanr: Helps You to Code Cleaner,Check your R code for some of the most common layout flaws.
    Many tried to teach us how to write code less dreadful, be it implicitly as
    B. W. Kernighan and D. M. Ritchie (1988) <ISBN:0-13-110362-8>
    in 'The C Programming Language' did, be it
    explicitly as R.C. Martin (2008) <ISBN:0-13-235088-2> in
    'Clean Code: A Handbook of Agile Software Craftsmanship' did.
    So we should check our code for files too long or wide, functions with too
    many lines, too wide lines, too many arguments or too many levels of 
    nesting.
    Note: This is not a static code analyzer like pylint or the like. Checkout
    https://github.com/jimhester/lintr instead.
conditions,2017-01-18,conditions: Standardized Conditions for R,Implements specialized conditions, i.e., typed errors,
    warnings and messages. Offers a set of standardized conditions (value error,
    deprecated warning, io message, ...) in the fashion of Python's built-in
    exceptions.
bayesianETAS,2016-12-14,bayesianETAS: Bayesian Estimation of the ETAS Model for Earthquake Occurrences,The Epidemic Type Aftershock Sequence  (ETAS) model is one of the best-performing methods for modeling and forecasting earthquake occurrences. This package implements Bayesian estimation routines to draw samples from the full posterior distribution of the model parameters, given an earthquake catalog. The paper on which this package is based is Gordon J. Ross - Bayesian Estimation of the ETAS Model for Earthquake Occurrences (2016), available from the below URL.
rCAT,2017-01-17,rCAT: Conservation Assessment Tools,A set of tools to help with species conservation assessments (Red List threat assessments). Includes tool for Extent of occurrence, Area of Occupancy, Minimum Enclosing Rectangle, a geographic Projection Wizard and Species batch processing.
cumstats,2017-01-16,cumstats: Cumulative Descriptive Statistics,Cumulative descriptive statistics for (arithmetic, geometric, harmonic) mean, median, mode, variance, skewness and kurtosis.
maxmatching,2017-01-15,maxmatching: Maximum Matching for General Weighted Graph,Computes the maximum matching for unweighted graph and maximum
    matching for (un)weighted bipartite graph efficiently.
PoSI,2017-01-15,PoSI: Valid Post-Selection Inference for Linear LS Regression,
  In linear LS regression, calculate for a given design matrix
  the multiplier K of coefficient standard errors such that the
  confidence intervals [b - K*SE(b), b + K*SE(b)] have a
  guaranteed coverage probability for all coefficient estimates
  b in any submodels after performing arbitrary model selection.
InfiniumPurify,2017-01-14,InfiniumPurify: Estimate and Account for Tumor Purity in Cancer Methylation Data
Analysis,The proportion of cancer cells in solid tumor sample, known as the tumor purity, has adverse impact on a variety of data analyses if not properly accounted for. We develop 'InfiniumPurify', which is a comprehensive R package for estimating and accounting for tumor purity based on DNA methylation Infinium 450k array data. 'InfiniumPurify' provides functionalities for tumor purity estimation. In addition, it can perform differential methylation detection and tumor sample clustering with the consideration of tumor purities. 
rwars,2017-01-14,rwars: R Client for the Star Wars API,Provides functions to retrieve and reformat data from the 'Star Wars' API (SWAPI) <https://swapi.co/>.
GeneClusterNet,2017-01-13,GeneClusterNet: Gene Expression Clustering and Gene Network,Functions for clustering time-course gene expression and reconstructing of gene regulatory network based on Dynamic Bayesian Network.
SADEG,2017-01-13,SADEG: Stability Analysis in Differentially Expressed Genes,We analyzed the nucleotide composition of genes with a special emphasis on stability of DNA sequences. Besides, in a variety of different organisms unequal use of synonymous codons, or codon usage bias, occurs which also show variation among genes in the same genome. Seemingly, codon usage bias is affected by both selective constraints and mutation bias which allows and enables us to examine and detect changes in these two evolutionary forces between genomes or along one genome. Therefore, we determined the codon adaptation index (CAI), effective number of codons (ENC) and codon usage analysis with calculation of the relative synonymous codon usage (RSCU), and subsequently predicted the translation efficiency and accuracy through GC-rich codon usages. Furthermore, we estimated the relative stability of the DNA sequence following calculation of the average free energy (Delta G) and Dimer base-stacking energy level.
sparkwarc,2017-01-10,sparkwarc: Load WARC Files into Apache Spark,Load WARC (Web ARChive) files into Apache Spark using 'sparklyr'. This
    allows to read files from the Common Crawl project <http://commoncrawl.org/>.
EBrank,2017-01-12,EBrank: Empirical Bayes Ranking,Empirical Bayes ranking applicable to parallel-estimation settings where the estimated parameters are asymptotically unbiased and normal, with known standard errors.  A mixture normal prior for each parameter is estimated using Empirical Bayes methods, subsequentially ranks for each parameter are simulated from the resulting joint posterior over all parameters (The marginal posterior densities for each parameter are assumed independent). Finally, experiments are ordered by expected posterior rank, although computations minimizing other plausible rank-loss functions are also given.  
rld,2017-01-12,rld: Analyze and Design Repeated Low-Dose Challenge Experiments,Analyzes data from repeated low-dose challenge experiments and provide vaccine efficacy estimates. In addition, this package can provide guidance to design repeated low-dose challenge studies.
zTree,2016-12-19,zTree: Functions to Import Data from 'z-Tree' into R,Read '.xls' and '.sbj' files which are written by the
   Microsoft Windows program 'z-Tree'. The latter is a software for
   developing and carrying out economic experiments
   (see <http://www.ztree.uzh.ch/> for more information).
esmisc,2017-01-11,esmisc: Misc Functions of Eduard Szöcs,Misc functions programmed by Eduard Szöcs. 
    Provides read_regnie() to read gridded precipitation data from German Weather 
    Service  (DWD, see <http://www.dwd.de/> for more information).
NetWeaver,2016-12-22,NetWeaver: Graphic Presentation of Complex Genomic and Network Data
Analysis,Implements various simple function utilities and flexible pipelines to generate circular images for visualizing complex genomic and network data analysis features.
QRank,2017-01-11,QRank: A Novel Quantile Regression Approach for eQTL Discovery,A Quantile Rank-score based test for the identification of expression quantitative trait loci.
BoolFilter,2017-01-09,BoolFilter: Optimal Estimation of Partially Observed Boolean Dynamical
Systems,Tools for optimal and approximate state estimation as well as
    network inference of Partially-Observed Boolean Dynamical Systems.
esaddle,2016-11-28,esaddle: Extended Empirical Saddlepoint Density Approximation,Tools for fitting the Extended Empirical Saddlepoint (EES) density.
rjsonapi,2017-01-09,rjsonapi: Consumer for APIs that Follow the JSON API Specification,Consumer for APIs that Follow the JSON API Specification
    (<http://jsonapi.org/>). Package mostly consumes data - with experimental
    support for serving JSON API data.
sysid,2017-01-07,sysid: System Identification in R,Provides functions for constructing mathematical models of dynamical systems from measured input-output data. 
BivRegBLS,2017-01-06,BivRegBLS: Tolerance Intervals and Errors-in-Variables Regressions in
Method Comparison Studies,Assess the agreement in method comparison studies by tolerance intervals and errors-in-variables regressions. The Ordinary Least Square regressions (OLSv and OLSh), the Deming Regression (DR), and the (Correlated)-Bivariate Least Square regressions (BLS and CBLS) can be used with unreplicated or replicated data. The BLS and CBLS are the two main functions to estimate a regression line, while XY.plot and MD.plot are the two main graphical functions to display, respectively an (X,Y) plot or (M,D) plot with the BLS or CBLS results. Assuming no proportional bias, the (M,D) plot (Band-Altman plot) may be simplified by calculating horizontal lines intervals with tolerance intervals (beta-expectation (type I) or beta-gamma content (type II)).
fabCI,2017-01-06,fabCI: FAB Confidence Intervals,Frequentist assisted by Bayes (FAB) confidence interval
    construction. See 'Adaptive multigroup confidence intervals with constant
    coverage' by Yu and Hoff <https://arxiv.org/abs/1612.08287>.
ltxsparklines,2016-12-27,ltxsparklines: Lightweight Sparklines for a LaTeX Document,Sparklines are small plots (about one line of text high),
  made popular by Edward Tufte.  This package is the interface from R
  to the LaTeX package sparklines by Andreas Loeffer and Dan Luecking
  (<http://www.ctan.org/pkg/sparklines>).  It can work with Sweave or
  knitr or other engines that produce TeX.  The package can be used to
  plot vectors, matrices, data frames, time series (in ts or zoo format).
Plasmidprofiler,2017-01-05,Plasmidprofiler: Visualization of Plasmid Profile Results,Contains functions developed to combine the results of querying a plasmid database using
    short-read sequence typing with the results of a blast analysis against the query results.
semver,2017-01-02,semver: 'Semantic Versioning V2.0.0' Parser,Tools and functions for parsing, rendering and operating on
    semantic version strings. Semantic versioning is a simple set of rules
    and requirements that dictate how version numbers are assigned and
    incremented as outlined at <http://semver.org>.
crisp,2017-01-05,crisp: Fits a Model that Partitions the Covariate Space into Blocks in
a Data- Adaptive Way,Implements convex regression with interpretable sharp partitions
    (CRISP), which considers the problem of predicting an outcome variable on the basis of two covariates, using an interpretable yet non-additive model. CRISP partitions the covariate space into blocks in a data-adaptive way, and fits a mean model within each block. Unlike other partitioning methods, CRISP is fit using a non-greedy approach by solving a convex optimization problem, resulting in low-variance fits. More details are provided in Petersen, A., Simon, N., and Witten, D. (2016). Convex Regression with Interpretable Sharp Partitions. Journal of Machine Learning Research, 17(94): 1-31 <http://jmlr.org/papers/volume17/15-344/15-344.pdf>.
FixSeqMTP,2016-12-01,FixSeqMTP: Fixed Sequence Multiple Testing Procedures,Several generalized / directional Fixed Sequence Multiple Testing
    Procedures (FSMTPs) are developed for testing a sequence of pre-ordered
    hypotheses while controlling the FWER, FDR and Directional Error (mdFWER).
    All three FWER controlling generalized FSMTPs are designed under arbitrary
    dependence, which allow any number of acceptances. Two FDR controlling
    generalized FSMTPs are respectively designed under arbitrary dependence and
    independence, which allow more but a given number of acceptances. Two mdFWER
    controlling directional FSMTPs are respectively designed under arbitrary
    dependence and independence, which can also make directional decisions based
    on the signs of the test statistics. The main functions for each proposed
    generalized / directional FSMTPs are designed to calculate adjusted p-values
    and critical values, respectively. For users' convenience, the functions also
    provide the output option for printing decision rules.
requireR,2016-12-11,requireR: R Source Code Modularizer,Modularizes source code. Keeps the global environment clean,
    explicifies interdependencies. Inspired by 'RequireJS'<http://requirejs.org/>.
dSVA,2017-01-04,dSVA: Direct Surrogate Variable Analysis,Functions for direct surrogate variable analysis, which can identify hidden factors in high-dimensional biomedical data.
HeritSeq,2017-01-04,HeritSeq: Heritability of Gene Expression for Next-Generation Sequencing,Statistical framework to analyze heritability of gene expression 
    based on next-generation sequencing data and simulating sequencing reads. 
    Variance partition coefficients (VPC) are computed using linear mixed effects 
    and generalized linear mixed effects models. Compound Poisson and negative 
    binomial models are included.
minimalRSD,2017-01-04,minimalRSD: Minimally Changed CCD and BBD,Generate central composite designs (CCD)with full as well 
    as fractional factorial points (half replicate) and Box Behnken 
    designs (BBD) with minimally changed run sequence.
Partiallyoverlapping,2017-01-04,Partiallyoverlapping: Partially Overlapping Samples t-Tests,The "partially overlapping samples t-tests", for the comparison
    of means for two samples which include both paired observations and independent
    observations. [See Derrick, B., Russ, B., Toher, D. & White P (2017). Test
    statistics for the comparison of means for two samples which include both paired
    observations and independent observations. Journal of Modern Applied Statistical
    Methods, 16(1)].
pwt9,2017-01-04,pwt9: Penn World Table (Version 9.x),The Penn World Table 9.x provides information on relative levels of
	income, output, inputs, and productivity for 182 countries
	between 1950 and 2014.
Redmonder,2017-01-04,Redmonder: Microsoft(r)-Inspired Color Palettes,Provide color schemes for maps (and other graphics) based on the
    color palettes of several Microsoft(r) products. Forked from 'RColorBrewer' v1.1-2.
tsdecomp,2017-01-04,tsdecomp: Decomposition of Time Series Data,ARIMA-model-based decomposition of quarterly and 
 monthly time series data.
 The methodology is developed and described, among others, in 
 Burman (1980) <doi:10.2307/2982132> and 
 Hillmer and Tiao (1982) <doi:10.2307/2287770>.
TSeriesMMA,2017-01-04,TSeriesMMA: Multiscale Multifractal Analysis of Time Series Data,Multiscale multifractal analysis (MMA) (Gieraltowski et al.,
    2012)<doi:10.1103/PhysRevE.85.021915> is a time series analysis method,
    designed to describe scaling properties of fluctuations within the signal
    analyzed. The main result of this procedure is the so called Hurst surface
    h(q,s) , which is a dependence of the local Hurst exponent h (fluctuation
    scaling exponent) on the multifractal parameter q and the scale of observation s
    (data window width).
colr,2017-01-03,colr: Functions to Select and Rename Data,Powerful functions to select and rename columns in dataframes, lists and numeric types 
  by 'Perl' regular expression. Regular expression ('regex') are a very powerful grammar to match 
  strings, such as column names. 
FTRLProximal,2016-11-11,FTRLProximal: FTRL Proximal Implementation for Elastic Net Regression,Implementation of Follow The Regularized Leader (FTRL) Proximal algorithm, proposed by McMahan et al. (2013) <doi:10.1145/2487575.2488200>, used for online training of large scale regression models using a mixture of L1 and L2 regularization.
natserv,2016-12-15,natserv: 'NatureServe' Interface,Interface to 'NatureServe' (<http://www.natureserve.org>).
    Includes methods to get data, image metadata, search taxonomic names,
    and make maps.
awsjavasdk,2017-01-01,awsjavasdk: Boilerplate R Access to the Amazon Web Services ('AWS') Java SDK,Provides boilerplate access to all of the classes included in the 
    Amazon Web Services ('AWS') Java Software Development Kit (SDK) via 
    package:'rJava'.  According to Amazon, the 'SDK helps take the complexity 
    out of coding by providing Java APIs for many AWS services including 
    Amazon S3, Amazon EC2, DynamoDB, and more'.  You can read more about the 
    included Java code on Amazon's website: 
    <https://aws.amazon.com/sdk-for-java/>.
censys,2016-12-31,censys: Tools to Query the 'Censys' API,The 'Censys' public search engine enables researchers to quickly ask 
    questions about the hosts and networks that compose the Internet. Details on how 
    'Censys' was designed and how it is operated are available at <https://www.censys.io/about>. 
    Both basic and extended research access queries are made available. More information 
    on the SQL dialect used by the 'Censys' engine can be found at 
    <https://cloud.google.com/bigquery/docs/reference/legacy-sql>.
hds,2016-12-31,hds: Hazard Discrimination Summary,Functions for calculating the hazard discrimination summary and its
    standard errors, as described in Liang and Heagerty (2016) <doi:10.1111/biom.12628>.
bossMaps,2016-12-30,bossMaps: Convert Binary Species Range Maps into Continuous Surfaces Based
on Distance to Range Edge,Contains functions to convert binary (presence-absence) expert species range maps (like those found in a field guide) into continuous surfaces based on distance to range edge.  These maps can then be used in species distribution models such as Maximum Entropy (Phillips 2008 <doi:10.1111/j.0906-7590.2008.5203.x>) using additional information (such as point occurrence data) to refine the expert map.
attrCUSUM,2016-12-28,attrCUSUM: Tools for Attribute VSI CUSUM Control Chart,An implementation of tools for design of attribute 
  variable sampling interval cumulative sum chart. 
  It currently provides information for monitoring of mean increase such as 
  average number of sample to signal, average time to signal,
  a matrix of transient probabilities, suitable control limits when the data are
  (zero inflated) Poisson/binomial distribution. 
  Functions in the tools can be easily applied to other count processes.
  Also, tools might be extended to more complicated cumulative sum control chart.
  We leave these issues as our perpetual work.
acrt,2016-12-18,acrt: Autocorrelation Robust Testing,Functions for testing affine hypotheses on the regression coefficient vector in regression models with autocorrelated errors. 
bayesloglin,2016-12-19,bayesloglin: Bayesian Analysis of Contingency Table Data,The function MC3() searches for log-linear models with the highest posterior probability. The function gibbsSampler() is a blocked Gibbs sampler for sampling from the posterior distribution of the log-linear parameters. The functions findPostMean() and findPostCov() compute the posterior mean and covariance matrix for decomposable models which, for these models, is available in closed form.
DStree,2016-12-27,DStree: Recursive Partitioning for Discrete-Time Survival Trees,Building discrete-time survival trees and bagged trees based on
    the functionalities of the rpart package. Splitting criterion maximizes the
    likelihood of a covariate-free logistic discrete time hazard model.
KTensorGraphs,2016-12-27,KTensorGraphs: Co-Tucker3 Analysis of Two Sequences of Matrices,Provides a function called COTUCKER3() (Co-Inertia Analysis
    + Tucker3 method) which performs a Co-Tucker3 analysis of two sequences of
    matrices, as well as other functions called PCA() (Principal Component Analysis)
    and BGA() (Between-Groups Analysis), which perform analysis of one matrix,
    COIA() (Co-Inertia Analysis), which performs analysis of two matrices, PTA()
    (Partial Triadic Analysis) and TUCKER3(), which perform analysis of a sequence
    of matrices, and BGCOIA() (Between-Groups Co-Inertia Analysis), STATICO()
    (STATIS method + Co-Inertia Analysis), COSTATIS() (Co-Inertia Analysis + STATIS
    method), which also perform analysis of two sequences of matrices.
restrictedMVN,2016-12-27,restrictedMVN: Multivariate Normal Restricted by Affine Constraints,A fast Gibbs sampler for multivariate normal with affine constraints.
rFTRLProximal,2016-12-27,rFTRLProximal: FTRL-Proximal Algorithm,An efficient C++ based implementation of "Follow The (Proximally) Regularized Leader" online learning algorithm.
  This algorithm was proposed in McMahan et al. (2013) <doi:10.1145/2487575.2488200>.
spark.sas7bdat,2016-11-18,spark.sas7bdat: Read in 'SAS' Data ('.sas7bdat' Files) into 'Apache Spark',Read in 'SAS' Data ('.sas7bdat' Files) into 'Apache Spark' from R. 'Apache Spark' is an open source cluster computing framework available at <http://spark.apache.org>. This R package uses the 'spark-sas7bdat' 'Spark' package (<https://spark-packages.org/package/saurfang/spark-sas7bdat>) to import and process 'SAS' data in parallel using 'Spark'. Hereby allowing to execute 'dplyr' statements in parallel on top of 'SAS' data.
UStatBookABSC,2016-12-27,UStatBookABSC: A Companion Package to the Book "U-Statistics, M-Estimation and
Resampling",A set of functions leading to multivariate response L1 regression. 
    This includes functions on computing Euclidean inner products and norms, 
    weighted least squares estimates on multivariate responses, function to compute 
    fitted values and residuals. This package is a companion to the book "U-Statistics,
    M-estimation and Resampling", by Arup Bose and Snigdhansu Chatterjee, to appear 
    in 2017 as part of the "Texts and Readings in Mathematics" (TRIM) series of 
    Hindustan Book Agency and Springer-Verlag.
DISTRIB,2016-12-26,DISTRIB: Four Essential Functions for Statistical Distributions Analysis:
A New Functional Approach,A different way for calculating pdf/pmf, cdf, quantile and random data such that the user is able to consider the name of related distribution as an argument and so easily can changed by a changing argument by user. It must be mentioned that the core and computation base of package 'DISTRIB' is package 'stats'. Although similar functions are introduced previously in package 'stats', but the package 'DISTRIB' has some special applications in some special computational programs.
factorcpt,2016-12-16,factorcpt: Simultaneous Change-Point and Factor Analysis,Identifies change-points in the common and the idiosyncratic components via factor modelling.
utf8latex,2016-12-26,utf8latex: Importing, Exporting and Converting Between Datasets and LaTeX,Methods to assist with importing data stored in text files with Unicode characters and to convert text or data with foreign characters or mathematical symbols to LaTeX. It also escapes UTF8 code points (fixing the "warning: found non-ASCII strings" problem), detects languages, encodings and more.  
findviews,2016-10-09,findviews: A View Generator for Multidimensional Data,A tool to explore wide data sets, by detecting, ranking
    and plotting groups of statistically dependent columns.
ggguitar,2016-11-30,ggguitar: Utilities for Creating Guitar Tablature,Utilities for Creating Guitar Tablature using tidyverse packages.
ROI.models.netlib,2016-12-23,ROI.models.netlib: 'ROI' Optimization Problems Based on 'NETLIB-LP',A collection of 'ROI' optimization problems based on the 'NETLIB-LP' collection.
  'Netlib' is a software repository, which amongst many other software for scientific computing contains a collection of linear programming problems. The purpose of this package is to make 
  this problems easily accessible from 'R' as 'ROI' optimization problems.
ztype,2016-12-23,ztype: Run a Ztype Game Loaded with R Functions,How fast can you type R functions on your keyboard? Find out by running a 'zty.pe' game: export R functions as instructions to type to destroy opponents vessels.
crosstalk,2016-12-21,crosstalk: Inter-Widget Interactivity for HTML Widgets,Provides building blocks for allowing HTML widgets to communicate
    with each other, with Shiny or without (i.e. static .html files). Currently
    supports linked brushing and filtering.
pgee.mixed,2016-12-21,pgee.mixed: Penalized Generalized Estimating Equations for Bivariate Mixed
Outcomes,Perform simultaneous estimation and variable selection for correlated bivariate
    mixed outcomes (one continuous outcome and one binary outcome per cluster) using
    penalized generalized estimating equations. In addition, clustered Gaussian and binary
    outcomes can also be modeled. The SCAD, MCP, and LASSO penalties are supported.
    Cross-validation can be performed to find the optimal regularization parameter(s).
rocNIT,2016-12-21,rocNIT: Non-Inferiority Test for Paired ROC Curves,
  Non-inferiority test and diagnostic test are very important in clinical trails.
  This package is to get a p value from the non-inferiority test for ROC curves from diagnostic test.   
SpaTimeClus,2016-12-21,SpaTimeClus: Model-Based Clustering of Spatio-Temporal Data,Mixture model is used to achieve the clustering goal. Each component is itself a mixture model of polynomial autoregressive regressions whose the logistic weights consider the spatial and temporal information.
aws.ses,2016-12-20,aws.ses: AWS SES Client Package,A simple client package for the Amazon Web Services (AWS) Simple
    Email Service (SES) <http://aws.amazon.com/ses/> REST API.
SPPcomb,2016-12-20,SPPcomb: Combining Different Spatial Datasets in Cancer Risk Estimation,We propose a novel two-step procedure to combine epidemiological
    data obtained from diverse sources with the aim to quantify risk factors
    affecting the probability that an individual develops certain disease such as
    cancer. See  Hui Huang, Xiaomei Ma, Rasmus Waagepetersen, Theodore R. Holford,
    Rong Wang, Harvey Risch, Lloyd Mueller & Yongtao Guan (2014) A New Estimation Approach
    for Combining Epidemiological Data From Multiple Sources, Journal of the American Statistical
    Association, 109:505, 11-23,  <doi:10.1080/01621459.2013.870904>.
stmgui,2016-11-27,stmgui: Shiny Application for Creating STM Models,Provides an application that acts as a GUI for the 'stm' text analysis package.
pipeliner,2016-12-16,pipeliner: Machine Learning Pipelines for R,A framework for defining 'pipelines' of functions for applying data transformations, 
  model estimation and inverse-transformations, resulting in predicted value generation (or 
  model-scoring) functions that automatically apply the entire pipeline of functions required to go
  from input to predicted output.
DirectStandardisation,2016-10-17,DirectStandardisation: Adjusted Means and Proportions by Direct Standardisation,Calculate adjusted means and proportions of a variable by groups defined by another variable by direct standardisation, standardised to the structure of the dataset.
magicfor,2016-12-18,magicfor: Magic Functions to Obtain Results from for Loops,Magic functions to obtain results from for loops.
MTDrh,2016-12-17,MTDrh: Mass Transportation Distance Rank Histogram,The Mass Transportation Distance rank histogram was developed to assess the reliability of scenarios with equal or different probabilities of occurrence <doi:10.1002/we.1872>.
MWRidge,2016-12-17,MWRidge: Two Stage Moving-Window Ridge Method for Prediction and
Estimation,A two stage moving-window Ridge method for coefficients estimation and model prediction. In the first stage, moving-window penalty and L1 penalty are applied. In the second stage, ridge regression is applied.
PepSAVIms,2016-12-03,PepSAVIms: PepSAVI-MS Data Analysis,An implementation of the data processing and data analysis portion
    of a pipeline named the PepSAVI-MS which is currently under development by
    the Hicks laboratory at the University of North Carolina.  The statistical
    analysis package presented herein provides a collection of software tools
    used to facilitate the prioritization of putative bioactive peptides from a
    complex biological matrix.  Tools are provided to deconvolute mass
    spectrometry features into a single representation for each peptide charge
    state, filter compounds to include only those possibly contributing to the
    observed bioactivity, and prioritize these remaining compounds for those
    most likely contributing to each bioactivity data set.
FinancialMath,2016-12-13,FinancialMath: Financial Mathematics for Actuaries,Contains financial math functions and introductory derivative functions included in the Society of Actuaries and Casualty Actuarial Society 'Financial Mathematics' exam, and some topics in the 'Models for Financial Economics' exam.
coprimary,2016-12-15,coprimary: Sample Size Calculation for Two Primary Time-to-Event Endpoints
in Clinical Trials,Computes the required number of patients for two time-to-event end-points as primary endpoint in phase III clinical trial.
BTYDplus,2016-12-14,BTYDplus: Probabilistic Models for Assessing and Predicting your Customer
Base,Provides advanced statistical methods to describe and predict customers'
  purchase behavior in a non-contractual setting. It uses historic transaction records to fit a
  probabilistic model, which then allows to compute quantities of managerial interest on a cohort-
  as well as on a customer level (Customer Lifetime Value, Customer Equity, P(alive), etc.). This
  package complements the BTYD package by providing several additional buy-till-you-die models, that
  have been published in the marketing literature, but whose implementation are complex and non-trivial.
  These models are: NBD, MBG/NBD, BG/CNBD-k, MBG/CNBD-k, Pareto/NBD (HB), Pareto/NBD (Abe) and Pareto/GGG.
bpp,2016-12-13,bpp: Computations Around Bayesian Predictive Power,Implements functions to update Bayesian Predictive Power Computations after not stopping a clinical trial at an interim analysis. Such an interim analysis can either be blinded or unblinded. Code is provided for Normally distributed endpoints with known variance, with a prominent example being the hazard ratio.
MODISSnow,2016-12-13,MODISSnow: Provides a Function to Download MODIS Snow Cover,Package for downloading Moderate-resolution Imaging Spectroradiometer (MODIS) snow cover data. Global daily snow cover at 500 m resolution derived from MODIS is made available by the National Snow and Ice Center Data Center <http://nsidc.org/>.
poptrend,2016-12-13,poptrend: Estimate Smooth and Linear Trends from Population Count Survey
Data,Functions to estimate and plot smooth or linear population trends, or population indices, 
    from animal or plant count survey data.
ampd,2016-11-03,ampd: An Algorithm for Automatic Peak Detection in Noisy Periodic and
Quasi-Periodic Signals,A method for automatic detection of peaks in noisy periodic and quasi-periodic signals. This method, called automatic multiscale-based peak detection (AMPD), is based on the calculation and analysis of the local maxima scalogram, a matrix comprising the scale-dependent occurrences of local maxima.
     For further information see  <doi:10.3390/a5040588>.
DNLC,2016-12-11,DNLC: Differential Network Local Consistency Analysis,Using Local Moran's I for detection of differential network local consistency.
errorizer,2016-11-06,errorizer: Function Errorizer,Provides a function to convert existing R functions into "errorized" versions 
    with added logging and handling functionality when encountering errors or warnings. 
    The errorize function accepts an existing R function as its first argument and 
    returns a R function with the exact same arguments and functionality. However, 
    if an error or warning occurs when running that "errorized" R function, it will save a 
    .Rds file to the current working directory with the relevant objects and information 
    required to immediately recreate the error.  
rtrends,2016-12-10,rtrends: Analyze Download Logs from the CRAN RStudio Mirror,Analyze download logs from the CRAN RStudio mirror 
            (<http://cran.rstudio.com/>). 
            This CRAN mirror is the default one used in RStudio.
            The available data is the result of parsed and anonymised raw log data from
            that CRAN mirror.
CuCubes,2016-12-09,CuCubes: MultiDimensional Feature Selection (MDFS),Functions for MultiDimensional Feature Selection (MDFS):
    * calculating multidimensional information gains,
    * finding interesting tuples for chosen variables,
    * scoring variables,
	* finding important variables,
	* plotting selection results.
	CuCubes is also known as CUDA Cubes and it is a library that allows fast
	CUDA-accelerated computation of information gains in binary classification
	problems.
	This package wraps CuCubes and provides an alternative CPU version as well
	as helper functions for building MultiDimensional Feature Selectors.
GLMaSPU,2016-12-09,GLMaSPU: An Adaptive Test on High Dimensional Parameters in Generalized
Linear Models,Several tests for high dimensional generalized linear models have been proposed recently. In this package, we implemented a new test called adaptive  sum of powered score (aSPU) for high dimensional generalized linear models, which is often more powerful than the existing methods in a wide scenarios. We also implemented permutation based version of several existing methods for research purpose. We recommend users use the aSPU test for their real testing problem. You can learn more about the tests implemented in the package via the following papers: 1. Pan, W., Kim, J., Zhang, Y., Shen, X. and Wei, P. (2014) <doi:10.1534/genetics.114.165035> A powerful and adaptive association test for rare variants, Genetics, 197(4). 2. Guo, B., and Chen, S. X. (2016) <doi:10.1111/rssb.12152>. Tests for high dimensional generalized linear models. Journal of the Royal Statistical Society: Series B. 3. Goeman, J. J., Van Houwelingen, H. C., and Finos, L. (2011) <doi:10.1093/biomet/asr016>. Testing against a high-dimensional alternative in the generalized linear model: asymptotic type I error control. Biometrika, 98(2).
magree,2016-12-09,magree: Implements the O'Connell-Dobson-Schouten Estimators of Agreement
for Multiple Observers,Implements an interface to the legacy Fortran code from O'Connell and Dobson (1984) <doi:10.2307/2531148>. Implements Fortran 77 code for the methods developed by Schouten (1982) <doi:10.1111/j.1467-9574.1982.tb00774.x>. Includes estimates of average agreement for each observer and average agreement for each subject.
rrr,2016-12-09,rrr: Reduced-Rank Regression,Reduced-rank regression, diagnostics and graphics.
aws.polly,2016-12-08,aws.polly: Client for AWS Polly,A client for AWS Polly <http://aws.amazon.com/documentation/polly>, a speech synthesis service.
gofMC,2016-12-08,gofMC: Goodness of Fit Noise Analysis Using Monte Carlo Techniques,Goodness-of-fit metrics, such as R-Squared, RMSE, etc., share a sensitivity to noise, dependent on the degrees of freedom.  Some metrics, such as R-Squared, decrease with increasing dof and some, such as RMSE, increase with increasing dof.  This package calculates the noise baseline (ceiling) by random sampling, calculating the metric’s value for each sample and counting the number of samples below a desired level, 95% by default. If one’s measure is above (below) the calculation corresponding to the desired level, then the measurement is distinguishable from noise.  In addition, the ratio of the measurement to the calculated level provides a way to compare measurements of different degrees of freedom. 
Radviz,2016-12-08,Radviz: Project Multidimensional Data in 2D Space,An implementation of the radviz projection in R. It enables the visualization of
    multidimensional data while maintaining the relation to the original dimensions.
    This package provides functions to create and plot radviz projections, and a number of summary
    plots that enable comparison and analysis. For reference see Ankerst et al. (1996) 
    <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.68.1811> for original implementation, 
    see Di Caro et al. (2010) <doi:10.1007/978-3-642-13672-6_13> for the original method for dimensional
    anchor arrangements.
DCM,2016-12-04,DCM: Data Converter Module,Data Converter Module (DCM) converts the dataset format from split into stack and to the reverse.
icesVocab,2016-12-06,icesVocab: ICES Vocabularies Database Web Services,R interface to access the RECO POX web services of the ICES (International
             Council for the Exploration of the Sea) Vocabularies database <http://vocab.ices.dk/services/POX.aspx>.
rccmisc,2016-12-06,rccmisc: Miscellaneous R Functions for Swedish Regional Cancer Centers,Functions either required by other Swedish Regional Cancer Center packages or standalone functions outside the scope of other packages.
robustsae,2016-12-06,robustsae: Robust Bayesian Small Area Estimation,Functions for Robust Bayesian Small Area Estimation.
AmmoniaConcentration,2016-12-05,AmmoniaConcentration: Un-Ionized Ammonia Concentration,Provides a function to calculate the concentration of un-ionized ammonia in the total ammonia in aqueous solution using the pH and temperature values.
bannerCommenter,2016-12-05,bannerCommenter: Make Banner Comments with a Consistent Format,A convenience package for use while drafting code.
    It facilitates making stand-out comment lines decorated with
    bands of characters.  The input text strings are converted into
    R comment lines, suitably formatted. These are then displayed in
    a console window and, if possible, automatically transferred to a
    clipboard ready for pasting into an R script.  Designed to save
    time when drafting R scripts that will need to be navigated and
    maintained by other programmers.
bridger2,2016-12-05,bridger2: Genome-Wide RNA Degradation Analysis Using BRIC-Seq Data,BRIC-seq is a genome-wide approach for determining RNA stability in mammalian cells.
    This package provides a series of functions for performing quality check of your BRIC-seq data,
    calculation of RNA half-life for each transcript and comparison of RNA half-lives between two conditions.
easypackages,2016-12-05,easypackages: Easy Loading and Installing of Packages,Easily load and install multiple packages from different sources, 
    including CRAN and GitHub. The libraries function allows you to load or attach 
    multiple packages in the same function call. The packages function will load one 
    or more packages, and install any packages that are not installed on your system 
    (after prompting you). Also included is a from_import function that allows you 
    to import specific functions from a package into the global environment.
melviewr,2016-12-05,melviewr: View and Classify MELODIC Output for ICA+FIX,Provides a graphical interface that allows the user to easily view 
    and classify output from 'MELODIC', a part of the 'FSL' neuroimaging analysis
    software suite that performs independent component analysis (ICA; see 
    <https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/MELODIC/> for more information). The 
    user categorizes a component as signal or noise based on its spatial and 
    temporal characteristics and can then save a text file of these 
    classifications in the format required by 'ICA+FIX', an automatic noise 
    removal tool (<https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FIX>).
MultiBD,2016-12-05,MultiBD: Multivariate Birth-Death Processes,Computationally efficient functions to provide direct likelihood-based
    inference for partially-observed multivariate birth-death processes.  Such processes
    range from a simple Yule model to the complex susceptible-infectious-removed model
    in disease dynamics.  Efficient likelihood evaluation facilitates maximum likelihood
    estimation and Bayesian inference.
optigrab,2016-12-05,optigrab: Command-Line Parsing for an R World,Parse options from the command-line using a simple, clean syntax. 
    It requires little or no specification and supports short and long options,
    GNU-, Java- or Microsoft- style syntaxes, verb commands and more. 
PANDA,2016-12-05,PANDA: Preferential Attachment Based Common Neighbor Distribution
Derived Functional Associations,PANDA (Preferential Attachment based common Neighbor Distribution derived Associations) is designed to perform the following tasks in PPI networks: (1) identify significantly functionally associated protein pairs, (2) predict GO terms and KEGG pathways for proteins, (3) make a cluster of proteins based on the significant protein pairs, (4) identify subclusters whose members are enriched in KEGG pathways. For other types of biological networks, (1) and (3) can still be performed.
rt3,2016-12-05,rt3: Tic-Tac-Toe Package for R,Play the classic game of tic-tac-toe (naughts and crosses).
tswge,2016-12-05,tswge: Applied Time Series Analysis,Accompanies the text Applied Time Series Analysis with R, 2nd edition by Woodward, Gray, and Elliott. It is helpful for data analysis and for time series instruction.
phuassess,2016-10-22,phuassess: Proportional Habitat Use Assessment,Assessment of habitat selection by means of the permutation-based combination of sign tests (Fattorini et al., 2014 <doi:10.1007/s10651-013-0250-7>). To exemplify the application of this procedure, habitat selection is assessed for a population of European Brown Hares settled in central Italy.
SISIR,2016-12-04,SISIR: Sparse Interval Sliced Inverse Regression,An interval fusion procedure for functional data in the
             semiparametric framework of SIR. Standard ridge and sparse SIR are 
             also included in the package.
rhnerm,2016-12-03,rhnerm: Random Heteroscedastic Nested Error Regression,Performs the random heteroscedastic nested error regression model described in Kubokawa, Sugasawa, Ghosh and Chaudhuri (2016) <doi:10.5705/ss.202014.0070>.
ClimDown,2016-12-02,ClimDown: Climate Downscaling Library for Daily Climate Model Output,A suite of routines for downscaling coarse scale global
    climate model (GCM) output to a fine spatial resolution. Includes
    Bias-Corrected Spatial Downscaling (BCDS), Constructed Analogues
    (CA), Climate Imprint (CI), and Bias Correction/Constructed
    Analogues with Quantile mapping reordering (BCCAQ). Developed by
    the the Pacific Climate Impacts Consortium (PCIC), Victoria,
    British Columbia, Canada.
vkR,2016-12-02,vkR: Access to VK API via R,Provides an interface to the VK API <https://vk.com/dev/methods>.
      VK <https://vk.com/> is the largest European online social networking
      service, based in Russia.
deconvolveR,2016-12-01,deconvolveR: Empirical Bayes Estimation Strategies,Empirical Bayes methods for learning prior distributions from data.
    An unknown prior distribution (g) has yielded (unobservable) parameters, each of
    which produces a data point from a parametric exponential family (f). The goal
    is to estimate the unknown prior ("g-modeling") by deconvolution and Empirical
    Bayes methods.
freqdist,2016-12-01,freqdist: Frequency Distribution,Generates a frequency distribution. The frequency
    distribution includes raw frequencies, percentages in each category, and
    cumulative frequencies. The frequency distribution can be stored as a data
    frame.
gbs2ploidy,2016-12-01,gbs2ploidy: Inference of Ploidy from (Genotyping-by-Sequencing) GBS Data,Functions for inference of ploidy from (Genotyping-by-sequencing) GBS data, including a function to infer allelic ratios and allelic proportions in a Bayesian framework. 
rxSeq,2016-12-01,rxSeq: Combined Total and Allele Specific Reads Sequencing Study,Analysis of combined total and allele specific reads from the reciprocal cross study with RNA-seq data.  
camsRad,2016-11-30,camsRad: Client for CAMS Radiation Service,Copernicus Atmosphere Monitoring Service (CAMS) radiations service 
    provides time series of global, direct, and diffuse irradiations on horizontal
    surface, and direct irradiation on normal plane for the actual weather 
    conditions as well as for clear-sky conditions.
    The geographical coverage is the field-of-view of the Meteosat satellite,
    roughly speaking Europe, Africa, Atlantic Ocean, Middle East. The time coverage
    of data is from 2004-02-01 up to 2 days ago. Data are available with a time step
    ranging from 15 min to 1 month. For license terms and to create an account,
    please see <http://www.soda-pro.com/web-services/radiation/cams-radiation-service>. 
eMLEloglin,2016-11-24,eMLEloglin: Fitting log-Linear Models in Sparse Contingency Tables,Log-linear modeling is a popular method for the analysis of contingency table data. When the table is sparse, the data can fall on the boundary of the convex support, and we say that "the MLE does not exist" in the sense that some parameters cannot be estimated. However, an extended MLE always exists, and a subset of the original parameters will be estimable. The 'eMLEloglin' package determines which sampling zeros contribute to the non-existence of the MLE. These problematic zero cells can be removed from the contingency table and the model can then be fit (as far as is possible) using the glm() function.
effectFusion,2016-11-29,effectFusion: Bayesian Effect Fusion for Categorical Predictors,Variable selection and Bayesian effect fusion for categorical predictors in linear regression models. Effect fusion aims at the question which categories have a similar effect on the response and therefore can be fused to obtain a sparser representation of the model. Effect fusion and variable selection can be obtained either with a prior that has an interpretation as spike and slab prior on the level effect differences or with a sparse finite mixture prior on the level effects. The regression coefficients are estimated with a flat uninformative prior after model selection or model averaged. For posterior inference, an MCMC sampling scheme is used that involves only Gibbs sampling steps.
listdtr,2016-11-29,listdtr: List-Based Rules for Dynamic Treatment Regimes,Construction of list-based rules, i.e. a list of if-then clauses, to estimate the optimal dynamic treatment regime.
Przewodnik,2016-11-29,Przewodnik: Datasets and Functions Used in the Book 'Przewodnik po Pakiecie
R',Data sets and functions used in the polish book 
    "Przewodnik po pakiecie R" (The Hitchhiker's Guide to the R). 
    See more at <http://biecek.pl/R>. Among others you will find here 
    data about housing prices, cancer patients, running times and many others.
testassay,2016-11-29,testassay: A Hypothesis Testing Framework for Validating an Assay for
Precision,A common way of validating a biological assay for is through a
    procedure, where m levels of an analyte are measured with n replicates at each
    level, and if all m estimates of the coefficient of variation (CV) are less
    than some prespecified level, then the assay is declared validated for precision
    within the range of the m analyte levels. Two limitations of this procedure are:
    there is no clear statistical statement of precision upon passing, and it is
    unclear how to modify the procedure for assays with constant standard deviation.
    We provide tools to convert such a procedure into a set of m hypothesis tests.
    This reframing motivates the m:n:q procedure, which upon completion delivers
    a 100q% upper confidence limit on the CV. Additionally, for a post-validation
    assay output of y, the method gives an “effective standard deviation interval”
    of log(y) plus or minus r, which is a 68% confidence interval on log(mu), where
    mu is the expected value of the assay output for that sample. Further, the m:n:q
    procedure can be straightforwardly applied to constant standard deviation assays.
    We illustrate these tools by applying them to a growth inhibition assay.
tsdisagg2,2016-11-29,tsdisagg2: Time Series Disaggregation,Disaggregates low frequency time series data to higher frequency series. Implements the following methods for temporal disaggregation: Boot, Feibes and Lisman (1967) <doi:10.2307/2985238>, Chow and Lin (1971) <doi:10.2307/1928739>, Fernandez (1981) <doi:10.2307/1924371> and Litterman (1983) <doi:10.2307/1391858>.
GeomComb,2016-11-27,GeomComb: (Geometric) Forecast Combination Methods,Provides eigenvector-based (geometric) forecast
    combination methods; also includes simple approaches (simple average,
    median, trimmed and winsorized mean, inverse rank method) and regression-based
    combination. Tools for data pre-processing are available in order to deal with 
    common problems in forecast combination (missingness, collinearity).
notifyme,2016-11-12,notifyme: Send Alerts to your Cellphone and Phillips Hue Lights,Functions to flash your hue lights, or text yourself, from R. Designed to be used with long running scripts.
aslib,2016-11-25,aslib: Interface to the Algorithm Selection Benchmark Library,Provides an interface to the algorithm selection benchmark library
    at <http://www.aslib.net> and the 'LLAMA' package
    (<https://cran.r-project.org/web/packages/llama/index.html>) for building
    algorithm selection models.
dynetNLAResistance,2016-11-25,dynetNLAResistance: Resisting Neighbor Label Attack in a Dynamic Network,An anonymization algorithm to resist neighbor label attack in a dynamic network.
rIsing,2016-11-25,rIsing: High-Dimensional Ising Model Selection,Fits an Ising model to a binary dataset using L1 regularized
    logistic regression and extended BIC. Also includes a fast lasso logistic
    regression function for high-dimensional problems. Uses the 'libLBFGS'
    optimization library by Naoaki Okazaki.
rlo,2016-11-25,rlo: Utilities for Writing to 'LibreOffice Writer' Documents,Utilities for writing to 'LibreOffice Writer'
  (see  <https://www.libreoffice.org/discover/writer/> for more information)
   documents using the 'Python-UNO' bridge.
survAWKMT2,2016-11-25,survAWKMT2: Two-Sample Tests Based on Differences of Kaplan-Meier Curves,Tests for equality of two survival functions based on integrated weighted differences of two Kaplan-Meier curves.
quarrint,2016-11-24,quarrint: Interaction Prediction Between Groundwater and Quarry Extension
Using Discrete Choice Models and Artificial Neural Networks,An implementation of two interaction indices between extractive
    activity and groundwater resources based on hazard and vulnerability
    parameters used in the assessment of natural hazards. One index is based
    on a discrete choice model and the other is relying on an artificial
    neural network.
RDStreeboot,2016-11-24,RDStreeboot: RDS Tree Bootstrap Method,A tree bootstrap method for estimating uncertainty in respondent-driven samples (RDS). Quantiles are estimated by multilevel resampling in such a way that preserves the dependencies of and accounts for the high variability of the RDS process.
epistasis,2016-11-07,epistasis: Detecting Epistatic Selection with Partially Observed Genotype
Data,An efficient multi-core package to reconstruct an underlying network of
             genomic signatures of high-dimensional epistatic selection from 
             partially observed genotype data. The phenotype that we consider is viability. 
			 The network captures the conditional dependent short- and long-range linkage 
			 disequilibrium structure of genomes and thus reveals aberrant marker-marker 
			 associations that are due to epistatic selection. We target on high-dimensional
			 genotype data where number of variables (markers) is larger than number of 
			 sample sizes (p >> n). The computations is memory-optimized using the sparse 
			 matrix output.
SpaCCr,2016-11-23,SpaCCr: Spatial Convex Clustering,Genomic Region Detection via Spatial Convex Clustering. See <https://arxiv.org/abs/1611.04696> for details.
strat,2016-11-23,strat: An Implementation of the Stratification Index,An implementation of the stratification index proposed by Zhou (2012) <doi:10.1177/0081175012452207>.
  The package provides two functions, srank, which returns stratum-specific
  information, including population share and average percentile rank; and strat,
  which returns the stratification index and its approximate standard error.
  When a grouping factor is specified, strat also provides a detailed decomposition
  of the overall stratification into between-group and within-group components.
mbclusterwise,2016-11-22,mbclusterwise: Clusterwise Multiblock Analyses,Perform clusterwise multiblock analyses (clusterwise multiblock Partial Least Squares, clusterwise multiblock Redundancy Analysis or a regularized method between the two latter ones) associated with a F-fold cross-validation procedure to select the optimal number of clusters and dimensions.
ockc,2016-11-22,ockc: Order Constrained Solutions in k-Means Clustering,Extends 'flexclust' with an R implementation of order constrained
  solutions in k-means clustering (Steinley and Hubert, 2008, <doi:10.1007/s11336-008-9058-z>).
Rdtq,2016-11-22,Rdtq: Density Tracking by Quadrature,Implementation of density tracking by quadrature (DTQ) algorithms for stochastic differential equations (SDEs).  DTQ algorithms numerically compute the density function of the solution of an SDE with user-specified drift and diffusion functions.  The calculation does not require generation of sample paths, but instead proceeds in a deterministic fashion by repeatedly applying quadrature to the Chapman-Kolmogorov equation associated with a discrete-time approximation of the SDE.  The DTQ algorithm is provably convergent.  For several practical problems of interest, we have found the DTQ algorithm to be fast, accurate, and easy to use.
pstest,2016-11-21,pstest: Specification Tests for Parametric Propensity Score Models,The propensity score is one of the most widely used tools in studying the causal effect
    of a treatment, intervention, or policy. Given that the propensity score is usually unknown,
    it has to be estimated, implying that the reliability of many treatment effect estimators depends
    on the correct specification of the (parametric) propensity score. This package provides
    data-driven nonparametric diagnostic tools for detecting propensity score misspecification.
relabeLoadings,2016-11-21,relabeLoadings: Relabel Loadings from MCMC Output for Confirmatory Factor
Analysis,In confirmatory factor analysis (CFA), structural constraints
    typically ensure that the model is identified up to all possible reflections,
    i.e., column sign changes of the matrix of loadings. Such reflection invariance
    is problematic for Bayesian CFA when the reflection modes are not well separated
    in the posterior distribution. Imposing rotational constraints – fixing
    some loadings to be zero or positive in order to pick a factor solution that
    corresponds to one reflection mode – may not provide a satisfactory solution
    for Bayesian CFA. The function 'relabel' uses the relabeling algorithm of
    Erosheva and Curtis to correct for sign invariance in MCMC draws from CFA
    models. The MCMC draws should come from Bayesian CFA models that are fit without
    rotational constraints.
ADCT,2016-11-20,ADCT: Adaptive Design in Clinical Trials,Existing adaptive design methods in clinical trials. The package
    includes power, stopping boundaries (sample size) calculation functions for
    two-group group sequential designs, adaptive design with coprimary endpoints,
    biomarker-informed adaptive design, etc.
climbeR,2016-11-19,climbeR: Calculate Average Minimal Depth of a Maximal Subtree for
'ranger' Package Forests,Calculates first, and second order, average minimal depth of a
    maximal subtree for a forest object produced by the R 'ranger'
    package. This variable importance metric is implemented as described in
    Ishwaran et. al. ("High-Dimensional Variable Selection for Survival Data",
    March 2010, <doi:10.1198/jasa.2009.tm08622>).
DGCA,2016-11-17,DGCA: Differential Gene Correlation Analysis,Performs differential correlation analysis on input
    matrices, with multiple conditions specified by a design matrix. Contains
    functions to filter, process, save, visualize, and interpret differential
    correlations of identifier-pairs across the entire identifier space, or with
    respect to a particular set of identifiers (e.g., one). Also contains several
    functions to perform differential correlation analysis on clusters (i.e., modules)
    or genes. Finally, it contains functions to generate empirical p-values for the
    hypothesis tests and adjust them for multiple comparisons. Although the package
    was built with gene expression data in mind, it is applicable to other types of
    genomics data as well, in addition to being potentially applicable to data from
    other fields entirely. It is described more fully in the manuscript
    introducing it, freely available at <doi:10.1186/s12918-016-0349-1>.
gwfa,2016-11-17,gwfa: Geographically Weighted Fractal Analysis,Performs Geographically Weighted Fractal Analysis (GWFA) to calculate the local fractal dimension of a set of points. GWFA mixes the Sandbox multifractal algorithm and the Geographically Weighted Regression. Unlike fractal box-counting algorithm, the sandbox algorithm avoids border effects because the boxes are adjusted on the set of points. The Geographically Weighted approach consists in applying a kernel that describes the way the neighbourhood of each estimated point is taken into account to estimate its fractal dimension. GWFA can be used to discriminate built patterns of a city, a region, or a whole country.
NegBinBetaBinreg,2016-11-17,NegBinBetaBinreg: Negative Binomial and Beta Binomial Bayesian Regression Models,The Negative Binomial regression with mean and shape modeling and mean and variance modeling and Beta Binomial regression with mean and dispersion modeling.
tinsel,2016-11-17,tinsel: Transform Functions using Decorators,Instead of nesting function calls, annotate and transform 
    functions using "#." comments.
apdesign,2016-11-15,apdesign: An Implementation of the Additive Polynomial Design Matrix,An implementation of the additive polynomial (AP) design matrix. It
    constructs and appends an AP design matrix to a data frame for use with
    longitudinal data subject to seasonality.
colormap,2016-10-21,colormap: Color Palettes using Colormaps Node Module,Allows to generate colors from palettes defined in the colormap module of 'Node.js'. (see <https://github.com/bpostlethwaite/colormap> for more information). In total it provides 44 distinct palettes made from sequential and/or diverging colors. In addition to the pre defined palettes you can also specify your own set of colors. There are also scale functions that can be used with 'ggplot2'.
WEE,2016-11-15,WEE: Weighted Estimated Equation (WEE) Approaches in Genetic
Case-Control Studies,Secondary analysis of case-control studies using a weighted estimating equation (WEE) approach: logistic regression for binary secondary outcomes, linear regression and quantile regression for continuous secondary outcomes.
PhyInformR,2016-11-13,PhyInformR: Rapid Calculation of Phylogenetic Information Content,Enables rapid calculation of phylogenetic information content using the latest advances in phylogenetic informativeness based theory. These advances include modifications that incorporate uneven branch lengths and any model of nucleotide substitution to provide assessments of the phylogenetic utility of any given dataset or dataset partition. Also provides new tools for data visualization and routines optimized for rapid statistical calculations, including approaches making use of Bayesian posterior distributions and parallel processing. Users can apply these approaches toward screening datasets for phylogenetic/genomic information content.
CSclone,2016-11-12,CSclone: Bayesian Nonparametric Modeling in R,Germline and somatic locus data which contain the total read depth and B allele 
    read depth using Bayesian model (Dirichlet Process) to cluster. Meanwhile, the cluster 
    model can deal with the SNVs mutation and the CNAs mutation.
flock,2016-11-08,flock: Process Synchronization Using File Locks,Implements synchronization between R processes (spawned by using the "parallel" package for instance) using file locks. Supports both exclusive and shared locking.
jointNmix,2016-11-12,jointNmix: Joint N-Mixture Models for Site-Associated Species,Fits univariate and joint N-mixture models for data on two unmarked site-associated species. Includes functions to estimate latent abundances through empirical Bayes methods.
LEANR,2016-11-12,LEANR: Finds "Local Subnetworks" Within an Interaction Network which
Show Enrichment for Differentially Expressed Genes,Implements the method described in "Network-based analysis of omics data: The LEAN method" [Gwinner Boulday (2016) <doi:10.1093/bioinformatics/btw676>]
 Given a protein interaction network and a list of p-values describing a measure of interest (as e.g. differential gene expression) this method
 computes an enrichment p-value for the protein neighborhood of each gene and compares it to a background distribution of randomly drawn p-values.
 The resulting scores are corrected for multiple testing and significant hits are returned in tabular format.
Planesmuestra,2016-11-12,Planesmuestra: Functions for Calculating Dodge Romig, MIL STD 105E and MIL STD
414 Acceptance Sampling Plan,Calculates an acceptance sampling plan, (sample size and acceptance number) based in MIL STD 105E, Dodge  Romig and MIL STD 414 tables and procedures. The arguments for each function are related to lot size, inspection level and quality level. The specific plan operating curve (OC), is calculated by the binomial distribution.  
ptest,2016-11-12,ptest: Periodicity Tests in Short Time Series,Implements p-value computations using an approximation to the cumulative distribution function for a variety of tests for periodicity. These tests include harmonic regression tests with normal and double exponential errors as well as modifications of Fisher's g test. An accompanying vignette illustrates the application of these tests.
qiitr,2016-11-12,qiitr: R Interface to Qiita API,Qiita is a technical knowledge sharing and collaboration platform for programmers.
  See <https://qiita.com/api/v2/docs> for more information.
sparkline,2016-11-12,sparkline: 'jQuery' Sparkline 'htmlwidget',Include interactive sparkline charts
    <http://omnipotent.net/jquery.sparkline> in 
    all R contexts with the convenience of 'htmlwidgets'.  
XRSCC,2016-11-12,XRSCC: Statistical Quality Control Simulation,This is a set of statistical quality control functions,  that allows plotting control charts and its iterations, process capability for variable and attribute control, highlighting the xrs_gr() function, like a first iteration for variable chart, meanwhile the we_rules() function detects non random patterns in sample.
medfate,2016-11-09,medfate: Mediterranean Forest Simulation,Functions to simulate forest dynamics using cohort-based description of vegetation.
cthreshER,2016-11-10,cthreshER: Continuous Threshold Expectile Regression,Estimation and inference methods for the continuous threshold expectile regression.
    It can fit the continuous threshold expectile regression and test the existence of change point,
    for the paper, "Feipeng Zhang and Qunhua Li (2016). A continuous threshold expectile regression, submitted." 
exteriorMatch,2016-11-10,exteriorMatch: Constructs the Exterior Match from Two Matched Control Groups,If one treated group is matched to one control reservoir in two different ways to produce two sets of treated-control matched pairs, then the two control groups may be entwined, in the sense that some control individuals are in both control groups.  The exterior match is used to compare the two control groups.
RSIP,2016-11-10,RSIP: Remote Sensing and Image Processing,Makes  operations with raster images, such as map
    viewing in time series, export values in time series for specific, total or limited
    within a polygon locations. Makes data processing of remote sensing of climatic variables distributed in the space (maps 2D) and the time (time series).
HARtools,2016-11-09,HARtools: Read HTTP Archive ('HAR') Data,The goal of 'HARtools' is to provide a simple set of functions
    to read/parse, write and visualise HTTP Archive ('HAR') files in R.
horseshoe,2016-11-08,horseshoe: Implementation of the Horseshoe Prior,Contains functions for applying the horseshoe prior to high-
    dimensional linear regression, yielding the posterior mean and credible
    intervals, amongst other things. The key parameter tau can be equipped with
    a prior or estimated via maximum marginal likelihood estimation (MMLE).
    The main function, horseshoe, is for linear regression. In addition, there
    are functions specifically for the sparse normal means problem, allowing
    for faster computation of for example the posterior mean and posterior
    variance. Finally, there is a function available to perform variable
    selection, using either a form of thresholding, or credible intervals.
msaFACE,2016-11-08,msaFACE: Moving Subset Analysis FACE,The new methodology "moving subset analysis" provides functions to investigate the effect of environmental conditions on the CO2 fertilization effect within longterm free air carbon enrichment (FACE)  experiments. In general, the functionality is applicable to derive the influence of a third variable (forcing experiment-support variable) on the relation between a dependent and an independent variable.
pirate,2016-11-08,pirate: Generated Effect Modifier,An implementation of the generated effect modifier (GEM) method. This method constructs composite variables by linearly combining pre-treatment scalar patient characteristics to create optimal treatment effect modifiers in linear models. The optimal linear combination is called a GEM. Treatment is assumed to have been assigned at random. For reference, see E Petkova, T Tarpey, Z Su, and RT Ogden. Generated effect modifiers (GEMs) in randomized clinical trials. Biostatistics (First published online: July 27, 2016, <doi:10.1093/biostatistics/kxw035>).
rehh.data,2016-11-08,rehh.data: Data Only: Searching for Footprints of Selection using Haplotype
Homozygosity Based Tests,Contains example data for the 'rehh' package. 
wvtool,2016-11-08,wvtool: Image Tools for Automated Wood Identification,This tool, wood vision tool, is intended to facilitate preprocessing and analyzing 2-dimensional wood images toward automated recognition. The former includes some basics such as functions to RGB to grayscale, gray to binary, cropping, rotation(bilinear), median/mean/Gaussian filter, and Canny/Sobel edge detection. The latter includes gray level co-occurrence matrix (GLCM), Haralick parameters, local binary pattern (LBP), higher order local autocorrelation (HLAC), Fourier transform (radial and azimuthal integration), and Gabor filtering. The functions are intended to read data using  'readTIFF(x,info=T)' from 'tiff' package. The functions in this packages basically assumes the grayscale images as input data, thus the color images should be subjected to the function rgb2gray() before used for some other functions.
diffrprojectswidget,2016-11-07,diffrprojectswidget: Visualization for 'diffrprojects',Interactive visualizations and tabulations for diffrprojects. 
    All presentations are based on the htmlwidgets framework allowing for 
    interactivity via HTML and Javascript, Rstudio viewer integration, 
    RMarkdown integration, as well as Shiny compatibility. 
regtools,2016-11-07,regtools: Regression Tools,Tools for linear, nonlinear and nonparametric regression
             and classification.  Parametric fit assessment using
             nonparametric methods. One vs. All and All vs. All
             multiclass classification.  Nonparametric regression for
             general dimension, locally-linear option.  Nonlinear 
             regression with Eickert-White method for dealing with 
             heteroscedasticity, k-NN for general dimension and 
             general descriptive functions.
Rga4gh,2016-11-07,Rga4gh: An Interface to the GA4GH API,An Interface to the GA4GH API that allows users to easily GET responses and POST requests to
  GA4GH Servers. See <http://ga4gh.org> for more information about the GA4GH project.
starmie,2016-11-07,starmie: Population Structure Model Inference and Visualisation,Data structures and methods for  manipulating output of genetic population structure clustering algorithms.
  'starmie' can parse output from 'STRUCTURE' (see <https://pritchardlab.stanford.edu/structure.html> for details) or
  'ADMIXTURE' (see <https://www.genetics.ucla.edu/software/admixture/> for details). 'starmie' performs model selection via
  information criterion, and provides functions for MCMC diagnostics, correcting label switching and visualisation of admixture coefficients.
varband,2016-11-07,varband: Variable Banding of Large Precision Matrices,Implementation of the variable banding procedure for modeling local dependence and estimating precision matrices that is introduced in Yu & Bien (2016) and is available at <https://arxiv.org/abs/1604.07451>.
diffrprojects,2016-11-06,diffrprojects: Projects for Text Version Comparison and Analytics in R,Provides data structures and methods for measuring, coding, 
    and analysing text within text corpora. The package allows for manual as 
    well computer aided coding on character, token and text pair level. 
varSel,2016-11-05,varSel: Sequential Forward Floating Selection using Jeffries-Matusita
Distance,Feature selection using Sequential Forward Floating feature Selection and Jeffries-Matusita distance. It returns a suboptimal set of features to use for image classification. Reference: Dalponte, M., Oerka, H.O., Gobakken, T., Gianelle, D. & Naesset, E. (2013). Tree Species Classification in Boreal Forests With Hyperspectral Data. IEEE Transactions on Geoscience and Remote Sensing, 51, 2632-2645, <doi:10.1109/TGRS.2012.2216272>.
ordcrm,2016-11-04,ordcrm: Likelihood-Based Continual Reassessment Method (CRM) Dose
Finding Designs,Provides the setup and calculations needed
        to run a likelihood-based continual reassessment method (CRM)
        dose finding trial and performs simulations to assess design
        performance under various scenarios. 3 dose finding designs
        are included in this package: ordinal proportional odds model
        (POM) CRM, ordinal continuation ratio (CR) model CRM, and the
        binary 2-parameter logistic model CRM.
        These functions allow customization of design characteristics
        to vary sample size, cohort sizes, target dose-limiting
        toxicity (DLT) rates, discrete or continuous dose levels,
        combining ordinal grades 0 and 1 into one category, and
        incorporate safety and/or stopping rules.
        For POM and CR model designs, ordinal toxicity grades are
        specified by common terminology criteria for adverse events
        (CTCAE) version 4.0.
        Function 'pseudodata' creates the necessary starting models
        for these 3 designs, and function 'nextdose' estimates the
        next dose to test in a cohort of patients for a target DLT
        rate.
        We also provide the function 'crmsimulations' to assess the
        performance of these 3 dose finding designs under various
        scenarios.
packagedocs,2016-11-04,packagedocs: Build Website of Package Documentation,Build a package documentation and function reference site and use it as the package vignette.
MiRAnorm,2016-11-03,MiRAnorm: Adaptive Normalization for miRNA Data,An adaptive normalization algorithm that selects housekeeping genes
    based on the sample level variability in the data. This is suitable for any data
    obtained from RT-qPCR assays.  A manuscript describing the method is submitted 
    to Genome Biology under “MiRA-norm: An Adaptive Method for the Normalization of MicroRNA Array Data“, Yuda Zhu et al.
rtext,2016-11-01,rtext: R6 Objects for Text and Data,For natural language processing and analysis of qualitative text
    coding structures which provide a way to bind together text and text data
    are fundamental. The package provides such a structure and accompanying
    methods in form of R6 objects. The 'rtext' class allows for text handling
    and text coding (character or regex based) including data updates on
    text transformations as well as aggregation on various levels.
    Furthermore, the usage of R6 enables inheritance and passing by reference
    which should enable 'rtext' instances to be used as back-end for R based
    graphical text editors or text coding GUIs.
stringb,2016-10-31,stringb: Convenient Base R String Handling,Base R already ships with string handling capabilities 'out-
    of-the-box' but lacks streamlined function names and workflow. The
    'stringi' ('stringr') package on the other hand has well named functions,
    extensive Unicode support and allows for a streamlined workflow. On the other
    hand it adds dependencies and regular expression interpretation between base R
    functions and 'stringi' functions might differ. This packages aims at providing
    a solution to the use case of unwanted dependencies on the one hand but the need
    for streamlined text processing on the other. The packages' functions are solely
    based on wrapping base R functions into 'stringr'/'stringi' like function names.
    Along the way it adds one or two extra functions and last but not least provides
    all functions as generics, therefore allowing for adding methods for other text
    structures besides plain character vectors.
rRAP,2016-10-09,rRAP: Real-Time Adaptive Penalization for Streaming Lasso Models,An implementation of the Real-time Adaptive Penalization (RAP) algorithm through which to iteratively update a regularization parameter in a streaming context.  
AdjBQR,2016-10-30,AdjBQR: Adjusted Bayesian Quantile Regression Inference,Adjusted inference for Bayesian quantile regression based on
    asymmetric Laplace working likelihood, for details see Yang, Y., Wang, H.
    and He, X. (2015), Posterior inference in Bayesian quantile regression with
    asymmetric Laplace likelihood, International Statistical 
    Review, 2015 <doi:10.1111/insr.12114>.
gtheory,2016-10-30,gtheory: Apply Generalizability Theory with R,Estimates variance components, generalizability coefficients,
    universe scores, and standard errors when observed scores contain variation from
    one or more measurement facets (e.g., items and raters).
mhtboot,2016-10-30,mhtboot: Multiple Hypothesis Test Based on Distribution of p Values,A framework for multiple hypothesis testing based on distribution
    of p values. It is well known that the p values come from different
    distribution for null and alternatives, in this package we provide
    functions to detect that change. We provide a method for using the change
    in distribution of p values as a way to detect the true signals in the
    data.
RDota2,2016-10-30,RDota2: An R Steam API Client for Valve's Dota2,An R API Client for Valve's Dota2. RDota2 can be easily used 
    to connect to the Steam API and retrieve data for Valve's popular video 
    game Dota2. You can find out more about Dota2 at 
    <http://store.steampowered.com/app/570/>.
rgeoapi,2016-10-30,rgeoapi: Get Information from the GeoAPI,Provides access to information from 
        <https://api.gouv.fr/explorer/geoapi/> about French 
        "Communes", "Departements" and "Regions".
endogenous,2016-10-29,endogenous: Classical Simultaneous Equation Models,Likelihood-based approaches to estimate linear regression parameters and treatment effects in the presence of endogeneity. Specifically, this package includes James Heckman's classical simultaneous equation models-the sample selection model for outcome selection bias and hybrid model with structural shift for endogenous treatment. For more information, see the seminal paper of Heckman (1978) <doi:10.3386/w0177> in which the details of these models are provided. This package accommodates repeated measures on subjects with a working independence approach. The hybrid model further accommodates treatment effect modification.
spftir,2016-10-29,spftir: Pre-Processing and Analysis of Mid-Infrared Spectral Region,Functions to manipulate, pre-process and analyze spectra in the mid-infrared region. The pre-processing of the mid-infrared spectra is a transcendental step in the spectral analysis. Preprocessing of the spectra includes smoothing, offset, baseline correction, and normalization,  is performed before the analysis of the spectra and is essential to obtain conclusive results in subsequent quantitative or qualitative analysis. This package was supported by FONDECYT 3150630, and CIPA Conicyt-Regional R08C1002 is gratefully acknowledged.
triangulation,2016-10-29,triangulation: Determine Position of Observer,Measuring angles between points in a landscape is much easier
    than measuring distances. When the location of three points is known the
    position of the observer can be determined based solely on the angles between
    these points as seen by the observer. This task (known as triangulation)
    however requires onerous calculations - these calculations are automated by this
    package.
MIDN,2016-10-28,MIDN: Nearly Exact Sample Size Calculation for Exact Powerful
Nonrandomized Tests for Differences Between Binomial
Proportions,Implementation of the mid-n algorithms presented in 
             Wellek S (2015) <doi:10.1111/stan.12063> Statistica Neerlandica 69, 358-373 for exact 
             sample size calculation for superiority trials with binary outcome.
spellcheckr,2016-10-28,spellcheckr: Correct the Spelling of a Given Word in the English Language,Corrects the spelling of a given word in English 
    using a modification of Peter Norvig's spell correct 
    algorithm (see <http://norvig.com/spell-correct.html>) 
    which handles up to three edits. The algorithm tries to 
    find the spelling with maximum probability of intended
    correction out of all possible candidate corrections from
    the original word.
fizzbuzzR,2016-10-27,fizzbuzzR: Fizz Buzz Implementation,An implementation of the Fizz Buzz algorithm, as defined e.g. in <https://en.wikipedia.org/wiki/Fizz_buzz>. 
    It provides the standard algorithm with 3 replaced by Fizz and 5 replaced by Buzz, with the option of specifying start 
    and end numbers, step size and the numbers being replaced by fizz and buzz, respectively. This package gives 
    interviewers the optional answer of "I use fizzbuzzR::fizzbuzz()" when interviewing rather than having to write an algorithm
    themselves.
countyweather,2016-10-26,countyweather: Compiles Meterological Data for U.S. Counties,Interacts with NOAA data sources (including the NCDC API at
  <http://www.ncdc.noaa.gov/cdo-web/webservices/v2> and ISD data) using
  functions from the 'rnoaa' package to obtain and compile weather time
  series for U.S. counties. This work was supported in part by grants from the
  National Institute of Environmental Health Sciences (R00ES022631) and the
  Colorado State University Water Center.
IRATER,2016-10-26,IRATER: A R Interface for the Instantaneous RATEs (IRATE) Model,A R interface to setup, run and read IRATE model runs to assess band recovery (conventional tagging) data (i.e. age-dependent or independent fishing and natural mortality rates).
gym,2016-10-25,gym: Provides Access to the OpenAI Gym API,OpenAI Gym is a open-source Python toolkit for developing and comparing
    reinforcement learning algorithms. This is a wrapper for the OpenAI Gym API,
    and enables access to an ever-growing variety of environments.
    For more details on OpenAI Gym, please see here: <https://github.com/openai/gym>.
    For more details on the OpenAI Gym API specification, please see here:
    <https://github.com/openai/gym-http-api>.
ABC.RAP,2016-10-20,ABC.RAP: Array Based CpG Region Analysis Pipeline,It aims to identify candidate genes that are “differentially
    methylated” between cases and controls. It applies Student’s t-test and delta beta analysis to
    identify candidate genes containing multiple “CpG sites”.
corlink,2016-10-20,corlink: Record Linkage, Incorporating Imputation for Missing Agreement
Patterns, and Modeling Correlation Patterns Between Fields,A matrix of agreement patterns and counts for record pairs is the input for the procedure.  An EM algorithm is used to impute plausible values for missing record pairs.  A second EM algorithm, incorporating possible correlations between per-field agreement, is used to estimate posterior probabilities that each pair is a true match - i.e. constitutes the same individual.
ggloop,2016-10-20,ggloop: Create 'ggplot2' Plots in a Loop,Pass a data frame and mapping aesthetics to ggloop() in order
    to create a list of 'ggplot2' plots. The way x-y and dots are paired together
    is controlled by the remapping arguments. Geoms, themes, facets, and other
    features can be added with the special %L+% (L-plus) operator.
MullerPlot,2016-10-20,MullerPlot: Generates Muller Plot from Population/Abundance/Frequency
Dynamics Data,Generates Muller plot from parental/genealogy/phylogeny information and population/abundance/frequency dynamics data.
    Muller plots are plots which combine information about succession of different OTUs (genotypes, phenotypes, species, ...) and information about dynamics of their abundances (populations or frequencies) over time. They are powerful and fascinating tools to visualize evolutionary dynamics. They may be employed also in study of diversity and its dynamics, i.e. how diversity emerges and how changes over time. They are called Muller plots in honor of Hermann Joseph Muller which used them to explain his idea of Muller's ratchet (Muller, 1932, American Naturalist).
    A big difference between Muller plots and normal box plots of abundances is that a Muller plot depicts not only the relative abundances but also succession of OTUs based on their genealogy/phylogeny/parental relation. In a Muller plot, horizontal axis is time/generations and vertical axis represents relative abundances of OTUs at the corresponding times/generations. Different OTUs are usually shown with polygons with different colors and each OTU originates somewhere in the middle of its parent area in order to illustrate their succession in evolutionary process.
    To generate a Muller plot one needs the genealogy/phylogeny/parental relation of OTUs and their abundances over time.
    MullerPlot package has the tools to generate Muller plots which clearly depict the origin of successors of OTUs.
validatejsonr,2016-10-20,validatejsonr: Validate JSON Against JSON Schemas,The current implementation uses the C++ library 'RapidJSON' to supply the schema functionality, it supports JSON Schema Draft v4. As of 2016-09-09, 'RapidJSON' passed 262 out of 263 tests in JSON Schema Test Suite (JSON Schema draft 4).
PCSinR,2016-10-19,PCSinR: Parallel Constraint Satisfaction Networks in R,Parallel Constraint Satisfaction (PCS) models are an increasingly
    common class of models in Psychology, with applications to reading and word
    recognition (McClelland & Rumelhart, 1981), judgment and decision making
    (Glöckner & Betsch, 2008; Glöckner, Hilbig, & Jekel, 2014), and several
    other fields (e.g. Read, Vanman, & Miller, 1997). In each of these fields,
    they provide a quantitative model of psychological phenomena, with precise
    predictions regarding choice probabilities, decision times, and often the degree
    of confidence. This package provides the necessary functions to create and
    simulate basic Parallel Constraint Satisfaction networks within R.
cryst,2016-10-18,cryst: Calculate the Relative Crystallinity of Starch by XRD and FTIR,Functions to calculate the relative crystallinity of starch by X-ray Diffraction (XRD) and Infrared Spectroscopy (FTIR). Starch is biosynthesized by plants in the form of granules semicrystalline. For XRD, the relative crystallinity is obtained by separating the crystalline peaks from the amorphous scattering region. For FTIR, the relative crystallinity is achieved by setting of a Gaussian holocrystalline-peak in the 800-1300 cm-1 region of FTIR spectrum of starch which is divided into amorphous region and crystalline region. The relative crystallinity of native starch granules varies from 14 of 45 percent. This package was supported by FONDECYT 3150630 and CIPA Conicyt-Regional R08C1002 is gratefully acknowledged.
TDPanalysis,2016-10-18,TDPanalysis: Granier's Sap Flow Sensors (TDP) Analysis,Set of functions designed to help in the
    analysis of TDP sensors. Features includes dates and time conversion, weather
    data interpolation, daily maximum of tension analysis and calculations required
    to convert sap flow density data to sap flow rates at the tree and plot scale (For more information see : Granier (1985) <doi:10.1051/forest:19850204> & Granier (1987) <doi:10.1093/treephys/3.4.309>).
GraphFactor,2016-10-17,GraphFactor: Network Topology of Intravariable Clusters with Intervariable
Links,A Network Implementation of Fuzzy Sets: Build Network Objects from Multivariate Flat Files. For more information on fuzzy sets, refer to: Zadeh, L.A. (1964) <doi:10.1016/S0019-9958(65)90241-X>.
KnapsackSampling,2016-10-16,KnapsackSampling: Generate Feasible Samples of a Knapsack Problem,The sampl.mcmc() function creates samples of the feasible region of a knapsack problem with both equalities and inequalities constraints.
fontLiberation,2016-10-15,fontLiberation: Liberation Fonts,A placeholder for the Liberation fontset intended for the
    'fontquiver' package. This fontset covers the 12 combinations of
    families (sans, serif, mono) and faces (plain, bold, italic, bold
    italic) supported in R graphics devices.
RSarules,2016-10-15,RSarules: Random Sampling Association Rules from a Transaction Dataset,Implements the Gibbs sampling algorithm to randomly sample association rules with one pre-chosen item as the consequent from a transaction dataset. The Gibbs sampling algorithm was proposed in G. Qian, C.R. Rao, X. Sun and Y. Wu (2016) <doi:10.1073/pnas.1604553113>. 
types,2016-10-15,types: Type Annotations,Provides a simple type annotation for R that is usable in scripts,
    in the R console and in packages. It is intended as a convention to allow other
    packages to use the type information to provide error checking,
    automatic documentation or optimizations.
dbfaker,2016-10-14,dbfaker: A Tool to Ensure the Validity of Database Writes,A tool to ensure the validity of database writes.
  It provides a set of utilities to analyze and type check the properties
  of data frames that are to be written to databases with SQL support.
ISR3,2016-10-14,ISR3: Iterative Sequential Regression,Performs multivariate normal imputation through iterative sequential 
  regression.  Conditional dependency structure between imputed variables can be 
  specified a priori to accelerate imputation.
scan,2016-10-14,scan: Single-Case Data Analyses for Single and Multiple AB Designs,A collection of procedures for analysing single-case data of an AB-design. Some procedures support multiple-baseline designs.
convertr,2016-10-13,convertr: Convert Between Units,Provides conversion functionality between a broad range of
    scientific, historical, and industrial unit types.
MethodCompare,2016-10-12,MethodCompare: Bias and Precision Plots to Compare Two Measurements with
Possibly Heteroscedastic Measurement Errors,Implementation of the methodology from the paper titled
    "Effective plots to assess bias and precision in method comparison studies"
    published in Statistical Methods in Medical Research, P. Taffe (2016) <doi:10.1177/0962280216666667>.
exp2flux,2016-10-11,exp2flux: Convert Gene EXPression Data to FBA FLUXes,For a given metabolic model with well formed Gene-Protein-Reaction (GPR) associations and an expressionSet with their associated gene expression values, this package converts gene expression values to the FBA boundaries for each reaction based in the boolean rules described in its associated GPR.
haploReconstruct,2016-10-10,haploReconstruct: Reconstruction of Haplotype-Blocks from Time Series Data,Reconstruction of founder haplotype blocks from time series data.
rgw,2016-10-10,rgw: Goodman-Weare Affine-Invariant Sampling,Implementation of the affine-invariant method of Goodman & Weare (2010) <doi:10.2140/camcos.2010.5.65>, a method of producing Monte-Carlo samples from a target distribution.
valorate,2016-10-02,valorate: Velocity and Accuracy of the LOg-RAnk TEst,The algorithm implemented in this package was
    designed to quickly estimates the distribution of the 
    log-rank especially for heavy unbalanced groups. VALORATE 
    estimates the null distribution and the p-value of the 
    log-rank test based on a recent formulation. For a given 
    number of alterations that define the size of survival 
    groups, the estimation involves a weighted sum of 
    distributions that are conditional on a co-occurrence term 
    where mutations and events are both present. The estimation 
    of conditional distributions is quite fast allowing the 
    analysis of large datasets in few minutes 
    <http://bioinformatica.mty.itesm.mx/valorate>.
ptwikiwords,2016-10-08,ptwikiwords: Words Used in Portuguese Wikipedia,Contains a dataset of words used in 15.000 randomly extracted pages
    from the Portuguese Wikipedia (<https://pt.wikipedia.org/>).
sharpeRratio,2016-10-07,sharpeRratio: Moment-Free Estimation of Sharpe Ratios,An efficient moment-free estimator of the Sharpe ratio, or signal-to-noise ratio, for heavy-tailed data (see <https://arxiv.org/abs/1505.01333>).
tsSelect,2016-10-06,tsSelect: Execution of Time Series Models,Execution of various time series models and choosing the best one
    either by a specific error metric or by picking the best one by majority vote.
    The models are based on the "forecast" package, written by Prof. Rob Hyndman.
sAIC,2016-10-05,sAIC: Akaike Information Criterion for Sparse Estimation,Computes the Akaike information criterion for the generalized linear models (logistic regression, Poisson regression, and Gaussian graphical models) estimated by the lasso. 
ordDisp,2016-10-04,ordDisp: Separating Location and Dispersion in Ordinal Regression Models,Estimate location-shift models or rating-scale models accounting for response styles (RSRS) for the regression analysis of ordinal responses.
EBASS,2016-10-02,EBASS: Sample Size Calculation Method for Cost-Effectiveness Studies
Based on Expected Value of Perfect Information,We propose a new sample size calculation method for trial-based
    cost-effectiveness analyses. Our strategy is based on the value of perfect
    information that would remain after the completion of the study.
fixedTimeEvents,2016-10-02,fixedTimeEvents: The Distribution of Distances Between Discrete Events in Fixed
Time,Distribution functions and test for over-representation of short
    distances in the Liland distribution. Simulation functions are included for
    comparison.
expandFunctions,2016-10-01,expandFunctions: Feature Matrix Builder,Generates feature matrix outputs from R object inputs
    using a variety of expansion functions.  The generated
    feature matrices have applications as inputs
    for a variety of machine learning algorithms.
    The expansion functions are based on coercing the input
    to a matrix, treating the columns as features and
    converting individual columns or combinations into blocks of
    columns.
    Currently these include expansion of columns by
    efficient sparse embedding by vectors of lags,
    quadratic expansion into squares and unique products,
    powers by vectors of degree,
    vectors of orthogonal polynomials functions,
    and block random affine projection transformations (RAPTs).
    The transformations are
    magrittr- and cbind-friendly, and can be used in a
    building block fashion.  For instance, taking the cos() of
    the output of the RAPT transformation generates a
    stationary kernel expansion via Bochner's theorem, and this
    expansion can then be cbind-ed with other features.
    Additionally, there are utilities for replacing features,
    removing rows with NAs,
    creating matrix samples of a given distribution,
    a simple wrapper for LASSO with CV,
    a Freeman-Tukey transform,
    generalizations of the outer function,
    matrix size-preserving discrete difference by row,
    plotting, etc.
sBIC,2016-10-01,sBIC: Computing the Singular BIC for Multiple Models,Computes the sBIC for various singular model collections including:
    binomial mixtures, factor analysis models, Gaussian mixtures,
    latent forests, latent class analyses, and reduced rank regressions.
